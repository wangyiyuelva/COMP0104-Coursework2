msg, files, lines, committer_date, 'modified_files'
Initial public release.,404,88984,2017-12-18 16:25:08-08:00,"['LICENSE', 'NOTICE', 'README.md', 'AppendFiles.java', 'CombinedScanTask.java', 'DataFile.java', 'DeleteFiles.java', 'ExpireSnapshots.java', 'FileFormat.java', 'FileScanTask.java', 'Files.java', 'Filterable.java', 'FilteredSnapshot.java', 'Metrics.java', 'PartitionField.java', 'PartitionSpec.java', 'PendingUpdate.java', 'RewriteFiles.java', 'Rollback.java', 'ScanTask.java', 'Schema.java', 'Snapshot.java', 'SnapshotIterable.java', 'StructLike.java', 'Table.java', 'TableScan.java', 'Tables.java', 'UpdateProperties.java', 'UpdateSchema.java', 'AlreadyExistsException.java', 'CommitFailedException.java', 'NoSuchTableException.java', 'RuntimeIOException.java', 'ValidationException.java', 'And.java', 'Binder.java', 'BoundPredicate.java', 'BoundReference.java', 'Evaluator.java', 'Expression.java', 'ExpressionVisitors.java', 'Expressions.java', 'False.java', 'Literal.java', 'Literals.java', 'NamedReference.java', 'Not.java', 'Or.java', 'Predicate.java', 'Projections.java', 'Reference.java', 'ResidualEvaluator.java', 'RewriteNot.java', 'SerializationProxies.java', 'True.java', 'UnboundPredicate.java', 'DelegatingInputStream.java', 'DelegatingOutputStream.java', 'FileAppender.java', 'InputFile.java', 'OutputFile.java', 'PositionOutputStream.java', 'SeekableInputStream.java', 'Bucket.java', 'Dates.java', 'Identity.java', 'ProjectionUtil.java', 'SerializationProxies.java', 'Timestamps.java', 'Transform.java', 'Transforms.java', 'Truncate.java', 'Comparators.java', 'Conversions.java', 'GetProjectedIds.java', 'IndexById.java', 'IndexByName.java', 'PrimitiveHolder.java', 'PruneColumns.java', 'ReassignIds.java', 'Type.java', 'TypeUtil.java', 'Types.java', 'TestHelpers.java', 'TestEvaluatior.java', 'TestExpressionBinding.java', 'TestExpressionHelpers.java', 'TestExpressionSerialization.java', 'TestLiteralSerialization.java', 'TestMiscLiteralConversions.java', 'TestNumericLiteralConversions.java', 'TestPredicateBinding.java', 'TestStringLiteralConversions.java', 'TestBucketing.java', 'TestProjection.java', 'TestResiduals.java', 'TestTransformSerialization.java', 'TestTruncate.java', 'TestBinaryComparator.java', 'TestCharSeqComparator.java', 'TestComparableComparator.java', 'TestSerializableTypes.java', 'Avro.java', 'AvroCustomOrderSchemaVisitor.java', 'AvroFileAppender.java', 'AvroIO.java', 'AvroIterable.java', 'AvroSchemaUtil.java', 'AvroSchemaVisitor.java', 'BuildAvroProjection.java', 'ProjectionDatumReader.java', 'PruneColumns.java', 'SchemaToType.java', 'TypeToSchema.java', 'UUIDConversion.java', 'AvroTestHelpers.java', 'TestAvroReadProjection.java', 'TestReadProjection.java', 'TestSchemaConversions.java', 'build.gradle', 'DynClasses.java', 'DynConstructors.java', 'DynFields.java', 'DynMethods.java', 'BaseFileScanTask.java', 'BaseSnapshot.java', 'BaseTable.java', 'BaseTableScan.java', 'DataFiles.java', 'FastAppend.java', 'FilteredManifest.java', 'GenericDataFile.java', 'ManifestEntry.java', 'ManifestReader.java', 'ManifestWriter.java', 'MergeAppend.java', 'PartitionData.java', 'PartitionSpecParser.java', 'PropertiesUpdate.java', 'RemoveSnapshots.java', 'ReplaceFiles.java', 'RollbackToSnapshot.java', 'SchemaParser.java', 'SchemaUpdate.java', 'SnapshotParser.java', 'SnapshotUpdate.java', 'StreamingDelete.java', 'TableMetadata.java', 'TableMetadataParser.java', 'TableOperations.java', 'TableProperties.java', 'HadoopInputFile.java', 'HadoopOutputFile.java', 'HadoopStreams.java', 'HadoopTableOperations.java', 'HadoopTables.java', 'Util.java', 'CharSequenceWrapper.java', 'Exceptions.java', 'JsonUtil.java', 'Pair.java', 'Tasks.java', 'AssertHelpers.java', 'TableTestBase.java', 'TestFastAppend.java', 'TestMergeAppend.java', 'TestSchemaUpdate.java', 'TestSnapshotJson.java', 'TestTableMetadataJson.java', 'TestTables.java', 'HadoopTableTestBase.java', 'TestHadoopCommits.java', 'allclasses-frame.html', 'allclasses-noframe.html', 'AppendFiles.html', 'BaseTable.html', 'CombinedScanTask.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DeleteFiles.html', 'ExpireSnapshots.html', 'FileFormat.html', 'FileScanTask.html', 'Files.html', 'Filterable.html', 'FilteredManifest.html', 'FilteredSnapshot.html', 'ManifestReader.html', 'Metrics.html', 'PartitionField.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'PendingUpdate.html', 'RewriteFiles.html', 'Rollback.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'Snapshot.html', 'SnapshotParser.html', 'StructLike.html', 'Table.html', 'TableMetadata.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableScan.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroIterable.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CommitFailedException.html', 'NoSuchTableException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'BoundPredicate.html', 'BoundReference.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'Literal.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'True.html', 'UnboundPredicate.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTables.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'FileAppender.html', 'InputFile.html', 'OutputFile.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetMetrics.html', 'ParquetSchemaUtil.html', 'ParquetWriteAdapter.html', 'TypeToMessageType.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PruneColumns.html', 'SparkDataFile.html', 'SparkFilters.html', 'SparkSchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSource.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Transform.html', 'Transforms.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Comparators.html', 'Conversions.html', 'IndexByName.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CharSequenceWrapper.html', 'Exceptions.html', 'JsonUtil.html', 'Pair.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'constant-values.html', 'deprecated-list.html', 'help-doc.html', 'index-all.html', 'index.html', 'overview-frame.html', 'overview-summary.html', 'overview-tree.html', 'package-list', 'script.js', 'serialized-form.html', 'stylesheet.css', 'MessageTypeToType.java', 'Parquet.java', 'ParquetFilters.java', 'ParquetIO.java', 'ParquetIterable.java', 'ParquetMetrics.java', 'ParquetReadSupport.java', 'ParquetSchemaUtil.java', 'ParquetTypeVisitor.java', 'ParquetWriteAdapter.java', 'ParquetWriteSupport.java', 'PruneColumns.java', 'TypeToMessageType.java', 'TestParquetReadProjection.java', 'TestReadProjection.java', 'settings.gradle', 'PruneColumns.java', 'SparkDataFile.java', 'SparkFilters.java', 'SparkSchemaUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'TypeToSparkType.java', 'SparkAvroReader.java', 'ValueReader.java', 'ValueReaders.java', 'Hive.java', 'IcebergSource.java', 'org.apache.spark.sql.sources.DataSourceRegister', 'SparkTableUtil.scala', 'RandomData.java', 'TestSparkAvroReader.java']"
"Add test for reading Avro files from Spark.

This also fixes some bugs and updates data generation to be valid for
Spark. Decimal generation was producing values larger than the
precision.",13,1000,2017-12-20 13:20:47-08:00,"['BuildAvroProjection.java', 'SchemaToType.java', 'UUIDConversion.java', 'TestSchemaConversions.java', 'StreamingDelete.java', 'UnsafeTransform.scala', 'IcebergSource.java', 'AvroDataTest.java', 'RandomData.java', 'TestHelpers.java', 'TestSparkAvroReader.java', 'TestSparkDateTimes.java', 'TestAvroScan.java']"
"Update Schema API to use ""find"" instead of ""get"".

Find is a better name because the fields may be nested anywhere in the
Schema.",9,66,2017-12-20 13:20:47-08:00,"['PartitionSpec.java', 'Schema.java', 'UpdateSchema.java', 'SchemaUpdate.java', 'TableMetadata.java', 'TestSchemaUpdate.java', 'ParquetFilters.java', 'ParquetSchemaUtil.java', 'TypeToMessageType.java']"
"Add test for Spark scan of Parquet data.

This fixes a couple of bugs, but tests are not passing because Spark
doesn't support INT64 timestamps and Parquet doesn't support UUID.",5,179,2017-12-20 13:20:47-08:00,"['MessageTypeToType.java', 'Parquet.java', 'ParquetIterable.java', 'ParquetTypeVisitor.java', 'TestParquetScan.java']"
Refactor Spark source.,5,617,2017-12-22 11:35:16-08:00,"['DynMethods.java', 'IcebergSource.java', 'Reader.java', 'Stats.java', 'SparkTableUtil.scala']"
Move TestParquetScan into source tests.,1,0,2017-12-22 11:35:16-08:00,['TestParquetScan.java']
Add properties accessor to Table API.,2,15,2017-12-22 11:35:16-08:00,"['Table.java', 'BaseTable.java']"
"Add PartitionSpec.partitionToPath and Transform.toHumanString.

To help implementations construct data file paths, the new
partitionToPath method creates a human-readable String from partition
data. These strings are not intended to be used like Hive's partition
keys. These should never be parsed to recover partition data.",13,630,2017-12-22 11:35:16-08:00,"['PartitionSpec.java', 'Dates.java', 'Identity.java', 'SerializationProxies.java', 'Timestamps.java', 'Transform.java', 'TransformUtil.java', 'Transforms.java', 'Truncate.java', 'TestPartitionPaths.java', 'TestDates.java', 'TestIdentity.java', 'TestTimestamps.java']"
"Add default format table property, make TableProperties public.",1,5,2017-12-22 11:35:16-08:00,['TableProperties.java']
"Fix Spark conversion.

The visitor API maintains a stack of field names, so the TypeToSparkType
class cannot be shared between threads. Each conversion should create a
new one.",2,12,2017-12-22 11:35:16-08:00,"['SparkSchemaUtil.java', 'TypeToSparkType.java']"
Use PartitionSpec.unpartitioned() in Spark tests.,2,29,2017-12-22 11:35:16-08:00,"['TestAvroScan.java', 'TestParquetScan.java']"
Add write support to Spark.,4,887,2017-12-22 12:09:33-08:00,"['IcebergSource.java', 'PartitionKey.java', 'Writer.java', 'TestParquetWrite.java']"
"Make Avro id access methods public, add function to create DatumReaders.",6,55,2017-12-22 12:09:33-08:00,"['Avro.java', 'AvroFileAppender.java', 'AvroSchemaUtil.java', 'BuildAvroProjection.java', 'PruneColumns.java', 'SchemaToType.java']"
Implement Avro write path for Spark source.,9,818,2017-12-22 12:09:58-08:00,"['LICENSE', 'NOTICE', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'ValueWriter.java', 'ValueWriters.java', 'Reader.java', 'Writer.java', 'TestDataFrameWrites.java']"
"Fix Parquet writes.

Timestamps now work, but UUID and Fixed are not implemented by Spark's
write support.",2,5,2017-12-22 12:09:58-08:00,"['Writer.java', 'AvroDataTest.java']"
Update build.gradle for 0.1.3.,1,26,2017-12-22 12:09:58-08:00,['build.gradle']
Update TestAvroWrite for Spark 2.3.0.,1,2,2017-12-22 12:09:58-08:00,['TestDataFrameWrites.java']
Minor updates to Parquet and tests.,4,25,2018-01-02 12:06:52-08:00,"['Parquet.java', 'ParquetIterable.java', 'ParquetTypeVisitor.java', 'TestDataFrameWrites.java']"
Update TestParquetWrite to test partitioning.,1,6,2018-01-02 12:15:58-08:00,['TestParquetWrite.java']
Remove decimal types that are not working with Spark 2.3.0.,1,4,2018-01-02 12:15:58-08:00,['AvroDataTest.java']
Add base class for metastore tables.,2,182,2018-01-03 14:00:48-08:00,"['BaseMetastoreTableOperations.java', 'HadoopTables.java']"
Add location to table metadata.,7,53,2018-01-03 14:34:22-08:00,"['BaseMetastoreTableOperations.java', 'TableMetadata.java', 'TableMetadataParser.java', 'HadoopTables.java', 'TestMergeAppend.java', 'TestTableMetadataJson.java', 'TestTables.java']"
Add base class for metastore tables.,1,65,2018-01-03 14:36:49-08:00,['BaseMetastoreTables.java']
Expose table base location in Table interface.,3,15,2018-01-04 10:40:41-08:00,"['Table.java', 'BaseTable.java', 'TableMetadata.java']"
Add TestIcebergSource and allow IcebergSource subclasses.,5,301,2018-01-04 10:40:41-08:00,"['IcebergSource.java', 'Reader.java', 'Writer.java', 'TestIcebergSource.java', 'TestTables.java']"
Add Avro projection test and fix reordered columns.,3,868,2018-01-04 10:40:41-08:00,"['ValueReaders.java', 'TestReadProjection.java', 'TestSparkReadProjection.java']"
Update Javadocs.,215,7061,2018-01-04 10:46:12-08:00,"['allclasses-frame.html', 'allclasses-noframe.html', 'AppendFiles.html', 'BaseMetastoreTableOperations.html', 'BaseMetastoreTables.html', 'BaseTable.html', 'CombinedScanTask.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DeleteFiles.html', 'ExpireSnapshots.html', 'FileFormat.html', 'FileScanTask.html', 'Files.html', 'Filterable.html', 'FilteredManifest.html', 'FilteredSnapshot.html', 'ManifestReader.html', 'Metrics.html', 'PartitionField.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'PendingUpdate.html', 'RewriteFiles.html', 'Rollback.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'Snapshot.html', 'SnapshotParser.html', 'StructLike.html', 'Table.html', 'TableMetadata.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableProperties.html', 'TableScan.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroIterable.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'UUIDConversion.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CommitFailedException.html', 'NoSuchTableException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'BoundPredicate.html', 'BoundReference.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'Literal.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'True.html', 'UnboundPredicate.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTables.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'FileAppender.html', 'InputFile.html', 'OutputFile.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetIterable.html', 'ParquetMetrics.html', 'ParquetSchemaUtil.html', 'ParquetTypeVisitor.html', 'ParquetWriteAdapter.html', 'TypeToMessageType.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PruneColumns.html', 'SparkDataFile.html', 'SparkFilters.html', 'SparkSchemaUtil.html', 'SparkAvroReader.html', 'SparkAvroWriter.html', 'ValueReader.html', 'ValueWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Hive.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSource.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Transform.html', 'Transforms.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Comparators.html', 'Conversions.html', 'IndexByName.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CharSequenceWrapper.html', 'Exceptions.html', 'JsonUtil.html', 'Pair.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'constant-values.html', 'deprecated-list.html', 'help-doc.html', 'index-all.html', 'index.html', 'overview-frame.html', 'overview-summary.html', 'overview-tree.html', 'package-list', 'serialized-form.html']"
Update README build requirements.,1,4,2018-01-04 10:54:38-08:00,['README.md']
Add google group to README.,1,3,2018-01-04 11:15:05-08:00,['README.md']
Evaluate residuals when reading Avro files.,2,169,2018-01-05 15:34:12-08:00,"['SparkFilters.java', 'Reader.java']"
Test Spark filtered scans.,4,451,2018-01-08 13:59:06-08:00,"['BaseTable.java', 'MessageTypeToType.java', 'SparkFilters.java', 'TestFilteredScan.java']"
"Fix Spark filtering by unprojected columns.

Spark does not request filter columns that are handled by the data
source. However, Spark's Parquet read support cannot handle extra
columns that are not projected, nor reordered columns.

In order to request the filter columns that are not projected from the
Parquet file, or certain schemas with reordered columns, the data source
must return a schema that doesn't match the requested Schema:

* Filter columns must be projected even if not requested by Spark
* Reordered columns must be projected in the file's order

Because the order must match the file, files must all use the same
column order. Currently, this is okay because schema evolution does not
expose a way to reorder columns. This may break on existing data files
that used different column orders.",8,515,2018-01-09 13:00:24-08:00,"['Binder.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'SparkSchemaUtil.java', 'Reader.java', 'TestFilteredScan.java', 'TestReadProjection.java', 'TestSparkReadProjection.java']"
Update Spark utils and add a table conversion notebook.,4,446,2018-01-10 10:08:12-08:00,"['DataFiles.java', 'Convert table to Iceberg.ipynb', 'Hive.java', 'SparkTableUtil.scala']"
Fix path bug in BaseMetastoreTableOperations.,1,4,2018-01-10 10:38:40-08:00,['BaseMetastoreTableOperations.java']
Add selectNot and join TypeUtil methods.,1,13,2018-01-12 13:25:54-08:00,['TypeUtil.java']
"Add partition spec to FileScanTask.

This is needed to use the partition tuple in the task's DataFile.",5,74,2018-01-12 13:25:54-08:00,"['FileScanTask.java', 'BaseFileScanTask.java', 'BaseTableScan.java', 'PartitionSpecParser.java', 'SchemaParser.java']"
Fix unclosed Parquet files from ParquetIterable.,1,4,2018-01-12 13:25:54-08:00,['ParquetIterable.java']
"Spark: Handle identity partition data when reading.

This commit adds support for identity partitions, where data must be
joined from a file's partition tuple to the final row. When identity
partition columns are projected, the Spark reader will split the
requested schema in two, one with columns from the file and one for the
partition data columns. To ensure the final columns are in the correct
order, this adds an unsafe projection to the requested column order.

This also updates handling for filter columns that are not projected.
Before this commit, filter columns that are not required by Spark were
added to the output rows anyway. Now, filter columns are removed by the
final unsafe projection, but are still loaded from the file for filters
to work.",3,321,2018-01-12 13:25:58-08:00,"['SparkSchemaUtil.java', 'Reader.java', 'TestFilteredScan.java']"
"Spark: Use path instead of iceberg.table.location.

The ""path"" property is set by load and save in Spark, so this works
better with the DataFrameReader and DataFrameWriter APIs.",6,40,2018-01-15 10:37:53-08:00,"['IcebergSource.java', 'TestAvroScan.java', 'TestDataFrameWrites.java', 'TestFilteredScan.java', 'TestParquetScan.java', 'TestParquetWrite.java']"
"Spark: Do not use ImmutableList in WriterCommitMessage.

ImmutableList can't be deserialized by Kryo because Kryo treats it as a
Collection and attempts to add elements to an empty ImmutableList.",1,16,2018-01-18 13:56:09-08:00,['Writer.java']
Ensure the base location is set when writing metadata.,1,4,2018-01-18 13:56:09-08:00,['BaseMetastoreTableOperations.java']
Create OSSMETADATA,1,1,2018-01-18 21:00:03-08:00,['OSSMETADATA']
Add schema compatibility checks.,6,593,2018-01-19 10:36:11-07:00,"['CheckReadability.java', 'Type.java', 'TypeUtil.java', 'Types.java', 'TestReadabilityChecks.java', 'SchemaUpdate.java']"
Spark: Use CheckReadability to validate schemas before writing.,2,17,2018-01-19 16:37:25-07:00,"['IcebergSource.java', 'Writer.java']"
"Spark: Fix conversion from DF schema when writing.

Previously, this used the prune method from the read path, but prune
will complain in cases where writes will succeed. For example, writing
an optional table column from a required Spark field is allowed, but was
caught by column pruning. This updates the schema conversion to convert
to a new schema, then reassign the schema's ids to match the table
schema, then fix up types that are lost because they aren't represented
in Spark (UUID and binary).

This commit also renames ReassignIds to AssignFreshIds, which is more
accurate.",12,484,2018-01-19 16:37:25-07:00,"['AssignFreshIds.java', 'ReassignIds.java', 'Type.java', 'TypeUtil.java', 'TestReadabilityChecks.java', 'SchemaUpdate.java', 'TableMetadata.java', 'FixupTypes.java', 'SparkSchemaUtil.java', 'SparkTypeToType.java', 'IcebergSource.java', 'TestParquetWrite.java']"
Check that fields are in the correct order when validating writes.,3,127,2018-01-19 16:37:25-07:00,"['CheckCompatibility.java', 'TestReadabilityChecks.java', 'IcebergSource.java']"
"Spark: Restore SparkSchemaUtil.convert(StructType).

This is used by Spark to create tables.",1,20,2018-01-22 13:51:43-08:00,['SparkSchemaUtil.java']
"Move ImmutableList to transient fields in types and specs for kryo.

Kryo can't handle immutable variants of Java collections.",2,145,2018-01-22 13:51:48-08:00,"['PartitionSpec.java', 'Types.java']"
"Spark: Support Timestamp and Date filter literals.

Spark passes timestamp and date types as java.sql objects. This uses
Spark's internal methods to convert to a day ordinal or timestamp in
microseconds, then creates filters from those values.

Originally, int/long couldn't be converted to date/timestamp literals to
avoid users accidentally creating bad expressions, but this is the best
way to get the right literals with the internal representation. Adding
support for java.sql objects would complicate the API code with time
zone logic.",3,47,2018-01-22 13:51:55-08:00,"['Literals.java', 'TestMiscLiteralConversions.java', 'SparkFilters.java']"
Fix isNull and notNull predicates with projection.,4,33,2018-01-24 17:05:18-08:00,"['Bucket.java', 'Dates.java', 'Timestamps.java', 'Truncate.java']"
"Support int32- and int64-backed decimals for Parquet.

This updates the schema conversion to use int32 and int64 primitive
types for decimal data stored in Parquet. It also adds int, long, and
fixed conversions for decimals in parquet-avro. Avro's built-in decimal
conversions support fixed, but not int32 or int64. To add support, this
replaces Avro's decimal type with a parquet-avro type with the necessary
conversions.",5,403,2018-01-24 17:05:23-08:00,"['Parquet.java', 'ParquetAvro.java', 'ParquetReadSupport.java', 'TypeToMessageType.java', 'Reader.java']"
"Enable decimal test cases.

These cases were failing before Parquet support for int32 and int64
decimals.",1,4,2018-01-24 17:10:52-08:00,['AvroDataTest.java']
"Assign missing top-level column IDs starting at 1.

When tables are created, the schema ids are reassigned starting at 1.
Starting at 1 to fill in missing top-level column ids ensures that
columns are matched by position.",2,8,2018-01-29 14:12:12-08:00,"['SchemaToType.java', 'MessageTypeToType.java']"
"Metastore operations should write the requested version.

The method writeNewMetadata should rely on the caller to increment the
metadata version. This was causing double-incrementing.",1,2,2018-01-29 14:12:12-08:00,['BaseMetastoreTableOperations.java']
Add gitignore (#2),1,6,2018-01-31 15:09:46-08:00,['.gitignore']
Always clean up manifests when committing.,2,5,2018-02-08 13:46:59-08:00,"['SnapshotUpdate.java', 'Tasks.java']"
"Fix minor problems with table conversion helpers.

* Ignore hidden files
* Fix table name passed to schema method when building a partition spec",2,9,2018-02-08 13:46:59-08:00,"['SparkSchemaUtil.java', 'SparkTableUtil.scala']"
Fix SparkTableUtil referencing non-existent HiddenFileFilter.,1,14,2018-02-09 15:59:55-08:00,['SparkTableUtil.scala']
Close files used to get Parquet file metrics.,1,4,2018-02-12 11:16:20-08:00,['ParquetMetrics.java']
Add metrics accessor to FileAppender.,5,74,2018-02-12 13:10:54-08:00,"['FileAppender.java', 'AvroFileAppender.java', 'ManifestWriter.java', 'ParquetWriteAdapter.java', 'Writer.java']"
Use minimal Parquet metrics until ParquetWriter's getFooter is released.,1,9,2018-02-12 13:16:13-08:00,['ParquetWriteAdapter.java']
Defensively copy Spark values in partition keys.,2,38,2018-02-13 13:08:13-08:00,"['PartitionKey.java', 'Writer.java']"
Add logging for job commit.,2,8,2018-02-16 10:42:02-08:00,"['Writer.java', 'TestParquetWrite.java']"
Remove distinct counts from metrics.,8,60,2018-02-16 10:47:55-08:00,"['DataFile.java', 'Metrics.java', 'AvroFileAppender.java', 'DataFiles.java', 'GenericDataFile.java', 'ParquetMetrics.java', 'ParquetWriteAdapter.java', 'SparkTableUtil.scala']"
Enforce decimal precision <= 38.,1,2,2018-02-16 10:52:46-08:00,['Types.java']
Remove timetz type.,15,168,2018-02-16 11:12:26-08:00,"['Literals.java', 'Types.java', 'TestLiteralSerialization.java', 'TestMiscLiteralConversions.java', 'TestStringLiteralConversions.java', 'TestBucketing.java', 'TestIdentity.java', 'TestTransformSerialization.java', 'TestReadabilityChecks.java', 'TestSerializableTypes.java', 'SchemaToType.java', 'TypeToSchema.java', 'TestSchemaConversions.java', 'TestSchemaUpdate.java', 'MessageTypeToType.java']"
Support scanning manifest files in parallel.,5,255,2018-02-16 15:34:47-08:00,"['BaseTableScan.java', 'ExceptionUtil.java', 'ParallelIterable.java', 'Tasks.java', 'ThreadPools.java']"
FastAppend: add new manifests to the start of a snapshot.,1,2,2018-02-20 13:11:45-08:00,['FastAppend.java']
"Add bin packing with limited lookback.

This will be used for merging manifest files and for planning splits.

The bin packing algorithm uses two settings, a target size and the
number of bins to consider. When a new bin is added that exceeds the bin
look-back size, the oldest bin is released and removed from
consideration.",2,336,2018-02-20 13:11:50-08:00,"['BinPacking.java', 'TestBinPacking.java']"
"Add manifest target size when merging.

This adds a default target size of 8MB and updates the merge algorithm
to pack existing manifests up to the target size. Manifests are packed
oldest to newest to avoid churn, and manifests use a lookback of 1 to
avoid reordering.",3,120,2018-02-20 13:11:54-08:00,"['MergeAppend.java', 'TableMetadata.java', 'TableProperties.java']"
"Update merge append new file tracking.

This uses an in-memory ManifestReader so that the new manifest entries
are packed into output manifests like existing manifests. This also
simplifies the merge logic.",4,170,2018-02-20 13:11:59-08:00,"['ManifestReader.java', 'ManifestWriter.java', 'MergeAppend.java', 'TestMergeAppend.java']"
Ensure manifest files are closed after reading.,10,315,2018-02-20 13:12:03-08:00,"['TableScan.java', 'ClosingIterable.java', 'AvroIterable.java', 'BaseSnapshot.java', 'BaseTableScan.java', 'ManifestReader.java', 'MergeAppend.java', 'StreamingDelete.java', 'ParquetIterable.java', 'Reader.java']"
Add initial travis ci build (#14),1,12,2018-03-12 12:13:43-07:00,['.travis.yml']
"Initial pass at adding ORC to Iceberg.

Known problems:
* Doesn't do schema evolution.
* Doesn't include column size metrics.
* Doesn't properly handle timestamp with timezone.
* Doesn't do the schema mangling for partitions.

This commit includes the following squashed commits:
5a6620f Initial pass at adding ORC to Iceberg.
836e938 fixing review comments
38fb65e Removing Hadoop's Configuration from the ORC API.
79190c3 Replacing the List<Integer> with a ColumnIdMap.
2900c25 Fix race issue on reading small decimals.
e48710d Update helpers and random data.",22,3007,2018-03-13 15:44:55-07:00,"['.gitignore', 'FileFormat.java', 'UpdateProperties.java', 'build.gradle', 'PropertiesUpdate.java', 'ColumnIdMap.java', 'ORC.java', 'OrcFileAppender.java', 'OrcIterator.java', 'TypeConversion.java', 'settings.gradle', 'SparkOrcReader.java', 'SparkOrcWriter.java', 'Reader.java', 'Writer.java', 'RandomData.java', 'TestHelpers.java', 'SimpleRecord.java', 'TestDataFrameWrites.java', 'TestOrcScan.java', 'TestOrcWrite.java', 'TestParquetWrite.java']"
"Update Spark version to the 2.3.0 release.

Closes #16.",6,108,2018-03-13 17:30:05-07:00,"['build.gradle', 'IcebergSource.java', 'Reader.java', 'Writer.java', 'TestFilteredScan.java', 'TestIcebergSource.java']"
"Add write.manifest.min-count-to-merge to avoid manifest rewrites.

This is a configurable property for merge appends that helps to avoid
rewriting manifest files before they hit the target size.

This implements #24.",4,150,2018-03-16 10:22:16-07:00,"['MergeAppend.java', 'TableProperties.java', 'TestMergeAppend.java', 'TestHadoopCommits.java']"
Use InputFile.location instead of InputFile.toString.,1,2,2018-03-16 10:24:43-07:00,['ManifestReader.java']
Default manifest target size to 4MB.,1,2,2018-03-16 10:25:39-07:00,['TableProperties.java']
"Fix missing manifests when refresh fails.

After committing, table metadata is immediately refreshed by
TableOperations in the commit method. When this refresh failed because
of eventual consistency in the underlying file system, the failure
handler in SnapshotUpdate was removing all of the manifests, which were
assumed to be uncommitted.

This updates the cleanup logic and removes the failure handler that
removes all manifests. Instead, the update now tracks the latest
snapshot id for which a commit was attmpted. If the commit is known to
be successful because the latest metadata has the snapshot, the snapshot
is used to clean up. Otherwise, no cleanup is attempted in case the
commit succeeded, but the metadata can't be read.",1,35,2018-03-22 09:51:14-07:00,['SnapshotUpdate.java']
Add retry logic to refresh in metastore table operations.,1,15,2018-03-22 09:51:35-07:00,['BaseMetastoreTableOperations.java']
"Use isEmpty to check items in ParallelIterable, not size.

Size is an O(n) operation.",1,4,2018-04-05 17:26:06-07:00,['ParallelIterable.java']
"Implement TableScan.planTasks and add a CombinedScanTask implementation.

TableScan.planTasks returns a CombinedScanTask with one FileScanTask for
each file. This should be extended with bin packing and splitting.",3,46,2018-04-05 17:26:13-07:00,"['TableScan.java', 'BaseCombinedScanTask.java', 'BaseTableScan.java']"
Spark: Support CombinedScanTask.,2,185,2018-04-05 17:26:17-07:00,"['SparkOrcReader.java', 'Reader.java']"
Update bin packing to be lazy using an iterable.,1,107,2018-04-05 17:26:21-07:00,['BinPacking.java']
Add simple split combining by packing whole file splits.,3,19,2018-04-05 17:26:24-07:00,"['BaseTableScan.java', 'TableProperties.java', 'TestFilteredScan.java']"
Spark: Ensure Avro and Parquet files are closed.,1,60,2018-04-05 17:26:33-07:00,['Reader.java']
Close Parquet readers used to get the file schema.,1,4,2018-04-05 17:26:39-07:00,['Parquet.java']
"Do not suppress delete-only manifests.

Manifests are used to clean up data files, so they must be present even
if there are no live data files.",1,7,2018-04-05 17:27:01-07:00,['StreamingDelete.java']
"Spark: Add attempt number to file names.

This fixes the case where two attempts ask to commit at the same time.
One succeeds and adds the file to the table (if the write succeeds), but
the other aborts and deletes its data file. If both tasks are using the
same file name, the abort deletes the file that gets committed.",1,2,2018-04-06 13:04:25-07:00,['Writer.java']
"Rename method to add metadata properties to Avro and Parquet.

This renames the set method to meta to be clear that the properties are
added to the file key-value metadata.",3,8,2018-04-06 13:16:56-07:00,"['Avro.java', 'ManifestWriter.java', 'Parquet.java']"
Use set and setAll to configure Avro and Parquet writes.,3,31,2018-04-06 13:43:41-07:00,"['Avro.java', 'Parquet.java', 'Writer.java']"
"Merge iceberg-avro into iceberg-core.

Avro needs access to TableProperties and to the SchemaParser to add
Iceberg schemas to data files.",20,62,2018-04-06 13:59:09-07:00,"['build.gradle', 'Avro.java', 'AvroCustomOrderSchemaVisitor.java', 'AvroFileAppender.java', 'AvroIO.java', 'AvroIterable.java', 'AvroSchemaUtil.java', 'AvroSchemaVisitor.java', 'BuildAvroProjection.java', 'ProjectionDatumReader.java', 'PruneColumns.java', 'SchemaToType.java', 'TypeToSchema.java', 'UUIDConversion.java', 'AvroTestHelpers.java', 'TestAvroReadProjection.java', 'TestReadProjection.java', 'TestSchemaConversions.java', 'Parquet.java', 'settings.gradle']"
Add table settings for compression and parquet sizes.,3,95,2018-04-09 14:58:31-07:00,"['TableProperties.java', 'Avro.java', 'Parquet.java']"
Pass table properties to Parquet and Avro writers.,3,17,2018-04-09 15:23:21-07:00,"['Avro.java', 'Parquet.java', 'Writer.java']"
SparkAppenderFactory always uses InternalRow.,1,8,2018-04-09 15:41:28-07:00,['Writer.java']
Spark: add support for an object storage layout.,4,91,2018-04-10 09:50:34-07:00,"['BaseTable.java', 'TableProperties.java', 'PartitionKey.java', 'Writer.java']"
Use Parquet Java 1.10.0.,1,2,2018-04-10 17:26:00-07:00,['build.gradle']
Remove unreleased dependencies note from README.,1,8,2018-04-10 17:27:10-07:00,['README.md']
Never remove the current snapshot.,1,10,2018-04-17 18:21:58-07:00,['TableMetadata.java']
Copy manifest entries when caching changes.,2,16,2018-04-17 18:22:04-07:00,"['ManifestEntry.java', 'ManifestReader.java']"
Add docs to SnapshotUpdate.,1,16,2018-04-17 18:22:16-07:00,['SnapshotUpdate.java']
Catch null column names passed to expressions.,3,71,2018-04-18 10:09:52-07:00,"['NamedReference.java', 'TestHelpers.java', 'TestExpressionHelpers.java']"
Add test to verify Iceberg fixes a Spark partition pruning bug.,1,52,2018-04-18 10:10:04-07:00,['TestProjection.java']
Add map key types to the API.,11,107,2018-04-18 10:12:20-07:00,"['AssignFreshIds.java', 'CheckCompatibility.java', 'GetProjectedIds.java', 'IndexById.java', 'IndexByName.java', 'PruneColumns.java', 'ReassignIds.java', 'TypeUtil.java', 'Types.java', 'TestReadabilityChecks.java', 'TestSerializableTypes.java']"
"Fix minor bugs in DynConstructors.

Unchecked newInstance call should not try to unwrap errors, and
additional arguments to a function should be ignored like the behavior
of DynMethods.",1,9,2018-04-18 10:12:20-07:00,['DynConstructors.java']
"Avro: Support non-string map keys.

This updates how maps are stored in Avro. Avro maps require that keys
are always strings. To support non-string keys, this uses a map logical
type that annotates an array of key-value records.

Avro classes now store all maps as arrays. Instead of adding logical
type conversions for maps, which would be slow, this updates Avro to
create a tree of ValueReaders like the Spark integration uses. The
reusable parts of ValueReaders are now in core and manifest files are
read using generic value readers.",22,2033,2018-04-18 10:12:20-07:00,"['SchemaParser.java', 'SchemaUpdate.java', 'Avro.java', 'AvroSchemaUtil.java', 'BuildAvroProjection.java', 'GenericAvroReader.java', 'GenericAvroWriter.java', 'LogicalMap.java', 'PruneColumns.java', 'SchemaToType.java', 'TypeToSchema.java', 'ValueReader.java', 'ValueReaders.java', 'ValueWriter.java', 'ValueWriters.java', 'TestSchemaUpdate.java', 'TestReadProjection.java', 'TestSchemaConversions.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkValueReaders.java', 'SparkValueWriters.java']"
"Add object reuse to new Avro readers.

This also adds additional correctness tests based on Spark's random data
testing, and fixes a few bugs caught by the tests.",11,1028,2018-04-18 10:12:20-07:00,"['GenericAvroReader.java', 'GenericAvroWriter.java', 'ValueReader.java', 'ValueReaders.java', 'ValueWriters.java', 'AvroDataTest.java', 'AvroTestHelpers.java', 'RandomAvroData.java', 'TestGenericAvro.java', 'SparkValueReaders.java', 'AvroDataTest.java']"
"Update DataFile to use map types instead of lists for metrics.

DataFile previously used lists of column id and metric pairs. Now that
integer keys are supported, it should use a map from column id to the
metric.

This also updates BuildAvroProjection to detect the case where an array
of pairs is read as a map type. This makes the map changes to DataFile
backward compatible with existing manifests.",4,100,2018-04-18 10:12:20-07:00,"['DataFile.java', 'GenericDataFile.java', 'AvroSchemaUtil.java', 'BuildAvroProjection.java']"
Use regular Avro maps when keys are strings.,5,41,2018-04-18 10:12:20-07:00,"['TypeToSchema.java', 'ValueReaders.java', 'TypeConversion.java', 'MessageTypeToType.java', 'TestReadProjection.java']"
Add TypeUtil.find.,2,90,2018-04-18 10:12:20-07:00,"['FindTypeVisitor.java', 'TypeUtil.java']"
Fix remaining tests with non-string map keys.,21,370,2018-04-18 10:12:20-07:00,"['ReassignIds.java', 'ValueWriters.java', 'RandomAvroData.java', 'TestReadProjection.java', 'TestSchemaConversions.java', 'MessageTypeToType.java', 'TestReadProjection.java', 'FixupTypes.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'SparkTypeToType.java', 'TypeToSparkType.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'RandomData.java', 'TestHelpers.java', 'TestParquetScan.java', 'TestReadProjection.java', 'TestSparkReadProjection.java']"
"Consolidate Tables API implementations (#29)

* Consolidate Tables implementations under Tables api and generify the metastore tables implementation
* Update parameter name and add some docs
* Add Tables api to BaseMetastoreTables implementation",3,58,2018-04-20 13:56:29-07:00,"['Tables.java', 'BaseMetastoreTables.java', 'HadoopTables.java']"
"Add manifest stats filtering (#30)

* Add lower and upper bounds to manifests and MetricsEvaluator to filter.
* Add lower and upper bounds to Parquet metrics.
* Spark: Project manifest columns for stats filtering.
* Update SparkTableUtil to handle lower and upper bounds.
* Use Seq to get around a Spark bug with Arrays of non-primitives.
* Fix bugs in GenericDataFile.
* Copy field ids when creating missing fields in BuildAvroProjection.
* Fix problems with stats.
* Do not add stats for nested columns.
* Update string handling in conversions.
* Fix byte array serialization in SparkTableUtil.
* Fix SerializableByteBufferMap with Kryo.",19,1460,2018-05-02 10:54:44-07:00,"['DataFile.java', 'Metrics.java', 'MetricsEvaluator.java', 'Conversions.java', 'TestHelpers.java', 'TestMetricsEvaluator.java', 'DataFiles.java', 'FilteredManifest.java', 'GenericDataFile.java', 'ManifestReader.java', 'SerializableByteBufferMap.java', 'BuildAvroProjection.java', 'HadoopTableTestBase.java', 'ParquetConversions.java', 'ParquetMetrics.java', 'SparkDataFile.java', 'Reader.java', 'SparkTableUtil.scala', 'TestOrcScan.java']"
Add strict metrics evaluation for safe deletes (#32),7,718,2018-05-10 11:38:23-07:00,"['InclusiveMetricsEvaluator.java', 'StrictMetricsEvaluator.java', 'TestInclusiveMetricsEvaluator.java', 'TestStrictMetricsEvaluator.java', 'FilteredManifest.java', 'StreamingDelete.java', 'ValueWriters.java']"
Fix partition key defensive copies in Spark.,1,3,2018-06-06 13:57:18-07:00,['PartitionKey.java']
Increase default timeout for commits to 10m.,1,2,2018-06-06 13:57:38-07:00,['TableProperties.java']
"Issue-25: Implementation of ReplaceFile action. (#31)

* Issue-25: Implementation of ReplaceFile action.
* Extracting the commonalities in a base class so both overwrite and replace can extend from it.",5,465,2018-06-25 14:39:52-07:00,"['RewriteFiles.java', 'BaseReplaceFiles.java', 'BaseTable.java', 'ReplaceFiles.java', 'TestReplaceFiles.java']"
"Use a consistent classloader for Avro reads. (#34)

Presto's context classloader was changing from when a scan is created to
when its manifests are read. This was causing Iceberg classes to be
unavailable when loaded dynamically because the context classloader was
used.

This fix sets the classloader to use when the Avro read is started using
the read builder.",2,32,2018-06-26 14:21:59-07:00,"['Avro.java', 'GenericAvroReader.java']"
Fixing te javadoc syntax error so the javadoc generation task will go through in gradle.,1,4,2018-06-26 14:41:32-07:00,['StrictMetricsEvaluator.java']
"Move Spark read path to an Iceberg-native Parquet reader (#35)

* Add Parquet value readers.
* Add container reuse to new Parquet readers.
* Clean up naming in ParquetValueReader.
* Fix failing Spark tests for new Parquet readers.
* Minor updates to new parquet read path.
* Add new Parquet write path for Avro.
* Move Spark to new Parquet read path.
* Use generators for new Parquet correctness tests.",42,6247,2018-06-28 15:58:16-07:00,"['Literals.java', 'CloseableGroup.java', 'CloseableIterable.java', 'BaseSnapshot.java', 'BaseTableScan.java', 'ManifestReader.java', 'Avro.java', 'AvroIterable.java', 'ColumnIterator.java', 'ColumnWriter.java', 'PageIterator.java', 'Parquet.java', 'ParquetAvroReader.java', 'ParquetAvroValueReaders.java', 'ParquetAvroWriter.java', 'ParquetIterable.java', 'ParquetMetricsRowGroupFilter.java', 'ParquetReader.java', 'ParquetValueReader.java', 'ParquetValueReaders.java', 'ParquetValueWriter.java', 'ParquetValueWriters.java', 'ParquetWriter.java', 'TripleIterator.java', 'TripleWriter.java', 'TypeWithSchemaVisitor.java', 'TestHelpers.java', 'TestMetricsRowGroupFilter.java', 'SparkParquetReaders.java', 'Reader.java', 'Writer.java', 'CodegenExamples.java', 'RandomData.java', 'TestHelpers.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkAvroReader.java', 'TestSparkParquetReader.java', 'TestAvroScan.java', 'TestDataFrameWrites.java', 'TestParquetScan.java', 'TestReadProjection.java']"
Add int and float type promotion to BuildAvroProjection.,1,20,2018-06-28 16:09:00-07:00,['BuildAvroProjection.java']
Add test for primitive data types with Parquet stats filtering. (#37),3,277,2018-06-29 16:57:36-07:00,"['ParquetMetricsRowGroupFilter.java', 'TypeToMessageType.java', 'TestMetricsRowGroupFilterTypes.java']"
"Fix record name conflict when converting schemas to Avro. (#38)

Using the last field name for the record name breaks when Avro tries to
index a schema by record names, which happens in toString. The fix is to
create record names using the record's field ID. This maintains stable
record names, but ensures records within a schema never conflict.

* Fix record name conflict when converting schemas to Avro.
* Fix manifest reader with new Avro record naming scheme.",4,122,2018-06-29 17:17:39-07:00,"['TypeUtil.java', 'ManifestReader.java', 'TypeToSchema.java', 'TestSchemaConversions.java']"
Fix metrics evaluation with not expressions.,8,167,2018-06-30 15:25:29-07:00,"['Expressions.java', 'InclusiveMetricsEvaluator.java', 'StrictMetricsEvaluator.java', 'TestInclusiveMetricsEvaluator.java', 'TestStrictMetricsEvaluator.java', 'ParquetConversions.java', 'ParquetMetricsRowGroupFilter.java', 'TestMetricsRowGroupFilter.java']"
Add Parquet dictionary row group filter and tests.,2,812,2018-06-30 16:23:27-07:00,"['ParquetDictionaryRowGroupFilter.java', 'TestDictionaryRowGroupFilter.java']"
Add Parquet dictionary filtering.,6,246,2018-06-30 16:33:45-07:00,"['ParquetDictionaryRowGroupFilter.java', 'ParquetMetricsRowGroupFilter.java', 'ParquetReader.java', 'TestDictionaryRowGroupFilter.java', 'TestMetricsRowGroupFilter.java', 'TestMetricsRowGroupFilterTypes.java']"
Fix method names in And and Or expressions.,6,38,2018-07-03 10:40:02-07:00,"['And.java', 'ExpressionVisitors.java', 'Or.java', 'TestExpressionBinding.java', 'TestExpressionSerialization.java', 'TestProjection.java']"
Fix Javadoc errors.,2,3,2018-07-03 10:57:55-07:00,"['UpdateProperties.java', 'Transforms.java']"
Remove accidental data file copy in ManifestEntry.copy.,1,1,2018-07-03 13:01:41-07:00,['ManifestEntry.java']
Fix new Spark Parquet readers for existing data.,4,57,2018-07-10 09:28:59-07:00,"['ParquetReader.java', 'ParquetSchemaUtil.java', 'TypeWithSchemaVisitor.java', 'SparkParquetReaders.java']"
Fix Parquet filters to handle types with missing ids.,2,18,2018-07-10 09:29:20-07:00,"['ParquetDictionaryRowGroupFilter.java', 'ParquetMetricsRowGroupFilter.java']"
Fix missing type ID in Parquet dictionary row group filter.,1,6,2018-07-10 09:30:49-07:00,['ParquetDictionaryRowGroupFilter.java']
"Improve handling for Parquet files without ids.

* Add better detection for any missing ids
* Assign non-root fields ids starting at 1,000,000
* Use Parquet type with fallback ids for filters",5,87,2018-07-10 09:31:21-07:00,"['MessageTypeToType.java', 'ParquetReadSupport.java', 'ParquetReader.java', 'ParquetSchemaUtil.java', 'SparkParquetReaders.java']"
"Delegate record filtering to Spark.

Instead of using an Iceberg expression filter, return all pushed filters
to Spark as unsupported filters. Spark will apply all of the filters
using codegen.

When Spark supports per-task residuals, it won't be necessary to return
all of the filters. For now, this must assume that any filter could be
in a residual and return them all for Spark to apply.",5,105,2018-07-10 09:44:20-07:00,"['ParquetReader.java', 'ParquetSchemaUtil.java', 'SparkParquetReaders.java', 'Reader.java', 'TestFilteredScan.java']"
Add more info logging for table scans.,1,12,2018-07-10 09:44:27-07:00,['BaseTableScan.java']
Parallelize merge append rewrites.,2,117,2018-07-10 09:44:36-07:00,"['MergeAppend.java', 'Tasks.java']"
Fix bug in PropertiesUpdate that prevents overwriting.,1,9,2018-07-10 09:44:49-07:00,['PropertiesUpdate.java']
"Clean up expression negation, add flipLR.",5,95,2018-07-10 09:45:06-07:00,"['BoundPredicate.java', 'Expression.java', 'Predicate.java', 'UnboundPredicate.java', 'SparkFilters.java']"
"Use Spark Expression instead of Filter.

This adds support for pushdown filters when Spark expressions are not
simple filters. For example, cast(ts as date) = date '2018-01-01' is now
supported.",7,641,2018-07-10 10:20:27-07:00,"['Expressions.java', 'Literals.java', 'UnboundPredicate.java', 'SparkExpressions.java', 'SparkFilters.java', 'Reader.java', 'TestFilteredScan.java']"
Update default table commit properties.,1,6,2018-07-10 13:32:30-07:00,['TableProperties.java']
"Fix timestamp literal conversion test.

Support for Spark expressions requires conversion from timestamp
literals to date literals. This fixes the test that validated that the
conversion was not implemented.",1,1,2018-07-10 13:33:47-07:00,['TestMiscLiteralConversions.java']
Update MergeAppend to open manifest readers in parallel.,1,20,2018-07-11 19:14:20-07:00,['MergeAppend.java']
"Refactor Spark reader to standardize joining partition data.

Instead of handling partition data differently for each file format,
this now uses the same logic across all sources. This should add support
for joining partition values to ORC, but this needs to be tested.",2,130,2018-07-12 09:15:31-07:00,"['SparkOrcReader.java', 'Reader.java']"
SparkTableUtil: Fix cases with no file stats.,1,2,2018-07-14 13:39:32-07:00,['SparkTableUtil.scala']
SparkTableUtil: Fix bytesMapToArray.,1,2,2018-07-17 17:01:18-07:00,['SparkTableUtil.scala']
Add gradle wrapper.,3,177,2018-07-17 17:19:49-07:00,"['gradle-wrapper.jar', 'gradle-wrapper.properties', 'gradlew']"
Bump version to 0.2.0.,1,2,2018-07-17 17:20:33-07:00,['build.gradle']
Add Travis CI and JitPack badges to README.,1,3,2018-07-17 17:35:07-07:00,['README.md']
Fix NPE in Spark Reader stats method.,1,2,2018-07-18 09:51:32-07:00,['Reader.java']
Remove accidental import.,1,1,2018-07-18 15:03:08-07:00,['AvroSchemaUtil.java']
Add logo images to repo and README.,4,2,2018-07-20 17:47:47-07:00,"['README.md', 'Iceberg-logo-wordmark.png', 'Iceberg-logo.png', 'iceberg-logo-icon.png']"
"Fix String filters in Spark Expressions.

Spark's UTF8String doesn't implement CharSequence.",3,93,2018-07-23 12:01:35-07:00,"['SparkExpressions.java', 'PartitionKey.java', 'TestFilteredScan.java']"
"Fix commit handling when metadata cannot be immediately read.

When refreshing metadata immediately after reading, an update may not be
able to read the metadata due to eventual consistency in S3. This
updates handling in 2 ways:

* Wait up to 10 minutes to load the metadata
* If metadata cannot be loaded but the commit succeeded, continue on

Because the commit succeeded in the second case, no cleanup can be done.
This was already handled in the RuntimeException handler, but accessing
the snapshot for cleanup was throwing a null pointer exception, hitting
the correct cleanup case, but then causing Spark to abort the commit.
When the commit succeeds, no exception should be thrown.",2,10,2018-07-24 12:51:25-07:00,"['BaseMetastoreTableOperations.java', 'SnapshotUpdate.java']"
Add identitySourceIds to PartitionSpec.,1,17,2018-07-25 10:07:00-07:00,['PartitionSpec.java']
Add useSnapshot(id) to TableScan interface.,2,32,2018-08-02 10:51:11-07:00,"['TableScan.java', 'BaseTableScan.java']"
Add TableScan.asOfTime for time-travel queries.,2,39,2018-08-02 10:51:16-07:00,"['TableScan.java', 'BaseTableScan.java']"
"Assign nested Parquet IDs starting at 1k instead of 1m.

This was causing type ID to stats maps in SparkSchemaUtil to be huge
because they are serialized as dense arrays.",1,2,2018-08-02 10:51:22-07:00,['MessageTypeToType.java']
Add checks to table scans for multiple calls to set the snapshot.,1,5,2018-08-02 10:51:29-07:00,['BaseTableScan.java']
Add support for Spark In and InSet expressions.,1,59,2018-08-02 10:51:33-07:00,['SparkExpressions.java']
Use String.valueOf in Scala.,1,2,2018-08-23 11:18:28-07:00,['SparkTableUtil.scala']
"Delete expired manifests and data files when removing snapshots. (#17)

* Delete expired manifests and data files when removing snapshots.
* Update RemoveSnapshots to avoid reading manifests more than once.
* Add more logging to RemoveSnapshots.
* Parallelize manifest file scanning in RemoveSnapshots.

After snapshots are removed, manifests and data files that are no longer needed are located and deleted. This requires scanning all manifests that are removed, which is slow, so this uses the worker thread pool to parallelize the scan.",2,113,2018-08-23 12:09:27-07:00,"['ExpireSnapshots.java', 'RemoveSnapshots.java']"
Add Pig storage reader (#50),7,1244,2018-08-24 10:16:29-07:00,"['build.gradle', 'ParquetValueReaders.java', 'IcebergPigInputFormat.java', 'IcebergStorage.java', 'PigParquetReader.java', 'SchemaUtil.java', 'settings.gradle']"
"Add single table transactions. (#52)

* Add table transactions.
* Add tests for create transactions.
* Add tests for existing table transactions.

This adds a Transaction API that exposes some Table updates that can be performed in a single commit.

The transaction works by replacing the underlying TableOperations passed to individual updates with a transaction version that applies changes to the table metadata result of the previous update. If the transaction commit needs to retry, it re-runs commit for each update in order. Each update must be committed before the next update is created to ensure a clear order.

Transaction also returns a table, which can be passed to code that expects a Table instead of a Transaction. Operations on that table become part of the transaction.",14,1389,2018-08-27 14:54:05-07:00,"['Table.java', 'Transaction.java', 'BaseMetastoreTables.java', 'BaseTable.java', 'BaseTransaction.java', 'MergeAppend.java', 'PropertiesUpdate.java', 'TableTestBase.java', 'TestCreateTransaction.java', 'TestFastAppend.java', 'TestMergeAppend.java', 'TestReplaceFiles.java', 'TestTables.java', 'TestTransaction.java']"
Fix the Spark reader for timestamps in milliseconds. (#45),1,5,2018-08-27 14:58:11-07:00,['SparkParquetReaders.java']
"Add snapshot log to metadata. (#54)

This is a forward-compatible change and adds metadata that older
versions can ignore.",5,233,2018-08-28 09:02:15-07:00,"['BaseTableScan.java', 'TableMetadata.java', 'TableMetadataParser.java', 'TestMergeAppend.java', 'TestTableMetadataJson.java']"
"Fix snapshot log when committing transactions.

This updates the transaction to keep a list of intermediate snapshot ids
and to remove them from the final committed snapshot log. This ensures
that even though snapshot ids are ""current"" in the commit, only the
final commit's snapshot id is added to the log.",2,50,2018-08-28 16:49:33-07:00,"['BaseTransaction.java', 'TableMetadata.java']"
Add support for remaining Parquet logical types.,1,13,2018-09-03 14:56:45-07:00,['MessageTypeToType.java']
Add partition spec visitor for conversions.,3,99,2018-09-03 14:56:45-07:00,"['Bucket.java', 'PartitionSpecVisitor.java', 'Truncate.java']"
Add conversion from Spark DataType to Type.,2,26,2018-09-03 14:56:45-07:00,"['SparkSchemaUtil.java', 'SparkTypeToType.java']"
"Pig: Fix complex schema conversion (#57)

* Fix for complex schema conversion
* Fix nested tuple/struct in list/bag
* Refactor schema conversion and add tests
* Cleanup some duplicate code and imports
* Update comment location",2,269,2018-09-05 21:32:21-07:00,"['SchemaUtil.java', 'SchemaUtilTest.java']"
Hive Table implementation.,9,387,2018-09-05 23:05:38-07:00,"['InitializationException.java', 'build.gradle', 'BaseMetastoreTableOperations.java', 'BaseMetastoreTables.java', 'HiveTableOperations.java', 'HiveTables.java', 'HiveTypeConverter.java', 'Test.java', 'TestHiveTables.java']"
Bugfixes:create would write to correct metadatalocation and refresh would load the metadata correctly,2,47,2018-09-06 10:55:03-07:00,"['HiveTableOperations.java', 'HiveTables.java']"
"Revert ""Bugfixes:create would write to correct metadatalocation and refresh would load the metadata correctly""

This reverts commit 96e609c80a580b6e4015f8457fb516d6bbbc077e.",2,47,2018-09-08 17:54:16-07:00,"['HiveTableOperations.java', 'HiveTables.java']"
"Revert ""Hive Table implementation.""

This reverts commit b5af3fc4c1640c6d5fad77f1f115457668b3c614.",9,387,2018-09-08 17:54:16-07:00,"['InitializationException.java', 'build.gradle', 'BaseMetastoreTableOperations.java', 'BaseMetastoreTables.java', 'HiveTableOperations.java', 'HiveTables.java', 'HiveTypeConverter.java', 'Test.java', 'TestHiveTables.java']"
Add table properties to table creation methods.,4,58,2018-09-08 17:54:16-07:00,"['Tables.java', 'BaseMetastoreTables.java', 'TableMetadata.java', 'HadoopTables.java']"
"Fix metrics evaluator in streaming delete.

The metrics evaluator was created before the filter was set, so it was
using Expressions.alwaysFalse.",1,10,2018-09-08 17:54:16-07:00,['StreamingDelete.java']
Add OverwriteFiles and ReplacePartitions APIs.,5,155,2018-09-08 17:54:16-07:00,"['OverwriteFiles.java', 'ReplacePartitions.java', 'Table.java', 'BaseTable.java', 'BaseTransaction.java']"
"Add Overwrite operation.

This commit combines the implementations from StreamingDelete and
MergeAppend to create MergingSnapshotUpdate that will delete files,
append, and merge the final manifests. All 3 operations now use this
common base.

Overwrite is now supported by tables and in transactions.",11,1278,2018-09-08 17:54:16-07:00,"['Transaction.java', 'BaseTable.java', 'BaseTransaction.java', 'MergeAppend.java', 'MergingSnapshotUpdate.java', 'OverwriteData.java', 'SnapshotUpdate.java', 'StreamingDelete.java', 'TestFastAppend.java', 'TestMergeAppend.java', 'TestOverwrite.java']"
"Add StructLikeWrapper to compare partition tuples.

This also adds size to the StructLike interface to implement the
comparison.",6,133,2018-09-08 20:52:34-07:00,"['StructLike.java', 'TestHelpers.java', 'PartitionData.java', 'StructLikeWrapper.java', 'PartitionKey.java', 'Reader.java']"
"Add ReplacePartitions implementation.

This also adds validateAppendOnly to ReplacePartitions to fail any
attempt that would delete data from the table. This is used to ensure
that a write is append-only.",8,289,2018-09-08 21:38:51-07:00,"['ReplacePartitions.java', 'Transaction.java', 'BaseTable.java', 'BaseTransaction.java', 'MergingSnapshotUpdate.java', 'ReplacePartitionsOperation.java', 'StructLikeWrapper.java', 'TestReplacePartitions.java']"
Fix overwrite test file metrics.,1,3,2018-09-10 13:04:29-07:00,['TestOverwrite.java']
Fix HadoopTables default constructor.,1,1,2018-09-10 13:04:29-07:00,['HadoopTables.java']
Add HasTableOperations to expose operations for creating input files.,2,31,2018-09-10 13:04:29-07:00,"['BaseTable.java', 'HasTableOperations.java']"
"Add Iceberg generic object model for local reads. (#36)

* Add generic object model for Avro serialization.
* Add single-message encoders and decoders for generic data.
* Fix copyright headers for single-message encoding.
* Implement size and add copy to generic Record interface.
* Add IcebergGenerics.read(Table) for direct table reads using generics.",27,3318,2018-09-10 16:41:17-07:00,"['build.gradle', 'AvroSchemaUtil.java', 'GenericAvroReader.java', 'GenericAvroWriter.java', 'LogicalMap.java', 'ProjectionDatumReader.java', 'ValueReaders.java', 'ValueWriters.java', 'DataReader.java', 'DataWriter.java', 'GenericReaders.java', 'GenericRecord.java', 'GenericWriters.java', 'IcebergDecoder.java', 'IcebergEncoder.java', 'IcebergGenerics.java', 'Record.java', 'TableScanIterable.java', 'DataTest.java', 'DataTestHelpers.java', 'RandomGenericData.java', 'TestGenericData.java', 'TestGenericReadProjection.java', 'TestLocalScan.java', 'TestReadProjection.java', 'TestSingleMessageEncoding.java', 'settings.gradle']"
Add Parquet file support to iceberg-data.,29,1595,2018-09-11 15:04:44-07:00,"['DynMethods.java', 'TableProperties.java', 'TableScanIterable.java', 'DataReader.java', 'DataWriter.java', 'GenericReaders.java', 'GenericWriters.java', 'IcebergDecoder.java', 'IcebergEncoder.java', 'GenericParquetReaders.java', 'GenericParquetWriter.java', 'DataTest.java', 'DataTestHelpers.java', 'TestLocalScan.java', 'TestGenericData.java', 'TestGenericReadProjection.java', 'TestSingleMessageEncoding.java', 'TestGenericData.java', 'TestGenericReadProjection.java', 'Parquet.java', 'ParquetAvroValueReaders.java', 'ParquetAvroWriter.java', 'ParquetIO.java', 'ParquetReader.java', 'ParquetValueReaders.java', 'ParquetValueWriters.java', 'ParquetWriter.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java']"
Implement replace table transaction. (#61),5,490,2018-09-19 15:29:51-07:00,"['BaseMetastoreTables.java', 'BaseTransaction.java', 'TableMetadata.java', 'TestReplaceTransaction.java', 'TestTables.java']"
"Fix manifest file names correctness bug.

When manifest files were written in parallel, multiple threads could use
the same manifest file name because the threads were using the manifest
cache sizes to create the next file name. Instead, this now uses an
atomic counter to ensure all file names are unique.",1,6,2018-09-19 16:40:33-07:00,['MergingSnapshotUpdate.java']
"Fix SparkExpressions.convert recursion with nulls.

Conversion returns null to signal that the expression is not supported,
but in recursive calls it wasn't checking that the wrapped expression
was converted to null. This caused some expressions like not(isnan(d))
to be converted and pushed to Iceberg even though they are not
supported. Iceberg later hit a NPE because an expression was null.

This also checks for null expressions in the Expressions factory
methods.",2,26,2018-09-24 10:23:21-07:00,"['Expressions.java', 'SparkExpressions.java']"
Lazily load file status to avoid remote calls.,1,64,2018-09-24 10:23:25-07:00,['HadoopInputFile.java']
Add ScanSummary.,1,125,2018-09-24 10:23:30-07:00,['ScanSummary.java']
Fix TableScanIterable next when called without hasNext.,1,6,2018-09-24 10:23:34-07:00,['TableScanIterable.java']
"Fix delete operation bug.

Deletes were un-deleting files in manifests that were marked as deleted
because the original code assumed deleted files would be removed before
returning.",2,81,2018-09-24 10:23:58-07:00,"['MergingSnapshotUpdate.java', 'TestDeleteFiles.java']"
Add tests for replace partitions with unpartitioned tables.,2,86,2018-09-26 10:12:02-07:00,"['TableTestBase.java', 'TestReplacePartitions.java']"
Add toString to ScanSummary.PartitionMetrics.,1,5,2018-09-26 10:24:02-07:00,['ScanSummary.java']
"Exclude Hadoop from iceberg-runtime dependencies. (#63)

Update the runtime jar dependencies to not pull in hadoop.  Add hadoop version variable.",1,34,2018-09-26 10:49:19-07:00,['build.gradle']
Update Spark dependency to 2.3.2. (#62),2,14,2018-09-26 11:23:26-07:00,"['build.gradle', 'SparkOrcWriter.java']"
Bump version to 0.3.0.,1,2,2018-09-26 11:25:37-07:00,['build.gradle']
Fix nebula plugin and Travis CI.,1,3,2018-09-26 11:41:42-07:00,['.travis.yml']
Update Javadoc for 0.3.0.,326,41982,2018-09-26 11:46:05-07:00,"['allclasses-frame.html', 'allclasses-noframe.html', 'AppendFiles.html', 'BaseCombinedScanTask.html', 'BaseMetastoreTableOperations.html', 'BaseMetastoreTables.html', 'BaseReplaceFiles.html', 'BaseTable.html', 'CombinedScanTask.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DeleteFiles.html', 'ExpireSnapshots.html', 'FileFormat.html', 'FileScanTask.html', 'Files.html', 'Filterable.html', 'FilteredManifest.html', 'FilteredSnapshot.html', 'HasTableOperations.html', 'ManifestReader.html', 'Metrics.html', 'OverwriteData.html', 'OverwriteFiles.html', 'PartitionField.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'PendingUpdate.html', 'ReplacePartitions.html', 'ReplacePartitionsOperation.html', 'RewriteFiles.html', 'Rollback.html', 'ScanSummary.Builder.html', 'ScanSummary.PartitionMetrics.html', 'ScanSummary.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'Snapshot.html', 'SnapshotParser.html', 'StructLike.html', 'Table.html', 'TableMetadata.SnapshotLogEntry.html', 'TableMetadata.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableProperties.html', 'TableScan.html', 'Tables.html', 'Transaction.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroIterable.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'LogicalMap.html', 'ProjectionDatumReader.html', 'UUIDConversion.html', 'ValueReader.html', 'ValueReaders.StructReader.html', 'ValueReaders.html', 'ValueWriter.html', 'ValueWriters.StructWriter.html', 'ValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericRecord.html', 'IcebergGenerics.ScanBuilder.html', 'IcebergGenerics.html', 'Record.html', 'DataReader.html', 'DataWriter.html', 'IcebergDecoder.html', 'IcebergEncoder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericParquetReaders.html', 'GenericParquetWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CommitFailedException.html', 'NoSuchTableException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'BoundPredicate.html', 'BoundReference.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'InclusiveMetricsEvaluator.html', 'Literal.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'StrictMetricsEvaluator.html', 'True.html', 'UnboundPredicate.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTables.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CloseableGroup.html', 'CloseableIterable.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'FileAppender.html', 'InputFile.html', 'OutputFile.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ColumnIdMap.html', 'ORC.ReadBuilder.html', 'ORC.WriteBuilder.html', 'ORC.html', 'OrcFileAppender.html', 'OrcIterator.html', 'TypeConversion.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ColumnIterator.html', 'ColumnWriter.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetAvroReader.html', 'ParquetAvroValueReaders.TimeMillisReader.html', 'ParquetAvroValueReaders.TimestampMillisReader.html', 'ParquetAvroValueReaders.html', 'ParquetAvroWriter.html', 'ParquetDictionaryRowGroupFilter.html', 'ParquetIterable.html', 'ParquetMetrics.html', 'ParquetMetricsRowGroupFilter.html', 'ParquetReader.html', 'ParquetSchemaUtil.html', 'ParquetTypeVisitor.html', 'ParquetValueReader.html', 'ParquetValueReaders.BinaryAsDecimalReader.html', 'ParquetValueReaders.BytesReader.html', 'ParquetValueReaders.FloatAsDoubleReader.html', 'ParquetValueReaders.IntAsLongReader.html', 'ParquetValueReaders.IntegerAsDecimalReader.html', 'ParquetValueReaders.ListReader.html', 'ParquetValueReaders.LongAsDecimalReader.html', 'ParquetValueReaders.MapReader.html', 'ParquetValueReaders.PrimitiveReader.html', 'ParquetValueReaders.RepeatedKeyValueReader.html', 'ParquetValueReaders.RepeatedReader.html', 'ParquetValueReaders.ReusableEntry.html', 'ParquetValueReaders.StringReader.html', 'ParquetValueReaders.StructReader.html', 'ParquetValueReaders.UnboxedReader.html', 'ParquetValueReaders.html', 'ParquetValueWriter.html', 'ParquetValueWriters.PrimitiveWriter.html', 'ParquetValueWriters.RepeatedKeyValueWriter.html', 'ParquetValueWriters.RepeatedWriter.html', 'ParquetValueWriters.StructWriter.html', 'ParquetValueWriters.html', 'ParquetWriteAdapter.html', 'TripleWriter.html', 'TypeToMessageType.html', 'TypeWithSchemaVisitor.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergPigInputFormat.IcebergRecordReader.html', 'IcebergPigInputFormat.html', 'IcebergStorage.html', 'PigParquetReader.html', 'SchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PruneColumnsWithReordering.html', 'PruneColumnsWithoutReordering.html', 'SparkDataFile.html', 'SparkExpressions.html', 'SparkFilters.html', 'SparkSchemaUtil.html', 'SparkAvroReader.html', 'SparkAvroWriter.html', 'SparkOrcReader.html', 'SparkOrcWriter.html', 'SparkParquetReaders.html', 'SparkValueReaders.html', 'SparkValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Hive.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSource.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PartitionSpecVisitor.html', 'Transform.html', 'Transforms.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CheckCompatibility.html', 'Comparators.html', 'Conversions.html', 'IndexByName.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BinPacking.ListPacker.html', 'BinPacking.PackingIterable.html', 'BinPacking.html', 'CharSequenceWrapper.html', 'ExceptionUtil.html', 'Exceptions.html', 'JsonUtil.html', 'Pair.html', 'ParallelIterable.html', 'StructLikeWrapper.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'ThreadPools.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'constant-values.html', 'deprecated-list.html', 'help-doc.html', 'index-all.html', 'index.html', 'overview-frame.html', 'overview-summary.html', 'overview-tree.html', 'package-list', 'serialized-form.html']"
Update README.md for 0.3.0.,1,25,2018-09-26 11:56:34-07:00,['README.md']
Fix float to double promotion in Parquet readers.,1,4,2018-09-28 09:37:51-07:00,['ParquetValueReaders.java']
Use filtered manifests from cache in snapshot updates.,1,42,2018-09-28 12:06:34-07:00,['MergingSnapshotUpdate.java']
Add iceberg-hive to track Iceberg tables in the Hive Metastore (#60),9,1708,2018-09-30 16:30:07-07:00,"['build.gradle', 'HiveTableOperations.java', 'HiveTables.java', 'HiveTypeConverter.java', 'HiveTableBaseTest.java', 'HiveTablesTest.java', 'ScriptRunner.java', 'hive-schema-3.1.0.derby.sql', 'settings.gradle']"
Update LICENSE.,1,30,2018-09-30 16:40:23-07:00,['LICENSE']
Remove public constructor for Expressions.,1,3,2018-09-30 16:40:23-07:00,['Expressions.java']
Allow IcebergSource subclasses to access SparkSession.,1,11,2018-09-30 16:40:23-07:00,['IcebergSource.java']
Fix Spark literal conversion in In expressions.,1,2,2018-10-02 10:11:44-07:00,['SparkExpressions.java']
Presto runtime jar that shades dependencies that conflict with presto. We still need to see if we can exclude hadoop dependencies that being brought in by both iceberg-core and hive-standalone-metastore so we can avoid specifying a laundry list of hadoop packages.,2,80,2018-10-03 10:49:16-07:00,"['build.gradle', 'settings.gradle']"
Moving off of guava emptyIterator to collections.emptyIterator() as guava version mismatch results in failures with Exceptions like tried to access method com.google.common.collect.Iterators.emptyIterator()Lcom/google/common/collect/UnmodifiableIterator; from class com.netflix.iceberg.avro.ValueReaders,3,22,2018-10-03 10:49:43-07:00,"['ValueReaders.java', 'TableScanIterable.java', 'ParquetValueReaders.java']"
Adding description about both iceberg-hive and iceberg-presto module.,1,2,2018-10-03 11:23:14-07:00,['README.md']
Update README module descriptions.,1,4,2018-10-03 11:28:52-07:00,['README.md']
Update version to 0.3.1 for iceberg-presto-runtime.,1,2,2018-10-03 11:29:30-07:00,['build.gradle']
Updating ReplaceFiles implementation so it will allow replacing a datafile that is duplicated in manifests.,2,55,2018-10-04 14:45:16-07:00,"['BaseReplaceFiles.java', 'TestReplaceFiles.java']"
"Fix iceberg-spark and iceberg-pig descriptions in README.md (#68)

iceberg-spark and iceberg-pig module descriptions were mixed up",1,4,2018-10-18 09:44:40-07:00,['README.md']
Spark: Fix NPE in PartitionKey accessors. (#73),1,17,2018-10-18 13:48:41-07:00,['PartitionKey.java']
Use nebula publishing and git version (#69),1,12,2018-10-18 14:43:53-07:00,['build.gradle']
"Add gitter link to README (#74)

Having people know a gitter channel exists is a good way to get them to join :)",1,1,2018-10-22 09:30:48-07:00,['README.md']
Update the runtime jar dependencies to not pull in hadoop. Add hadoop version variable (#64),0,0,2018-10-25 15:05:16-07:00,[]
"Add metadata file compression. (#79)

This adds support for reading and writing the metadata file using gzip compression when the file path ends in "".gz"". Hadoop and metastore tables have been updated to write compressed metadata files when the Hadoop Configuration option iceberg.compress.metadata is set to true.",7,157,2018-10-30 16:46:35-07:00,"['BaseMetastoreTableOperations.java', 'ConfigProperties.java', 'TableMetadataParser.java', 'HadoopTableOperations.java', 'TableMetadataParserTest.java', 'HadoopTableTestBase.java', 'HiveTableBaseTest.java']"
"Update ReplaceFiles to use MergingSnapshotUpdate. (#84)

This changes the implementation of ReplaceFiles. Previously,
ReplaceFiles used BaseReplaceFiles, which was only used by ReplaceFiles.
Now it uses MergingSnapshotUpdate, the same base class that is used for
deletes, merge appends, and overwrites.

The new implementation adds automatic merging when replacing files and
takes advantage of caching that makes retries much faster.

To use MergingSnapshotUpdate for ReplaceFiles, this adds a mode that
will fail when any specific paths to delete are not found in the table's
current manifests. Filtered manifests are cached and reused in this mode
by tracking the files that were deleted in a filtered manifest.",6,440,2018-10-31 11:36:37-07:00,"['RewriteFiles.java', 'BaseReplaceFiles.java', 'MergingSnapshotUpdate.java', 'ReplaceFiles.java', 'CharSequenceWrapper.java', 'TestReplaceFiles.java']"
Add parent ID to snapshots. (#85),6,46,2018-10-31 11:48:14-07:00,"['Snapshot.java', 'BaseSnapshot.java', 'SnapshotParser.java', 'SnapshotUpdate.java', 'TableMetadata.java', 'TestTableMetadataJson.java']"
Remove mapred exception from catch in HadoopOutputFile.,1,2,2018-11-02 14:07:50-07:00,['HadoopOutputFile.java']
Add FileHistory helper.,3,149,2018-11-02 14:07:50-07:00,"['FileHistory.java', 'ManifestEntry.java', 'ManifestReader.java']"
Fix snapshot log order check causing flaky tests.,1,2,2018-11-02 14:07:50-07:00,['TableMetadata.java']
Fix GenericDataFile when partition is not projected.,1,13,2018-11-02 14:07:50-07:00,['GenericDataFile.java']
Add snapshot ID and operation info log.,1,2,2018-11-02 14:07:50-07:00,['SnapshotUpdate.java']
"Do not refresh tables in commit.

Refreshing table metadata in the commit method creates an error case
that is indistinguishable from a failed commit. This can be handled by
not deleting data that was written, but Iceberg cannot return an unknown
commit status to engines like Spark. Spark needs a clear success or
failure to return its success code that determines whether the job will
be retried.",5,68,2018-11-02 15:23:59-07:00,"['BaseMetastoreTableOperations.java', 'SnapshotUpdate.java', 'TableOperations.java', 'HadoopTableOperations.java', 'HiveTableOperations.java']"
Fix default value for parent snapshot ID in SnapshotUpdate.,1,5,2018-11-05 10:55:36-08:00,['SnapshotUpdate.java']
Close scans in ScanSummary.,1,24,2018-11-05 14:07:53-08:00,['ScanSummary.java']
"Add hard limit to ScanSummary.

When the limit is reached, throw IllegalStateException.",1,18,2018-11-05 14:08:50-08:00,['ScanSummary.java']
Avoid projecting all manifest columns in ScanSummary.,1,10,2018-11-05 14:25:48-08:00,['ScanSummary.java']
Add total partition size to ScanSummary.,1,6,2018-11-05 14:26:11-08:00,['ScanSummary.java']
"Add system property to turn off parallel scan planning. (#86)

The system property is iceberg.scan.plan-in-worker-pool.",3,59,2018-11-05 14:27:03-08:00,"['BaseTableScan.java', 'SystemProperties.java', 'ThreadPools.java']"
"Remove Closeable from TableScan interface. (#87)

TableScan should be immutable so it can be shared between threads. If
TableScan is Closeable, then it can't be shared because resources in use
from one thread can be closed by another when the scan is closed.

Instead, the iterables created by a scan should be closeable.",8,165,2018-11-05 15:56:17-08:00,"['TableScan.java', 'CloseableGroup.java', 'CloseableIterable.java', 'BaseTableScan.java', 'ScanSummary.java', 'TableScanIterable.java', 'IcebergPigInputFormat.java', 'Reader.java']"
Update partition metrics toString.,1,5,2018-11-05 16:42:32-08:00,['ScanSummary.java']
"Implement StructLike in GenericDataFile.

This enables filtering data files with evaluators.",1,17,2018-11-07 09:32:44-08:00,['GenericDataFile.java']
Use a concurrent queue when parallelizing manifest scans.,2,4,2018-11-07 09:34:39-08:00,"['TableScan.java', 'BaseTableScan.java']"
Add factory method withNoopClose to CloseableIterable.,2,24,2018-11-07 09:35:33-08:00,"['CloseableIterable.java', 'ManifestReader.java']"
Add FilteredManifest.entries to get filtered manifest entries.,1,34,2018-11-07 09:36:42-08:00,['FilteredManifest.java']
"Add ManifestGroup to scan a set of manifests.

This allows filtering files using a data filter to prune based on
partition and statistics, as well as a file filter to prune based on
data file properties like location or row count.

FileHistory and ScanSummary have been updated to use ManifestGroup.",3,179,2018-11-07 10:08:10-08:00,"['FileHistory.java', 'ManifestGroup.java', 'ScanSummary.java']"
Fix NPE in ScanSummary.,1,4,2018-11-07 11:25:06-08:00,['ScanSummary.java']
Do not filter data files if filter is null or always true.,1,42,2018-11-08 13:33:51-08:00,['FilteredManifest.java']
Add ignoreDeleted to ManifestGroup.,3,44,2018-11-08 13:33:56-08:00,"['FilteredManifest.java', 'ManifestGroup.java', 'ScanSummary.java']"
Cache results in schema and partition spec parsers. (#89),2,43,2018-11-08 13:34:03-08:00,"['PartitionSpecParser.java', 'SchemaParser.java']"
Add exception trace when logging a task retry.,1,2,2018-11-09 12:49:18-08:00,['Tasks.java']
Add optional number of retries when refreshing metadata.,1,6,2018-11-09 13:02:13-08:00,['BaseMetastoreTableOperations.java']
Add ScanEvent and Listeners.,5,222,2018-11-09 17:31:01-08:00,"['Listener.java', 'Listeners.java', 'ScanEvent.java', 'TestListeners.java', 'BaseTableScan.java']"
Apply the idea plugin for all projects. (#70),1,1,2018-11-12 13:14:24-08:00,['build.gradle']
"Update TableScan.select to select data columns, not manifest columns. (#95)

* Update TableScan.select to select data columns, not manifest columns.
* Add TableScan#project to set a projection without select.
* Add projection schema to scan events.",8,146,2018-11-12 13:29:23-08:00,"['TableScan.java', 'ScanEvent.java', 'BaseTableScan.java', 'ScanSummary.java', 'IcebergGenerics.java', 'TableScanIterable.java', 'IcebergPigInputFormat.java', 'Reader.java']"
"Add task dependency on shadowJar to install.

This fixes #96.",1,1,2018-11-13 09:58:43-08:00,['build.gradle']
Add accessor for data timestamp to ScanSummary.PartitionMetrics.,1,16,2018-11-13 11:28:01-08:00,['ScanSummary.java']
Add snapshot timestamp filtering to ScanSummary.,1,26,2018-11-13 11:37:58-08:00,['ScanSummary.java']
Add Apache site.,14,165,2018-11-19 13:03:03-08:00,"['.gitignore', 'README.md', 'README.md', 'community.md', 'extra.css', 'Iceberg-logo-wordmark.png', 'Iceberg-logo.png', 'favicon-16x16.png', 'favicon-32x32.png', 'favicon-96x96.png', 'favicon.ico', 'iceberg-logo-icon.png', 'index.md', 'mkdocs.yml']"
"Update headers and licensing for Apache.

* Use Apache headers
* Add check-licenses script from Apache Spark
* Add license headers to markdown files
* Remove javadocs, which will be published on the site",671,111301,2018-11-19 13:31:41-08:00,"['.travis.yml', 'LICENSE', 'NOTICE', 'OSSMETADATA', 'README.md', 'AppendFiles.java', 'CombinedScanTask.java', 'DataFile.java', 'DeleteFiles.java', 'ExpireSnapshots.java', 'FileFormat.java', 'FileScanTask.java', 'Files.java', 'Filterable.java', 'FilteredSnapshot.java', 'Metrics.java', 'OverwriteFiles.java', 'PartitionField.java', 'PartitionSpec.java', 'PendingUpdate.java', 'ReplacePartitions.java', 'RewriteFiles.java', 'Rollback.java', 'ScanTask.java', 'Schema.java', 'Snapshot.java', 'SnapshotIterable.java', 'StructLike.java', 'Table.java', 'TableScan.java', 'Tables.java', 'Transaction.java', 'UpdateProperties.java', 'UpdateSchema.java', 'Listener.java', 'Listeners.java', 'ScanEvent.java', 'AlreadyExistsException.java', 'CommitFailedException.java', 'NoSuchTableException.java', 'RuntimeIOException.java', 'ValidationException.java', 'And.java', 'Binder.java', 'BoundPredicate.java', 'BoundReference.java', 'Evaluator.java', 'Expression.java', 'ExpressionVisitors.java', 'Expressions.java', 'False.java', 'InclusiveMetricsEvaluator.java', 'Literal.java', 'Literals.java', 'NamedReference.java', 'Not.java', 'Or.java', 'Predicate.java', 'Projections.java', 'Reference.java', 'ResidualEvaluator.java', 'RewriteNot.java', 'SerializationProxies.java', 'StrictMetricsEvaluator.java', 'True.java', 'UnboundPredicate.java', 'CloseableGroup.java', 'CloseableIterable.java', 'DelegatingInputStream.java', 'DelegatingOutputStream.java', 'FileAppender.java', 'InputFile.java', 'OutputFile.java', 'PositionOutputStream.java', 'SeekableInputStream.java', 'Bucket.java', 'Dates.java', 'Identity.java', 'PartitionSpecVisitor.java', 'ProjectionUtil.java', 'Timestamps.java', 'Transform.java', 'TransformUtil.java', 'Transforms.java', 'Truncate.java', 'AssignFreshIds.java', 'CheckCompatibility.java', 'Comparators.java', 'Conversions.java', 'FindTypeVisitor.java', 'GetProjectedIds.java', 'IndexById.java', 'IndexByName.java', 'PrimitiveHolder.java', 'PruneColumns.java', 'ReassignIds.java', 'Type.java', 'TypeUtil.java', 'Types.java', 'TestHelpers.java', 'TestPartitionPaths.java', 'TestListeners.java', 'TestEvaluatior.java', 'TestExpressionBinding.java', 'TestExpressionHelpers.java', 'TestExpressionSerialization.java', 'TestInclusiveMetricsEvaluator.java', 'TestLiteralSerialization.java', 'TestMiscLiteralConversions.java', 'TestNumericLiteralConversions.java', 'TestPredicateBinding.java', 'TestStrictMetricsEvaluator.java', 'TestStringLiteralConversions.java', 'TestBucketing.java', 'TestDates.java', 'TestIdentity.java', 'TestProjection.java', 'TestResiduals.java', 'TestTimestamps.java', 'TestTransformSerialization.java', 'TestTruncate.java', 'TestBinaryComparator.java', 'TestCharSeqComparator.java', 'TestComparableComparator.java', 'TestReadabilityChecks.java', 'TestSerializableTypes.java', 'build.gradle', 'DynClasses.java', 'DynFields.java', 'BaseCombinedScanTask.java', 'BaseFileScanTask.java', 'BaseMetastoreTableOperations.java', 'BaseMetastoreTables.java', 'BaseSnapshot.java', 'BaseTable.java', 'BaseTableScan.java', 'BaseTransaction.java', 'ConfigProperties.java', 'DataFiles.java', 'FastAppend.java', 'FileHistory.java', 'FilteredManifest.java', 'GenericDataFile.java', 'HasTableOperations.java', 'ManifestEntry.java', 'ManifestGroup.java', 'ManifestReader.java', 'ManifestWriter.java', 'MergeAppend.java', 'MergingSnapshotUpdate.java', 'OverwriteData.java', 'PartitionData.java', 'PartitionSpecParser.java', 'PropertiesUpdate.java', 'RemoveSnapshots.java', 'ReplaceFiles.java', 'ReplacePartitionsOperation.java', 'RollbackToSnapshot.java', 'ScanSummary.java', 'SchemaParser.java', 'SchemaUpdate.java', 'SerializableByteBufferMap.java', 'SnapshotParser.java', 'SnapshotUpdate.java', 'StreamingDelete.java', 'SystemProperties.java', 'TableMetadata.java', 'TableMetadataParser.java', 'TableOperations.java', 'TableProperties.java', 'Avro.java', 'AvroCustomOrderSchemaVisitor.java', 'AvroFileAppender.java', 'AvroIO.java', 'AvroIterable.java', 'AvroSchemaUtil.java', 'AvroSchemaVisitor.java', 'BuildAvroProjection.java', 'GenericAvroReader.java', 'GenericAvroWriter.java', 'LogicalMap.java', 'ProjectionDatumReader.java', 'PruneColumns.java', 'SchemaToType.java', 'TypeToSchema.java', 'UUIDConversion.java', 'ValueReader.java', 'ValueReaders.java', 'ValueWriter.java', 'ValueWriters.java', 'HadoopInputFile.java', 'HadoopOutputFile.java', 'HadoopTableOperations.java', 'HadoopTables.java', 'Util.java', 'BinPacking.java', 'CharSequenceWrapper.java', 'ExceptionUtil.java', 'Exceptions.java', 'JsonUtil.java', 'Pair.java', 'ParallelIterable.java', 'StructLikeWrapper.java', 'Tasks.java', 'ThreadPools.java', 'TableMetadataParserTest.java', 'TableTestBase.java', 'TestCreateTransaction.java', 'TestDeleteFiles.java', 'TestFastAppend.java', 'TestMergeAppend.java', 'TestOverwrite.java', 'TestReplaceFiles.java', 'TestReplacePartitions.java', 'TestReplaceTransaction.java', 'TestSchemaUpdate.java', 'TestSnapshotJson.java', 'TestTableMetadataJson.java', 'TestTables.java', 'TestTransaction.java', 'AvroDataTest.java', 'AvroTestHelpers.java', 'RandomAvroData.java', 'TestAvroReadProjection.java', 'TestGenericAvro.java', 'TestReadProjection.java', 'TestSchemaConversions.java', 'HadoopTableTestBase.java', 'TestHadoopCommits.java', 'TestBinPacking.java', 'GenericRecord.java', 'IcebergGenerics.java', 'Record.java', 'TableScanIterable.java', 'DataReader.java', 'DataWriter.java', 'GenericReaders.java', 'GenericWriters.java', 'IcebergDecoder.java', 'IcebergEncoder.java', 'GenericParquetReaders.java', 'GenericParquetWriter.java', 'DataTest.java', 'DataTestHelpers.java', 'RandomGenericData.java', 'TestLocalScan.java', 'TestReadProjection.java', 'TestGenericData.java', 'TestGenericReadProjection.java', 'TestSingleMessageEncoding.java', 'TestGenericData.java', 'TestGenericReadProjection.java', '.rat-excludes', 'check-license', 'allclasses-frame.html', 'allclasses-noframe.html', 'AppendFiles.html', 'BaseCombinedScanTask.html', 'BaseMetastoreTableOperations.html', 'BaseMetastoreTables.html', 'BaseReplaceFiles.html', 'BaseTable.html', 'CombinedScanTask.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DeleteFiles.html', 'ExpireSnapshots.html', 'FileFormat.html', 'FileScanTask.html', 'Files.html', 'Filterable.html', 'FilteredManifest.html', 'FilteredSnapshot.html', 'HasTableOperations.html', 'ManifestReader.html', 'Metrics.html', 'OverwriteData.html', 'OverwriteFiles.html', 'PartitionField.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'PendingUpdate.html', 'ReplacePartitions.html', 'ReplacePartitionsOperation.html', 'RewriteFiles.html', 'Rollback.html', 'ScanSummary.Builder.html', 'ScanSummary.PartitionMetrics.html', 'ScanSummary.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'Snapshot.html', 'SnapshotParser.html', 'StructLike.html', 'Table.html', 'TableMetadata.SnapshotLogEntry.html', 'TableMetadata.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableProperties.html', 'TableScan.html', 'Tables.html', 'Transaction.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroIterable.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'LogicalMap.html', 'ProjectionDatumReader.html', 'UUIDConversion.html', 'ValueReader.html', 'ValueReaders.StructReader.html', 'ValueReaders.html', 'ValueWriter.html', 'ValueWriters.StructWriter.html', 'ValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericRecord.html', 'IcebergGenerics.ScanBuilder.html', 'IcebergGenerics.html', 'Record.html', 'DataReader.html', 'DataWriter.html', 'IcebergDecoder.html', 'IcebergEncoder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericParquetReaders.html', 'GenericParquetWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CommitFailedException.html', 'NoSuchTableException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'BoundPredicate.html', 'BoundReference.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'InclusiveMetricsEvaluator.html', 'Literal.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'StrictMetricsEvaluator.html', 'True.html', 'UnboundPredicate.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTables.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CloseableGroup.html', 'CloseableIterable.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'FileAppender.html', 'InputFile.html', 'OutputFile.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ColumnIdMap.html', 'ORC.ReadBuilder.html', 'ORC.WriteBuilder.html', 'ORC.html', 'OrcFileAppender.html', 'OrcIterator.html', 'TypeConversion.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ColumnIterator.html', 'ColumnWriter.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetAvroReader.html', 'ParquetAvroValueReaders.TimeMillisReader.html', 'ParquetAvroValueReaders.TimestampMillisReader.html', 'ParquetAvroValueReaders.html', 'ParquetAvroWriter.html', 'ParquetDictionaryRowGroupFilter.html', 'ParquetIterable.html', 'ParquetMetrics.html', 'ParquetMetricsRowGroupFilter.html', 'ParquetReader.html', 'ParquetSchemaUtil.html', 'ParquetTypeVisitor.html', 'ParquetValueReader.html', 'ParquetValueReaders.BinaryAsDecimalReader.html', 'ParquetValueReaders.BytesReader.html', 'ParquetValueReaders.FloatAsDoubleReader.html', 'ParquetValueReaders.IntAsLongReader.html', 'ParquetValueReaders.IntegerAsDecimalReader.html', 'ParquetValueReaders.ListReader.html', 'ParquetValueReaders.LongAsDecimalReader.html', 'ParquetValueReaders.MapReader.html', 'ParquetValueReaders.PrimitiveReader.html', 'ParquetValueReaders.RepeatedKeyValueReader.html', 'ParquetValueReaders.RepeatedReader.html', 'ParquetValueReaders.ReusableEntry.html', 'ParquetValueReaders.StringReader.html', 'ParquetValueReaders.StructReader.html', 'ParquetValueReaders.UnboxedReader.html', 'ParquetValueReaders.html', 'ParquetValueWriter.html', 'ParquetValueWriters.PrimitiveWriter.html', 'ParquetValueWriters.RepeatedKeyValueWriter.html', 'ParquetValueWriters.RepeatedWriter.html', 'ParquetValueWriters.StructWriter.html', 'ParquetValueWriters.html', 'ParquetWriteAdapter.html', 'TripleWriter.html', 'TypeToMessageType.html', 'TypeWithSchemaVisitor.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergPigInputFormat.IcebergRecordReader.html', 'IcebergPigInputFormat.html', 'IcebergStorage.html', 'PigParquetReader.html', 'SchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PruneColumnsWithReordering.html', 'PruneColumnsWithoutReordering.html', 'SparkExpressions.html', 'SparkFilters.html', 'SparkSchemaUtil.html', 'SparkAvroReader.html', 'SparkAvroWriter.html', 'SparkOrcReader.html', 'SparkOrcWriter.html', 'SparkParquetReaders.html', 'SparkValueReaders.html', 'SparkValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Hive.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSource.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PartitionSpecVisitor.html', 'Transform.html', 'Transforms.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CheckCompatibility.html', 'Comparators.html', 'Conversions.html', 'IndexByName.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BinPacking.ListPacker.html', 'BinPacking.PackingIterable.html', 'BinPacking.html', 'CharSequenceWrapper.html', 'ExceptionUtil.html', 'Exceptions.html', 'JsonUtil.html', 'Pair.html', 'ParallelIterable.html', 'StructLikeWrapper.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'ThreadPools.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'constant-values.html', 'deprecated-list.html', 'help-doc.html', 'index-all.html', 'index.html', 'overview-frame.html', 'overview-summary.html', 'overview-tree.html', 'package-list', 'script.js', 'serialized-form.html', 'stylesheet.css', 'gradle-wrapper.properties', 'ColumnIterator.java', 'ColumnWriter.java', 'MessageTypeToType.java', 'PageIterator.java', 'Parquet.java', 'ParquetAvro.java', 'ParquetAvroReader.java', 'ParquetAvroValueReaders.java', 'ParquetAvroWriter.java', 'ParquetConversions.java', 'ParquetDictionaryRowGroupFilter.java', 'ParquetFilters.java', 'ParquetIO.java', 'ParquetIterable.java', 'ParquetMetrics.java', 'ParquetMetricsRowGroupFilter.java', 'ParquetReadSupport.java', 'ParquetReader.java', 'ParquetSchemaUtil.java', 'ParquetTypeVisitor.java', 'ParquetValueReader.java', 'ParquetValueReaders.java', 'ParquetValueWriter.java', 'ParquetValueWriters.java', 'ParquetWriteAdapter.java', 'ParquetWriteSupport.java', 'ParquetWriter.java', 'PruneColumns.java', 'TripleIterator.java', 'TripleWriter.java', 'TypeToMessageType.java', 'TypeWithSchemaVisitor.java', 'TestHelpers.java', 'TestParquetReadProjection.java', 'TestReadProjection.java', 'TestDictionaryRowGroupFilter.java', 'TestMetricsRowGroupFilter.java', 'TestMetricsRowGroupFilterTypes.java', 'IcebergPigInputFormat.java', 'IcebergStorage.java', 'PigParquetReader.java', 'SchemaUtil.java', 'SchemaUtilTest.java', 'settings.gradle', 'README.md', 'community.md', 'extra.css', 'index.md', 'mkdocs.yml', 'FixupTypes.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'SparkExpressions.java', 'SparkFilters.java', 'SparkSchemaUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'TypeToSparkType.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkParquetReaders.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'Hive.java', 'IcebergSource.java', 'PartitionKey.java', 'Reader.java', 'Stats.java', 'Writer.java', 'org.apache.spark.sql.sources.DataSourceRegister', 'SparkTableUtil.scala', 'AvroDataTest.java', 'CodegenExamples.java', 'RandomData.java', 'TestHelpers.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkAvroReader.java', 'TestSparkDateTimes.java', 'TestSparkParquetReader.java', 'TestAvroScan.java', 'TestDataFrameWrites.java', 'TestFilteredScan.java', 'TestIcebergSource.java', 'TestParquetScan.java', 'TestParquetWrite.java', 'TestReadProjection.java', 'TestSparkReadProjection.java', 'TestTables.java']"
Update README for Apache.,1,72,2018-11-19 14:02:26-08:00,['README.md']
Docs: Update mailing lists and add Travis CI badge to README.,2,23,2018-11-20 09:16:23-08:00,"['README.md', 'community.md']"
Allow Tables implementations to override table paths. (#1),1,4,2018-11-26 09:37:44-08:00,['BaseMetastoreTables.java']
Fix gitignore for IDEA project files. (#5),1,2,2018-11-26 12:14:54-08:00,['.gitignore']
Allow custom FileSystem logic in HadoopTableOperations. (#15),1,16,2018-11-27 11:22:16-08:00,['HadoopTableOperations.java']
Support dateCreated expressions in ScanSummary. (#2),2,233,2018-11-28 15:30:53-08:00,"['ScanSummary.java', 'TestScanSummary.java']"
"Remove filter and iterable methods from Snapshot. (#17)

These are not used.",5,143,2018-11-28 15:31:26-08:00,"['Filterable.java', 'FilteredSnapshot.java', 'Snapshot.java', 'SnapshotIterable.java', 'BaseSnapshot.java']"
Fix Javadoc link in README.,1,4,2018-12-04 17:02:33-08:00,['README.md']
"Set derby log system property earlier (#19)

Otherwise an empty hive/derby.log file is created when running the tests.",1,8,2018-12-05 08:43:38-08:00,['HiveTableBaseTest.java']
"Store multiple partition specs in table metadata. (#3)

The purpose of this change is to enable future partition spec changes
and to assign IDs to specs that can be easily encoded in an Avro file
that tracks a snapshot's manifests.

This updates TableMetadata and the metadata parser to support multiple
partition specs. This change is forward-compatible for older readers
because the ""partition-spec"" field in table metadata is still set to the
default spec.

Multiple specs are now stored in an array in table metadata called
""partition-specs"". Each entry in the array is an object with two fields,
a ""spec-id"" field with an integer ID value, and a ""partition-spec""
field with a partition spec value (an array of partition fields). This
also adds ""default-spec-id"" that points to the spec that should be used
when writing.",8,523,2018-12-05 11:53:06-08:00,"['PartitionSpec.java', 'ManifestReader.java', 'ManifestWriter.java', 'PartitionSpecParser.java', 'TableMetadata.java', 'TableMetadataParser.java', 'TestMergeAppend.java', 'TestTableMetadataJson.java']"
"Add manifest listing files (#21)

* Add ManifestFile and migrate Snapshot to return it.
* Optionally write manifest lists to separate files.
    This adds a new table property, write.manifest-lists.enabled, that
    defaults to false. When enabled, new snapshot manifest lists will be
    written into separate files. The file location will be stored in the
    snapshot metadata as ""manifest-list"".
* Aggregate partition field summaries when writing manifests.
* Add InclusiveManifestEvaluator.
    This expression evaluator determines whether a manifest needs to be
    scanned or whether it cannot contain data files matching a partition
    predicate.
* Add file length to ManifestFile.
* Ensure files in manifest lists have helpful metadata.
    This modifies SnapshotUpdate when writing a snapshot with a manifest
    list file. If files for the manifest list do not have full metadata,
    then this will scan the manifests to add metadata, including snapshot
    ID, added/existing/deleted count, and partition field summaries.
* Add partitions name mapping when reading Snapshot manifest list.
* Update ScanSummary and FileHistory to use ManifestFile metadata.
    This optimizes ScanSummary and FileHistory to ignore manifests that
    cannot have changes in the configured time range.",40,2640,2018-12-05 17:20:06-08:00,"['Files.java', 'ManifestFile.java', 'Snapshot.java', 'BoundReference.java', 'InclusiveManifestEvaluator.java', 'Literals.java', 'OutputFile.java', 'Comparators.java', 'TestHelpers.java', 'TestPartitionPaths.java', 'TestInclusiveManifestEvaluator.java', 'BaseSnapshot.java', 'BaseTableScan.java', 'FastAppend.java', 'FileHistory.java', 'GenericManifestFile.java', 'GenericPartitionFieldSummary.java', 'ManifestGroup.java', 'ManifestListWriter.java', 'ManifestWriter.java', 'MergingSnapshotUpdate.java', 'OverwriteData.java', 'PartitionSummary.java', 'RemoveSnapshots.java', 'ReplacePartitionsOperation.java', 'ScanSummary.java', 'SnapshotParser.java', 'SnapshotUpdate.java', 'TableMetadata.java', 'TableProperties.java', 'Avro.java', 'HadoopOutputFile.java', 'LocalTableOperations.java', 'TableTestBase.java', 'TestFastAppend.java', 'TestMergeAppend.java', 'TestReplaceFiles.java', 'TestSnapshotJson.java', 'TestTableMetadataJson.java', 'TestTransaction.java']"
Update ExpireSnapshots to avoid commit when no snapshots are removed. (#22),1,5,2018-12-06 09:45:39-08:00,['RemoveSnapshots.java']
"Return FileAppender from Avro.WriteBuilder, not a package-private implementation. (#27)",1,3,2018-12-06 09:49:59-08:00,['Avro.java']
Add doc about hidden partitioning.,2,72,2018-12-10 09:16:05-08:00,"['partitioning.md', 'mkdocs.yml']"
Update community doc with repo location.,1,6,2018-12-10 09:18:50-08:00,['community.md']
"Update to Spark 2.4 (#30)

* Update to the Spark 2.4 API.
* Remove ORC support from iceberg-spark.
* Use Filter instead of Expression.",12,2558,2018-12-10 09:35:15-08:00,"['build.gradle', 'SparkOrcReader.java', 'SparkOrcWriter.java', 'Reader.java', 'Writer.java', 'CodegenExamples.java', 'TestDataFrameWrites.java', 'TestFilteredScan.java', 'TestOrcScan.java', 'TestOrcWrite.java', 'TestSparkReadProjection.java', 'TestTables.java']"
Add Javadoc link.,1,3,2018-12-10 09:56:58-08:00,['mkdocs.yml']
"Add pluggable file I/O submodule in TableOperations (#14)

This adds FileIO that is returned by TableOperations and used to delete paths and to create InputFile and OutputFile instances. FileIO is Serializable so that it can be sent to tasks running in different JVMs and used for all file-related tasks for a table.",20,427,2018-12-11 09:14:45-08:00,"['Files.java', 'BaseMetastoreTableOperations.java', 'BaseSnapshot.java', 'BaseTableScan.java', 'BaseTransaction.java', 'FileIO.java', 'ManifestGroup.java', 'MergingSnapshotUpdate.java', 'RemoveSnapshots.java', 'SnapshotParser.java', 'SnapshotUpdate.java', 'TableOperations.java', 'HadoopFileIO.java', 'HadoopTableOperations.java', 'SerializableConfiguration.java', 'LocalTableOperations.java', 'TestTables.java', 'TableScanIterable.java', 'HiveTableOperations.java', 'TestTables.java']"
"Spark: Support custom data location (#6)

This adds a new table property, write.folder-storage.path, that controls the location of new data files.",5,57,2018-12-11 12:36:59-08:00,"['TableProperties.java', 'Writer.java', 'AvroDataTest.java', 'TestDataFrameWrites.java', 'TestParquetWrite.java']"
Do not scan manifests with no deletes when expiring. (#46),1,7,2018-12-12 13:50:01-08:00,['RemoveSnapshots.java']
Fix type handling in Spark and Pig. (#49),2,25,2018-12-13 08:40:17-08:00,"['PigParquetReader.java', 'SparkParquetReaders.java']"
"Fix commit retry with manfiest lists. (#48)

A manifest list is created for every commit attempt. Before this update,
the same file was used, which caused retries to fail trying to create
the same list file. This uses a new location for every manifest list,
keeps track of old lists, and cleans up unused lists after a commit
succeeds.",2,49,2018-12-13 13:18:37-08:00,"['SnapshotUpdate.java', 'TestFastAppend.java']"
"Allow custom hadoop properties to be loaded in the Spark data source (#7)

Properties that start with iceberg.hadoop are copied into the Hadoop Configuration used in the Spark source. These may be set in table properties or in read and write options passed to the Spark operation. Read and write options take precedence over the table properties.

Supporting these custom Hadoop properties should also be done in other Iceberg integrations in subsequent patches.",2,43,2018-12-14 10:04:17-08:00,"['IcebergSource.java', 'TestIcebergSource.java']"
"Update ScanSummary behavior. (#29)

* Use all manifests created after the start of the time range
* Fail when the time range may include expired snapshots
* Filter manifests with the data filter in ManifestGroup",3,60,2018-12-20 12:05:12-08:00,"['Table.java', 'ManifestGroup.java', 'ScanSummary.java']"
Use manifest lists by default and fix tests. (#51),12,100,2018-12-20 12:05:31-08:00,"['Files.java', 'BaseSnapshot.java', 'TableProperties.java', 'TableTestBase.java', 'TestCreateTransaction.java', 'TestFastAppend.java', 'TestMergeAppend.java', 'TestReplaceFiles.java', 'TestReplaceTransaction.java', 'TestTables.java', 'HadoopTableTestBase.java', 'TestHadoopCommits.java']"
"Add support for field documentation. (#59)

This adds an optional documentation string to the field level in Iceberg schemas.

Support for doc strings is added to Spark field conversion and to the UpdateSchema API.

To store field documentation, this adds a ""doc"" field to each nested field in the JSON representation of types. The spec has also been updated. This is a forward compatible change. Older readers will ignore the new doc field.",14,293,2018-12-20 12:05:58-08:00,"['Schema.java', 'UpdateSchema.java', 'AssignFreshIds.java', 'PruneColumns.java', 'ReassignIds.java', 'Types.java', 'SchemaParser.java', 'SchemaUpdate.java', 'JsonUtil.java', 'TestSchemaUpdate.java', 'TestTableMetadataJson.java', 'HadoopTableTestBase.java', 'SparkTypeToType.java', 'TypeToSparkType.java']"
Use a UUID-based approach to generate snapshot ids (#57),6,85,2018-12-21 13:58:12-08:00,"['build.gradle', 'BaseMetastoreTableOperations.java', 'TableOperations.java', 'HadoopTableOperations.java', 'HiveTableOperations.java', 'HiveTablesTest.java']"
"Use a separate executor service for the concurrent Hive test (#67)

This fixes CI build errors for master.",1,10,2019-01-07 14:04:54-08:00,['HiveTablesTest.java']
Use the FileIO submodule in Spark writers and readers. (#52),14,240,2019-01-08 16:55:54-08:00,"['Table.java', 'FileIO.java', 'BaseMetastoreTableOperations.java', 'BaseTable.java', 'BaseTransaction.java', 'TableOperations.java', 'HadoopFileIO.java', 'HadoopTableOperations.java', 'LocalTableOperations.java', 'TestTables.java', 'IcebergSource.java', 'Reader.java', 'Writer.java', 'TestTables.java']"
Remove calls to deprecated ColumnDescriptor.getType method. (#62),4,19,2019-01-11 12:33:35-08:00,"['ColumnIterator.java', 'ColumnWriter.java', 'PageIterator.java', 'ParquetDictionaryRowGroupFilter.java']"
"Fix filtering manifests in unpartitioned tables. (#72)

FilteredManifest only ran filters if there was a row filter AND a
partition filter, but it should run filteres if there is a row filter OR
a partition filter.

Because a filter may be null, this also updates the functions that
create evaluators to create an evaluator for alwaysTrue when the
expression is null.",2,127,2019-01-14 10:54:57-08:00,"['FilteredManifest.java', 'TestFilterFiles.java']"
Allow passing the unpartitioned spec to DataFiles.builder. (#71),1,6,2019-01-14 10:55:57-08:00,['DataFiles.java']
"Allow schema updates in transactions. (#70)

This is safe because schema updates can always read older data. If a
transaction includes a write followed by a schema update, the new schema
can read the data that was just written. Also, writers are allowed to
write with older schemas because the current schema can read any file
written with an older schema. If a transaction includes a schema update
followed by a write, using either the original schema or the new schema
will work.",2,17,2019-01-14 11:01:24-08:00,"['Transaction.java', 'BaseTransaction.java']"
Update struct fields for doc-only changes. (#66),1,5,2019-01-14 13:45:36-08:00,['SchemaUpdate.java']
"Support customizing table locations (#68)

* Add write.metadata.path to relocate metadata.
* Add UpdateLocation API to change a table's base location.
* Remove empty folder from Hive locations.",12,213,2019-01-14 13:45:55-08:00,"['Table.java', 'Transaction.java', 'UpdateLocation.java', 'BaseMetastoreTableOperations.java', 'BaseTable.java', 'BaseTransaction.java', 'SetLocation.java', 'TableMetadata.java', 'TableProperties.java', 'HadoopTableOperations.java', 'HiveTableOperations.java', 'HiveTableBaseTest.java']"
"Lazily submit tasks in ParallelIterable and add cancellation. (#45)

* Lazily submit tasks in ParallelIterable and add cancellation.

This removes the planner pool from ParallelIterable, which was used to
submit all of the iterable's tasks in parallel. This was used to queue
up tasks to read every manifest in a snapshot. However, when a caller
stopped reading early, all tasks would still run and add results to the
queue.

Now, tasks are submitted from the thread consuming the iterator as it
runs hasNext. If the caller stops consuming the iterator, then no new
tasks are submitted. This also keeps track of the submitted tasks and
will cancel them when the iterator is closed.

* Remove SystemProperties.PLANNER_THREAD_POOL_SIZE_PROP.",6,159,2019-01-16 08:29:52-08:00,"['CloseableGroup.java', 'BaseTableScan.java', 'SystemProperties.java', 'ParallelIterable.java', 'ThreadPools.java', 'TestHadoopCommits.java']"
Fix propagation of Hive configs (#79),2,49,2019-01-16 09:50:31-08:00,"['HiveTableBaseTest.java', 'metastore-site.xml']"
"Use Hadoop conf from HadoopOutputFile for Parquet (#84)

This fixes a copy & paste error in Parquet's write builder that checked whether an OutputFile was a HadoopInputFile instead of a HadoopOutputFile to get its Configuration.",1,5,2019-01-21 10:43:46-08:00,['Parquet.java']
"Add case sensitivity flag to expression binding (#82)

This doesn't change default behavior. Configuring case sensitivity for processing engines will be added in future commits.",18,142,2019-01-23 11:19:16-08:00,"['Binder.java', 'Evaluator.java', 'InclusiveManifestEvaluator.java', 'InclusiveMetricsEvaluator.java', 'Projections.java', 'ResidualEvaluator.java', 'StrictMetricsEvaluator.java', 'UnboundPredicate.java', 'Types.java', 'TestExpressionBinding.java', 'TestPredicateBinding.java', 'TestProjection.java', 'BaseTableScan.java', 'ParquetDictionaryRowGroupFilter.java', 'ParquetFilters.java', 'ParquetMetricsRowGroupFilter.java', 'SparkExpressions.java', 'SparkSchemaUtil.java']"
"Add LocationProvider to determine data file locations. (#87)

* Add LocationProvider to determine data file locations.
* Fix bug in stripTrailingSlash found by @fbosce.",15,435,2019-02-06 16:05:42-08:00,"['Table.java', 'FileIO.java', 'LocationProvider.java', 'BaseMetastoreTableOperations.java', 'BaseTable.java', 'BaseTransaction.java', 'LocationProviders.java', 'TableMetadata.java', 'TableOperations.java', 'HadoopTableOperations.java', 'PropertyUtil.java', 'LocalTableOperations.java', 'TestTables.java', 'Writer.java', 'TestTables.java']"
Add finalizer for Hadoop streams to catch paths that don't call close. (#90),1,35,2019-02-11 10:01:35-08:00,['HadoopStreams.java']
Update README to state Spark 2.4.0 support. (#95),1,7,2019-02-14 11:29:01-08:00,['README.md']
Remove unused SparkExpressions class. (#94),1,437,2019-02-15 13:21:25-08:00,['SparkExpressions.java']
Fix unnecessary indentation in parameter list (#98),1,2,2019-02-15 13:22:03-08:00,['Binder.java']
Fix typo in README.md (#97),1,2,2019-02-15 13:22:21-08:00,['README.md']
Remove unnecessary retry when reading metadata for existing manifest files (#88),1,5,2019-02-15 13:24:33-08:00,['SnapshotUpdate.java']
Add stream-level encryption API. (#85),18,596,2019-02-18 14:16:55-08:00,"['DataFile.java', 'Table.java', 'EncryptedInputFile.java', 'EncryptedOutputFile.java', 'EncryptionKeyMetadata.java', 'EncryptionManager.java', 'TestHelpers.java', 'DataFiles.java', 'GenericDataFile.java', 'SerializableByteBufferMap.java', 'TableOperations.java', 'BaseEncryptedInputFile.java', 'BaseEncryptedOutputFile.java', 'BaseEncryptionKeyMetadata.java', 'EncryptedFiles.java', 'EncryptionKeyMetadatas.java', 'ByteBuffers.java', 'Writer.java']"
"Fix Iceberg Parquet Reader scanning when filtering on nested types (#110)

* Fix parquet reader scan not returning rows when filtering on nested columns
* Addressed review comments, added unit tests for map & struct types for isNull & notNull expressions",2,40,2019-02-24 11:03:35-08:00,"['ParquetMetricsRowGroupFilter.java', 'TestMetricsRowGroupFilter.java']"
Add unit test UpdateSchemaWithComplexStruct (#115),1,51,2019-03-01 16:19:50-08:00,['TestHadoopCommits.java']
Add PlaintextEncryptionManager and add encryption support in Spark (#107),13,237,2019-03-05 09:47:13-08:00,"['Table.java', 'EncryptionKeyMetadata.java', 'BaseTable.java', 'BaseTransaction.java', 'DataFiles.java', 'TableOperations.java', 'BaseEncryptionKeyMetadata.java', 'EncryptedFiles.java', 'EncryptionKeyMetadatas.java', 'PlaintextEncryptionManager.java', 'ByteBuffers.java', 'Reader.java', 'Writer.java']"
Delete manifest lists after expiring snapshots. (#102),1,16,2019-03-05 16:13:27-08:00,['RemoveSnapshots.java']
Deep copy maps and lists in GenericDataFile. (#106),1,26,2019-03-05 16:21:16-08:00,['GenericDataFile.java']
"Fix handling of null partition values (#100)

* Fix StructLikeWrapper equals and hashCode null handling.
* Spark: Fix reading null partition values.
* Add test for null partition values.",3,142,2019-03-05 16:23:48-08:00,"['StructLikeWrapper.java', 'Reader.java', 'TestPartitionValues.java']"
Remove unused in-memory ManifestReader code. (#109),1,27,2019-03-05 16:42:16-08:00,['ManifestReader.java']
Add snapshot summary and operation. (#74),16,468,2019-03-05 16:43:39-08:00,"['DataOperations.java', 'Snapshot.java', 'BaseSnapshot.java', 'FastAppend.java', 'MergeAppend.java', 'MergingSnapshotUpdate.java', 'OverwriteData.java', 'ReplaceFiles.java', 'ReplacePartitionsOperation.java', 'SnapshotParser.java', 'SnapshotSummary.java', 'SnapshotUpdate.java', 'StreamingDelete.java', 'TestSnapshotJson.java', 'TestTableMetadataJson.java', 'AvroTestHelpers.java']"
Initial python implementation (#54),157,13101,2019-03-14 17:25:55-07:00,"['CHANGELOG.md', 'README.md', '__init__.py', '__init__.py', 'append_files.py', 'combined_scan_task.py', 'data_file.py', 'delete_files.py', '__init__.py', 'already_exists.py', 'validation_exception.py', 'expire_snapshots.py', '__init__.py', 'binder.py', 'evaluator.py', 'expression.py', 'expressions.py', 'inclusive_metrics_evaluator.py', '__init__.py', 'literals.py', 'predicate.py', 'reference.py', 'strict_metrics_evaluator.py', 'file_format.py', 'file_scan_task.py', 'files.py', 'filterable.py', 'filtered_snapshot.py', '__init__.py', 'closeable_group.py', 'closeable_iterable.py', 'delegating_input_stream.py', 'delegating_output_stream.py', 'file_appender.py', 'input_file.py', 'output_file.py', 'position_output_stream.py', 'seekable_input_stream.py', 'manifest_file.py', 'metrics.py', 'overwrite_files.py', 'partition_field.py', 'partition_spec.py', 'pending_update.py', 'replace_partitions.py', 'rewrite_files.py', 'rollback.py', 'scan_task.py', 'schema.py', 'snapshot.py', 'snapshot_iterable.py', 'struct_like.py', 'table.py', 'table_scan.py', 'tables.py', 'transaction.py', '__init__.py', 'bucket.py', 'dates.py', 'identity.py', 'projection_util.py', 'timestamps.py', 'transform.py', 'transform_util.py', 'transforms.py', 'truncate.py', '#conversions.py#', '__init__.py', 'check_compatibility.py', 'conversions.py', 'type.py', 'type_util.py', 'types.py', 'update_properties.py', 'update_schema.py', '__init__.py', '__init__.py', 'avro_schema_util.py', 'avro_to_iceberg.py', 'iceberg_to_avro.py', 'base_metastore_table_operations.py', 'base_metastore_tables.py', 'base_snapshot.py', 'base_table.py', 'base_table_scan.py', 'base_transaction.py', 'config_properties.py', 'data_files.py', 'generic_data_file.py', 'generic_manifest_file.py', 'generic_partition_field_summary.py', '__init__.py', 'file_status.py', 'file_system.py', 'hadoop_input_file.py', 'hadoop_output_file.py', 'hadoop_table_operations.py', 'local_filesystem.py', 's3_filesystem_wrapper.py', 'util.py', 'manifest_entry.py', 'manifest_list_writer.py', 'manifest_reader.py', 'partition_data.py', 'partition_spec_parser.py', 'partition_summary.py', 'schema_parser.py', 'schema_update.py', 'snapshot_parser.py', 'table_metadata.py', 'table_metadata_parser.py', 'table_operations.py', '__init__.py', 'atomic_integer.py', '__init__.py', 'exceptions.py', '__init__.py', '__init__.py', 'spark_catalog.py', 'table_identifier.py', 'setup.py', '__init__.py', '__init__.py', '__init__.py', 'conftest.py', 'test_evaluator.py', 'test_expression_binding.py', 'test_expression_helpers.py', 'test_expression_serializations.py', 'test_inclusive_metrics_evaluator.py', 'test_literal_serialization.py', 'test_misc_literal_conversions.py', 'test_numeric_literal_conversions.py', 'test_predicate_binding.py', 'test_strict_metrics_evaluator.py', 'test_string_literal_conversions.py', 'test_conversions.py', 'test_helpers.py', '__init__.py', 'test_bucketing.py', 'test_dates.py', 'test_identity.py', 'test_timestamps.py', 'test_truncate.py', '__init__.py', 'test_binary_comparator.py', 'test_char_seq_comparator.py', 'test_comparable_comparator.py', 'test_readabilty_checks.py', '__init__.py', '__init__.py', 'test_avro.py', 'conftest.py', 'test_snapshot_json.py', 'test_table_metadata_json.py', 'test_table_metadata_parser.py', 'tox.ini']"
Split files when planning scan tasks (#119),7,321,2019-03-15 17:50:36-07:00,"['FileFormat.java', 'FileScanTask.java', 'BaseFileScanTask.java', 'BaseTableScan.java', 'TestSplitScanTaskIterator.java', 'TestSplitScan.java', 'TestFilteredScan.java']"
"Account for file open cost in split planning (#130)

This tasks with lots of small files by applying a file open cost that acts as a minimum file weight when combining files into tasks. Tasks with a large number of small files can be stragglers because of the latency to open each file.",3,136,2019-03-18 15:20:49-07:00,"['BaseTableScan.java', 'TableProperties.java', 'TestSplitPlanning.java']"
Fix collection of bounds for small decimals in ParquetMetrics (#131),3,336,2019-03-18 15:26:31-07:00,"['ParquetConversions.java', 'ParquetMetrics.java', 'TestParquetMetrics.java']"
Support case sensitivity configuration (#89),25,809,2019-03-18 17:46:39-07:00,"['Schema.java', 'TableScan.java', 'Evaluator.java', 'InclusiveManifestEvaluator.java', 'InclusiveMetricsEvaluator.java', 'Projections.java', 'ResidualEvaluator.java', 'TypeUtil.java', 'TestEvaluatior.java', 'TestInclusiveManifestEvaluator.java', 'TestInclusiveMetricsEvaluator.java', 'TestProjection.java', 'TestResiduals.java', 'TestReadabilityChecks.java', 'BaseTableScan.java', 'FilteredManifest.java', 'ManifestReader.java', 'TestBaseTableScan.java', 'TestFilterFiles.java', 'IcebergGenerics.java', 'TableScanIterable.java', 'SparkSchemaUtil.java', 'IcebergSource.java', 'Reader.java', 'TestFilteredScan.java']"
Python: Remove unused conversions file (#129),1,87,2019-03-19 10:50:42-07:00,['#conversions.py#']
Use Iceberg writers for Parquet data written from Spark. (#63),5,673,2019-03-19 14:03:41-07:00,"['SparkParquetWriters.java', 'Writer.java', 'RandomData.java', 'TestHelpers.java', 'TestSparkParquetWriter.java']"
Add length to FileAppender to avoid a call to S3 when writing. (#101),8,85,2019-03-19 15:41:51-07:00,"['Files.java', 'FileAppender.java', 'ManifestListWriter.java', 'ManifestWriter.java', 'AvroFileAppender.java', 'OrcFileAppender.java', 'ParquetWriteAdapter.java', 'ParquetWriter.java']"
Collect lower/upper bounds for nested struct fields in ParquetMetrics (#136),2,70,2019-03-20 13:48:35-07:00,"['ParquetMetrics.java', 'TestParquetMetrics.java']"
"Rename packages to org.apache.iceberg (#138)

* Move all packages by directory (but don't change references)
* Rename all references from com.netflix.iceberg to org.apache.iceberg
* Reorganize all imports due to new package name.
  Previous commit only did a string find-replace, which made all the imports out of order. Use an IDE to auto-sort all imports.",382,5727,2019-03-20 16:25:05-07:00,"['AppendFiles.java', 'CombinedScanTask.java', 'DataFile.java', 'DataOperations.java', 'DeleteFiles.java', 'ExpireSnapshots.java', 'FileFormat.java', 'FileScanTask.java', 'Files.java', 'Filterable.java', 'ManifestFile.java', 'Metrics.java', 'OverwriteFiles.java', 'PartitionField.java', 'PartitionSpec.java', 'PendingUpdate.java', 'ReplacePartitions.java', 'RewriteFiles.java', 'Rollback.java', 'ScanTask.java', 'Schema.java', 'Snapshot.java', 'StructLike.java', 'Table.java', 'TableScan.java', 'Tables.java', 'Transaction.java', 'UpdateLocation.java', 'UpdateProperties.java', 'UpdateSchema.java', 'EncryptedInputFile.java', 'EncryptedOutputFile.java', 'EncryptionKeyMetadata.java', 'EncryptionManager.java', 'Listener.java', 'Listeners.java', 'ScanEvent.java', 'AlreadyExistsException.java', 'CommitFailedException.java', 'NoSuchTableException.java', 'RuntimeIOException.java', 'ValidationException.java', 'And.java', 'Binder.java', 'BoundPredicate.java', 'BoundReference.java', 'Evaluator.java', 'Expression.java', 'ExpressionVisitors.java', 'Expressions.java', 'False.java', 'InclusiveManifestEvaluator.java', 'InclusiveMetricsEvaluator.java', 'Literal.java', 'Literals.java', 'NamedReference.java', 'Not.java', 'Or.java', 'Predicate.java', 'Projections.java', 'Reference.java', 'ResidualEvaluator.java', 'RewriteNot.java', 'SerializationProxies.java', 'StrictMetricsEvaluator.java', 'True.java', 'UnboundPredicate.java', 'CloseableGroup.java', 'CloseableIterable.java', 'DelegatingInputStream.java', 'DelegatingOutputStream.java', 'FileAppender.java', 'FileIO.java', 'InputFile.java', 'LocationProvider.java', 'OutputFile.java', 'PositionOutputStream.java', 'SeekableInputStream.java', 'Bucket.java', 'Dates.java', 'Identity.java', 'PartitionSpecVisitor.java', 'ProjectionUtil.java', 'Timestamps.java', 'Transform.java', 'TransformUtil.java', 'Transforms.java', 'Truncate.java', 'AssignFreshIds.java', 'CheckCompatibility.java', 'Comparators.java', 'Conversions.java', 'FindTypeVisitor.java', 'GetProjectedIds.java', 'IndexById.java', 'IndexByName.java', 'PrimitiveHolder.java', 'PruneColumns.java', 'ReassignIds.java', 'Type.java', 'TypeUtil.java', 'Types.java', 'TestHelpers.java', 'TestPartitionPaths.java', 'TestListeners.java', 'TestEvaluatior.java', 'TestExpressionBinding.java', 'TestExpressionHelpers.java', 'TestExpressionSerialization.java', 'TestInclusiveManifestEvaluator.java', 'TestInclusiveMetricsEvaluator.java', 'TestLiteralSerialization.java', 'TestMiscLiteralConversions.java', 'TestNumericLiteralConversions.java', 'TestPredicateBinding.java', 'TestStrictMetricsEvaluator.java', 'TestStringLiteralConversions.java', 'TestBucketing.java', 'TestDates.java', 'TestIdentity.java', 'TestProjection.java', 'TestResiduals.java', 'TestTimestamps.java', 'TestTransformSerialization.java', 'TestTruncate.java', 'TestBinaryComparator.java', 'TestCharSeqComparator.java', 'TestComparableComparator.java', 'TestReadabilityChecks.java', 'TestSerializableTypes.java', 'build.gradle', 'DynClasses.java', 'DynConstructors.java', 'DynFields.java', 'DynMethods.java', 'BaseCombinedScanTask.java', 'BaseFileScanTask.java', 'BaseMetastoreTableOperations.java', 'BaseMetastoreTables.java', 'BaseSnapshot.java', 'BaseTable.java', 'BaseTableScan.java', 'BaseTransaction.java', 'ConfigProperties.java', 'DataFiles.java', 'FastAppend.java', 'FileHistory.java', 'FilteredManifest.java', 'GenericDataFile.java', 'GenericManifestFile.java', 'GenericPartitionFieldSummary.java', 'HasTableOperations.java', 'LocationProviders.java', 'ManifestEntry.java', 'ManifestGroup.java', 'ManifestListWriter.java', 'ManifestReader.java', 'ManifestWriter.java', 'MergeAppend.java', 'MergingSnapshotUpdate.java', 'OverwriteData.java', 'PartitionData.java', 'PartitionSpecParser.java', 'PartitionSummary.java', 'PropertiesUpdate.java', 'RemoveSnapshots.java', 'ReplaceFiles.java', 'ReplacePartitionsOperation.java', 'RollbackToSnapshot.java', 'ScanSummary.java', 'SchemaParser.java', 'SchemaUpdate.java', 'SerializableByteBufferMap.java', 'SetLocation.java', 'SnapshotParser.java', 'SnapshotSummary.java', 'SnapshotUpdate.java', 'StreamingDelete.java', 'SystemProperties.java', 'TableMetadata.java', 'TableMetadataParser.java', 'TableOperations.java', 'TableProperties.java', 'Avro.java', 'AvroCustomOrderSchemaVisitor.java', 'AvroFileAppender.java', 'AvroIO.java', 'AvroIterable.java', 'AvroSchemaUtil.java', 'AvroSchemaVisitor.java', 'BuildAvroProjection.java', 'GenericAvroReader.java', 'GenericAvroWriter.java', 'LogicalMap.java', 'ProjectionDatumReader.java', 'PruneColumns.java', 'SchemaToType.java', 'TypeToSchema.java', 'UUIDConversion.java', 'ValueReader.java', 'ValueReaders.java', 'ValueWriter.java', 'ValueWriters.java', 'BaseEncryptedInputFile.java', 'BaseEncryptedOutputFile.java', 'BaseEncryptionKeyMetadata.java', 'EncryptedFiles.java', 'EncryptionKeyMetadatas.java', 'PlaintextEncryptionManager.java', 'HadoopFileIO.java', 'HadoopInputFile.java', 'HadoopOutputFile.java', 'HadoopStreams.java', 'HadoopTableOperations.java', 'HadoopTables.java', 'SerializableConfiguration.java', 'Util.java', 'BinPacking.java', 'ByteBuffers.java', 'CharSequenceWrapper.java', 'ExceptionUtil.java', 'Exceptions.java', 'JsonUtil.java', 'Pair.java', 'ParallelIterable.java', 'PropertyUtil.java', 'StructLikeWrapper.java', 'Tasks.java', 'ThreadPools.java', 'AssertHelpers.java', 'LocalTableOperations.java', 'TableMetadataParserTest.java', 'TableTestBase.java', 'TestBaseTableScan.java', 'TestCreateTransaction.java', 'TestDeleteFiles.java', 'TestFastAppend.java', 'TestFilterFiles.java', 'TestMergeAppend.java', 'TestOverwrite.java', 'TestReplaceFiles.java', 'TestReplacePartitions.java', 'TestReplaceTransaction.java', 'TestScanSummary.java', 'TestSchemaUpdate.java', 'TestSnapshotJson.java', 'TestSplitPlanning.java', 'TestSplitScanTaskIterator.java', 'TestTableMetadataJson.java', 'TestTables.java', 'TestTransaction.java', 'AvroDataTest.java', 'AvroTestHelpers.java', 'RandomAvroData.java', 'TestAvroReadProjection.java', 'TestGenericAvro.java', 'TestReadProjection.java', 'TestSchemaConversions.java', 'HadoopTableTestBase.java', 'TestHadoopCommits.java', 'TestBinPacking.java', 'GenericRecord.java', 'IcebergGenerics.java', 'Record.java', 'TableScanIterable.java', 'DataReader.java', 'DataWriter.java', 'GenericReaders.java', 'GenericWriters.java', 'IcebergDecoder.java', 'IcebergEncoder.java', 'GenericParquetReaders.java', 'GenericParquetWriter.java', 'TestSplitScan.java', 'DataTest.java', 'DataTestHelpers.java', 'RandomGenericData.java', 'TestLocalScan.java', 'TestReadProjection.java', 'TestGenericData.java', 'TestGenericReadProjection.java', 'TestSingleMessageEncoding.java', 'TestGenericData.java', 'TestGenericReadProjection.java', 'Convert table to Iceberg.ipynb', 'HiveTableOperations.java', 'HiveTables.java', 'HiveTypeConverter.java', 'HiveTableBaseTest.java', 'HiveTablesTest.java', 'ScriptRunner.java', 'ColumnIdMap.java', 'ORC.java', 'OrcFileAppender.java', 'OrcIterator.java', 'TypeConversion.java', 'ColumnIterator.java', 'ColumnWriter.java', 'MessageTypeToType.java', 'PageIterator.java', 'Parquet.java', 'ParquetAvro.java', 'ParquetAvroReader.java', 'ParquetAvroValueReaders.java', 'ParquetAvroWriter.java', 'ParquetConversions.java', 'ParquetDictionaryRowGroupFilter.java', 'ParquetFilters.java', 'ParquetIO.java', 'ParquetIterable.java', 'ParquetMetrics.java', 'ParquetMetricsRowGroupFilter.java', 'ParquetReadSupport.java', 'ParquetReader.java', 'ParquetSchemaUtil.java', 'ParquetTypeVisitor.java', 'ParquetValueReader.java', 'ParquetValueReaders.java', 'ParquetValueWriter.java', 'ParquetValueWriters.java', 'ParquetWriteAdapter.java', 'ParquetWriteSupport.java', 'ParquetWriter.java', 'PruneColumns.java', 'TripleIterator.java', 'TripleWriter.java', 'TypeToMessageType.java', 'TypeWithSchemaVisitor.java', 'TestHelpers.java', 'TestParquetReadProjection.java', 'TestReadProjection.java', 'TestDictionaryRowGroupFilter.java', 'TestMetricsRowGroupFilter.java', 'TestMetricsRowGroupFilterTypes.java', 'TestParquetMetrics.java', 'IcebergPigInputFormat.java', 'IcebergStorage.java', 'PigParquetReader.java', 'SchemaUtil.java', 'SchemaUtilTest.java', 'FixupTypes.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'SparkFilters.java', 'SparkSchemaUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'TypeToSparkType.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'Hive.java', 'IcebergSource.java', 'PartitionKey.java', 'Reader.java', 'Stats.java', 'Writer.java', 'org.apache.spark.sql.sources.DataSourceRegister', 'SparkTableUtil.scala', 'AvroDataTest.java', 'RandomData.java', 'TestHelpers.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkAvroReader.java', 'TestSparkDateTimes.java', 'TestSparkParquetReader.java', 'TestSparkParquetWriter.java', 'SimpleRecord.java', 'TestAvroScan.java', 'TestDataFrameWrites.java', 'TestFilteredScan.java', 'TestIcebergSource.java', 'TestParquetScan.java', 'TestParquetWrite.java', 'TestPartitionValues.java', 'TestReadProjection.java', 'TestSparkReadProjection.java', 'TestTables.java']"
Use largest task first in split planning (#117),4,65,2019-03-24 15:29:13-07:00,"['BaseTableScan.java', 'MergingSnapshotUpdate.java', 'BinPacking.java', 'TestBinPacking.java']"
Fix row group dictionary filter handling of null values. (#86),2,44,2019-03-24 15:44:37-07:00,"['ParquetDictionaryRowGroupFilter.java', 'TestDictionaryRowGroupFilter.java']"
Fix missing close call for Avro with container reuse. (#140),1,4,2019-03-24 15:46:11-07:00,['AvroIterable.java']
Return metrics from the Parquet footer after writing. (#137),1,10,2019-03-24 15:55:41-07:00,['ParquetWriteAdapter.java']
Use big-endian byte order for UUIDs in Conversions (#135),3,139,2019-04-02 14:36:09-07:00,"['Conversions.java', 'TestConversions.java', 'TestParquetMetrics.java']"
Applies the Baseline plugin for iceberg-api only. (#143),55,1992,2019-04-03 09:12:28-07:00,"['.checkstyle.xml.swp', 'checkstyle-suppressions.xml', 'checkstyle.xml', '001_apache-2.0.txt', 'dotfile.checkstyle', 'org.eclipse.jdt.core.prefs', 'org.eclipse.jdt.ui.prefs', 'intellij-java-palantir-style.xml', 'FileFormat.java', 'Files.java', 'PartitionField.java', 'PartitionSpec.java', 'RewriteFiles.java', 'TableScan.java', 'UpdateSchema.java', 'RuntimeIOException.java', 'BoundReference.java', 'Expression.java', 'ExpressionVisitors.java', 'Literals.java', 'NamedReference.java', 'Projections.java', 'ResidualEvaluator.java', 'SerializationProxies.java', 'CloseableGroup.java', 'Bucket.java', 'Dates.java', 'Identity.java', 'ProjectionUtil.java', 'Timestamps.java', 'TransformUtil.java', 'Transforms.java', 'Truncate.java', 'CheckCompatibility.java', 'Comparators.java', 'Conversions.java', 'IndexById.java', 'IndexByName.java', 'PruneColumns.java', 'ReassignIds.java', 'TypeUtil.java', 'Types.java', 'TestHelpers.java', 'TestListeners.java', 'TestEvaluatior.java', 'TestExpressionSerialization.java', 'TestMiscLiteralConversions.java', 'TestPredicateBinding.java', 'TestBucketing.java', 'TestIdentity.java', 'TestProjection.java', 'TestReadabilityChecks.java', 'build.gradle', 'TypeToSchema.java', 'gradle-wrapper.properties']"
"Update Tasks to retry at least once, log timeouts. (#142)",1,5,2019-04-03 10:18:31-07:00,['Tasks.java']
Add missing override annotations (#147),13,30,2019-04-04 09:24:01-07:00,"['ExpressionVisitors.java', 'SerializationProxies.java', 'Bucket.java', 'Type.java', 'DynFields.java', 'DynMethods.java', 'BaseTableScan.java', 'PartitionData.java', 'HadoopTableOperations.java', 'BinPacking.java', 'ParquetFilters.java', 'SparkParquetReaders.java', 'Writer.java']"
Use the current schema in all partition specs in scan planning. (#108),9,209,2019-04-04 09:25:24-07:00,"['BaseSnapshot.java', 'BaseTableScan.java', 'ManifestGroup.java', 'ManifestReader.java', 'MergingSnapshotUpdate.java', 'RemoveSnapshots.java', 'SnapshotUpdate.java', 'TableMetadata.java', 'TestScansAndSchemaEvolution.java']"
Add override annotation for test classes (#149),10,10,2019-04-04 15:24:38-07:00,"['TestAvroReadProjection.java', 'TestGenericAvro.java', 'TestGenericData.java', 'TestGenericReadProjection.java', 'TestGenericData.java', 'TestGenericReadProjection.java', 'TestParquetReadProjection.java', 'TestSparkAvroReader.java', 'TestSparkParquetReader.java', 'TestAvroScan.java']"
Turn urls into links in community.md (#148),2,10,2019-04-05 09:15:06-07:00,"['README.md', 'community.md']"
Close open manifests during scan planning. (#150),8,205,2019-04-05 16:10:04-07:00,"['Filterable.java', 'CloseableGroup.java', 'CloseableIterable.java', 'BaseTableScan.java', 'FilteredManifest.java', 'ManifestGroup.java', 'ManifestReader.java', 'ParallelIterable.java']"
Fix binary partition values in Spark. (#146),5,137,2019-04-08 09:19:18-07:00,"['MergingSnapshotUpdate.java', 'PartitionData.java', 'PartitionKey.java', 'Reader.java', 'TestPartitionValues.java']"
Delete temporary metadata file when rename fails in HadoopTableOperations (#144),3,137,2019-04-08 17:16:28-07:00,"['HadoopTableOperations.java', 'HadoopTableTestBase.java', 'TestHadoopCommits.java']"
Update shadow plugin to fix broken gradle 5 build (#151),1,2,2019-04-08 17:17:38-07:00,['build.gradle']
Apply Baseline to iceberg-common and fix Baseline for iceberg-api (#152),8,221,2019-04-10 09:10:08-07:00,"['CloseableIterable.java', 'Timestamps.java', 'TestTimestamps.java', 'build.gradle', 'DynClasses.java', 'DynConstructors.java', 'DynFields.java', 'DynMethods.java']"
Add case insensitive support to Parquet. (#141),10,138,2019-04-11 08:38:34-07:00,"['Parquet.java', 'ParquetDictionaryRowGroupFilter.java', 'ParquetFilters.java', 'ParquetMetricsRowGroupFilter.java', 'ParquetReader.java', 'TestDictionaryRowGroupFilter.java', 'TestMetricsRowGroupFilter.java', 'Reader.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java']"
Break early if exception matches onlyRetryExceptions. (#163),1,1,2019-04-17 17:36:28-07:00,['Tasks.java']
Add a Catalog interface for table operations. (#165),3,187,2019-04-21 13:28:19-07:00,"['Catalog.java', 'Namespace.java', 'TableIdentifier.java']"
"Properly serialize key metadata in GenericDataFile (#172)

Required since ByteBuffer itself isn't serializable. Override Java serialization to convert to byte array first before pushing to object streams.",1,30,2019-05-01 08:53:18-07:00,['GenericDataFile.java']
Use Hive 1.2.1 and add a client pool (#166),9,518,2019-05-02 11:35:46-07:00,"['build.gradle', 'ClientPool.java', 'HiveClientPool.java', 'HiveTableOperations.java', 'HiveTables.java', 'RuntimeMetaException.java', 'HiveTableBaseTest.java', 'HiveTablesTest.java', 'hive-schema-3.1.0.derby.sql']"
Apply baseline linting to iceberg-core (#153),89,2328,2019-05-07 16:47:30-07:00,"['build.gradle', 'BaseMetastoreTableOperations.java', 'BaseMetastoreTables.java', 'BaseSnapshot.java', 'BaseTableScan.java', 'BaseTransaction.java', 'ConfigProperties.java', 'DataFiles.java', 'FileHistory.java', 'FilteredManifest.java', 'GenericDataFile.java', 'GenericManifestFile.java', 'GenericPartitionFieldSummary.java', 'LocationProviders.java', 'ManifestEntry.java', 'ManifestGroup.java', 'ManifestReader.java', 'ManifestWriter.java', 'MergingSnapshotUpdate.java', 'PartitionData.java', 'PartitionSpecParser.java', 'PropertiesUpdate.java', 'RemoveSnapshots.java', 'ScanSummary.java', 'SchemaParser.java', 'SchemaUpdate.java', 'SerializableByteBufferMap.java', 'SetLocation.java', 'SnapshotParser.java', 'SnapshotUpdate.java', 'SystemProperties.java', 'TableMetadata.java', 'TableMetadataParser.java', 'TableProperties.java', 'Avro.java', 'AvroCustomOrderSchemaVisitor.java', 'AvroIO.java', 'AvroIterable.java', 'AvroSchemaUtil.java', 'AvroSchemaVisitor.java', 'BuildAvroProjection.java', 'GenericAvroReader.java', 'GenericAvroWriter.java', 'LogicalMap.java', 'ProjectionDatumReader.java', 'PruneColumns.java', 'SchemaToType.java', 'TypeToSchema.java', 'ValueReaders.java', 'ValueWriters.java', 'BaseEncryptedInputFile.java', 'HadoopFileIO.java', 'HadoopOutputFile.java', 'HadoopStreams.java', 'HadoopTableOperations.java', 'HadoopTables.java', 'Util.java', 'BinPacking.java', 'ByteBuffers.java', 'CharSequenceWrapper.java', 'ExceptionUtil.java', 'Exceptions.java', 'JsonUtil.java', 'Pair.java', 'ParallelIterable.java', 'PropertyUtil.java', 'StructLikeWrapper.java', 'Tasks.java', 'ThreadPools.java', 'AssertHelpers.java', 'TableMetadataParserTest.java', 'TableTestBase.java', 'TestBaseTableScan.java', 'TestCreateTransaction.java', 'TestFilterFiles.java', 'TestReplaceFiles.java', 'TestReplaceTransaction.java', 'TestScansAndSchemaEvolution.java', 'TestSchemaUpdate.java', 'TestSplitPlanning.java', 'TestSplitScanTaskIterator.java', 'TestTables.java', 'TestTransaction.java', 'AvroTestHelpers.java', 'RandomAvroData.java', 'TestSchemaConversions.java', 'HadoopTableTestBase.java', 'TestHadoopCommits.java', 'TestBinPacking.java']"
Fix typo in site/README.md (#176),1,2,2019-05-08 08:53:44-07:00,['README.md']
"Remove listTables from the Catalog API (#177)

It isn't clear what discovery actions the catalog should provide, so we are removing this for now.",1,9,2019-05-08 08:54:56-07:00,['Catalog.java']
Update Gradle reference in README.md (#171),1,2,2019-05-10 09:00:46-07:00,['README.md']
"Fix Parquet write properties forwarded from table properites (#183)

This updates Iceberg to use ParquetProperties directly instead of configuration properties.",5,224,2019-05-10 15:45:44-07:00,"['Parquet.java', 'ParquetWriter.java', 'BaseParquetWritingTest.java', 'TestParquet.java', 'TestParquetMetrics.java']"
Add SnapshotUpdate interface with set method (#180),15,123,2019-05-10 15:46:10-07:00,"['AppendFiles.java', 'DeleteFiles.java', 'OverwriteFiles.java', 'ReplacePartitions.java', 'RewriteFiles.java', 'SnapshotUpdate.java', 'FastAppend.java', 'MergeAppend.java', 'MergingSnapshotProducer.java', 'OverwriteData.java', 'ReplaceFiles.java', 'ReplacePartitionsOperation.java', 'SnapshotProducer.java', 'SnapshotSummary.java', 'StreamingDelete.java']"
"Remove block_size_in_bytes from DataFile (#184)

This field is not used and won't be used for better split planning based on row group or stripe offsets.",5,76,2019-05-15 16:21:30-07:00,"['DataFile.java', 'TestHelpers.java', 'DataFiles.java', 'GenericDataFile.java', 'SparkTableUtil.scala']"
ORC read integration for Spark 2.4.0 (#139),14,1744,2019-05-16 13:15:37-07:00,"['build.gradle', 'ColumnIdMap.java', 'ORC.java', 'OrcFileAppender.java', 'OrcIterable.java', 'OrcValueReader.java', 'OrcValueWriter.java', 'TypeConversion.java', 'VectorizedRowBatchIterator.java', 'SparkOrcReader.java', 'SparkOrcWriter.java', 'Reader.java', 'TestHelpers.java', 'TestSparkOrcReader.java']"
Store split offsets for Parquet files (#186),13,216,2019-05-16 14:39:07-07:00,"['DataFile.java', 'FileAppender.java', 'TestHelpers.java', 'DataFiles.java', 'GenericDataFile.java', 'ParquetUtil.java', 'ParquetWriteAdapter.java', 'ParquetWriter.java', 'TestParquetUtil.java', 'Writer.java', 'SparkTableUtil.scala', 'TestParquetScan.java', 'TestParquetWrite.java']"
Split Parquet tasks at row group boundaries (#188),7,178,2019-05-17 12:19:29-07:00,"['DataFile.java', 'FileAppender.java', 'BaseFileScanTask.java', 'MockFileScanTask.java', 'TestFixedSizeSplitScanTaskIterator.java', 'TestOffsetsBasedSplitScanTaskIterator.java', 'ParquetUtil.java']"
Remove redundant metastore-site.xml from tests (#190),1,35,2019-05-24 15:30:29-07:00,['metastore-site.xml']
Support filtering based on nested struct fields (#123),13,1317,2019-05-28 12:40:04-07:00,"['Accessor.java', 'Accessors.java', 'Schema.java', 'BoundReference.java', 'InclusiveManifestEvaluator.java', 'InclusiveMetricsEvaluator.java', 'UnboundPredicate.java', 'TestEvaluatior.java', 'TestEvaluator.java', 'ParquetDictionaryRowGroupFilter.java', 'ParquetMetricsRowGroupFilter.java', 'TestDictionaryRowGroupFilter.java', 'TestMetricsRowGroupFilter.java']"
"Backporting case-sensitivity flag to expression module (#196)

* [WIP] Initial python implementation commit

* Updating PR per comments from @xhochy

* Backporting case-insensitve expressions",20,540,2019-05-31 12:27:18-07:00,"['__init__.py', 'already_exists.py', 'validation_exception.py', '__init__.py', 'binder.py', 'evaluator.py', 'inclusive_metrics_evaluator.py', 'predicate.py', 'projections.py', 'reference.py', 'strict_metrics_evaluator.py', 'schema.py', 'table_scan.py', 'check_compatibility.py', 'types.py', '__init__.py', 'conftest.py', 'test_evaluator.py', 'test_expression_binding.py', 'test_inclusive_metrics_evaluator.py']"
Bug fixes for Pig (#202),2,29,2019-06-03 16:23:24-07:00,"['Parquet.java', 'IcebergPigInputFormat.java']"
Plan splits using both offsets and target size (#204),2,87,2019-06-04 11:29:34-07:00,"['BaseFileScanTask.java', 'TestOffsetsBasedSplitScanTaskIterator.java']"
Adding InclusiveManifestEvaluator and ResidualEvaluator (#205),7,503,2019-06-05 16:30:37-07:00,"['__init__.py', 'evaluator.py', 'inclusive_manifest_evaluator.py', 'inclusive_metrics_evaluator.py', 'residual_evaluator.py', 'strict_metrics_evaluator.py', 'test_inclusive_manifest_evaluator.py']"
Store split offsets for ORC files (#192),3,89,2019-06-06 09:31:13-07:00,"['ORC.java', 'OrcFileAppender.java', 'TestOrcWrite.java']"
Adding Bin Packing util for Combining scan tasks (#208),3,113,2019-06-06 13:39:05-07:00,"['bin_packing.py', '__init__.py', 'test_bin_packing.py']"
"Add option to load column stats with data files. (#206)

* Add option to load column stats with data files.

* Fix style problems.

* Rename slimCopy to copyWithoutStats, fix other comments.

* Fix javadoc.

* Fix style.",11,253,2019-06-06 14:57:25-07:00,"['DataFile.java', 'TableScan.java', 'TestHelpers.java', 'BaseSnapshot.java', 'BaseTableScan.java', 'FilteredManifest.java', 'GenericDataFile.java', 'ManifestEntry.java', 'ManifestReader.java', 'MergingSnapshotProducer.java', 'TestScanDataFileColumns.java']"
"Add ORC support for listPartitions (#210)

* Add ORC support for listPartitions
* Add OrcMetrics with row count only",2,89,2019-06-08 13:52:09-07:00,"['OrcMetrics.java', 'SparkTableUtil.scala']"
"Add RewriteManifests operation (#200)

This operation can select manifests to rewrite and cluster the entries of those manifests to make scan planning more efficient.",7,683,2019-06-08 14:04:14-07:00,"['RewriteManifests.java', 'Table.java', 'Transaction.java', 'BaseTable.java', 'BaseTransaction.java', 'ReplaceManifests.java', 'TestReplaceManifests.java']"
Spark: Add snapshot selection options to reads (#61),3,258,2019-06-10 10:36:27-07:00,"['IcebergSource.java', 'Reader.java', 'TestSnapshotSelection.java']"
ORC: Make converters reusable (#195) (#209),1,74,2019-06-10 13:48:47-07:00,['SparkOrcReader.java']
"Add appendManifest to AppendFiles API (#201)

This is intended for writers that need to checkpoint state. Writers that checkpoint should be able to create manifest files and append the contents of those manifests to a table, instead of checkpointing
individual data files.",9,382,2019-06-10 14:22:35-07:00,"['AppendFiles.java', 'FastAppend.java', 'ManifestWriter.java', 'MergeAppend.java', 'MergingSnapshotProducer.java', 'ReplaceManifests.java', 'TableTestBase.java', 'TestFastAppend.java', 'TestMergeAppend.java']"
[Baseline] Apply Baseline to iceberg-data #156 (#198),14,199,2019-06-11 09:40:54-07:00,"['build.gradle', 'GenericRecord.java', 'IcebergGenerics.java', 'TableScanIterable.java', 'DataReader.java', 'DataWriter.java', 'GenericReaders.java', 'IcebergDecoder.java', 'GenericParquetReaders.java', 'GenericParquetWriter.java', 'TestSplitScan.java', 'DataTestHelpers.java', 'RandomGenericData.java', 'TestLocalScan.java']"
[Baseline] Apply baseline to iceberg-orc #158 (#211),7,79,2019-06-12 11:39:06-07:00,"['build.gradle', 'ColumnIdMap.java', 'ORC.java', 'OrcFileAppender.java', 'OrcIterable.java', 'OrcMetrics.java', 'TypeConversion.java']"
Support multiple partitions derived from the same field (#203),8,369,2019-06-12 12:59:00-07:00,"['PartitionField.java', 'PartitionSpec.java', 'Projections.java', 'ResidualEvaluator.java', 'TestPartitionPaths.java', 'TestPartitionSpecValidation.java', 'TestTransformSerialization.java', 'Writer.java']"
"Basic Benchmarks for Iceberg Spark Data Source (#105)

* Basic benchmarks for Iceberg Spark Data Source

* Add benchmarks for Parquet readers/writers & restructure code

* Minor style fixes",17,1806,2019-06-12 15:18:52-07:00,"['build.gradle', 'gradle.properties', 'SparkBenchmarkUtil.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'Action.java', 'IcebergSourceBenchmark.java', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java']"
Support calling FileAppender.length during write (#215),3,7,2019-06-15 10:57:03-07:00,"['FileAppender.java', 'AvroFileAppender.java', 'ParquetWriteAdapter.java']"
ReplaceManifests: use writer length instead of estimate (#221),1,17,2019-06-17 12:04:57-07:00,['ReplaceManifests.java']
Add Table method to look up a snapshot by id (#222),4,64,2019-06-18 15:12:48-07:00,"['Table.java', 'BaseTable.java', 'BaseTransaction.java', 'TestSnapshotSelection.java']"
Make Spark options use a consistent style (#224),2,173,2019-06-18 15:14:37-07:00,"['IcebergSource.java', 'TestDataSourceOptions.java']"
Enforce a blank line after license headers (#225),8,9,2019-06-18 15:15:18-07:00,"['checkstyle.xml', 'Catalog.java', 'Namespace.java', 'TableIdentifier.java', 'ConfigProperties.java', 'MockFileScanTask.java', 'TableMetadataParserTest.java', 'IcebergEncoder.java']"
Support FastAppend in BaseTransaction (#223),2,36,2019-06-18 15:16:06-07:00,"['BaseTransaction.java', 'TestTransaction.java']"
Fix concurrent access to lazy PartitionSpec methods (#219),1,57,2019-06-18 15:16:27-07:00,['PartitionSpec.java']
"Update Guava to fix IntelliJ (#229)

Test Plan: ./gradlew build (it runs unit tests)",10,50,2019-06-21 09:51:22-07:00,"['build.gradle', 'DynFields.java', 'BaseFileScanTask.java', 'BaseSnapshot.java', 'BaseTableScan.java', 'GenericDataFile.java', 'GenericManifestFile.java', 'GenericPartitionFieldSummary.java', 'ManifestEntry.java', 'TableMetadata.java']"
Spark: Support structured streaming writes (#228),5,429,2019-06-22 16:02:44-07:00,"['build.gradle', 'IcebergSource.java', 'StreamingWriter.java', 'Writer.java', 'TestStructuredStreaming.java']"
Use JDK StandardCharsets instead of commons-io (#230),3,18,2019-06-22 16:03:26-07:00,"['ParquetConversions.java', 'TestMetricsRowGroupFilterTypes.java', 'TestParquetUtil.java']"
Avro: escape special characters in field names (#220),3,77,2019-06-22 16:08:15-07:00,"['AvroSchemaUtil.java', 'TypeToSchema.java', 'TestSchemaConversions.java']"
"Remove usage of deprecated Schema.Field constructor (#231) (#231)

Without the cast, the deprecated variant that takes JsonNode is
chosen by Java's overload resolution because it is ""more specific"".",2,8,2019-06-22 16:51:26-07:00,"['AvroSchemaUtil.java', 'Pair.java']"
"Add Javadoc for master to ASF site, add refresh task.",393,122790,2019-06-22 18:40:02-07:00,"['build.gradle', 'index.html', 'allclasses-frame.html', 'allclasses-noframe.html', 'SparkParquetWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'constant-values.html', 'deprecated-list.html', 'help-doc.html', 'index-all.html', 'index.html', 'Accessor.html', 'Accessors.html', 'AppendFiles.html', 'BaseCombinedScanTask.html', 'BaseMetastoreTableOperations.html', 'BaseMetastoreTables.html', 'BaseTable.html', 'CombinedScanTask.html', 'ConfigProperties.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DataOperations.html', 'DeleteFiles.html', 'ExpireSnapshots.html', 'FileFormat.html', 'FileHistory.Builder.html', 'FileHistory.html', 'FileScanTask.html', 'Files.html', 'Filterable.html', 'FilteredManifest.html', 'GenericManifestFile.html', 'GenericPartitionFieldSummary.html', 'HasTableOperations.html', 'LocationProviders.html', 'ManifestFile.PartitionFieldSummary.html', 'ManifestFile.html', 'ManifestReader.html', 'ManifestWriter.html', 'Metrics.html', 'OverwriteData.html', 'OverwriteFiles.html', 'PartitionField.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'PendingUpdate.html', 'ReplaceManifests.html', 'ReplacePartitions.html', 'ReplacePartitionsOperation.html', 'RewriteFiles.html', 'RewriteManifests.html', 'Rollback.html', 'ScanSummary.Builder.html', 'ScanSummary.PartitionMetrics.html', 'ScanSummary.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'SetLocation.html', 'Snapshot.html', 'SnapshotParser.html', 'SnapshotSummary.Builder.html', 'SnapshotSummary.html', 'SnapshotUpdate.html', 'StructLike.html', 'SystemProperties.html', 'Table.html', 'TableMetadata.SnapshotLogEntry.html', 'TableMetadata.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableProperties.html', 'TableScan.html', 'Tables.html', 'Transaction.html', 'UpdateLocation.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroIterable.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'LogicalMap.html', 'ProjectionDatumReader.html', 'UUIDConversion.html', 'ValueReader.html', 'ValueReaders.StructReader.html', 'ValueReaders.html', 'ValueWriter.html', 'ValueWriters.StructWriter.html', 'ValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Catalog.html', 'Namespace.html', 'TableIdentifier.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericRecord.html', 'IcebergGenerics.ScanBuilder.html', 'IcebergGenerics.html', 'Record.html', 'DataReader.html', 'DataWriter.html', 'IcebergDecoder.html', 'IcebergEncoder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericParquetReaders.html', 'GenericParquetWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'EncryptedFiles.html', 'EncryptedInputFile.html', 'EncryptedOutputFile.html', 'EncryptionKeyMetadata.html', 'EncryptionKeyMetadatas.html', 'EncryptionManager.html', 'PlaintextEncryptionManager.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Listener.html', 'Listeners.html', 'ScanEvent.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CommitFailedException.html', 'NoSuchTableException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'BoundPredicate.html', 'BoundReference.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'InclusiveManifestEvaluator.html', 'InclusiveMetricsEvaluator.html', 'Literal.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'StrictMetricsEvaluator.html', 'True.html', 'UnboundPredicate.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'HadoopFileIO.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTableOperations.html', 'HadoopTables.html', 'SerializableConfiguration.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'HiveTableOperations.html', 'HiveTables.html', 'HiveTypeConverter.html', 'RuntimeMetaException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CloseableGroup.html', 'CloseableIterable.ConcatCloseableIterable.html', 'CloseableIterable.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'FileAppender.html', 'FileIO.html', 'InputFile.html', 'LocationProvider.html', 'OutputFile.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ColumnIdMap.html', 'ORC.ReadBuilder.html', 'ORC.WriteBuilder.html', 'ORC.html', 'OrcMetrics.html', 'OrcValueReader.html', 'OrcValueWriter.html', 'TypeConversion.html', 'VectorizedRowBatchIterator.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ColumnIterator.html', 'ColumnWriter.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetAvroReader.html', 'ParquetAvroValueReaders.TimeMillisReader.html', 'ParquetAvroValueReaders.TimestampMillisReader.html', 'ParquetAvroValueReaders.html', 'ParquetAvroWriter.html', 'ParquetDictionaryRowGroupFilter.html', 'ParquetIterable.html', 'ParquetMetricsRowGroupFilter.html', 'ParquetReader.html', 'ParquetSchemaUtil.html', 'ParquetTypeVisitor.html', 'ParquetUtil.html', 'ParquetValueReader.html', 'ParquetValueReaders.BinaryAsDecimalReader.html', 'ParquetValueReaders.BytesReader.html', 'ParquetValueReaders.FloatAsDoubleReader.html', 'ParquetValueReaders.IntAsLongReader.html', 'ParquetValueReaders.IntegerAsDecimalReader.html', 'ParquetValueReaders.ListReader.html', 'ParquetValueReaders.LongAsDecimalReader.html', 'ParquetValueReaders.MapReader.html', 'ParquetValueReaders.PrimitiveReader.html', 'ParquetValueReaders.RepeatedKeyValueReader.html', 'ParquetValueReaders.RepeatedReader.html', 'ParquetValueReaders.ReusableEntry.html', 'ParquetValueReaders.StringReader.html', 'ParquetValueReaders.StructReader.html', 'ParquetValueReaders.UnboxedReader.html', 'ParquetValueReaders.html', 'ParquetValueWriter.html', 'ParquetValueWriters.PrimitiveWriter.html', 'ParquetValueWriters.RepeatedKeyValueWriter.html', 'ParquetValueWriters.RepeatedWriter.html', 'ParquetValueWriters.StructWriter.html', 'ParquetValueWriters.html', 'ParquetWriteAdapter.html', 'TripleWriter.html', 'TypeToMessageType.html', 'TypeWithSchemaVisitor.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergPigInputFormat.IcebergRecordReader.html', 'IcebergPigInputFormat.html', 'IcebergStorage.html', 'PigParquetReader.html', 'SchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PruneColumnsWithReordering.html', 'PruneColumnsWithoutReordering.html', 'SparkFilters.html', 'SparkSchemaUtil.html', 'SparkAvroReader.html', 'SparkAvroWriter.html', 'SparkOrcReader.html', 'SparkOrcWriter.html', 'SparkParquetReaders.html', 'SparkParquetWriters.html', 'SparkValueReaders.html', 'SparkValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Hive.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSource.html', 'StreamingWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PartitionSpecVisitor.html', 'Transform.html', 'Transforms.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CheckCompatibility.html', 'Comparators.html', 'Conversions.html', 'IndexByName.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BinPacking.ListPacker.html', 'BinPacking.PackingIterable.html', 'BinPacking.html', 'ByteBuffers.html', 'CharSequenceWrapper.html', 'ExceptionUtil.html', 'Exceptions.html', 'JsonUtil.html', 'Pair.html', 'ParallelIterable.html', 'PropertyUtil.html', 'StructLikeWrapper.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'ThreadPools.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'overview-frame.html', 'overview-summary.html', 'overview-tree.html', 'package-list', 'script.js', 'serialized-form.html', 'stylesheet.css', 'mkdocs.yml']"
"Fix uncommitted file clean-up in transactions (#218)

* Fix uncommitted file clean-up in transactions.

This adds a callback to delete files and adds a callback in Transaction
that keeps track of deletes instead of running them. When a transaction
is committed, the last set of deletes are run so that the actual deletes
are for the last commit of each operation in the transaction.

* Update for baseline and fix problems porting to OSS.",7,157,2019-06-23 09:52:11-07:00,"['SnapshotUpdate.java', 'BaseTransaction.java', 'FastAppend.java', 'MergingSnapshotProducer.java', 'ReplaceManifests.java', 'SnapshotProducer.java', 'TestTransaction.java']"
Move spec to ASF site.,5,622,2019-06-23 13:11:00-07:00,"['README.md', 'extra.css', 'iceberg-metadata.png', 'spec.md', 'mkdocs.yml']"
Fix typo in spec.,1,2,2019-06-23 13:17:34-07:00,['spec.md']
Update spec headings for TOC.,1,66,2019-06-23 13:27:44-07:00,['spec.md']
[Baseline] Apply Baseline plugin to iceberg-spark (#226),40,1109,2019-06-24 08:57:49-07:00,"['checkstyle.xml', 'build.gradle', 'scalastyle_config.xml', 'FixupTypes.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'SparkFilters.java', 'SparkSchemaUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'Hive.java', 'PartitionKey.java', 'Reader.java', 'Writer.java', 'SparkTableUtil.scala', 'RandomData.java', 'TestHelpers.java', 'TestOrcWrite.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkOrcReader.java', 'SimpleRecord.java', 'TestAvroScan.java', 'TestDataFrameWrites.java', 'TestFilteredScan.java', 'TestParquetScan.java', 'TestParquetWrite.java', 'TestPartitionValues.java', 'TestReadProjection.java', 'TestSnapshotSelection.java', 'TestSparkReadProjection.java', 'TestTables.java']"
Replace hidden dependency on commons-compress with JDK zip (#232),2,17,2019-06-26 08:30:57-07:00,"['TableMetadataParser.java', 'TableMetadataParserTest.java']"
Update ASF site with more docs.,14,501,2019-06-26 16:29:16-07:00,"['community.md', 'configuration.md', 'extra.css', 'evolution.md', 'getting-started.md', 'index.md', 'performance.md', 'presto.md', 'reliability.md', 'schemas.md', 'snapshots.md', 'spark.md', 'terms.md', 'mkdocs.yml']"
Do not show permalink for h1.,1,5,2019-06-27 10:09:46-07:00,['extra.css']
Add API doc for Java.,1,188,2019-06-27 11:32:37-07:00,['api.md']
"Fix thread safety of date formatting in BaseTableScan (#237)

SimpleDateFormat is not thread safe.",1,16,2019-06-27 14:10:03-07:00,['BaseTableScan.java']
Fix row group skipping in ParquetReader. (#238),1,1,2019-06-27 21:50:43-07:00,['ParquetReader.java']
[Baseline] Apply Baseline plugin to iceberg-hive (#233),10,400,2019-06-27 21:53:03-07:00,"['checkstyle-suppressions.xml', 'build.gradle', 'ClientPool.java', 'HiveTableOperations.java', 'HiveTables.java', 'HiveTypeConverter.java', 'HiveTableBaseTest.java', 'HiveTablesTest.java', 'ScriptRunner.java', 'scalastyle_config.xml']"
Move BaseTransaction factory methods to Transaction (#234),5,70,2019-06-28 08:49:06-07:00,"['BaseMetastoreTables.java', 'BaseTable.java', 'BaseTransaction.java', 'Transactions.java', 'TestTables.java']"
Add exists method to InputFile (#242),3,21,2019-06-29 07:15:55-07:00,"['Files.java', 'InputFile.java', 'HadoopInputFile.java']"
Add HiveCatalog implementation (#240),10,546,2019-06-29 08:00:44-07:00,"['Catalog.java', 'Namespace.java', 'TableIdentifier.java', 'BaseMetastoreCatalog.java', 'ClientPool.java', 'HiveCatalog.java', 'HiveClientPool.java', 'HiveTableOperations.java', 'HiveTableBaseTest.java', 'HiveTableTest.java']"
Update iceberg-spark to use HiveTables (#239),8,482,2019-07-02 08:39:00-07:00,"['TableIdentifier.java', 'TestTableIdentifier.java', 'build.gradle', 'HiveCatalogs.java', 'HiveTableBaseTest.java', 'TestHiveMetastore.java', 'IcebergSource.java', 'TestIcebergSourceHiveTables.java']"
Use gradle-consistent-versions to manage dependencies (#241),4,388,2019-07-04 10:21:54-07:00,"['build.gradle', 'gradle-wrapper.properties', 'versions.lock', 'versions.props']"
Update Spark runtime Jar contents (#250),2,79,2019-07-05 14:49:59-07:00,"['build.gradle', 'settings.gradle']"
Support dynamic partition overwrite (#246),4,226,2019-07-05 15:15:55-07:00,"['IcebergSource.java', 'StreamingWriter.java', 'Writer.java', 'TestParquetWrite.java']"
Docs: Add API quickstart guide.,3,180,2019-07-05 16:24:02-07:00,"['api-quickstart.md', 'spark.md', 'mkdocs.yml']"
Docs: Update javadoc for master.,392,4539,2019-07-05 16:27:27-07:00,"['allclasses-frame.html', 'allclasses-noframe.html', 'SparkParquetWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'constant-values.html', 'deprecated-list.html', 'help-doc.html', 'index-all.html', 'index.html', 'Accessor.html', 'Accessors.html', 'AppendFiles.html', 'BaseCombinedScanTask.html', 'BaseMetastoreCatalog.html', 'BaseMetastoreTableOperations.html', 'BaseMetastoreTables.html', 'BaseTable.html', 'CombinedScanTask.html', 'ConfigProperties.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DataOperations.html', 'DeleteFiles.html', 'ExpireSnapshots.html', 'FileFormat.html', 'FileHistory.Builder.html', 'FileHistory.html', 'FileScanTask.html', 'Files.html', 'Filterable.html', 'FilteredManifest.html', 'GenericManifestFile.html', 'GenericPartitionFieldSummary.html', 'HasTableOperations.html', 'LocationProviders.html', 'ManifestFile.PartitionFieldSummary.html', 'ManifestFile.html', 'ManifestReader.html', 'ManifestWriter.html', 'Metrics.html', 'OverwriteData.html', 'OverwriteFiles.html', 'PartitionField.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'PendingUpdate.html', 'ReplaceManifests.html', 'ReplacePartitions.html', 'ReplacePartitionsOperation.html', 'RewriteFiles.html', 'RewriteManifests.html', 'Rollback.html', 'ScanSummary.Builder.html', 'ScanSummary.PartitionMetrics.html', 'ScanSummary.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'SetLocation.html', 'Snapshot.html', 'SnapshotParser.html', 'SnapshotSummary.Builder.html', 'SnapshotSummary.html', 'SnapshotUpdate.html', 'StructLike.html', 'SystemProperties.html', 'Table.html', 'TableMetadata.SnapshotLogEntry.html', 'TableMetadata.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableProperties.html', 'TableScan.html', 'Tables.html', 'Transaction.html', 'Transactions.html', 'UpdateLocation.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroIterable.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'LogicalMap.html', 'ProjectionDatumReader.html', 'UUIDConversion.html', 'ValueReader.html', 'ValueReaders.StructReader.html', 'ValueReaders.html', 'ValueWriter.html', 'ValueWriters.StructWriter.html', 'ValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Catalog.html', 'Namespace.html', 'TableIdentifier.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericRecord.html', 'IcebergGenerics.ScanBuilder.html', 'IcebergGenerics.html', 'Record.html', 'DataReader.html', 'DataWriter.html', 'IcebergDecoder.html', 'IcebergEncoder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericParquetReaders.html', 'GenericParquetWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'EncryptedFiles.html', 'EncryptedInputFile.html', 'EncryptedOutputFile.html', 'EncryptionKeyMetadata.html', 'EncryptionKeyMetadatas.html', 'EncryptionManager.html', 'PlaintextEncryptionManager.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Listener.html', 'Listeners.html', 'ScanEvent.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CommitFailedException.html', 'NoSuchTableException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'BoundPredicate.html', 'BoundReference.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'InclusiveManifestEvaluator.html', 'InclusiveMetricsEvaluator.html', 'Literal.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'StrictMetricsEvaluator.html', 'True.html', 'UnboundPredicate.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'HadoopFileIO.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTableOperations.html', 'HadoopTables.html', 'SerializableConfiguration.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'HiveCatalog.html', 'HiveCatalogs.html', 'HiveTableOperations.html', 'HiveTables.html', 'HiveTypeConverter.html', 'RuntimeMetaException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CloseableGroup.html', 'CloseableIterable.ConcatCloseableIterable.html', 'CloseableIterable.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'FileAppender.html', 'FileIO.html', 'InputFile.html', 'LocationProvider.html', 'OutputFile.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ColumnIdMap.html', 'ORC.ReadBuilder.html', 'ORC.WriteBuilder.html', 'ORC.html', 'OrcMetrics.html', 'OrcValueReader.html', 'OrcValueWriter.html', 'TypeConversion.html', 'VectorizedRowBatchIterator.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ColumnIterator.html', 'ColumnWriter.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetAvroReader.html', 'ParquetAvroValueReaders.TimeMillisReader.html', 'ParquetAvroValueReaders.TimestampMillisReader.html', 'ParquetAvroValueReaders.html', 'ParquetAvroWriter.html', 'ParquetDictionaryRowGroupFilter.html', 'ParquetIterable.html', 'ParquetMetricsRowGroupFilter.html', 'ParquetReader.html', 'ParquetSchemaUtil.html', 'ParquetTypeVisitor.html', 'ParquetUtil.html', 'ParquetValueReader.html', 'ParquetValueReaders.BinaryAsDecimalReader.html', 'ParquetValueReaders.BytesReader.html', 'ParquetValueReaders.FloatAsDoubleReader.html', 'ParquetValueReaders.IntAsLongReader.html', 'ParquetValueReaders.IntegerAsDecimalReader.html', 'ParquetValueReaders.ListReader.html', 'ParquetValueReaders.LongAsDecimalReader.html', 'ParquetValueReaders.MapReader.html', 'ParquetValueReaders.PrimitiveReader.html', 'ParquetValueReaders.RepeatedKeyValueReader.html', 'ParquetValueReaders.RepeatedReader.html', 'ParquetValueReaders.ReusableEntry.html', 'ParquetValueReaders.StringReader.html', 'ParquetValueReaders.StructReader.html', 'ParquetValueReaders.UnboxedReader.html', 'ParquetValueReaders.html', 'ParquetValueWriter.html', 'ParquetValueWriters.PrimitiveWriter.html', 'ParquetValueWriters.RepeatedKeyValueWriter.html', 'ParquetValueWriters.RepeatedWriter.html', 'ParquetValueWriters.StructWriter.html', 'ParquetValueWriters.html', 'ParquetWriteAdapter.html', 'TripleWriter.html', 'TypeToMessageType.html', 'TypeWithSchemaVisitor.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergPigInputFormat.IcebergRecordReader.html', 'IcebergPigInputFormat.html', 'IcebergStorage.html', 'PigParquetReader.html', 'SchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PruneColumnsWithReordering.html', 'PruneColumnsWithoutReordering.html', 'SparkFilters.html', 'SparkSchemaUtil.html', 'SparkAvroReader.html', 'SparkAvroWriter.html', 'SparkOrcReader.html', 'SparkOrcWriter.html', 'SparkParquetReaders.html', 'SparkParquetWriters.html', 'SparkValueReaders.html', 'SparkValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Hive.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSource.html', 'StreamingWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PartitionSpecVisitor.html', 'Transform.html', 'Transforms.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CheckCompatibility.html', 'Comparators.html', 'Conversions.html', 'IndexByName.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BinPacking.ListPacker.html', 'BinPacking.PackingIterable.html', 'BinPacking.html', 'ByteBuffers.html', 'CharSequenceWrapper.html', 'ExceptionUtil.html', 'Exceptions.html', 'JsonUtil.html', 'Pair.html', 'ParallelIterable.html', 'PropertyUtil.html', 'StructLikeWrapper.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'ThreadPools.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'overview-frame.html', 'overview-summary.html', 'overview-tree.html', 'package-list', 'serialized-form.html']"
Fix mkdocs and add missing footnotes to spec (#243),2,28,2019-07-06 11:40:00-07:00,"['README.md', 'spec.md']"
"Truncate string and binary stats from Parquet files (#254)

The default truncate length is 16 bytes for binary and fixed, and 16 characters for strings.",11,467,2019-07-06 12:01:03-07:00,"['Comparators.java', 'BinaryUtil.java', 'UnicodeUtil.java', 'TableProperties.java', 'Parquet.java', 'ParquetUtil.java', 'ParquetWriteAdapter.java', 'ParquetWriter.java', 'TestParquetMetricsTruncation.java', 'SparkTableUtil.scala', 'TestParquetScan.java']"
Minor updates to docs.,3,12,2019-07-06 13:07:27-07:00,"['api-quickstart.md', 'extra.css', 'spec.md']"
Exclude transitive artifacts already part of orc-core fat jar (#265),1,5,2019-07-07 11:36:27-07:00,['build.gradle']
Publish resolved versions in POMs (#270),1,5,2019-07-08 11:34:15-07:00,['build.gradle']
Simplify BucketUUID to remove thread local (#268),1,16,2019-07-08 12:45:17-07:00,['Bucket.java']
Build: always use UTF-8 for source files (#267),1,8,2019-07-08 17:36:01-07:00,['build.gradle']
Add table UUID (#264),7,109,2019-07-09 11:03:21-07:00,"['BaseMetastoreTableOperations.java', 'SnapshotProducer.java', 'TableMetadata.java', 'TableMetadataParser.java', 'HadoopTableOperations.java', 'TestTableMetadataJson.java', 'spec.md']"
Remove iceberg-presto-runtime that is no longer used (#271),5,85,2019-07-11 13:00:46-07:00,"['README.md', 'build.gradle', 'settings.gradle', 'api.md', 'versions.lock']"
Control metadata compression via table properties (#258),15,396,2019-07-12 11:02:30-07:00,"['BaseMetastoreTableOperations.java', 'ConfigProperties.java', 'TableMetadata.java', 'TableMetadataParser.java', 'TableProperties.java', 'HadoopTableOperations.java', 'TableMetadataParserCodecTest.java', 'TableMetadataParserTest.java', 'HadoopTableTestBase.java', 'TestHadoopCommits.java', 'HiveTableBaseTest.java', 'configuration.md', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'TestDataSourceOptions.java']"
Fix README link to latest spec (#273),1,2,2019-07-12 11:03:12-07:00,['README.md']
"Add metadata tables (#252)

This commit adds metadata tables:
* history -- the snapshot log
* snapshots -- known snapshots
* manifests -- manifest files for a snapshot
* files -- data files for a snapshot
* entries -- manifest entries for a snapshot",39,2514,2019-07-12 12:55:36-07:00,"['DataTask.java', 'FileFormat.java', 'HistoryEntry.java', 'ManifestFile.java', 'ScanTask.java', 'Table.java', 'TableScan.java', 'ManifestEvaluator.java', 'ResidualEvaluator.java', 'CloseableIterable.java', 'TestInclusiveManifestEvaluator.java', 'TestResiduals.java', 'BaseMetadataTable.java', 'BaseMetastoreCatalog.java', 'BaseTable.java', 'BaseTableScan.java', 'BaseTransaction.java', 'DataFiles.java', 'DataFilesTable.java', 'DataTableScan.java', 'FilteredManifest.java', 'HistoryTable.java', 'ManifestEntriesTable.java', 'ManifestGroup.java', 'ManifestsTable.java', 'SnapshotsTable.java', 'StaticDataTask.java', 'StaticTableScan.java', 'TableMetadata.java', 'TableMetadataParser.java', 'SnapshotUtil.java', 'TestDataTableScan.java', 'TestEntriesMetadataTable.java', 'TestTableMetadataJson.java', 'HiveCatalog.java', 'Reader.java', 'StructInternalRow.java', 'TestHelpers.java', 'TestIcebergSourceHiveTables.java']"
Fix iceberg-spark-runtime transitive dependencies (#275),1,11,2019-07-12 13:35:48-07:00,['build.gradle']
Remove BaseMetastoreTables and HiveTables (#284),2,189,2019-07-14 12:09:39-07:00,"['BaseMetastoreTables.java', 'HiveTables.java']"
Add metadata table docs.,2,138,2019-07-14 21:40:06-07:00,"['extra.css', 'spark.md']"
Make metrics collection configurable via table properties (#263),12,702,2019-07-15 10:43:20-07:00,"['MetricsConfig.java', 'MetricsModes.java', 'TableProperties.java', 'TestMetricsModes.java', 'Parquet.java', 'ParquetUtil.java', 'ParquetWriteAdapter.java', 'ParquetWriter.java', 'configuration.md', 'Writer.java', 'SparkTableUtil.scala', 'TestWriteMetricsConfig.java']"
Fix Parquet page size property (#291),1,2,2019-07-16 09:15:52-07:00,['Parquet.java']
Fix data files table for unpartitioned tables (#285),9,286,2019-07-16 09:44:16-07:00,"['Filterable.java', 'DataFilesTable.java', 'DataTableScan.java', 'FilteredManifest.java', 'ManifestEntriesTable.java', 'ManifestEntry.java', 'ManifestReader.java', 'Reader.java', 'TestIcebergSourceHiveTables.java']"
Add Spark application ID to snapshot summary (#282),3,21,2019-07-16 09:48:27-07:00,"['IcebergSource.java', 'StreamingWriter.java', 'Writer.java']"
Spark: Fix specForTable with unpartitioned tables (#292),1,5,2019-07-17 16:23:44-07:00,['SparkSchemaUtil.java']
Spark: Support loading Hive partitions that match a filter expression (#248),4,169,2019-07-17 16:37:04-07:00,"['HiveTableBaseTest.java', 'Hive.java', 'SparkTableUtil.scala', 'TestSparkTableUtil.java']"
Add multi AND helper method (#294),2,22,2019-07-18 08:52:49-07:00,"['Expressions.java', 'TestExpressionHelpers.java']"
"Fix RewriteManifests metadata after retry (#296)

SnapshotProducer caches ManifestFile metadata to avoid reading a manifest more than once when passed a ManifestFile without stats. ReplaceManifests reused manifest file names, which caused the new manifests to be stored with incorrect metadata.",1,5,2019-07-18 08:56:56-07:00,['ReplaceManifests.java']
Minor: Fix storage descriptor classes (#300),1,4,2019-07-19 13:12:33-07:00,['HiveTableOperations.java']
Fix typo in TableProperties class docs (#299),1,2,2019-07-19 13:12:58-07:00,['TableProperties.java']
Bucket transform: Use doubleToLongBits instead of doubleToRawLongBits (#303),2,6,2019-07-24 12:50:22-06:00,"['Bucket.java', 'spec.md']"
Fix typo in error message for day transform (#306),1,2,2019-07-24 13:00:13-06:00,['Transforms.java']
"Fix spelling, grammar, and formatting in the spec (#308)",1,82,2019-07-24 13:04:32-06:00,['spec.md']
Add argument validation to HadoopTables#create (#298),1,11,2019-07-25 14:25:52-07:00,['HadoopTables.java']
Install source JAR when running install target (#310),1,4,2019-07-25 14:30:47-07:00,['build.gradle']
Add projectStrict for Dates and Timestamps (#283),7,693,2019-07-26 14:06:30-07:00,"['Projections.java', 'ResidualEvaluator.java', 'Dates.java', 'ProjectionUtil.java', 'Timestamps.java', 'TestDatesProjection.java', 'TestTimestampsProjection.java']"
"Correctly publish artifacts on JitPack (#321)

The Gradle install target produces invalid POM files that are missing
the dependencyManagement section and versions for some dependencies.
Instead, we directly tell JitPack to run the correct Gradle target.",2,6,2019-07-26 14:51:00-07:00,"['build.gradle', 'jitpack.yml']"
Add build info to README.md (#304),1,3,2019-07-29 10:01:09-07:00,['README.md']
Convert Iceberg time type to Hive string type (#325),1,2,2019-07-29 12:09:21-07:00,['HiveTypeConverter.java']
Add overwrite option to write builders (#318),7,48,2019-07-30 09:31:58-07:00,"['ManifestListWriter.java', 'ManifestWriter.java', 'Avro.java', 'AvroFileAppender.java', 'ORC.java', 'Parquet.java', 'ParquetWriter.java']"
Fix out of order Pig partition fields (#326),1,8,2019-07-30 09:35:01-07:00,['IcebergPigInputFormat.java']
Add mapping to Iceberg for external name-based schemas (#338),12,1234,2019-07-31 14:44:05-07:00,"['SchemaUpdate.java', 'TableProperties.java', 'MappedField.java', 'MappedFields.java', 'MappingUtil.java', 'NameMapping.java', 'NameMappingParser.java', 'JsonUtil.java', 'TableTestBase.java', 'TestTables.java', 'TestMappingUpdates.java', 'TestNameMapping.java']"
Site: Fix broken link to Iceberg API (#333),1,2,2019-07-31 15:00:11-07:00,['spark.md']
Add forTable method for Avro WriteBuilder (#322),1,7,2019-07-31 15:02:01-07:00,['Avro.java']
Remove multiple literal strings check rule for scala (#335),1,6,2019-07-31 15:02:24-07:00,['scalastyle_config.xml']
Fix invalid javadoc url in README.md (#336),1,4,2019-07-31 15:16:26-07:00,['README.md']
"Use UnicodeUtil.truncateString for Truncate transform. (#340)

This truncates by unicode codepoint instead of Java chars.",1,3,2019-07-31 15:36:26-07:00,['Truncate.java']
Refactor metrics tests for reuse (#331),6,157,2019-07-31 17:20:03-07:00,"['build.gradle', 'TestMetrics.java', 'TestMetricsTruncation.java', 'ParquetWritingTestUtils.java', 'TestParquet.java', 'TestParquetMetrics.java']"
Spark: Add support for write-audit-publish workflows (#342),6,58,2019-08-01 13:05:56-07:00,"['SnapshotUpdate.java', 'SnapshotProducer.java', 'TableMetadata.java', 'TableProperties.java', 'IcebergSource.java', 'Writer.java']"
Avoid write failures if metrics mode is invalid (#301),3,54,2019-08-01 13:48:02-07:00,"['MetricsConfig.java', 'TableProperties.java', 'TestMetricsModes.java']"
"Fix truncateStringMax in UnicodeUtil (#334)

Fixes #328, fixes #329.

Index to codePointAt should be the offset calculated by code points",2,17,2019-08-01 13:50:10-07:00,"['UnicodeUtil.java', 'TestMetricsTruncation.java']"
"Add strict projections for Truncate transformations (#332)

This also includes new tests for residual evaluation.",6,782,2019-08-02 10:52:27-07:00,"['ProjectionUtil.java', 'Truncate.java', 'TestDatesProjection.java', 'TestTimestampsProjection.java', 'TestTruncatesProjection.java', 'TestTruncatesResiduals.java']"
Improve filtering in Snapshot#addedFiles (#341),2,73,2019-08-02 12:13:08-07:00,"['BaseSnapshot.java', 'ManifestReader.java']"
Remove stale Netflix copyright notice (#346),1,16,2019-08-02 12:14:52-07:00,['org.apache.spark.sql.sources.DataSourceRegister']
Refactor BaseMetastoreCatalog and remove dependency on Hadoop Configuration. (#347),2,30,2019-08-03 15:28:04-07:00,"['BaseMetastoreCatalog.java', 'HiveCatalog.java']"
Add Travis CI config for Python (#354),14,84,2019-08-06 12:41:53-07:00,"['.gitignore', '.travis.yml', '__init__.py', 'evaluator.py', 'strict_metrics_evaluator.py', 'bin_packing.py', '__init__.py', '__init__.py', 'test_helpers.py', '__init__.py', '__init__.py', '__init__.py', '__init__.py', 'test_bin_packing.py']"
Fix iceberg-spark-runtime lint and exclusions (#236),1,8,2019-08-06 17:33:23-07:00,['build.gradle']
Fix transaction cleanup (#352),2,106,2019-08-06 17:54:46-07:00,"['BaseTransaction.java', 'SnapshotProducer.java']"
Python: Remove unused dependencies (#355),2,8,2019-08-07 10:56:16-07:00,"['setup.py', 'tox.ini']"
Clean up after create and replace transaction failures (#364),3,266,2019-08-08 13:06:20-07:00,"['BaseTransaction.java', 'TestCreateTransaction.java', 'TestReplaceTransaction.java']"
Moving/Renameing hadoop module to filesystem (#277),25,1077,2019-08-09 12:18:43-07:00,"['avro_schema_util.py', 'base_metastore_table_operations.py', 'data_files.py', '__init__.py', 'file_status.py', 'file_system.py', 'filesystem_table_operations.py', 'filesystem_tables.py', 'local_filesystem.py', 's3_filesystem.py', 'util.py', 'file_system.py', 'hadoop_output_file.py', 'hadoop_table_operations.py', 's3_filesystem_wrapper.py', 'table_properties.py', '__init__.py', 'bin_packing.py', '__init__.py', '__init__.py', 'spark_catalog.py', 'table_identifier.py', 'setup.py', 'test_table_metadata_parser.py', 'tox.ini']"
Add public factory methods for NameMapping. (#367),1,13,2019-08-09 12:25:25-07:00,['NameMapping.java']
Minor update to BaseTransaction snapshot ID handling. (#368),1,16,2019-08-09 12:26:56-07:00,['BaseTransaction.java']
Return full stats for added files from Snapshot (#369),1,2,2019-08-12 11:10:21-07:00,['BaseSnapshot.java']
Add LICENSE and NOTICE to publication artifacts (#356),4,536,2019-08-12 11:11:23-07:00,"['build.gradle', 'LICENSE', 'NOTICE', 'versions.lock']"
"Supports startsWith predicates (#327)

Co-authored-by: Renato Marroquin <marenato@inf.ethz.ch>
Co-authored-by: Lior Baber <liorbaber@gmail.com>
Co-authored-by: Sujith Jay Nair <sujith@sujithjay.com>",12,175,2019-08-12 11:59:17-07:00,"['Evaluator.java', 'Expression.java', 'ExpressionVisitors.java', 'Expressions.java', 'Predicate.java', 'ResidualEvaluator.java', 'Bucket.java', 'ProjectionUtil.java', 'Truncate.java', 'TestExpressionBinding.java', 'TestStartsWith.java', 'TestTruncatesResiduals.java']"
Fix reading of old .metadata.json.gz files (#371),4,71,2019-08-13 10:14:23-07:00,"['TableMetadataParser.java', 'HadoopTableOperations.java', 'HadoopTableTestBase.java', 'TestHadoopCommits.java']"
Test metrics in files with multiple row groups (#365),3,196,2019-08-13 10:23:55-07:00,"['TestMetrics.java', 'ParquetWritingTestUtils.java', 'TestParquetMetrics.java']"
Allow read split behavior overrides (#372),10,216,2019-08-13 17:18:52-07:00,"['TableScan.java', 'BaseTableScan.java', 'DataFilesTable.java', 'DataTableScan.java', 'ManifestEntriesTable.java', 'StaticTableScan.java', 'TestSplitPlanning.java', 'configuration.md', 'Reader.java', 'TestDataSourceOptions.java']"
Return full stats for added files in snapshots (#379),3,49,2019-08-14 10:03:15-07:00,"['BaseSnapshot.java', 'ManifestReader.java', 'TestSnapshotSelection.java']"
Do not use original manifest list when adding filters. (#376),1,4,2019-08-14 11:24:07-07:00,['ManifestGroup.java']
Handle nulls in Conversions. (#383),1,8,2019-08-14 12:40:26-07:00,['Conversions.java']
Update formatting in python/README.md (#392),1,4,2019-08-14 16:40:37-07:00,['README.md']
Add missing test cases (#389),2,45,2019-08-15 09:15:55-07:00,"['TestScanSummary.java', 'AvroDataTest.java']"
"Make original ManifestReader factory method public. (#385)

This is easier to use when reading a manifest directly, even though the
partition spec will use the schema from when the manifest was written,
not the current table schema.",1,13,2019-08-15 09:17:35-07:00,['ManifestReader.java']
Add BaseCombinedScanTask.toString (#384),1,9,2019-08-15 09:17:59-07:00,['BaseCombinedScanTask.java']
Add FindFiles helper API (#377),4,380,2019-08-15 09:43:09-07:00,"['FindFiles.java', 'ManifestGroup.java', 'TableTestBase.java', 'TestFindFiles.java']"
Bringing type module into sync (#382),4,111,2019-08-19 16:43:51-07:00,"['conversions.py', 'type.py', 'type_util.py', 'types.py']"
Bringing expression implementations into a consistent state (#381),6,89,2019-08-19 16:52:36-07:00,"['evaluator.py', 'inclusive_manifest_evaluator.py', 'inclusive_metrics_evaluator.py', 'literals.py', 'residual_evaluator.py', 'strict_metrics_evaluator.py']"
Include column_sizes in stats columns (#393),2,9,2019-08-19 17:34:05-07:00,"['DataTableScan.java', 'TestScanDataFileColumns.java']"
Remove Hadoop Configuration dependency in BaseMetastoreTableOperations (#395),2,34,2019-08-20 09:40:43-07:00,"['BaseMetastoreTableOperations.java', 'HiveTableOperations.java']"
Fix create transaction metadata locations (#391),3,76,2019-08-22 11:38:30-07:00,"['BaseMetastoreTableOperations.java', 'BaseTransaction.java', 'TableOperations.java']"
Handle null values in transforms (#378),4,37,2019-08-22 11:40:14-07:00,"['Bucket.java', 'Dates.java', 'Timestamps.java', 'Truncate.java']"
"Minor updates to BaseMetastoreTableOperations (#390)

This includes 2 updates to BaseMetastoreTableOperations:

* Use overwrite to create metadata JSON files to avoid S3 negative caching
* Add an optional predicate to determine if loading metadata should be retried after an exception",3,45,2019-08-22 12:12:56-07:00,"['BaseMetastoreTableOperations.java', 'TableMetadataParser.java', 'Tasks.java']"
Hive: Improve error message when table type is not iceberg (#403) (#405),1,4,2019-08-23 11:27:55-07:00,['HiveTableOperations.java']
Propagate Hadoop config in SparkTableUtil (#402),1,19,2019-08-23 11:32:21-07:00,['SparkTableUtil.scala']
"Optimize overwrite and delete commits (#387)

This uses manifest metadata to avoid filtering manifests that cannot
contain deleted files in overwrite and delete operations.",4,194,2019-08-24 13:00:48-07:00,"['MergingSnapshotProducer.java', 'ReplaceFiles.java', 'ManifestFileUtil.java', 'StructLikeWrapper.java']"
Hive: Wait between lock state requests to HMS (#401),2,33,2019-08-24 13:45:20-07:00,"['HiveTableOperations.java', 'HiveTableTest.java']"
Add dropTable purge option to Catalog API (#350),5,207,2019-08-26 10:05:55-07:00,"['Catalog.java', 'BaseMetastoreCatalog.java', 'HiveCatalog.java', 'HiveTableBaseTest.java', 'HiveTableTest.java']"
Use null counts in metrics evaluators (#412),4,136,2019-08-26 10:23:12-07:00,"['InclusiveMetricsEvaluator.java', 'StrictMetricsEvaluator.java', 'TestInclusiveMetricsEvaluator.java', 'TestStrictMetricsEvaluator.java']"
Add toByteBuffer to Literal (#414),4,141,2019-08-26 11:21:12-07:00,"['Literal.java', 'Literals.java', 'Conversions.java', 'TestConversions.java']"
Add validation in OverwriteFiles for eager updates and deletes (#351),6,735,2019-08-26 14:24:08-07:00,"['OverwriteFiles.java', 'InclusiveMetricsEvaluator.java', 'OverwriteData.java', 'TableTestBase.java', 'TestOverwrite.java', 'TestOverwriteWithValidation.java']"
Support create and replace transactions in Catalog (#362),10,637,2019-08-26 15:53:53-07:00,"['Catalog.java', 'build.gradle', 'BaseMetastoreCatalog.java', 'BaseMetastoreTableOperations.java', 'BaseTransaction.java', 'Transactions.java', 'HiveTableOperations.java', 'HiveCreateReplaceTableTest.java', 'HiveMetastoreTest.java', 'HiveTableBaseTest.java']"
Push down StringStartsWith in Spark IcebergSource (#398),13,400,2019-08-27 10:16:08-07:00,"['InclusiveMetricsEvaluator.java', 'ManifestEvaluator.java', 'ResidualEvaluator.java', 'StrictMetricsEvaluator.java', 'BinaryUtil.java', 'TestInclusiveManifestEvaluator.java', 'TestInclusiveMetricsEvaluator.java', 'ParquetDictionaryRowGroupFilter.java', 'ParquetMetricsRowGroupFilter.java', 'TestDictionaryRowGroupFilter.java', 'TestMetricsRowGroupFilter.java', 'SparkFilters.java', 'TestFilteredScan.java']"
"Handle rollback in snapshot expiration (#388)

This fixes snapshot expiration to handle rollbacks. When a table's state
is rolled back, manifests and data files from the commit must be handled
differently. Files added in the commit should be physically deleted and
files deleted should not be physically deleted.

This also applies some optimizations to ignore manifests that do not
need to be scanned during expiration because they contain no deletes.",1,181,2019-08-27 10:17:02-07:00,['RemoveSnapshots.java']
"Remove unreferenced hash computations (#349)

The types float, double, and boolean are excluded from bucket
partitioning, which is the only part of the spec that uses hashing. As
such, we can remove these types from ""Appendix B: 32-bit Hash
Requirements"".",1,21,2019-08-27 12:50:00-07:00,['spec.md']
Move generic checks into BaseMetastoreTableOperations (#419),2,22,2019-08-27 14:54:05-07:00,"['BaseMetastoreTableOperations.java', 'HiveTableOperations.java']"
Fix copies in partition data and field summaries (#386),3,52,2019-08-27 15:31:59-07:00,"['GenericPartitionFieldSummary.java', 'PartitionData.java', 'ByteBuffers.java']"
Docs: Add custom catalog docs (#416),2,136,2019-08-27 16:13:30-07:00,"['custom-catalog.md', 'mkdocs.yml']"
"Keep format forward-compatible with future transforms (#411)

This includes the following squashed commits:
[code review] Use TestHelpers to assert thrown exception
[code review] fix format
[code review] No need for an named reference argument
[code review] Public API should throw IllegalArgumentException when trying to add an unsupported transforms",8,414,2019-08-28 09:05:24-07:00,"['PartitionSpec.java', 'Transform.java', 'Transforms.java', 'UnknownTransform.java', 'TestTransformSerialization.java', 'build.gradle', 'IcebergSource.java', 'TestForwardCompatibility.java']"
Produce date types from day partition transforms (#424),4,46,2019-08-28 14:12:10-07:00,"['Dates.java', 'Timestamps.java', 'TestDates.java', 'TestTimestamps.java']"
Fix Literal serializability (#425),2,18,2019-08-29 09:12:59-07:00,"['Literals.java', 'TestFilteredScan.java']"
Improve exception messages for embedded metastore failures (#406),3,18,2019-08-29 12:05:40-07:00,"['HiveClientPool.java', 'HiveTableOperations.java', 'RuntimeMetaException.java']"
Fix float conversion in fromPartitionString (#431),1,2,2019-08-30 09:41:45-07:00,['Conversions.java']
"Add commit.manifest-merge.enabled property (#420)

This property can disable manifest merging. This is intended to be used
with RewriteManifests. Instead of automatic merging, RewriteManifests is
used to maintain metadata.",2,53,2019-08-30 09:42:31-07:00,"['MergingSnapshotProducer.java', 'TableProperties.java']"
Fix flaky TestScanSummary test (#433),1,6,2019-09-02 14:22:01-07:00,['TestScanSummary.java']
"Use a shared client in Hive table tests (#427)

* Share a catalog in TestIcebergSourceHiveTables to fix parallel failures
* Use a client pool in TestIcebergSourceHiveTables instead of a client
* Reuse Hive connection from Spark",4,199,2019-09-03 09:23:58-07:00,"['ClientPool.java', 'HiveClientPool.java', 'Hive.java', 'TestIcebergSourceHiveTables.java']"
Python: Fix test failing CI builds (#445),5,13,2019-09-03 15:11:21-07:00,"['residual_evaluator.py', 'types.py', 'avro_schema_util.py', 's3_filesystem.py', 'table_properties.py']"
Move Hive concurrency tests and run one at a time (#450),2,186,2019-09-04 10:00:31-07:00,"['HiveTableTest.java', 'TestHiveTableConcurrency.java']"
Use constant readers for Pig partition values. (#444),3,104,2019-09-04 10:51:12-07:00,"['ParquetValueReaders.java', 'IcebergPigInputFormat.java', 'PigParquetReader.java']"
Rename some implementations for consistency (#380),8,42,2019-09-04 16:15:46-07:00,"['BaseOverwriteFiles.java', 'BaseReplacePartitions.java', 'BaseRewriteFiles.java', 'BaseRewriteManifests.java', 'BaseTable.java', 'BaseTransaction.java', 'TestRewriteFiles.java', 'TestRewriteManifests.java']"
"Add missing manifest cleanup tests. (#418)

+1",1,113,2019-09-04 16:56:55-07:00,['TestManifestCleanup.java']
Update PartitionSpec ID assignment comment (#448),1,2,2019-09-05 09:19:54-07:00,['PartitionSpec.java']
"Add null check in GenericRecord#get method (#443)

Fix failures when the value is null.",3,66,2019-09-05 13:57:07-07:00,"['build.gradle', 'GenericRecord.java', 'TestGenericRecord.java']"
Add short-circuit logic to evaluators (#442),7,63,2019-09-06 13:02:29-07:00,"['Evaluator.java', 'ExpressionVisitors.java', 'InclusiveMetricsEvaluator.java', 'ManifestEvaluator.java', 'StrictMetricsEvaluator.java', 'ParquetDictionaryRowGroupFilter.java', 'ParquetMetricsRowGroupFilter.java']"
Run flaky test suite one test at a time. (#455),1,14,2019-09-06 13:22:52-07:00,['TestIcebergSourceHiveTables.java']
Add SparkTableUtil import from a Hive table to a Hadoop table (#374),3,182,2019-09-06 13:24:09-07:00,"['TestHiveMetastore.java', 'SparkTableUtil.scala', 'TestSparkTableUtil.java']"
Update Avro test schemas to use unique IDs (#456),3,47,2019-09-06 13:25:04-07:00,"['TypeUtil.java', 'TestCreateTransaction.java', 'AvroDataTest.java']"
Throw NotFoundException from IO methods when file does not exist (#454),4,42,2019-09-06 13:26:19-07:00,"['Files.java', 'NotFoundException.java', 'InputFile.java', 'HadoopInputFile.java']"
Spark: Create data files using overwrite (#453),1,2,2019-09-09 11:10:16+03:00,['Writer.java']
[python] Adding a string to iceberg expression converter an tests (#426),3,218,2019-09-10 15:57:46-07:00,"['expressions.py', 'setup.py', 'test_str_to_expr.py']"
Make MappedField and MappedFields factory methods public (#465),2,12,2019-09-11 17:20:36-07:00,"['MappedField.java', 'MappedFields.java']"
Add key_metadata to DataTableScan SCAN_COLUMNS (#469),1,2,2019-09-11 17:30:06-07:00,['DataTableScan.java']
Spark: Add a unit test for importing existing tables as Iceberg Hive tables (#461),1,26,2019-09-12 16:55:15+03:00,['TestSparkTableUtil.java']
"Fix BaseTransaction to allow create and append in the same transaction (#472)

Fixes #471",2,28,2019-09-12 20:59:39+03:00,"['BaseTransaction.java', 'HiveCreateReplaceTableTest.java']"
Spec: Update day transform to produce date type (#447),1,2,2019-09-13 09:09:31-07:00,['spec.md']
Throw exception in ReassignIds when a field is missing (#438),2,45,2019-09-13 09:49:23-07:00,"['ReassignIds.java', 'TestTypeUtil.java']"
Optimize ParquetMetricsRowGroupFilter by using ByteBuffer (#473),1,17,2019-09-13 17:53:02-07:00,['ParquetMetricsRowGroupFilter.java']
Throw NotFoundException in LocalOutputFile (#466),2,3,2019-09-19 13:19:24-07:00,"['.gitignore', 'Files.java']"
Add metadata tables for path-based tables (#458),9,530,2019-09-19 14:54:20-07:00,"['BaseMetastoreCatalog.java', 'DataFilesTable.java', 'HistoryTable.java', 'ManifestEntriesTable.java', 'ManifestsTable.java', 'MetadataTableType.java', 'SnapshotsTable.java', 'HadoopTables.java', 'TestIcebergSourceHadoopTables.java']"
Add Concurrency presentation PDF.,1,0,2019-09-19 16:13:05-07:00,['Concurrency in Iceberg.pdf']
"Add deleteFile(DataFile) to StreamingDelete (#486)

This allows the underlying implementation to keep track of partitions with deleted data for filtering manifest files that may contain deleted data files.",1,6,2019-09-19 16:53:10-07:00,['StreamingDelete.java']
Fix import test to use correct source tables (#478),1,8,2019-09-19 16:56:00-07:00,['TestSparkTableUtil.java']
Refactor tests to use AssertHelpers.assertThrows (#485),10,136,2019-09-19 17:28:39-07:00,"['AssertHelpers.java', 'TestHelpers.java', 'TestPartitionSpecValidation.java', 'TestEvaluator.java', 'TestExpressionHelpers.java', 'TestInclusiveManifestEvaluator.java', 'TestInclusiveMetricsEvaluator.java', 'TestStrictMetricsEvaluator.java', 'TestProjection.java', 'build.gradle']"
Enable build without .git directory (#468),1,47,2019-09-20 13:09:48-07:00,['build.gradle']
Add TIME_MICROS support to GenericParquetReaders (#487),2,17,2019-09-23 10:40:17-07:00,"['GenericParquetReaders.java', 'DataTest.java']"
Bump Apache Parquet to 1.10.1 (#488),2,14,2019-09-23 10:53:38-07:00,"['versions.lock', 'versions.props']"
Spark: Allow limiting output data file size (#432),5,374,2019-09-24 16:24:16-07:00,"['TableProperties.java', 'ParquetWriter.java', 'configuration.md', 'Writer.java', 'TestParquetWrite.java']"
Parquet: Throw an exception if a dictionary is missing (#93),2,14,2019-09-24 16:28:00-07:00,"['ParquetDictionaryRowGroupFilter.java', 'TestDictionaryRowGroupFilter.java']"
Add custom field names to PartitionSpec builder (#498),2,155,2019-09-27 09:53:59-07:00,"['PartitionSpec.java', 'TestPartitionSpecValidation.java']"
Fix snapshot summary data for appended manifests (#503),6,41,2019-09-30 10:53:27-07:00,"['MergingSnapshotProducer.java', 'ScanSummary.java', 'SnapshotProducer.java', 'SnapshotSummary.java', 'TestFastAppend.java', 'TestMergeAppend.java']"
Update Apache Spark dependency to 2.4.4 (#489),3,41,2019-09-30 15:09:41-07:00,"['README.md', 'versions.lock', 'versions.props']"
Support date format in Conversions.fromPartitionString (#506),2,70,2019-09-30 16:03:10-07:00,"['Conversions.java', 'TestTimestampPartitions.java']"
Spark: Remove flaky Hive table tests (#509),1,386,2019-10-01 08:48:28+01:00,['TestIcebergSourceHiveTables.java']
"[python] Part 1 of adding parquet read path (#407)

+1 LGTM.  Thanks Ted",45,1904,2019-10-03 12:19:22-07:00,"['__init__.py', 'data_file.py', 'data_operations.py', 'file_format.py', 'file_scan_task.py', 'files.py', 'manifest_file.py', 'partition_spec.py', 'schema.py', 'snapshot.py', 'table_scan.py', 'tables.py', '__init__.py', 'avro_to_iceberg.py', 'base_combined_scan_task.py', 'base_file_scan_task.py', 'base_metastore_table_operations.py', 'base_snapshot.py', 'base_table.py', 'base_table_scan.py', 'data_files.py', 'data_table_scan.py', 'filtered_manifest.py', 'generic_data_file.py', 'generic_manifest_file.py', 'generic_partition_field_summary.py', 'manifest_entry.py', 'manifest_reader.py', 'partition_data.py', 'partition_summary.py', 'scan_summary.py', 'schema_parser.py', 'snapshot_parser.py', 'table_metadata.py', 'table_metadata_parser.py', '__init__.py', 'setup.py', 'test_inclusive_manifest_evaluator.py', 'test_file_format.py', 'conftest.py', 'test_read_projection.py', 'conftest.py', 'test_base_table_scan.py', 'test_snapshot_json.py', 'test_bin_packing.py']"
Docs: set append mode for Spark append (#517),1,5,2019-10-08 08:35:15-07:00,['spark.md']
Docs: Fix typos (#523),4,12,2019-10-09 09:01:56-07:00,"['partitioning.md', 'reliability.md', 'spark.md', 'spec.md']"
Expose partition specs from Table (#511),6,126,2019-10-09 09:19:50-07:00,"['Table.java', 'BaseMetadataTable.java', 'BaseTable.java', 'BaseTransaction.java', 'TableMetadata.java', 'TestPartitionSpecInfo.java']"
Hive: Fix concurrency issue in HiveTableOperations when Table is reused (#513),2,26,2019-10-09 19:20:34+01:00,"['HiveTableOperations.java', 'TestHiveTableConcurrency.java']"
Update docs to Gradle 5.4.1 (#527),1,2,2019-10-09 13:38:10-07:00,['README.md']
"Update build for Apache releases (#531)

* Add Apache publication
* Add source, javadoc, and test artifacts with signatures to publication
* Add Apache snapshot and release repositories
* Add metadata to publication POM files
* Add missing licenses and update RAT excludes
* Add DISCLAIMER
* Add disclaimer page to ASF site
* Add release scripts",35,671,2019-10-10 10:27:36-07:00,"['DISCLAIMER', 'build.gradle', '.rat-excludes', 'source-release.sh', 'stage-binaries.sh', 'gradle.properties', 'jitpack.yml', 'CHANGELOG.md', 'README.md', 'test_str_to_expr.py', 'test_file_format.py', 'test_helpers.py', 'conftest.py', 'test_avro.py', 'test_read_projection.py', '__init__.py', 'tox.ini', 'api-quickstart.md', 'api.md', 'configuration.md', 'custom-catalog.md', 'disclaimer.md', 'evolution.md', 'getting-started.md', 'partitioning.md', 'performance.md', 'presto.md', 'reliability.md', 'schemas.md', 'snapshots.md', 'spark.md', 'spec.md', 'terms.md', 'mkdocs.yml', 'version.txt']"
Avoid NullPointerException when a source column is missing (#532),1,2,2019-10-10 10:42:57-07:00,['PartitionSpec.java']
Remove version.txt accidentally in release update PR (#534),1,1,2019-10-10 11:21:22-07:00,['version.txt']
Update Jackson to 2.9.10 for CVE-2019-14379 (#535),2,20,2019-10-10 12:18:20-07:00,"['versions.lock', 'versions.props']"
"Fix connection leak in Hive table tests (#538)

This is another attempt to fix the connection leak in the Hive table tests. The current theory is that the cache in HiveCatalogs is not behaving correctly. Because it uses weak keys, garbage collection will almost always remove the cached catalog between SQL queries, and the next query will result in a new connection to the metastore. The garbage collected catalog is not closed in this case.

This fixes the leak in two ways:

1. Use a fixed duration after the last access, 10 minutes, to expire catalogs
2. Because catalogs are expired instead of garbage collected, use a removal listener to close
3. Add a catch-all finalizer to HiveCatalog to ensure that catalogs are closed when leaked, and a stack trace is logged to help fix the leak",3,417,2019-10-11 23:24:29+01:00,"['HiveCatalog.java', 'HiveCatalogs.java', 'TestIcebergSourceHiveTables.java']"
Remove comment handling in Schema because field handles it (#547),1,2,2019-10-14 22:57:57+01:00,['Schema.java']
"Update license docs for 0.7.0 release (#548)

* Remove gradle-wrapper.jar that should be downloaded
* Add gradlew and gradle/wrapper/gradle-wrapper.properties to LICENSE
* Add license header to Hive Metastore schema SQL file",4,35,2019-10-14 17:59:45-07:00,"['LICENSE', 'gradle-wrapper.jar', 'gradlew', 'hive-schema-3.1.0.derby.sql']"
Use Java collections in GenericDataFile to fix Kryo serialization (#546),3,155,2019-10-15 09:36:42-07:00,"['DataFiles.java', 'GenericDataFile.java', 'TestKryoSerialization.java']"
Add How to Release docs (#536),2,121,2019-10-15 13:25:17-07:00,"['how-to-release.md', 'mkdocs.yml']"
Handle empty path in DataFiles.Builder.withPartitionPath (#554),3,20,2019-10-17 09:22:38-07:00,"['DataFiles.java', 'TestReplacePartitions.java', 'SparkTableUtil.scala']"
Bump ORC from 1.5.5 to 1.5.6 (#550),2,6,2019-10-17 09:39:48-07:00,"['versions.lock', 'versions.props']"
Site: Add Python API and quickstart docs (#551),5,311,2019-10-17 17:22:46-07:00,"['README.md', 'python-api-intro.md', 'python-feature-support.md', 'python-quickstart.md', 'mkdocs.yml']"
Fix NullPointerException in FindFiles when there is no snapshot (#543),2,17,2019-10-18 09:05:38-07:00,"['FindFiles.java', 'TestFindFiles.java']"
Fix Kryo serialization in ParquetUtil.getSplitOffsets (#556),2,37,2019-10-18 09:06:20-07:00,"['ParquetUtil.java', 'TestKryoSerialization.java']"
"Python: Support reading Iceberg tables in a Hive metastore (#530)

This implements the same conventions for storing Iceberg metadata in the Hive Metastore that are used by the Java implementation.",9,301,2019-10-18 11:28:12-07:00,"['__init__.py', 'hive_table_operations.py', 'hive_tables.py', 'setup.py', 'test_str_to_expr.py', '__init__.py', 'conftest.py', 'test_hive_tables.py', 'tox.ini']"
Fix JitPack builds (#557),1,8,2019-10-18 12:41:36-07:00,['build.gradle']
"Python: Fix status in ManifestEntry, remove unused configs (#558)",2,6,2019-10-18 13:20:07-07:00,"['manifest_entry.py', '__init__.py']"
Fix key metadata Kryo serialization (#560),2,164,2019-10-18 15:06:10-07:00,"['GenericDataFile.java', 'TestDataFileSerialization.java']"
Use OutputFile.location to track metadata JSON files (#566),2,26,2019-10-18 17:01:20-07:00,"['BaseMetastoreTableOperations.java', 'HiveCreateReplaceTableTest.java']"
"Avro: Add name to ID mapping for files with name-based schemas (#207)

Fixes #40.",9,581,2019-10-22 10:47:52-07:00,"['Avro.java', 'AvroSchemaUtil.java', 'AvroSchemaVisitor.java', 'BuildAvroProjection.java', 'ProjectionDatumReader.java', 'PruneColumns.java', 'RemoveIds.java', 'TestAvroNameMapping.java', 'IcebergDecoder.java']"
Baseline: Add Baseline to iceberg-parquet (#526),30,953,2019-10-22 11:17:28-07:00,"['build.gradle', 'ColumnIterator.java', 'ColumnWriter.java', 'MessageTypeToType.java', 'PageIterator.java', 'Parquet.java', 'ParquetAvro.java', 'ParquetAvroValueReaders.java', 'ParquetAvroWriter.java', 'ParquetDictionaryRowGroupFilter.java', 'ParquetFilters.java', 'ParquetIO.java', 'ParquetIterable.java', 'ParquetMetricsRowGroupFilter.java', 'ParquetReadSupport.java', 'ParquetReader.java', 'ParquetSchemaUtil.java', 'ParquetTypeVisitor.java', 'ParquetUtil.java', 'ParquetValueReaders.java', 'ParquetValueWriters.java', 'ParquetWriter.java', 'PruneColumns.java', 'TypeWithSchemaVisitor.java', 'TestHelpers.java', 'ParquetWritingTestUtils.java', 'TestDictionaryRowGroupFilter.java', 'TestMetricsRowGroupFilter.java', 'TestMetricsRowGroupFilterTypes.java', 'TestParquetMetrics.java']"
Update copyright dates in NOTICE (#573),1,2,2019-10-25 12:53:25-07:00,['NOTICE']
"Update docs for the 0.7.0-incubating release (#579)

* Update docs for the 0.7.0-incubating release
* Add 0.7.0-incubating Javadoc",428,140378,2019-10-27 13:43:25-07:00,"['how-to-release.md', 'allclasses-frame.html', 'allclasses-noframe.html', 'constant-values.html', 'deprecated-list.html', 'help-doc.html', 'index-all.html', 'index.html', 'Accessor.html', 'Accessors.html', 'AppendFiles.html', 'BaseCombinedScanTask.html', 'BaseMetastoreCatalog.html', 'BaseMetastoreTableOperations.html', 'BaseOverwriteFiles.html', 'BaseReplacePartitions.html', 'BaseRewriteManifests.html', 'BaseTable.html', 'CombinedScanTask.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DataFilesTable.FilesTableScan.html', 'DataFilesTable.html', 'DataOperations.html', 'DataTableScan.html', 'DataTask.html', 'DeleteFiles.html', 'ExpireSnapshots.html', 'FileFormat.html', 'FileHistory.Builder.html', 'FileHistory.html', 'FileScanTask.html', 'Files.html', 'Filterable.html', 'FilteredManifest.html', 'FindFiles.Builder.html', 'FindFiles.html', 'GenericManifestFile.html', 'GenericPartitionFieldSummary.html', 'HasTableOperations.html', 'HistoryEntry.html', 'HistoryTable.html', 'LocationProviders.html', 'ManifestEntriesTable.html', 'ManifestFile.PartitionFieldSummary.html', 'ManifestFile.html', 'ManifestReader.html', 'ManifestWriter.html', 'ManifestsTable.html', 'MetadataTableType.html', 'Metrics.html', 'MetricsConfig.html', 'MetricsModes.Counts.html', 'MetricsModes.Full.html', 'MetricsModes.MetricsMode.html', 'MetricsModes.None.html', 'MetricsModes.Truncate.html', 'MetricsModes.html', 'OverwriteFiles.html', 'PartitionField.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'PendingUpdate.html', 'ReplacePartitions.html', 'RewriteFiles.html', 'RewriteManifests.html', 'Rollback.html', 'ScanSummary.Builder.html', 'ScanSummary.PartitionMetrics.html', 'ScanSummary.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'SetLocation.html', 'Snapshot.html', 'SnapshotParser.html', 'SnapshotSummary.Builder.html', 'SnapshotSummary.html', 'SnapshotUpdate.html', 'SnapshotsTable.html', 'StructLike.html', 'SystemProperties.html', 'Table.html', 'TableMetadata.SnapshotLogEntry.html', 'TableMetadata.html', 'TableMetadataParser.Codec.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableProperties.html', 'TableScan.html', 'Tables.html', 'Transaction.html', 'Transactions.html', 'UpdateLocation.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroIterable.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'LogicalMap.html', 'ProjectionDatumReader.html', 'UUIDConversion.html', 'ValueReader.html', 'ValueReaders.StructReader.html', 'ValueReaders.html', 'ValueWriter.html', 'ValueWriters.StructWriter.html', 'ValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Catalog.html', 'Namespace.html', 'TableIdentifier.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericRecord.html', 'IcebergGenerics.ScanBuilder.html', 'IcebergGenerics.html', 'Record.html', 'DataReader.html', 'DataWriter.html', 'IcebergDecoder.html', 'IcebergEncoder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericParquetReaders.html', 'GenericParquetWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'EncryptedFiles.html', 'EncryptedInputFile.html', 'EncryptedOutputFile.html', 'EncryptionKeyMetadata.html', 'EncryptionKeyMetadatas.html', 'EncryptionManager.html', 'PlaintextEncryptionManager.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Listener.html', 'Listeners.html', 'ScanEvent.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CommitFailedException.html', 'NoSuchTableException.html', 'NotFoundException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'BoundPredicate.html', 'BoundReference.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'InclusiveMetricsEvaluator.html', 'Literal.html', 'ManifestEvaluator.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'StrictMetricsEvaluator.html', 'True.html', 'UnboundPredicate.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'HadoopFileIO.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTableOperations.html', 'HadoopTables.html', 'SerializableConfiguration.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ClientPool.Action.html', 'ClientPool.html', 'HiveCatalog.html', 'HiveCatalogs.html', 'HiveClientPool.html', 'HiveTableOperations.html', 'HiveTypeConverter.html', 'RuntimeMetaException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CloseableGroup.html', 'CloseableIterable.ConcatCloseableIterable.html', 'CloseableIterable.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'FileAppender.html', 'FileIO.html', 'InputFile.html', 'LocationProvider.html', 'OutputFile.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'MappedField.html', 'MappedFields.html', 'MappingUtil.html', 'NameMapping.html', 'NameMappingParser.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ColumnIdMap.html', 'ORC.ReadBuilder.html', 'ORC.WriteBuilder.html', 'ORC.html', 'OrcMetrics.html', 'OrcValueReader.html', 'OrcValueWriter.html', 'TypeConversion.html', 'VectorizedRowBatchIterator.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ColumnIterator.html', 'ColumnWriter.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetAvroReader.html', 'ParquetAvroValueReaders.TimeMillisReader.html', 'ParquetAvroValueReaders.TimestampMillisReader.html', 'ParquetAvroValueReaders.html', 'ParquetAvroWriter.html', 'ParquetDictionaryRowGroupFilter.html', 'ParquetIterable.html', 'ParquetMetricsRowGroupFilter.html', 'ParquetReader.html', 'ParquetSchemaUtil.html', 'ParquetTypeVisitor.html', 'ParquetUtil.html', 'ParquetValueReader.html', 'ParquetValueReaders.BinaryAsDecimalReader.html', 'ParquetValueReaders.BytesReader.html', 'ParquetValueReaders.FloatAsDoubleReader.html', 'ParquetValueReaders.IntAsLongReader.html', 'ParquetValueReaders.IntegerAsDecimalReader.html', 'ParquetValueReaders.ListReader.html', 'ParquetValueReaders.LongAsDecimalReader.html', 'ParquetValueReaders.MapReader.html', 'ParquetValueReaders.PrimitiveReader.html', 'ParquetValueReaders.RepeatedKeyValueReader.html', 'ParquetValueReaders.RepeatedReader.html', 'ParquetValueReaders.ReusableEntry.html', 'ParquetValueReaders.StringReader.html', 'ParquetValueReaders.StructReader.html', 'ParquetValueReaders.UnboxedReader.html', 'ParquetValueReaders.html', 'ParquetValueWriter.html', 'ParquetValueWriters.PrimitiveWriter.html', 'ParquetValueWriters.RepeatedKeyValueWriter.html', 'ParquetValueWriters.RepeatedWriter.html', 'ParquetValueWriters.StructWriter.html', 'ParquetValueWriters.html', 'ParquetWriteAdapter.html', 'TripleWriter.html', 'TypeToMessageType.html', 'TypeWithSchemaVisitor.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergPigInputFormat.IcebergRecordReader.html', 'IcebergPigInputFormat.html', 'IcebergStorage.html', 'PigParquetReader.html', 'SchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PruneColumnsWithReordering.html', 'PruneColumnsWithoutReordering.html', 'SparkFilters.html', 'SparkSchemaUtil.html', 'SparkAvroReader.html', 'SparkAvroWriter.html', 'SparkOrcReader.html', 'SparkOrcWriter.html', 'SparkParquetReaders.html', 'SparkParquetWriters.html', 'SparkValueReaders.html', 'SparkValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Hive.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSource.html', 'StreamingWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PartitionSpecVisitor.html', 'Transform.html', 'Transforms.html', 'UnknownTransform.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CheckCompatibility.html', 'Comparators.html', 'Conversions.html', 'IndexByName.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BinPacking.ListPacker.html', 'BinPacking.PackingIterable.html', 'BinPacking.html', 'BinaryUtil.html', 'ByteBuffers.html', 'CharSequenceWrapper.html', 'ExceptionUtil.html', 'Exceptions.html', 'JsonUtil.html', 'ManifestFileUtil.html', 'Pair.html', 'ParallelIterable.html', 'PropertyUtil.html', 'SnapshotUtil.html', 'StructLikeWrapper.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'ThreadPools.html', 'UnicodeUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'overview-frame.html', 'overview-summary.html', 'overview-tree.html', 'package-list', 'script.js', 'serialized-form.html', 'stylesheet.css', 'index.html', 'releases.md', 'mkdocs.yml']"
Update .gitignore exclusions (#581),1,6,2019-10-27 13:44:00-07:00,['.gitignore']
Apply Baseline to iceberg-pig (#525),8,386,2019-10-27 14:06:22-07:00,"['build.gradle', 'IcebergPigInputFormat.java', 'IcebergStorage.java', 'PigParquetReader.java', 'SchemaUtil.java', 'SchemaUtilTest.java', 'versions.lock', 'versions.props']"
"Replace StringBuffer by StringBuilder (#539)

incubator-iceberg/api/src/main/java/org/apache/iceberg/util/UnicodeUtil.java:44: warning:
[JdkObsolete] StringBuffer performs synchronization that is usually unnecessary; prefer StringBuilder.",2,20,2019-10-27 14:34:24-07:00,"['UnicodeUtil.java', 'ScriptRunner.java']"
"Update Jackson to 2.10.0 for CVE-2019-16943 (#583)

Fixes #582",2,12,2019-10-28 14:44:01+01:00,"['versions.lock', 'versions.props']"
Use a map of partition specs in ManifestReader::read (#467),8,39,2019-10-29 21:32:46+00:00,"['BaseRewriteManifests.java', 'DataTableScan.java', 'FastAppend.java', 'ManifestGroup.java', 'ManifestReader.java', 'MergingSnapshotProducer.java', 'RemoveSnapshots.java', 'SnapshotProducer.java']"
"Avro: Infer a name mapping when Avro has no IDs (#580)

Fixes #528",6,164,2019-10-30 13:59:45-07:00,"['AvroSchemaUtil.java', 'HasIds.java', 'ProjectionDatumReader.java', 'RemoveIds.java', 'TestAvroNameMapping.java', 'TestHasIds.java']"
Add IN and NOT_IN predicates (#594),19,936,2019-10-31 12:58:05-07:00,"['Binder.java', 'BoundPredicate.java', 'BoundSetPredicate.java', 'Evaluator.java', 'ExpressionVisitors.java', 'Expressions.java', 'InclusiveMetricsEvaluator.java', 'Literals.java', 'ManifestEvaluator.java', 'Predicate.java', 'StrictMetricsEvaluator.java', 'UnboundPredicate.java', 'CharSequenceWrapper.java', 'TestHelpers.java', 'TestEvaluator.java', 'TestExpressionSerialization.java', 'TestPredicateBinding.java', 'ParquetDictionaryRowGroupFilter.java', 'ParquetMetricsRowGroupFilter.java']"
Remove checkstyle .swp file.,1,0,2019-10-31 14:12:50-07:00,['.checkstyle.xml.swp']
Pig: Scope config specific to LOAD using signatures (#593),2,39,2019-10-31 14:31:02-07:00,"['IcebergPigInputFormat.java', 'IcebergStorage.java']"
Refactor the build into multiple gradle scripts (#599),5,457,2019-11-01 13:13:05+00:00,"['baseline.gradle', 'build.gradle', 'deploy.gradle', 'jmh.gradle', 'tasks.gradle']"
Disable ErrorProne for JMH generated classes (#606),1,4,2019-11-06 11:21:48+02:00,['jmh.gradle']
Add explicit override annotations to fix warnings in ErrorProne (#608),5,21,2019-11-06 11:25:33+02:00,"['TableIdentifier.java', 'DataTableScan.java', 'ManifestReader.java', 'HiveCatalog.java', 'SparkOrcWriter.java']"
Fix InconsistentCapitalization error (#614),1,4,2019-11-06 10:34:20-08:00,['SerializableConfiguration.java']
Fix EqualsGetClass error (#611),18,88,2019-11-06 10:36:18-08:00,"['PartitionField.java', 'PartitionSpec.java', 'Bucket.java', 'Identity.java', 'Truncate.java', 'UnknownTransform.java', 'Types.java', 'CharSequenceWrapper.java', 'GenericManifestFile.java', 'MetricsModes.java', 'PartitionData.java', 'TableMetadata.java', 'MappedField.java', 'MappedFields.java', 'Pair.java', 'StructLikeWrapper.java', 'GenericRecord.java', 'PartitionKey.java']"
Fix ImmutableEnumChecker (#609),1,2,2019-11-06 10:36:55-08:00,['Avro.java']
Fix MutableConstantField (#610),10,27,2019-11-06 10:38:07-08:00,"['CheckCompatibility.java', 'DataTableScan.java', 'FileHistory.java', 'ManifestReader.java', 'ScanSummary.java', 'gradle-wrapper.jar', 'ParquetValueReaders.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'SparkFilters.java']"
Fix ObjectsHashCodePrimitive error (#612),1,3,2019-11-06 10:38:49-08:00,['PartitionSpec.java']
Fix PreconditionsInvalidPlaceholder error (#615),2,4,2019-11-06 10:39:10-08:00,"['PartitionSpec.java', 'TableMetadataParser.java']"
Javadoc: Fix iceberg-api link warnings (#622),5,65,2019-11-08 15:53:26-08:00,"['PartitionSpec.java', 'Schema.java', 'Evaluator.java', 'UnboundPredicate.java', 'Transforms.java']"
Rename runtime folder to spark-runtime for consistency (#616),3,4,2019-11-08 16:36:57-08:00,"['settings.gradle', 'LICENSE', 'NOTICE']"
Support reading Avro enums as strings (#625),6,212,2019-11-08 17:21:44-08:00,"['GenericAvroReader.java', 'ValueReaders.java', 'TestAvroEnums.java', 'SparkAvroReader.java', 'SparkValueReaders.java', 'TestSparkAvroEnums.java']"
"Fix reading Avro with arrays of structs with 2 fields (#618)

Fixes #605",4,87,2019-11-08 17:24:29-08:00,"['AvroSchemaVisitor.java', 'PruneColumns.java', 'RemoveIds.java', 'TestAvroNameMapping.java']"
Fix Parquet with special characters in field names (#601),11,262,2019-11-08 17:25:36-08:00,"['Avro.java', 'AvroSchemaUtil.java', 'AvroSchemaWithTypeVisitor.java', 'BuildAvroProjection.java', 'DataReader.java', 'IcebergDecoder.java', 'TestReadProjection.java', 'TypeToMessageType.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkParquetWriter.java']"
Use SessionCatalog and proper MetricsConfig in SparkTableUtil (#624),6,612,2019-11-11 12:57:24-08:00,"['MetricsConfig.java', 'MetricsModes.java', 'Hive.java', 'SparkTableUtil.scala', 'TestSparkTableUtil.java', 'TestSparkTableUtilWithInMemoryCatalog.java']"
Add incompatible changes to UpdateSchema API (#574),4,350,2019-11-12 08:57:58-08:00,"['UpdateSchema.java', 'Types.java', 'SchemaUpdate.java', 'TestSchemaUpdate.java']"
Add hadoop table catalog (#529),2,226,2019-11-12 09:13:57-08:00,"['HadoopCatalog.java', 'TestHadoopCatalog.java']"
Extend RewriteManifests to delete/add manifests directly (#512),5,650,2019-11-12 10:01:44-08:00,"['RewriteManifests.java', 'BaseRewriteManifests.java', 'ManifestWriter.java', 'TableTestBase.java', 'TestRewriteManifests.java']"
Python: Pin mo_sql_parser to unbroken version (#630),2,4,2019-11-12 11:31:21-08:00,"['setup.py', '__init__.py']"
Spark: Add option to allow writing optional to required fields (#514),5,197,2019-11-12 17:39:48-08:00,"['CheckCompatibility.java', 'TestReadabilityChecks.java', 'configuration.md', 'IcebergSource.java', 'TestDataFrameWrites.java']"
Update indexing to handle nested lists (#627),3,79,2019-11-12 19:41:12-08:00,"['IndexByName.java', 'TypeUtil.java', 'TestSchemaUpdate.java']"
Extend SparkTableUtil to import only certain partitions (#637),2,64,2019-11-13 09:03:50-08:00,"['SparkTableUtil.scala', 'TestSparkTableUtilWithInMemoryCatalog.java']"
"Remove the gradle-wrapper jar from the repo (#639)

Fixes #638",2,1,2019-11-13 17:22:51+00:00,"['.gitignore', 'gradle-wrapper.jar']"
Add parallel execution for Gradle build (#635),1,1,2019-11-13 09:49:18-08:00,['gradle.properties']
"Fix flaky ScanSummary test (#641)

Fixes #576",1,4,2019-11-13 19:11:10+00:00,['TestScanSummary.java']
Spark: Support projection schema from DataFrameReader (#590),2,227,2019-11-13 12:57:37-08:00,"['IcebergSource.java', 'TestSparkSchema.java']"
Use SessionState to load Hadoop conf (#642),8,24,2019-11-13 12:59:37-08:00,"['Convert table to Iceberg.ipynb', 'api-quickstart.md', 'IcebergSourceBenchmark.java', 'IcebergSource.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestPartitionValues.java', 'TestSparkTableUtil.java']"
Allow ordered projections when writing (#640),6,265,2019-11-13 14:00:11-08:00,"['IcebergSource.java', 'StreamingWriter.java', 'Writer.java', 'TestParquetWrite.java', 'TestStructuredStreaming.java', 'ThreeColumnRecord.java']"
Python: Remove unused iceberg.api.exception module causing test failures (#649),1,26,2019-11-15 11:46:36-08:00,['__init__.py']
Add mechanism to track and remove old metadata files (#631),6,428,2019-11-15 16:51:06-08:00,"['BaseMetastoreTableOperations.java', 'TableMetadata.java', 'TableMetadataParser.java', 'TableProperties.java', 'HadoopTableOperations.java', 'TestTableMetadata.java']"
Do not merge appended manifests under min count (#524),3,97,2019-11-16 13:08:03-08:00,"['MergingSnapshotProducer.java', 'TableTestBase.java', 'TestMergeAppend.java']"
Spark: Fix case sensitivity setting (#656),1,4,2019-11-19 13:22:30+00:00,['IcebergSource.java']
Add back old constructor to BinPacking (#651),1,5,2019-11-19 14:51:33+00:00,['BinPacking.java']
Add list tables support in Iceberg catalog (#657),5,132,2019-11-19 09:57:05-08:00,"['Catalog.java', 'HadoopCatalog.java', 'TestHadoopCatalog.java', 'HiveCatalog.java', 'HiveTableTest.java']"
Add CachingCatalog (#653),5,243,2019-11-20 09:30:17+00:00,"['Catalog.java', 'Namespace.java', 'TableIdentifier.java', 'CachingCatalog.java', 'CommitCallbackTransaction.java']"
Implement listTables in CachingCatalog (#662),1,7,2019-11-20 09:13:50-08:00,['CachingCatalog.java']
"Decouple TableMetadataParser and TableMetadata from TableOperations (#591)

The rationale behind not using TableOperations is:
1. It saves the need to construct a TableOperations instance when you
 want to get a table's metadata by parsing its metadata files.
2. It's more intuitive because a TableMetadata instance reflects a
 table's state and is determined by only a set of metadata files.",19,241,2019-11-20 09:48:39-08:00,"['BaseMetastoreCatalog.java', 'BaseMetastoreTableOperations.java', 'BaseSnapshot.java', 'FileHistory.java', 'FindFiles.java', 'ManifestGroup.java', 'ScanSummary.java', 'SnapshotParser.java', 'SnapshotProducer.java', 'TableMetadata.java', 'TableMetadataParser.java', 'HadoopTableOperations.java', 'HadoopTables.java', 'TableMetadataParserTest.java', 'TestSnapshotJson.java', 'TestTableMetadata.java', 'TestTables.java', 'HadoopTableTestBase.java', 'TestTables.java']"
"Refactor in and notIn expressions (#650)

* Make BoundSetPredicate extend BoundPredicate
* Remove visitor method for BoundSetPredicate
* Add BoundUnaryPredicate
* Add BoundPredicate subclass test and cast methods
* Replace LiteralSet and CharSeqLiteralSet with CharSequenceSet
* Implement all Set methods in CharSequenceSet",22,1193,2019-11-20 09:58:39-08:00,"['Binder.java', 'BoundLiteralPredicate.java', 'BoundPredicate.java', 'BoundSetPredicate.java', 'BoundUnaryPredicate.java', 'ExpressionVisitors.java', 'Expressions.java', 'Predicate.java', 'UnboundPredicate.java', 'Bucket.java', 'Dates.java', 'Identity.java', 'ProjectionUtil.java', 'Timestamps.java', 'Truncate.java', 'CharSequenceSet.java', 'CharSequenceWrapper.java', 'TestEvaluator.java', 'TestExpressionSerialization.java', 'TestPredicateBinding.java', 'TestProjection.java', 'ParquetFilters.java']"
Improve docs on converting Avro schemas (#587),3,35,2019-11-20 10:05:29-08:00,"['AvroSchemaUtil.java', 'api-quickstart.md', 'spark.md']"
Move identifier validation into BaseMetastoreCatalog (#654),3,147,2019-11-20 19:26:49+00:00,"['BaseMetastoreCatalog.java', 'HadoopCatalog.java', 'HiveCatalog.java']"
Add schema field ID validation (#619),8,70,2019-11-20 15:59:34-08:00,"['Schema.java', 'TestSerializableTypes.java', 'TestTypeUtil.java', 'AvroDataTest.java', 'TestNameMapping.java', 'DataTest.java', 'SchemaUtilTest.java', 'AvroDataTest.java']"
Add PartitionsTable for partition metadata (#655),7,304,2019-11-20 16:00:39-08:00,"['BaseMetastoreCatalog.java', 'MetadataTableType.java', 'PartitionsTable.java', 'HadoopTables.java', 'StructInternalRow.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java']"
Add friendly names to catalog tables (#421),3,46,2019-11-22 10:25:44-08:00,"['BaseMetastoreCatalog.java', 'HadoopCatalog.java', 'HiveCatalog.java']"
Add case insensitive support to CachingCatalog (#671),3,49,2019-11-25 12:48:49-08:00,"['TableIdentifier.java', 'TestTableIdentifier.java', 'CachingCatalog.java']"
Fix MissingOverride error (#677),1,1,2019-12-02 10:34:42-08:00,['BoundSetPredicate.java']
Add quick build option to disable checkstyle and error-prone (#685),2,44,2019-12-05 17:35:58+02:00,"['baseline.gradle', 'jmh.gradle']"
"Add compression level for Parquet (#689)

This adds a table configuration setting for compression level. Zstd, brotli, and gzip support compression levels and this sets the Hadoop configuration property for each based on the table property.",2,23,2019-12-06 16:03:21+02:00,"['TableProperties.java', 'Parquet.java']"
Add Spark Avro JMH tests (#694),5,278,2019-12-09 09:40:01-08:00,"['build.gradle', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'versions.lock', 'versions.props']"
Remove some of the unused variables (#676),5,14,2019-12-09 09:41:42-08:00,"['InclusiveMetricsEvaluator.java', 'BaseMetastoreTableOperations.java', 'ClientPool.java', 'SparkParquetWriters.java', 'Writer.java']"
"Use broadcast variables in IcebergSource (#569)

This avoids serializing the Hadoop Configuration in each task, which is expensive.",6,167,2019-12-09 10:25:28-08:00,"['HadoopFileIO.java', 'SerializableSupplier.java', 'IcebergSource.java', 'Reader.java', 'StreamingWriter.java', 'Writer.java']"
Add missing table properties to configuration.md (#699),1,7,2019-12-12 16:58:08-08:00,['configuration.md']
"Add transform expressions (#686)

* Add transform expressions.

* Fix checkstyle violations.

* Rename ValueExpression to Term and clean up class hierarchy.

* Restore BoundExpressionVisitor to avoid compatibility problems.

* Fix documentation typo.

* Add missing BoundTransform.toString method.

* Revert unnecessary change to TestExpressionSerialization.

* Rename child to term.",30,1081,2019-12-18 09:58:30-08:00,"['Bound.java', 'BoundLiteralPredicate.java', 'BoundPredicate.java', 'BoundReference.java', 'BoundSetPredicate.java', 'BoundTerm.java', 'BoundTransform.java', 'BoundUnaryPredicate.java', 'Evaluator.java', 'ExpressionVisitors.java', 'Expressions.java', 'NamedReference.java', 'Predicate.java', 'Reference.java', 'ResidualEvaluator.java', 'Term.java', 'Unbound.java', 'UnboundPredicate.java', 'UnboundTerm.java', 'UnboundTransform.java', 'Bucket.java', 'Dates.java', 'ProjectionUtil.java', 'Timestamps.java', 'Truncate.java', 'TestExpressionBinding.java', 'TestExpressionHelpers.java', 'TestExpressionSerialization.java', 'ScanSummary.java', 'ParquetFilters.java']"
Hive: Handle null exception message (#701),1,2,2019-12-18 11:25:54-08:00,['HiveTableOperations.java']
Lazily index schemas to fix column names that differ by case (#703),2,46,2019-12-18 11:29:36-08:00,"['Types.java', 'TestTypeUtil.java']"
HadoopCatalog: Ignore non-table directories in listTable (#681),2,9,2019-12-18 11:36:29-08:00,"['HadoopCatalog.java', 'TestHadoopCatalog.java']"
Add missing overrides (#720),4,4,2019-12-27 10:22:29-08:00,"['BoundReference.java', 'NamedReference.java', 'UnboundPredicate.java', 'UnboundTransform.java']"
Implement in and notIn in multiple visitors (#600),10,1393,2019-12-27 13:07:53-08:00,"['InclusiveMetricsEvaluator.java', 'ManifestEvaluator.java', 'StrictMetricsEvaluator.java', 'TestInclusiveManifestEvaluator.java', 'TestInclusiveMetricsEvaluator.java', 'TestStrictMetricsEvaluator.java', 'ParquetDictionaryRowGroupFilter.java', 'ParquetMetricsRowGroupFilter.java', 'TestDictionaryRowGroupFilter.java', 'TestMetricsRowGroupFilter.java']"
Update project and projectStrict for set predicates (#628),9,736,2019-12-27 13:09:55-08:00,"['Bucket.java', 'Dates.java', 'ProjectionUtil.java', 'Timestamps.java', 'Truncate.java', 'TestBucketingProjection.java', 'TestDatesProjection.java', 'TestTimestampsProjection.java', 'TestTruncatesProjection.java']"
Support retaining last N snapshots (#497),3,371,2019-12-27 14:42:33-08:00,"['ExpireSnapshots.java', 'RemoveSnapshots.java', 'TestRemoveSnapshots.java']"
"Vectorization: Parquet additions to support batch reads (#710)

Co-authored-by: gautamkowshik@gmail.com
Co-authored-by: anjalinorwood@gmail.com",8,695,2019-12-30 09:50:00-08:00,"['Parquet.java', 'ParquetDictionaryRowGroupFilter.java', 'ParquetReader.java', 'ParquetUtil.java', 'ReadConf.java', 'ValuesAsBytesReader.java', 'VectorizedParquetReader.java', 'VectorizedReader.java']"
Project all DataFile columns for Snapshot.addedFiles (#718),3,78,2019-12-30 09:53:45-08:00,"['BaseSnapshot.java', 'ManifestReader.java', 'TestSnapshot.java']"
"Site: Add links to the issues@ list, update private@ description (#724)",1,8,2020-01-06 16:42:27-08:00,['community.md']
Update BaseRewriteManifests to work with multiple partition specs (#666),2,222,2020-01-07 10:33:20-08:00,"['BaseRewriteManifests.java', 'TestRewriteManifests.java']"
Javadoc: Fix typos in ExpireSnapshots documentation (#725),1,4,2020-01-07 10:38:39-08:00,['ExpireSnapshots.java']
ORC: Implement schema evolution using IDs (#227),21,2255,2020-01-07 11:07:45-08:00,"['build.gradle', 'GenericOrcReader.java', 'GenericOrcWriter.java', 'TestReadProjection.java', 'TestGenericReadProjection.java', 'ColumnIdMap.java', 'ORC.java', 'ORCSchemaUtil.java', 'OrcFileAppender.java', 'OrcIterable.java', 'OrcMetrics.java', 'OrcValueWriter.java', 'TypeConversion.java', 'VectorizedRowBatchIterator.java', 'TestBuildOrcProjection.java', 'TestORCSchemaUtil.java', 'spec.md', 'SparkOrcReader.java', 'SparkOrcWriter.java', 'versions.lock', 'versions.props']"
Hive: Avoid recursive listing to build unused stats (#734),1,8,2020-01-14 17:37:25-08:00,['HiveTableOperations.java']
Return ByteBuffer for keyMetadata in GenericDataFile (#728),1,2,2020-01-14 17:38:51-08:00,['GenericDataFile.java']
Remove warnings from the build (#722),2,29,2020-01-15 09:18:29-08:00,"['CheckCompatibility.java', 'ParquetFilters.java']"
Hive: Add timeout for acquiring locks in HiveTableOperations (#736),1,28,2020-01-16 09:08:04-08:00,['HiveTableOperations.java']
Update .gitignore for eclipse (#739),1,3,2020-01-16 09:09:26-08:00,['.gitignore']
Track row counts in ManifestFile (#738),8,300,2020-01-23 09:51:03-08:00,"['ManifestFile.java', 'TestHelpers.java', 'GenericManifestFile.java', 'ManifestWriter.java', 'SnapshotProducer.java', 'TestGenericManifestFile.java', 'TestManifestWriter.java', 'SparkTableUtil.scala']"
Spark: Add PreferredLocations support for HDFS paths (#721),1,63,2020-01-23 10:06:03-08:00,['Reader.java']
Fix duplicate name in metadata tables (#747),1,2,2020-01-23 10:32:15-08:00,['BaseMetastoreCatalog.java']
Fix purge option in CachingCatalog.dropTable (#746),1,2,2020-01-23 10:33:37-08:00,['CachingCatalog.java']
Fix Javadoc build (#753),1,2,2020-01-27 14:55:07+02:00,['VectorizedReader.java']
Update docs to include newly added Java predicate expressions (#752),1,3,2020-01-27 15:02:51+02:00,['api.md']
Fix thread-safety in HadoopTableOperations (#754),1,2,2020-01-27 09:03:37-08:00,['HadoopTableOperations.java']
Fix Python API doc intro (#755),1,2,2020-01-27 09:56:12-08:00,['python-api-intro.md']
Make the size of Hive client pool configurable (#756),2,3,2020-01-27 10:02:03-08:00,"['HiveCatalog.java', 'TestHiveMetastore.java']"
Refactor FilteredManifest and ManifestGroup (#735),6,241,2020-01-27 10:32:14-08:00,"['FilteredManifest.java', 'FindFiles.java', 'ManifestGroup.java', 'ManifestReader.java', 'ScanSummary.java', 'TestFindFiles.java']"
Bump Apache Parquet to 1.11.0 (#708),4,68,2020-01-28 09:50:46-08:00,"['ParquetWriter.java', 'TestDataSourceOptions.java', 'versions.lock', 'versions.props']"
Add time-travel methods to IcebergGenerics (#750),2,234,2020-01-29 09:08:16-08:00,"['IcebergGenerics.java', 'TestLocalScan.java']"
Incremental scan implementation (#315),7,549,2020-02-02 14:00:08-08:00,"['TableScan.java', 'BaseTableScan.java', 'DataTableScan.java', 'IncrementalDataTableScan.java', 'ManifestGroup.java', 'SnapshotUtil.java', 'TestIncrementalDataTableScan.java']"
Spark: Convert In filter to in expression (#749),2,52,2020-02-03 09:07:54-08:00,"['SparkFilters.java', 'TestFilteredScan.java']"
"Inherit snapshot ids for manifest entries (#675)

This change makes the snapshot ID optional for each data file in a manifest so that a null snapshot ID indicates that it should be inherited from the manifest metadata. As a consequence, people can create manifests with missing snapshot IDs that will be assigned at commit time.

Closes #504.",33,1430,2020-02-03 14:53:50-08:00,"['AppendFiles.java', 'RewriteManifests.java', 'BaseMetastoreCatalog.java', 'BaseRewriteManifests.java', 'DataFilesTable.java', 'FastAppend.java', 'GenericManifestFile.java', 'GenericPartitionFieldSummary.java', 'InheritableMetadata.java', 'InheritableMetadataFactory.java', 'ManifestEntry.java', 'ManifestGroup.java', 'ManifestReader.java', 'ManifestWriter.java', 'MergeAppend.java', 'MergingSnapshotProducer.java', 'PartitionSummary.java', 'RemoveSnapshots.java', 'SnapshotProducer.java', 'SnapshotSummary.java', 'TableProperties.java', 'TableTestBase.java', 'TestFastAppend.java', 'TestManifestReader.java', 'TestMergeAppend.java', 'TestRewriteManifests.java', 'TestTransaction.java', 'configuration.md', 'SparkTableUtil.scala', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestParquetWrite.java', 'TestSparkTableUtilWithInMemoryCatalog.java']"
"Hadoop tables: If the version matches, do not reload metadata (#774)",2,20,2020-02-04 11:28:25-08:00,"['HadoopTableOperations.java', 'TestHadoopCommits.java']"
Make GenericManifestFile compatible with Kryo (#775),2,193,2020-02-04 13:15:06-08:00,"['GenericManifestFile.java', 'TestManifestFileSerialization.java']"
Add SnapshotManager to roll back and cherry-pick snapshots (#695),16,1234,2020-02-04 13:49:56-08:00,"['ManageSnapshots.java', 'Rollback.java', 'Table.java', 'CherrypickAncestorCommitException.java', 'DuplicateWAPCommitException.java', 'BaseMetadataTable.java', 'BaseTable.java', 'BaseTransaction.java', 'RollbackToSnapshot.java', 'SnapshotManager.java', 'SnapshotProducer.java', 'SnapshotSummary.java', 'TableMetadata.java', 'WapUtil.java', 'TestWapWorkflow.java', 'Writer.java']"
Document Hadoop config options (#777),1,7,2020-02-05 11:21:29-08:00,['configuration.md']
Support in and notIn in ResidualVisitor (#766),2,121,2020-02-05 11:36:04-08:00,"['ResidualEvaluator.java', 'TestResiduals.java']"
"Add TableMetadataParser.read(FileIO, String) (#785)",3,8,2020-02-10 16:24:33-08:00,"['BaseMetastoreTableOperations.java', 'TableMetadataParser.java', 'HadoopTableOperations.java']"
"Drop stats in files loaded by ManifestGroup if possible (#781)

1. Cache residual evaluator
2. Detect and drop stats if possible",2,27,2020-02-10 16:51:01-08:00,"['FilteredManifest.java', 'ManifestGroup.java']"
Plan incremental scans in one group (#783),1,33,2020-02-10 17:05:04-08:00,['IncrementalDataTableScan.java']
Fix SnapshotProducer for multi-threaded operations (#789),1,8,2020-02-11 11:45:36-08:00,['SnapshotProducer.java']
Improve incremental scan range validation (#782),3,121,2020-02-11 11:47:54-08:00,"['IncrementalDataTableScan.java', 'SnapshotUtil.java', 'TestIncrementalDataTableScan.java']"
Python: Fix CI by pinning virtualenv before 20.0.0 (#794),1,2,2020-02-12 09:26:22-08:00,['.travis.yml']
Spark: Make column order check optional (#745),6,167,2020-02-13 12:59:49-08:00,"['CheckCompatibility.java', 'TestReadabilityChecks.java', 'IcebergSource.java', 'PartitionKey.java', 'Writer.java', 'TestPartitionValues.java']"
Python: Support 3.6+ (#795),1,11,2020-02-13 13:01:37-08:00,['setup.py']
Improve getWriter in BaseRewriteManifests (#790),1,12,2020-02-14 10:38:21-08:00,['BaseRewriteManifests.java']
Add factory methods for HadoopInputFile and HadoopOutputFile with a FileSystem (#784),2,95,2020-02-16 16:08:17-08:00,"['HadoopInputFile.java', 'HadoopOutputFile.java']"
Bump Apache Avro to 1.9.x (#297),4,53,2020-02-16 16:11:47-08:00,"['TestStringLiteralConversions.java', 'TestDataSourceOptions.java', 'versions.lock', 'versions.props']"
Fix manifests table for empty ManifestFiles. (#800),1,4,2020-02-17 08:42:29-08:00,['ManifestsTable.java']
Support input_file_name() in Spark. (#804),1,6,2020-02-17 09:38:57-08:00,['Reader.java']
"Fix metadata tables that use manifestListLocation (#803)

* Fix metadata tables that use manifestListLocation.

* Fix checkstyle.

* Update fix to metadata tables without current snapshot.",5,41,2020-02-17 10:11:32-08:00,"['DataFilesTable.java', 'HistoryTable.java', 'ManifestEntriesTable.java', 'ManifestsTable.java', 'SnapshotsTable.java']"
Metrics javadoc fixes #767 (#768),2,88,2020-02-17 13:16:59-08:00,"['Metrics.java', 'TestMetrics.java']"
"Add all_data_files, all_manifests, and all_entries metadata tables (#805)",12,883,2020-02-17 13:52:41-08:00,"['AllDataFilesTable.java', 'AllEntriesTable.java', 'AllManifestsTable.java', 'BaseMetastoreCatalog.java', 'BaseSnapshot.java', 'DataFiles.java', 'DataFilesTable.java', 'ManifestsTable.java', 'MetadataTableType.java', 'HadoopTables.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java']"
Update spec.md with ManifestFile row modification counts (#807),1,5,2020-02-17 17:18:08-08:00,['spec.md']
"Fix HadoopTableOperations with create transactions (#806)

Calling locationProvider() threw a NullPointerException because current metadata was null without a temporary table operations instance.",2,63,2020-02-18 09:35:26-08:00,"['HadoopTableOperations.java', 'TestHadoopCatalog.java']"
"Handle negative row counts in InclusiveMetricsEvaluator (#810)

Avro data imported using SparkTableUtil would create DataFile instances with -1 rows, which were filtered out by this check. This updates the check so that files with < 0 rows are read, assuming that the row count is incorrect.",1,9,2020-02-18 09:37:50-08:00,['InclusiveMetricsEvaluator.java']
Fix UUID check for existing tables without a UUID (#652),3,27,2020-02-18 13:02:58-08:00,"['BaseMetastoreTableOperations.java', 'HadoopTableOperations.java', 'JsonUtil.java']"
"Use DataFile instead of SparkDataFile in SparkTableUtil (#786)


Fixes #763",1,220,2020-02-19 09:17:27-08:00,['SparkTableUtil.scala']
Fix manifest scanning in RemoveSnapshots (#812),2,60,2020-02-19 09:28:56-08:00,"['RemoveSnapshots.java', 'TestRemoveSnapshots.java']"
Allow cherry-picking any commit as long as it is a fast-forward. (#799),2,112,2020-02-20 09:42:51-08:00,"['SnapshotManager.java', 'TestWapWorkflow.java']"
NameMapping: reassign already mapped names for new columns (#811),3,423,2020-02-20 14:08:50-08:00,"['MappingUtil.java', 'TestSchemaAndMappingUpdate.java', 'TestMappingUpdates.java']"
Allow Long to Date Literal conversion (#815),3,25,2020-02-20 14:11:54-08:00,"['Literals.java', 'TestMiscLiteralConversions.java', 'TestNumericLiteralConversions.java']"
"Use HadoopInputFile and HadoopOutputFile FileSystem for ORC (#823)

Also, fix a resource leak.",6,73,2020-03-02 13:58:01-08:00,"['HadoopInputFile.java', 'HadoopOutputFile.java', 'ORC.java', 'OrcFileAppender.java', 'OrcIterable.java', 'OrcMetrics.java']"
"Add Arrow classes for vectorized reads (#723)

Co-authored-by: gautamkowshik@gmail.com
Co-authored-by: anjalinorwood@gmail.com",24,3897,2020-03-03 17:13:48-08:00,"['LICENSE', 'ArrowSchemaUtil.java', 'IcebergArrowVectors.java', 'NullabilityHolder.java', 'VectorHolder.java', 'VectorizedArrowReader.java', 'BaseVectorizedParquetValuesReader.java', 'VectorizedColumnIterator.java', 'VectorizedDictionaryEncodedParquetValuesReader.java', 'VectorizedPageIterator.java', 'VectorizedParquetDefinitionLevelReader.java', 'ArrowSchemaUtilTest.java', 'build.gradle', 'BaseColumnIterator.java', 'BasePageIterator.java', 'ColumnIterator.java', 'PageIterator.java', 'ParquetUtil.java', 'ValuesAsBytesReader.java', 'VectorizedParquetReader.java', 'VectorizedReader.java', 'settings.gradle', 'versions.lock', 'versions.props']"
Spark: Fix ORC Reader to not create a new RowWriter for each row (#826),1,3,2020-03-04 10:44:17-08:00,['SparkOrcReader.java']
"Spark: Update table tests to use common test cases (#827)

Co-authored-by: Lammott <jlammott@usa483e72e3960.am.sony.com>",3,2091,2020-03-06 11:38:06-08:00,"['TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java']"
"Spark: Add incremental scan support (#829)

Adds start-snapshot-id and end-snapshot-id options to configure an incremental scan.",2,110,2020-03-06 11:50:37-08:00,"['Reader.java', 'TestDataSourceOptions.java']"
Update RemoveSnapshots to protect cherry-picked data (#814),2,240,2020-03-09 16:13:34-07:00,"['RemoveSnapshots.java', 'TestRemoveSnapshots.java']"
Fix SchemaVisitor thread safety (#840),2,44,2020-03-13 09:11:40-07:00,"['TypeUtil.java', 'TypeToSchema.java']"
Refactor BaseRewriteManifests to simplify writer tracking (#818),1,73,2020-03-13 09:46:59-07:00,['BaseRewriteManifests.java']
"CI: Update travis to use bionic (#793)

Co-authored-by: Ted Gooch <tgooch@netflix.com>
Co-authored-by: Ryan Blue <rdblue@users.noreply.github.com>",1,3,2020-03-13 15:57:39-07:00,['.travis.yml']
Build: Remove warnings (#770),12,87,2020-03-13 16:00:14-07:00,"['PartitionSpec.java', 'StrictMetricsEvaluator.java', 'Bucket.java', 'AllManifestsTable.java', 'BaseRewriteManifests.java', 'InheritableMetadataFactory.java', 'TableMetadataParser.java', 'HadoopTableOperations.java', 'IcebergGenerics.java', 'GenericOrcWriter.java', 'SparkSchemaUtil.java', 'Writer.java']"
Hive: Update to 2.3.6 (#841),5,172,2020-03-17 09:21:56-07:00,"['build.gradle', 'HiveTableOperations.java', 'TestTables.java', 'versions.lock', 'versions.props']"
Spark: Add tests for identity partition data (#839),2,247,2020-03-19 12:50:56-07:00,"['LogMessage.java', 'TestIdentityPartitionData.java']"
Spark: Extract base data reader for vectorized reads (#853),4,763,2020-03-20 19:11:48-07:00,"['BaseDataReader.java', 'PartitionRowConverter.java', 'Reader.java', 'RowDataReader.java']"
Remove mortbay Log (#861),3,13,2020-03-22 16:16:04-07:00,"['build.gradle', 'IcebergStorage.java', 'versions.lock']"
IcebergGenerics: Support ORC format (#851),2,39,2020-03-22 16:35:58-07:00,"['TableScanIterable.java', 'TestLocalScan.java']"
Fix CloseableIterable.concat issue with starting empty iterables (#854),3,97,2020-03-24 13:57:42-07:00,"['CloseableIterable.java', 'AssertHelpers.java', 'TestCloseableIterable.java']"
Docs: fix inaccurate docs (#863),2,16,2020-03-24 15:15:30-07:00,"['Schema.java', 'TableIdentifier.java']"
Support configurable split size for metadata tables (#819),10,228,2020-03-30 09:28:02-07:00,"['AllDataFilesTable.java', 'AllEntriesTable.java', 'AllManifestsTable.java', 'DataFilesTable.java', 'ManifestEntriesTable.java', 'StaticTableScan.java', 'TableProperties.java', 'TestEntriesMetadataTable.java', 'TestSplitPlanning.java', 'TestDataSourceOptions.java']"
Fix typos in internal APIs (#880),11,22,2020-03-30 09:29:35-07:00,"['TypeUtil.java', 'TestBucketing.java', 'TestTruncatesResiduals.java', 'TestSerializableTypes.java', 'TypeToSchema.java', 'ValueWriters.java', 'ParquetAvro.java', 'ParquetValueWriters.java', 'TypeToMessageType.java', 'SparkParquetWriters.java', 'SparkValueWriters.java']"
"Remove use of Netty's ConcurrentSet (#876)

Replaced it with ConcurrentHashMap.newKeySet

Fixes #874.",1,4,2020-03-30 09:34:27-07:00,['RemoveSnapshots.java']
Rename ORC reader project config for consistency (#879),5,12,2020-03-30 14:07:37-07:00,"['TableScanIterable.java', 'TestGenericReadProjection.java', 'ORC.java', 'RowDataReader.java', 'TestSparkOrcReader.java']"
Update docs with read.split.metadata-target-size property (#883),1,13,2020-03-31 07:23:12-07:00,['configuration.md']
Hadoop catalog: Allow empty namespaces (#878),3,29,2020-03-31 09:45:13-07:00,"['TableIdentifier.java', 'HadoopCatalog.java', 'TestHadoopCatalog.java']"
ORC: Implement TestGenericData and fix related issues (#778),11,584,2020-03-31 14:54:30-07:00,"['GenericOrcReader.java', 'GenericOrcWriter.java', 'TestGenericData.java', 'ORC.java', 'ORCSchemaUtil.java', 'OrcFileAppender.java', 'spec.md', 'SparkOrcReader.java', 'SparkOrcWriter.java', 'versions.lock', 'versions.props']"
"Use FileAppender.length instead of calling FileSystem.getStat (#882)

Co-authored-by: Sudarshan S <ssarolkar@box.com>",2,7,2020-04-02 16:56:37-07:00,"['ParquetWriter.java', 'Writer.java']"
"Spec: Add file and position delete file (#887)

Co-authored-by: Ryan Blue <rdblue@users.noreply.github.com>",1,21,2020-04-03 10:24:41-07:00,['spec.md']
"Spark: support ORC writes (#857)

Fixes #855.",2,102,2020-04-03 17:02:59-07:00,"['Writer.java', 'TestSparkDataWrite.java']"
MR: Add InputFormat (#843),8,1194,2020-04-06 16:02:56-07:00,"['.gitignore', 'build.gradle', 'Util.java', 'SerializationUtil.java', 'IcebergInputFormat.java', 'TestIcebergInputFormat.java', 'settings.gradle', 'Reader.java']"
Fix Javadoc errors in TableScan. (#895),1,20,2020-04-06 18:08:59-07:00,['TableScan.java']
"Fix classloader used for metadata files (#898)

By default, the Avro read helper uses the current thread's classloader. In some cases, this may not be able to load Iceberg classes so internal Avro reads should explicitly use the right classloader to avoid ClassCastException.",6,14,2020-04-07 10:36:51-07:00,"['AllManifestsTable.java', 'BaseSnapshot.java', 'ManifestReader.java', 'RemoveSnapshots.java', 'Avro.java', 'TestGenericManifestFile.java']"
Add Java code examples and update site docs (#678),14,1123,2020-04-08 20:20:44-07:00,"['api-quickstart.md', 'evolution.md', 'getting-started.md', 'partition-spec-evolution.png', 'java-api-quickstart.md', 'mkdocs.yml', 'ConcurrencyTest.java', 'README.md', 'ReadAndWriteTablesTest.java', 'SchemaEvolutionTest.java', 'SimpleRecord.java', 'SnapshotFunctionalityTest.java', 'books.json', 'new-books.json']"
Wrap DataFile when writing to support any implementation (#901),2,204,2020-04-08 20:28:43-07:00,"['ManifestEntry.java', 'ManifestWriter.java']"
"Use null-safe locations in metadata tables (#906)

Fixes #904.",10,50,2020-04-09 08:35:27-07:00,"['AllDataFilesTable.java', 'AllEntriesTable.java', 'AllManifestsTable.java', 'BaseMetadataTable.java', 'DataFilesTable.java', 'HistoryTable.java', 'ManifestEntriesTable.java', 'ManifestsTable.java', 'PartitionsTable.java', 'SnapshotsTable.java']"
"Spark: Add ORC to parameterized tests (#892)

* Spark: Add ORC to parameterized tests.

* Fix GenericsHelpers.

* Build: Increase JVM heap size.

* Fix review comments.

* Revert ""Build: Increase JVM heap size.""

This reverts commit 1f0996113923c5d279a5877a03af2db7b7e4e076.

* Avoid keeping records in memory for TestDataFrameWrites.",8,861,2020-04-09 09:11:46-07:00,"['build.gradle', 'GenericsHelpers.java', 'TestDataFrameWrites.java', 'TestFilteredScan.java', 'TestIdentityPartitionData.java', 'TestPartitionValues.java', 'TestReadProjection.java', 'TestSparkReadProjection.java']"
Avro: Support partition values using a constants map (#896),10,304,2020-04-09 09:28:53-07:00,"['ManifestWriter.java', 'ValueReaders.java', 'ByteBuffers.java', 'PartitionUtil.java', 'TableScanIterable.java', 'DataReader.java', 'GenericReaders.java', 'SparkAvroReader.java', 'SparkValueReaders.java', 'RowDataReader.java']"
"Prepare metadata writers for format v2 (#903)

* Track format version in TableMetadata.
* Pass formatVersion when creating a manifest writer.
* Pass formatVersion when creating a manifest list writer.
* Add v2 change section to spec.",14,477,2020-04-09 12:14:34-07:00,"['BaseRewriteManifests.java', 'FastAppend.java', 'ManifestListWriter.java', 'ManifestWriter.java', 'MergingSnapshotProducer.java', 'SnapshotProducer.java', 'TableMetadata.java', 'TableMetadataParser.java', 'TestFormatVersions.java', 'TestSnapshotJson.java', 'TestTableMetadata.java', 'TestTables.java', 'spec.md', 'TestTables.java']"
ORC: Refactor readers to remove duplicate null handling code (#899),2,623,2020-04-09 14:31:37-07:00,"['GenericOrcReader.java', 'SparkOrcReader.java']"
"Use only guava Preconditions (#911)

Co-authored-by: Luan <xuluan@ebay.com>",4,14,2020-04-10 09:51:17-07:00,"['BaseVectorizedParquetValuesReader.java', 'VectorizedColumnIterator.java', 'MessageTypeToType.java', 'BaseDataReader.java']"
Spark: Implement an action to remove orphan files (#894),7,948,2020-04-10 12:02:51-07:00,"['HiddenPathFilter.java', 'Action.java', 'Actions.java', 'RemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java']"
Update Snapshot and TableMetadata with sequence numbers (#910),12,243,2020-04-10 16:02:33-07:00,"['Snapshot.java', 'BaseSnapshot.java', 'ManifestListWriter.java', 'SnapshotParser.java', 'SnapshotProducer.java', 'TableMetadata.java', 'TableMetadataParser.java', 'JsonUtil.java', 'TestSnapshotJson.java', 'TestTableMetadata.java', 'spec.md', 'TestForwardCompatibility.java']"
Remove unused fields from DataFile (#914),5,100,2020-04-11 08:47:22-07:00,"['DataFile.java', 'TestHelpers.java', 'GenericDataFile.java', 'ManifestEntry.java', 'spec.md']"
"Add missing @Override annotations (#916)

Reduces the number of errors in the build",2,4,2020-04-11 08:47:59-07:00,"['GenericOrcWriter.java', 'PageIterator.java']"
"Parquet: Support constant map for partition values (#909)

This is a follow-up to #896, which added the same constant map support for Avro.

Fixes #575 for Parquet and replaces #585. Andrei did a lot of the work for this in #585.

Co-authored-by: Andrei Ionescu <webdev.andrei@gmail.com>",10,352,2020-04-11 08:51:33-07:00,"['ValueReaders.java', 'PartitionUtil.java', 'DateTimeUtil.java', 'TableScanIterable.java', 'GenericReaders.java', 'GenericParquetReaders.java', 'SparkParquetReaders.java', 'SparkValueReaders.java', 'RowDataReader.java', 'TestPartitionValues.java']"
"HOTFIX: Fix partition constants (#918)

Only identity partitions should be added to constants.",3,20,2020-04-11 13:36:58-07:00,"['Identity.java', 'Transform.java', 'PartitionUtil.java']"
Add v2 manifest lists (#907),13,1059,2020-04-14 16:40:48-07:00,"['ManifestFile.java', 'TestHelpers.java', 'BaseSnapshot.java', 'GenericManifestFile.java', 'ManifestListWriter.java', 'ManifestLists.java', 'ManifestWriter.java', 'SnapshotProducer.java', 'V1Metadata.java', 'V2Metadata.java', 'TestGenericManifestFile.java', 'TestManifestFileVersions.java', 'TestSnapshotJson.java']"
Fix metadata tables with staged initial snapshots (#908),5,102,2020-04-15 11:04:35-07:00,"['AllDataFilesTable.java', 'AllEntriesTable.java', 'AllManifestsTable.java', 'BaseAllMetadataTableScan.java', 'TestIcebergSourceTablesBase.java']"
Add persistent IDs to partition fields (#845),11,444,2020-04-15 13:13:35-07:00,"['PartitionField.java', 'PartitionSpec.java', 'TestPartitionSpecValidation.java', 'TestTransformSerialization.java', 'PartitionSpecParser.java', 'TableMetadata.java', 'TestManifestReader.java', 'TestMergeAppend.java', 'TestPartitionSpecInfo.java', 'TestPartitionSpecParser.java', 'TestTableMetadata.java']"
Fix the size in GenericDataFile (#929),1,2,2020-04-15 16:18:20-07:00,['GenericDataFile.java']
Spark: move actions to a separate package (#927),5,22,2020-04-15 16:28:17-07:00,"['Action.java', 'Actions.java', 'RemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction.java', 'TestIcebergSourceTablesBase.java']"
Move manifest factory methods (#925),20,360,2020-04-15 16:44:35-07:00,"['BaseMetastoreCatalog.java', 'BaseRewriteManifests.java', 'DataFilesTable.java', 'FastAppend.java', 'ManifestFiles.java', 'ManifestGroup.java', 'ManifestReader.java', 'ManifestWriter.java', 'MergingSnapshotProducer.java', 'RemoveSnapshots.java', 'SnapshotProducer.java', 'TableTestBase.java', 'TestManifestReader.java', 'TestMergeAppend.java', 'TestRewriteManifests.java', 'TestTransaction.java', 'SparkTableUtil.scala', 'TestManifestFileSerialization.java', 'TestForwardCompatibility.java', 'TestSparkDataWrite.java']"
Add void transform that always produces null (#924),7,296,2020-04-15 16:45:44-07:00,"['PartitionSpec.java', 'SerializationProxies.java', 'Transforms.java', 'VoidTransform.java', 'PartitionSpecTestBase.java', 'TestTransformSerialization.java', 'TestPartitionSpecParser.java']"
Remove unused ManifestLists.write method (#921),2,9,2020-04-15 16:53:35-07:00,"['ManifestLists.java', 'TestSnapshotJson.java']"
Bump Apache Spark to 2.4.5 (#917),2,32,2020-04-15 17:27:47-07:00,"['versions.lock', 'versions.props']"
Improve failure handling after Snapshot expiration (#928),1,210,2020-04-16 12:27:05-07:00,['RemoveSnapshots.java']
Spark: limit the listing depth in RemoveOrphanFilesAction (#930),1,6,2020-04-16 12:28:03-07:00,['RemoveOrphanFilesAction.java']
"Add SupportsNamespaces extension to Catalog (#919)

This also adds implementations for HadoopCatalog and HiveCatalog.",7,914,2020-04-17 14:35:19-07:00,"['SupportsNamespaces.java', 'NamespaceNotEmptyException.java', 'NoSuchNamespaceException.java', 'HadoopCatalog.java', 'TestHadoopCatalog.java', 'HiveCatalog.java', 'TestHiveCatalog.java']"
Add residual evaluation for MR reader (#931),2,101,2020-04-20 11:33:04-07:00,"['IcebergInputFormat.java', 'TestIcebergInputFormat.java']"
Add v2 manifests (#913),13,1331,2020-04-20 12:56:39-07:00,"['GenericManifestEntry.java', 'IndexedStructLike.java', 'InheritableMetadataFactory.java', 'ManifestEntry.java', 'ManifestFiles.java', 'ManifestListWriter.java', 'ManifestReader.java', 'ManifestWriter.java', 'V1Metadata.java', 'V2Metadata.java', 'TableTestBase.java', 'TestManifestListVersions.java', 'TestManifestWriterVersions.java']"
Spark: Implement an adapter to wrap Row into DataFile (#937),5,540,2020-04-20 17:13:54-07:00,"['build.gradle', 'SparkDataFile.java', 'SparkStructLike.java', 'SparkValueConverter.java', 'TestSparkDataFile.java']"
Spark: Use SparkValueConverter in TestSparkReadProjection (#942),1,89,2020-04-21 09:30:38-07:00,['TestSparkReadProjection.java']
"Update dev/source-release.sh to add arrow, mr, and spark-runtime (#944)",1,2,2020-04-21 09:31:37-07:00,['source-release.sh']
Log test failure exceptions in Travis CI. (#945),1,7,2020-04-21 09:40:01-07:00,['build.gradle']
Fix thread safety in listeners and simplify implementation (#940),1,27,2020-04-21 09:42:09-07:00,['Listeners.java']
Document Java version should be 1.8 (#938),1,2,2020-04-21 09:42:57-07:00,['README.md']
Add more v2 details to the spec (#912),1,77,2020-04-21 12:13:28-07:00,['spec.md']
Update TableTestBase tests to run with formats v1 and v2 (#936),37,589,2020-04-21 12:50:32-07:00,"['ManifestFiles.java', 'TableMetadata.java', 'V2Metadata.java', 'TableTestBase.java', 'TestCreateTransaction.java', 'TestDataTableScan.java', 'TestDeleteFiles.java', 'TestEntriesMetadataTable.java', 'TestFastAppend.java', 'TestFilterFiles.java', 'TestFindFiles.java', 'TestFormatVersions.java', 'TestIncrementalDataTableScan.java', 'TestManifestCleanup.java', 'TestManifestReader.java', 'TestManifestWriter.java', 'TestMergeAppend.java', 'TestOverwrite.java', 'TestOverwriteWithValidation.java', 'TestPartitionSpecInfo.java', 'TestPartitionSpecParser.java', 'TestRemoveSnapshots.java', 'TestReplacePartitions.java', 'TestReplaceTransaction.java', 'TestRewriteFiles.java', 'TestRewriteManifests.java', 'TestScanSummary.java', 'TestScansAndSchemaEvolution.java', 'TestSchemaAndMappingUpdate.java', 'TestSnapshot.java', 'TestSnapshotSelection.java', 'TestSplitPlanning.java', 'TestTables.java', 'TestTimestampPartitions.java', 'TestTransaction.java', 'TestWapWorkflow.java', 'TestMappingUpdates.java']"
Remove trivial errors from output (#946),5,17,2020-04-21 14:32:14-07:00,"['DataTableScan.java', 'GenericManifestEntry.java', 'ManifestListWriter.java', 'ManifestReader.java', 'ManifestWriter.java']"
Refactor metadata inheritance for manifest rewrites (#941),6,178,2020-04-22 09:40:34-07:00,"['BaseRewriteManifests.java', 'FastAppend.java', 'InheritableMetadataFactory.java', 'ManifestFiles.java', 'MergingSnapshotProducer.java', 'TestForwardCompatibility.java']"
Inherit snapshot id and sequence number in entries metadata table (#951),5,217,2020-04-22 10:52:01-07:00,"['GenericManifestEntry.java', 'ManifestEntriesTable.java', 'TestEntriesMetadataTable.java', 'TestDataSourceOptions.java', 'TestIcebergSourceTablesBase.java']"
Refactor Parquet visitors to reduce duplication (#950),9,208,2020-04-23 10:06:16-07:00,"['GenericParquetReaders.java', 'GenericParquetWriter.java', 'ParquetAvroValueReaders.java', 'ParquetAvroWriter.java', 'ParquetTypeVisitor.java', 'TypeWithSchemaVisitor.java', 'PigParquetReader.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java']"
Spark: Implement an action to rewrite manifests (#875),9,1065,2020-04-23 10:43:05-07:00,"['Actions.java', 'BaseAction.java', 'BaseSnapshotUpdateAction.java', 'RemoveOrphanFilesAction.java', 'RewriteManifestsAction.java', 'RewriteManifestsActionResult.java', 'SnapshotUpdateAction.java', 'SparkDataFile.java', 'TestRewriteManifestsAction.java']"
Spark: Reorder null checks in SparkDataFile (#958),1,12,2020-04-23 14:00:24-07:00,['SparkDataFile.java']
Spec: Add field-id to partition fields (#957),1,5,2020-04-23 14:03:13-07:00,['spec.md']
Spark: Default staging location in RewriteManifestsAction to metadata location (#959),2,19,2020-04-23 16:28:48-07:00,"['RewriteManifestsAction.java', 'TestRewriteManifestsAction.java']"
ORC: Fix IndexOutOfBoundsException in GenericOrcReader caused by repeated records (#953),3,81,2020-04-24 10:02:29-07:00,"['GenericOrcReader.java', 'TestGenericData.java', 'TestSparkOrcReader.java']"
Site: Update status for Presto SQL (#967),1,2,2020-04-26 15:40:30-07:00,['presto.md']
Update iceberg-spark-runtime LICENSE and NOTICE (#966),4,538,2020-04-27 13:35:26-07:00,"['VectorHolder.java', 'build.gradle', 'LICENSE', 'NOTICE']"
Update release script and rat excludes for 0.8.0 (#975),2,4,2020-04-27 14:19:23-07:00,"['.rat-excludes', 'source-release.sh']"
Add DISCLAIMER to spark-runtime. (#977),1,10,2020-04-27 16:27:15-07:00,['DISCLAIMER']
Spark: Move TestRewriteManifestsAction to actions package (#979),1,10,2020-04-27 17:35:21-07:00,['TestRewriteManifestsAction.java']
Use correct manifest versions while rewriting manifests (#980),3,41,2020-04-27 18:01:44-07:00,"['ManifestFiles.java', 'TableTestBase.java', 'RewriteManifestsAction.java']"
Remove unused var in BaseRewriteManifests (#981),1,3,2020-04-27 18:01:59-07:00,['BaseRewriteManifests.java']
Clean up TestWapWorkflow (#982),1,16,2020-04-28 17:56:28-07:00,['TestWapWorkflow.java']
Add back deprecated methods used by Presto (#986),3,23,2020-04-29 16:34:21-07:00,"['TableMetadata.java', 'TableMetadataParser.java', 'TableMetadataParserTest.java']"
Suppress exceptions while unlocking tables in HiveTableOperations (#987),2,84,2020-04-29 17:51:01-07:00,"['HiveTableOperations.java', 'TestHiveCommits.java']"
ORC: Upgrade to 1.6.3 (#991),2,9,2020-05-01 16:25:32-07:00,"['versions.lock', 'versions.props']"
Fix Hadoop commit race condition (#990),1,34,2020-05-04 09:00:49-07:00,['HadoopTableOperations.java']
Emit UpdateEvent from operations that create snapshots (#939),17,231,2020-05-04 12:54:12-07:00,"['PendingUpdate.java', 'BaseMetastoreCatalog.java', 'BaseOverwriteFiles.java', 'BaseReplacePartitions.java', 'BaseRewriteFiles.java', 'BaseTable.java', 'BaseTransaction.java', 'FastAppend.java', 'MergeAppend.java', 'MergingSnapshotProducer.java', 'RollbackToSnapshot.java', 'SnapshotManager.java', 'SnapshotProducer.java', 'StreamingDelete.java', 'Transactions.java', 'CreateSnapshotEvent.java', 'TestTables.java']"
Add DateTimeUtil conversions to internal values (#1003),1,16,2020-05-05 09:36:56-07:00,['DateTimeUtil.java']
Hive: Allow managed table creation in test even if location exists (#1007),1,1,2020-05-06 10:39:28-07:00,['TestSparkTableUtil.java']
"Python: Removing dependency on moz_sql_parser (#993)

Co-authored-by: Ted Gooch <tgooch@netflix.com>",4,258,2020-05-06 11:40:48-07:00,"['expression_parser.py', 'expressions.py', 'setup.py', 'test_str_to_expr.py']"
Spark: Pass correct types to get data from InternalRow (#999),16,681,2020-05-07 08:55:01-07:00,"['AvroSchemaUtil.java', 'ValueWriters.java', 'GenericParquetWriter.java', 'ParquetAvroWriter.java', 'ParquetValueWriters.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'AvroWithSparkSchemaVisitor.java', 'ParquetWithSparkSchemaVisitor.java', 'SparkAvroWriter.java', 'SparkParquetWriters.java', 'IcebergSource.java', 'StreamingWriter.java', 'Writer.java', 'TestDataFileSerialization.java', 'TestSparkParquetWriter.java']"
Python: Fix partition spec names (#996),2,60,2020-05-07 09:37:18-07:00,"['partition_spec.py', 'test_partition_spec_parser.py']"
Add column reordering to UpdateSchema (#995),5,849,2020-05-07 09:38:15-07:00,"['UpdateSchema.java', 'IndexParents.java', 'TypeUtil.java', 'SchemaUpdate.java', 'TestSchemaUpdate.java']"
Refactor IndexByName to use before and after (#1002),2,146,2020-05-07 10:38:42-07:00,"['IndexByName.java', 'TypeUtil.java']"
Spark: Remove hasExtraFilterColumns (#1004),2,67,2020-05-07 12:18:24-07:00,"['Reader.java', 'RowDataReader.java']"
Parquet: Use new logical type annotations (#891),6,285,2020-05-07 13:01:45-07:00,"['GenericParquetWriter.java', 'DataTest.java', 'MessageTypeToType.java', 'ParquetWriter.java', 'TypeToMessageType.java', 'versions.props']"
Update docs for 0.8.0 release (#1012),516,177023,2020-05-08 10:01:51-07:00,"['getting-started.md', 'allclasses-frame.html', 'allclasses-noframe.html', 'constant-values.html', 'deprecated-list.html', 'help-doc.html', 'index-all.html', 'index.html', 'Accessor.html', 'Accessors.html', 'AllDataFilesTable.AllDataFilesTableScan.html', 'AllDataFilesTable.html', 'AllEntriesTable.html', 'AllManifestsTable.AllManifestsTableScan.html', 'AllManifestsTable.html', 'AppendFiles.html', 'BaseCombinedScanTask.html', 'BaseMetastoreCatalog.html', 'BaseMetastoreTableOperations.html', 'BaseOverwriteFiles.html', 'BaseReplacePartitions.html', 'BaseRewriteManifests.html', 'BaseTable.html', 'CachingCatalog.html', 'CombinedScanTask.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DataFilesTable.FilesTableScan.html', 'DataFilesTable.html', 'DataOperations.html', 'DataTableScan.html', 'DataTask.html', 'DeleteFiles.html', 'ExpireSnapshots.html', 'FileFormat.html', 'FileHistory.Builder.html', 'FileHistory.html', 'FileScanTask.html', 'Files.html', 'Filterable.html', 'FilteredManifest.html', 'FindFiles.Builder.html', 'FindFiles.html', 'GenericManifestFile.CopyBuilder.html', 'GenericManifestFile.html', 'GenericPartitionFieldSummary.html', 'HasTableOperations.html', 'HistoryEntry.html', 'HistoryTable.html', 'LocationProviders.html', 'ManageSnapshots.html', 'ManifestEntriesTable.html', 'ManifestFile.PartitionFieldSummary.html', 'ManifestFile.html', 'ManifestFiles.html', 'ManifestReader.html', 'ManifestWriter.html', 'ManifestsTable.html', 'MetadataTableType.html', 'Metrics.html', 'MetricsConfig.html', 'MetricsModes.Counts.html', 'MetricsModes.Full.html', 'MetricsModes.MetricsMode.html', 'MetricsModes.None.html', 'MetricsModes.Truncate.html', 'MetricsModes.html', 'OverwriteFiles.html', 'PartitionField.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'PartitionsTable.html', 'PendingUpdate.html', 'ReplacePartitions.html', 'RewriteFiles.html', 'RewriteManifests.html', 'Rollback.html', 'ScanSummary.Builder.html', 'ScanSummary.PartitionMetrics.html', 'ScanSummary.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'SetLocation.html', 'Snapshot.html', 'SnapshotManager.html', 'SnapshotParser.html', 'SnapshotSummary.Builder.html', 'SnapshotSummary.html', 'SnapshotUpdate.html', 'SnapshotsTable.html', 'StructLike.html', 'SystemProperties.html', 'Table.html', 'TableMetadata.MetadataLogEntry.html', 'TableMetadata.SnapshotLogEntry.html', 'TableMetadata.html', 'TableMetadataParser.Codec.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableProperties.html', 'TableScan.html', 'Tables.html', 'Transaction.html', 'Transactions.html', 'UpdateLocation.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Action.html', 'Actions.html', 'RemoveOrphanFilesAction.html', 'RewriteManifestsAction.html', 'RewriteManifestsActionResult.html', 'SnapshotUpdateAction.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ArrowSchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergArrowVectors.DecimalArrowVector.html', 'IcebergArrowVectors.VarBinaryArrowVector.html', 'IcebergArrowVectors.VarcharArrowVector.html', 'IcebergArrowVectors.html', 'NullabilityHolder.html', 'VectorHolder.html', 'VectorizedArrowReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseVectorizedParquetValuesReader.html', 'VectorizedColumnIterator.html', 'VectorizedDictionaryEncodedParquetValuesReader.html', 'VectorizedPageIterator.html', 'VectorizedParquetDefinitionLevelReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroIterable.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'AvroSchemaWithTypeVisitor.html', 'LogicalMap.html', 'ProjectionDatumReader.html', 'UUIDConversion.html', 'ValueReader.html', 'ValueReaders.StructReader.html', 'ValueReaders.html', 'ValueWriter.html', 'ValueWriters.StructWriter.html', 'ValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Catalog.html', 'Namespace.html', 'SupportsNamespaces.html', 'TableIdentifier.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DateTimeUtil.html', 'GenericRecord.html', 'IcebergGenerics.ScanBuilder.html', 'IcebergGenerics.html', 'Record.html', 'DataReader.html', 'DataWriter.html', 'IcebergDecoder.html', 'IcebergEncoder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericOrcReader.html', 'GenericOrcWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericParquetReaders.html', 'GenericParquetWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'EncryptedFiles.html', 'EncryptedInputFile.html', 'EncryptedOutputFile.html', 'EncryptionKeyMetadata.html', 'EncryptionKeyMetadatas.html', 'EncryptionManager.html', 'PlaintextEncryptionManager.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Listener.html', 'Listeners.html', 'ScanEvent.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CherrypickAncestorCommitException.html', 'CommitFailedException.html', 'DuplicateWAPCommitException.html', 'NamespaceNotEmptyException.html', 'NoSuchNamespaceException.html', 'NoSuchTableException.html', 'NotFoundException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'Bound.html', 'BoundLiteralPredicate.html', 'BoundPredicate.html', 'BoundReference.html', 'BoundSetPredicate.html', 'BoundTerm.html', 'BoundTransform.html', 'BoundUnaryPredicate.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.BoundVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'InclusiveMetricsEvaluator.html', 'Literal.html', 'ManifestEvaluator.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'StrictMetricsEvaluator.html', 'Term.html', 'True.html', 'Unbound.html', 'UnboundPredicate.html', 'UnboundTerm.html', 'UnboundTransform.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'HadoopCatalog.html', 'HadoopFileIO.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTableOperations.html', 'HadoopTables.html', 'HiddenPathFilter.html', 'SerializableConfiguration.html', 'Util.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ClientPool.Action.html', 'ClientPool.html', 'HiveCatalog.html', 'HiveCatalogs.html', 'HiveClientPool.html', 'HiveTableOperations.html', 'HiveTypeConverter.html', 'RuntimeMetaException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CloseableGroup.html', 'CloseableIterable.ConcatCloseableIterable.html', 'CloseableIterable.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'FileAppender.html', 'FileIO.html', 'InputFile.html', 'LocationProvider.html', 'OutputFile.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'MappedField.html', 'MappedFields.html', 'MappingUtil.html', 'NameMapping.html', 'NameMappingParser.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'SerializationUtil.html', 'IcebergInputFormat.ConfigBuilder.html', 'IcebergInputFormat.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ORC.ReadBuilder.html', 'ORC.WriteBuilder.html', 'ORC.html', 'ORCSchemaUtil.BinaryType.html', 'ORCSchemaUtil.LongType.html', 'ORCSchemaUtil.html', 'OrcMetrics.html', 'OrcValueReader.html', 'OrcValueWriter.html', 'VectorizedRowBatchIterator.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseColumnIterator.html', 'BasePageIterator.IntIterator.html', 'BasePageIterator.html', 'ColumnIterator.html', 'ColumnWriter.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetAvroReader.html', 'ParquetAvroValueReaders.TimeMillisReader.html', 'ParquetAvroValueReaders.TimestampMillisReader.html', 'ParquetAvroValueReaders.html', 'ParquetAvroWriter.html', 'ParquetDictionaryRowGroupFilter.html', 'ParquetIterable.html', 'ParquetMetricsRowGroupFilter.html', 'ParquetReader.html', 'ParquetSchemaUtil.html', 'ParquetTypeVisitor.html', 'ParquetUtil.html', 'ParquetValueReader.html', 'ParquetValueReaders.BinaryAsDecimalReader.html', 'ParquetValueReaders.BytesReader.html', 'ParquetValueReaders.FloatAsDoubleReader.html', 'ParquetValueReaders.IntAsLongReader.html', 'ParquetValueReaders.IntegerAsDecimalReader.html', 'ParquetValueReaders.ListReader.html', 'ParquetValueReaders.LongAsDecimalReader.html', 'ParquetValueReaders.MapReader.html', 'ParquetValueReaders.PrimitiveReader.html', 'ParquetValueReaders.RepeatedKeyValueReader.html', 'ParquetValueReaders.RepeatedReader.html', 'ParquetValueReaders.ReusableEntry.html', 'ParquetValueReaders.StringReader.html', 'ParquetValueReaders.StructReader.html', 'ParquetValueReaders.UnboxedReader.html', 'ParquetValueReaders.html', 'ParquetValueWriter.html', 'ParquetValueWriters.PrimitiveWriter.html', 'ParquetValueWriters.RepeatedKeyValueWriter.html', 'ParquetValueWriters.RepeatedWriter.html', 'ParquetValueWriters.StructWriter.html', 'ParquetValueWriters.html', 'ParquetWriteAdapter.html', 'TripleWriter.html', 'TypeToMessageType.html', 'TypeWithSchemaVisitor.html', 'ValuesAsBytesReader.html', 'VectorizedParquetReader.html', 'VectorizedReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergPigInputFormat.IcebergRecordReader.html', 'IcebergPigInputFormat.html', 'IcebergStorage.html', 'PigParquetReader.html', 'SchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PruneColumnsWithReordering.html', 'PruneColumnsWithoutReordering.html', 'SparkDataFile.html', 'SparkFilters.html', 'SparkSchemaUtil.html', 'SparkStructLike.html', 'SparkValueConverter.html', 'SparkAvroReader.html', 'SparkAvroWriter.html', 'SparkOrcReader.html', 'SparkOrcWriter.html', 'SparkParquetReaders.html', 'SparkParquetWriters.html', 'SparkValueReaders.html', 'SparkValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSource.html', 'StreamingWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PartitionSpecVisitor.html', 'Transform.html', 'Transforms.html', 'UnknownTransform.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CheckCompatibility.html', 'Comparators.html', 'Conversions.html', 'IndexByName.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BinPacking.ListPacker.html', 'BinPacking.PackingIterable.html', 'BinPacking.html', 'BinaryUtil.html', 'ByteBuffers.html', 'CharSequenceSet.html', 'CharSequenceWrapper.html', 'ExceptionUtil.html', 'Exceptions.html', 'JsonUtil.html', 'ManifestFileUtil.html', 'Pair.html', 'ParallelIterable.html', 'PartitionUtil.html', 'PropertyUtil.html', 'SerializableSupplier.html', 'SnapshotUtil.html', 'StructLikeWrapper.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'ThreadPools.html', 'UnicodeUtil.html', 'WapUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'overview-frame.html', 'overview-summary.html', 'overview-tree.html', 'package-list', 'script.js', 'serialized-form.html', 'stylesheet.css', 'index.html', 'releases.md', 'spark.md']"
Update ASF site to meet Apache guidelines (#1035),2,11,2020-05-11 15:46:44-07:00,"['trademarks.md', 'mkdocs.yml']"
Correctly catch CommitFailedException in BaseMetastoreCatalog#createTable (#1016),1,6,2020-05-11 18:08:38-07:00,['BaseMetastoreCatalog.java']
Support time type in Avro generics (#1015),3,9,2020-05-12 17:02:18-07:00,"['GenericAvroReader.java', 'GenericAvroWriter.java', 'AvroDataTest.java']"
Python: Add style checking with Flake8 to CI (#1034),13,35,2020-05-13 09:19:24-07:00,"['.travis.yml', 'README.md', 'closeable_iterable.py', 'partition_spec.py', 'type_util.py', 'avro_to_iceberg.py', 'base_metastore_tables.py', 'data_files.py', 's3_filesystem.py', 'scan_summary.py', 'setup.py', 'conftest.py', 'tox.ini']"
Refactor Parquet visitor (#1001),2,229,2020-05-13 10:20:05-07:00,"['MessageTypeToType.java', 'ParquetTypeVisitor.java']"
Update Copyright years to include 2020 (#1042),2,4,2020-05-13 16:50:18-07:00,"['NOTICE', 'NOTICE']"
Refactor ManifestReader (#1036),10,898,2020-05-14 11:00:43-07:00,"['Filterable.java', 'BaseManifestReader.java', 'BaseRewriteManifests.java', 'BaseSnapshot.java', 'FilteredManifest.java', 'ManifestEntriesTable.java', 'ManifestGroup.java', 'ManifestReader.java', 'TableTestBase.java', 'TestManifestReader.java']"
Add CloseableIterator (#1011),13,209,2020-05-15 08:58:07-07:00,"['CloseableIterable.java', 'CloseableIterator.java', 'BaseManifestReader.java', 'AvroIterable.java', 'ParallelIterable.java', 'TableScanIterable.java', 'IcebergInputFormat.java', 'OrcIterable.java', 'ParquetIterable.java', 'ParquetReader.java', 'VectorizedParquetReader.java', 'BaseDataReader.java', 'RowDataReader.java']"
Spotless: Add JMH source folders and update import order config (#1048),1,4,2020-05-18 11:52:27-07:00,['baseline.gradle']
Python: Fix partition spec and transforms (#1045),7,151,2020-05-18 13:38:22-07:00,"['partition_spec.py', 'bucket.py', 'dates.py', 'timestamps.py', 'transforms.py', 'truncate.py', 'test_partition_spec.py']"
"Python: Add persistent IDs to partition fields (#1047)

Python port of #845.",5,184,2020-05-18 13:56:36-07:00,"['partition_field.py', 'partition_spec.py', 'transforms.py', 'partition_spec_parser.py', 'test_partition_spec_parser.py']"
Python: Update tests for partition field ID (#1049),1,62,2020-05-19 21:48:14-07:00,['test_partition_spec.py']
Python: Enable mypy type validation (#1041),5,34,2020-05-21 10:25:39-07:00,"['.gitignore', 'type_util.py', 'base_table_scan.py', 'manifest_reader.py', 'tox.ini']"
"Add assertions for sequence numbers to TestFastAppend (#1038)

* Add assertions for sequence numbers to TestFastAppend.

* Fix checkstyle.",2,123,2020-05-21 10:31:07-07:00,"['TableTestBase.java', 'TestFastAppend.java']"
"Parquet: Support reading TIME_MILLIS in GenericParquetReader (#1031)

Fixes #502.",1,13,2020-05-21 12:59:26-07:00,['GenericParquetReaders.java']
Fix RemoveOrphanFilesAction when file_path is not a qualified path (#1052),2,70,2020-05-22 08:46:38-07:00,"['RemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction.java']"
Spark: Add ORC JMH tests for IcebergSource (#900),3,381,2020-05-22 11:31:43-07:00,"['IcebergSourceFlatORCDataBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java']"
ORC: Supported nested identity partition data (#989),14,1185,2020-05-22 11:41:45-07:00,"['GenericOrcReader.java', 'ORC.java', 'ORCSchemaUtil.java', 'OrcIterable.java', 'OrcRowReader.java', 'OrcSchemaWithTypeVisitor.java', 'OrcValueReader.java', 'OrcValueReaders.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'PartitionRowConverter.java', 'RowDataReader.java', 'TestSparkOrcReader.java', 'TestPartitionValues.java']"
Remove most references to the Incubator (#1059),11,63,2020-05-22 12:57:50-07:00,"['DISCLAIMER', 'README.md', 'build.gradle', 'deploy.gradle', 'source-release.sh', 'extra.css', 'disclaimer.md', 'how-to-release.md', 'index.md', 'mkdocs.yml', 'DISCLAIMER']"
Add content types to DataFile and ManifestFile (#1030),16,695,2020-05-23 12:10:42-07:00,"['DataFile.java', 'FileContent.java', 'ManifestContent.java', 'ManifestFile.java', 'Types.java', 'TestHelpers.java', 'AllEntriesTable.java', 'GenericDataFile.java', 'GenericManifestFile.java', 'ManifestListWriter.java', 'ManifestWriter.java', 'SnapshotProducer.java', 'V1Metadata.java', 'V2Metadata.java', 'TestManifestListVersions.java', 'TestIcebergSourceTablesBase.java']"
ORC: Push down Iceberg filters (#973),14,2944,2020-05-25 10:15:35-07:00,"['TableScanIterable.java', 'TestMetricsRowGroupFilter.java', 'TestMetricsRowGroupFilterTypes.java', 'IcebergInputFormat.java', 'ExpressionToSearchArgument.java', 'IdToOrcName.java', 'ORC.java', 'ORCSchemaUtil.java', 'OrcIterable.java', 'TestExpressionToSearchArgument.java', 'TestIdToOrcName.java', 'TestMetricsRowGroupFilter.java', 'TestMetricsRowGroupFilterTypes.java', 'RowDataReader.java']"
"Fix conversion accessors for nested fields (#1013)

Accessors that convert values were not correctly wrapped when nested because they extend PositionAccessor, which is replaced when nested by Position2Accessor or similar classes. The short-term fix is to check that the accessor is PositionAccessor, not a subclass. Long term, conversion should not be done in accessors.",3,62,2020-05-25 10:38:48-07:00,"['Accessors.java', 'PartitionKey.java', 'TestPartitionValues.java']"
"Fix date and timestamp filters with generics (#983)

Date and timestamp values were not the correct type for Evaluator.",3,141,2020-05-26 09:42:36-07:00,"['InternalRecordWrapper.java', 'TableScanIterable.java', 'TestLocalScan.java']"
Spark: Apply options from Spark to Hadoop conf used for locality (#1066),1,16,2020-05-26 12:07:38-07:00,['Reader.java']
"Add shaded Guava module (#1068)

Co-authored-by: awoodhead <awoodhead@expediagroup.com>
Co-authored-by: cmathiesen <t-cmathiesen@hotels.com>",348,1853,2020-05-26 14:42:24-07:00,"['Accessors.java', 'PartitionField.java', 'PartitionSpec.java', 'Schema.java', 'TableScan.java', 'Tables.java', 'Namespace.java', 'SupportsNamespaces.java', 'TableIdentifier.java', 'EncryptionManager.java', 'Listeners.java', 'Binder.java', 'BoundLiteralPredicate.java', 'BoundSetPredicate.java', 'Expressions.java', 'Literals.java', 'NamedReference.java', 'Predicate.java', 'StrictMetricsEvaluator.java', 'UnboundPredicate.java', 'CloseableGroup.java', 'CloseableIterable.java', 'Bucket.java', 'Identity.java', 'PartitionSpecVisitor.java', 'ProjectionUtil.java', 'Transforms.java', 'Truncate.java', 'AssignFreshIds.java', 'CheckCompatibility.java', 'Comparators.java', 'GetProjectedIds.java', 'IndexById.java', 'IndexByName.java', 'IndexParents.java', 'PruneColumns.java', 'ReassignIds.java', 'TypeUtil.java', 'Types.java', 'BinaryUtil.java', 'CharSequenceSet.java', 'UnicodeUtil.java', 'TestInclusiveManifestEvaluator.java', 'TestInclusiveMetricsEvaluator.java', 'TestStrictMetricsEvaluator.java', 'TestCloseableIterable.java', 'TestBucketing.java', 'TestBucketingProjection.java', 'TestDatesProjection.java', 'TestProjection.java', 'TestTimestampsProjection.java', 'TestTruncatesProjection.java', 'ArrowSchemaUtil.java', 'VectorizedArrowReader.java', 'BaseVectorizedParquetValuesReader.java', 'VectorizedColumnIterator.java', 'build.gradle', 'LICENSE', 'NOTICE', 'GuavaClasses.java', 'DynClasses.java', 'DynConstructors.java', 'DynFields.java', 'DynMethods.java', 'AllDataFilesTable.java', 'AllEntriesTable.java', 'AllManifestsTable.java', 'BaseAllMetadataTableScan.java', 'BaseCombinedScanTask.java', 'BaseFileScanTask.java', 'BaseManifestReader.java', 'BaseMetadataTable.java', 'BaseMetastoreCatalog.java', 'BaseMetastoreTableOperations.java', 'BaseOverwriteFiles.java', 'BaseRewriteFiles.java', 'BaseRewriteManifests.java', 'BaseSnapshot.java', 'BaseTableScan.java', 'BaseTransaction.java', 'DataFiles.java', 'DataFilesTable.java', 'DataTableScan.java', 'FastAppend.java', 'FileHistory.java', 'FindFiles.java', 'GenericDataFile.java', 'GenericManifestEntry.java', 'GenericManifestFile.java', 'GenericPartitionFieldSummary.java', 'HistoryTable.java', 'IncrementalDataTableScan.java', 'InheritableMetadataFactory.java', 'LocationProviders.java', 'ManifestEntriesTable.java', 'ManifestFiles.java', 'ManifestGroup.java', 'ManifestListWriter.java', 'ManifestLists.java', 'ManifestWriter.java', 'ManifestsTable.java', 'MergeAppend.java', 'MergingSnapshotProducer.java', 'MetricsConfig.java', 'MetricsModes.java', 'PartitionData.java', 'PartitionSpecParser.java', 'PartitionsTable.java', 'PropertiesUpdate.java', 'RemoveSnapshots.java', 'ScanSummary.java', 'SchemaParser.java', 'SchemaUpdate.java', 'SerializableByteBufferMap.java', 'SnapshotManager.java', 'SnapshotParser.java', 'SnapshotProducer.java', 'SnapshotSummary.java', 'StaticDataTask.java', 'StaticTableScan.java', 'TableMetadata.java', 'TableMetadataParser.java', 'Transactions.java', 'V2Metadata.java', 'Avro.java', 'AvroCustomOrderSchemaVisitor.java', 'AvroIterable.java', 'AvroSchemaUtil.java', 'AvroSchemaVisitor.java', 'AvroSchemaWithTypeVisitor.java', 'BuildAvroProjection.java', 'GenericAvroReader.java', 'GenericAvroWriter.java', 'LogicalMap.java', 'PruneColumns.java', 'SchemaToType.java', 'TypeToSchema.java', 'ValueReaders.java', 'ValueWriters.java', 'HadoopCatalog.java', 'HadoopInputFile.java', 'HadoopStreams.java', 'HadoopTableOperations.java', 'HadoopTables.java', 'Util.java', 'MappedField.java', 'MappedFields.java', 'MappingUtil.java', 'NameMapping.java', 'NameMappingParser.java', 'BinPacking.java', 'JsonUtil.java', 'ManifestFileUtil.java', 'Pair.java', 'ParallelIterable.java', 'SnapshotUtil.java', 'Tasks.java', 'ThreadPools.java', 'LocalTableOperations.java', 'TableMetadataParserTest.java', 'TableTestBase.java', 'TestCreateTransaction.java', 'TestEntriesMetadataTable.java', 'TestFastAppend.java', 'TestFilterFiles.java', 'TestFindFiles.java', 'TestFixedSizeSplitScanTaskIterator.java', 'TestIncrementalDataTableScan.java', 'TestManifestListVersions.java', 'TestManifestReader.java', 'TestManifestWriterVersions.java', 'TestMergeAppend.java', 'TestMetrics.java', 'TestMetricsModes.java', 'TestOffsetsBasedSplitScanTaskIterator.java', 'TestOverwrite.java', 'TestOverwriteWithValidation.java', 'TestPartitionSpecInfo.java', 'TestRemoveSnapshots.java', 'TestReplaceTransaction.java', 'TestRewriteManifests.java', 'TestScanDataFileColumns.java', 'TestScanSummary.java', 'TestScansAndSchemaEvolution.java', 'TestSchemaAndMappingUpdate.java', 'TestSchemaUpdate.java', 'TestSnapshotJson.java', 'TestSnapshotSelection.java', 'TestSplitPlanning.java', 'TestTableMetadata.java', 'TestTables.java', 'TestTransaction.java', 'TestWapWorkflow.java', 'RandomAvroData.java', 'RemoveIds.java', 'TestAvroEnums.java', 'TestAvroNameMapping.java', 'TestAvroReadProjection.java', 'TestGenericAvro.java', 'TestReadProjection.java', 'TestSchemaConversions.java', 'HadoopTableTestBase.java', 'TestHadoopCatalog.java', 'TestHadoopCommits.java', 'TestMappingUpdates.java', 'TestBinPacking.java', 'GenericRecord.java', 'IcebergGenerics.java', 'TableScanIterable.java', 'DataReader.java', 'DataWriter.java', 'IcebergDecoder.java', 'IcebergEncoder.java', 'GenericOrcReader.java', 'GenericOrcWriter.java', 'GenericParquetReaders.java', 'GenericParquetWriter.java', 'TestSplitScan.java', 'RandomGenericData.java', 'TestLocalScan.java', 'TestReadProjection.java', 'TestGenericData.java', 'TestGenericReadProjection.java', 'TestSingleMessageEncoding.java', 'TestGenericData.java', 'TestGenericReadProjection.java', 'TestGenericData.java', 'TestGenericReadProjection.java', 'deploy.gradle', 'ClientPool.java', 'HiveCatalog.java', 'HiveTableOperations.java', 'HiveCreateReplaceTableTest.java', 'HiveTableTest.java', 'TestHiveCatalog.java', 'TestHiveTableConcurrency.java', 'IcebergInputFormat.java', 'TestIcebergInputFormat.java', 'ORC.java', 'ORCSchemaUtil.java', 'OrcFileAppender.java', 'BasePageIterator.java', 'MessageTypeToType.java', 'PageIterator.java', 'Parquet.java', 'ParquetAvro.java', 'ParquetAvroValueReaders.java', 'ParquetAvroWriter.java', 'ParquetDictionaryRowGroupFilter.java', 'ParquetMetricsRowGroupFilter.java', 'ParquetReadSupport.java', 'ParquetSchemaUtil.java', 'ParquetTypeVisitor.java', 'ParquetUtil.java', 'ParquetValueReaders.java', 'ParquetValueWriters.java', 'ParquetWriteAdapter.java', 'ParquetWriteSupport.java', 'ParquetWriter.java', 'PruneColumns.java', 'ReadConf.java', 'TypeWithSchemaVisitor.java', 'ValuesAsBytesReader.java', 'VectorizedReader.java', 'TestParquetReadProjection.java', 'TestReadProjection.java', 'ParquetWritingTestUtils.java', 'TestParquet.java', 'IcebergPigInputFormat.java', 'IcebergStorage.java', 'PigParquetReader.java', 'SchemaUtil.java', 'settings.gradle', 'SparkBenchmarkUtil.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'BaseSnapshotUpdateAction.java', 'RemoveOrphanFilesAction.java', 'RewriteManifestsAction.java', 'RewriteManifestsActionResult.java', 'FixupTypes.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'SparkDataFile.java', 'SparkFilters.java', 'SparkSchemaUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'SparkValueConverter.java', 'TypeToSparkType.java', 'AvroWithSparkSchemaVisitor.java', 'ParquetWithSparkSchemaVisitor.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'BaseDataReader.java', 'IcebergSource.java', 'PartitionKey.java', 'Reader.java', 'RowDataReader.java', 'StructInternalRow.java', 'Writer.java', 'SparkTableUtil.scala', 'TestDataFileSerialization.java', 'TestManifestFileSerialization.java', 'TestRemoveOrphanFilesAction.java', 'TestRewriteManifestsAction.java', 'ReadAndWriteTablesTest.java', 'SimpleRecord.java', 'SnapshotFunctionalityTest.java', 'TestSparkDataFile.java', 'GenericsHelpers.java', 'RandomData.java', 'TestHelpers.java', 'TestSparkAvroEnums.java', 'TestSparkAvroReader.java', 'SimpleRecord.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestFilteredScan.java', 'TestForwardCompatibility.java', 'TestIcebergSourceTablesBase.java', 'TestIdentityPartitionData.java', 'TestPartitionValues.java', 'TestReadProjection.java', 'TestSnapshotSelection.java', 'TestSparkDataWrite.java', 'TestSparkReadProjection.java', 'TestSparkSchema.java', 'TestSparkTableUtil.java', 'TestSparkTableUtilWithInMemoryCatalog.java', 'TestStructuredStreaming.java', 'TestTables.java', 'TestWriteMetricsConfig.java', 'versions.props']"
"ORC: Disable predicate pushdown for timestamp type (#1069)

* Correctly handle timestamps less than epoch
* Disable ORC pushdown for timestamp types because of ORC-611",4,39,2020-05-26 16:55:55-07:00,"['TestLocalScan.java', 'TestMetricsRowGroupFilterTypes.java', 'ExpressionToSearchArgument.java', 'TestExpressionToSearchArgument.java']"
Update metrics tests to use Iceberg generics (#1070),15,473,2020-05-27 13:56:37-07:00,"['Record.java', 'build.gradle', 'GenericRecord.java', 'DataReader.java', 'DataWriter.java', 'GenericReaders.java', 'GenericWriters.java', 'IcebergDecoder.java', 'IcebergEncoder.java', 'DateTimeUtil.java', 'TestMetrics.java', 'InternalRecordWrapper.java', 'TableScanIterable.java', 'TestParquetMetrics.java', 'TestParquetMetrics.java']"
ORC: In BuildOrcProjection field should be optional if any parent is optional (#1071),4,111,2020-05-28 08:38:30-07:00,"['TestMetricsRowGroupFilter.java', 'TestReadProjection.java', 'ORCSchemaUtil.java', 'TestBuildOrcProjection.java']"
Replace references for incubator-iceberg with iceberg repository (#1062),11,68,2020-05-28 08:39:25-07:00,"['README.md', 'deploy.gradle', 'source-release.sh', 'README.md', 'setup.py', 'community.md', 'how-to-release.md', 'python-quickstart.md', 'releases.md', 'mkdocs.yml', 'README.md']"
ORC: Support nested identity partitioning for Iceberg generics (#1072),4,710,2020-05-28 10:19:11-07:00,"['TableScanIterable.java', 'GenericOrcReader.java', 'GenericOrcReaders.java', 'DataTestHelpers.java']"
Add DeleteFile and manifest reader and writer for deletes (#1064),33,1608,2020-05-29 12:26:56-07:00,"['ContentFile.java', 'DataFile.java', 'DeleteFile.java', 'InclusiveMetricsEvaluator.java', 'BaseFile.java', 'BaseManifestReader.java', 'BaseMetastoreCatalog.java', 'BaseRewriteManifests.java', 'BaseSnapshot.java', 'DeleteManifestReader.java', 'FileHistory.java', 'FindFiles.java', 'GenericDataFile.java', 'GenericDeleteFile.java', 'GenericManifestEntry.java', 'InheritableMetadata.java', 'InheritableMetadataFactory.java', 'ManifestEntriesTable.java', 'ManifestEntry.java', 'ManifestFiles.java', 'ManifestGroup.java', 'ManifestWriter.java', 'MergingSnapshotProducer.java', 'RemoveSnapshots.java', 'ScanSummary.java', 'SnapshotProducer.java', 'V1Metadata.java', 'V2Metadata.java', 'TableTestBase.java', 'TestManifestReader.java', 'TestManifestWriterVersions.java', 'TestMergeAppend.java', 'TestRewriteManifests.java']"
Use relocated guava classes (#1076),15,46,2020-05-29 12:56:08-07:00,"['checkstyle-suppressions.xml', 'checkstyle.xml', 'GenericOrcReaders.java', 'TestLocalScan.java', 'TestMetricsRowGroupFilter.java', 'TestMetricsRowGroupFilterTypes.java', 'ExpressionToSearchArgument.java', 'IdToOrcName.java', 'OrcSchemaWithTypeVisitor.java', 'OrcValueReaders.java', 'IcebergSourceFlatORCDataBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java']"
Exclude Guava from the compile classpath (#1079),4,19,2020-05-29 14:51:29-07:00,"['build.gradle', 'BaseFile.java', 'GenericDataFile.java', 'GenericDeleteFile.java']"
Hive: Upgrade 2.3.6 to 2.3.7 (#1084),2,25,2020-06-01 12:16:41-07:00,"['versions.lock', 'versions.props']"
Add .asf.yaml,1,12,2020-06-01 18:36:34-07:00,['.asf.yaml']
"Use Nebula version plugins (#1067)

This replaces `gradle-consistent-versions` with `nebula.dependency-recommender` and `nebula.dependency-lock`. The purpose of this change is to enable having separate Spark 2.x and Spark 3.x modules in the build. An empty `spark3` project is included.

The dependency recommender plugin is used to get versions from `versions.props` or the per-project dependency lock files.

The dependency lock plugin is used to lock versions. Locks are now generated in the `build/` folders using `./gradlew generateLock`, and used in the build after running `./gradlew saveLock`. The JSON lock files are added in this commit. These are large because they include transitive information and a set of dependencies per configuration.

This also fixes a problem where JMH dependencies needed to be declared in the compile configuration. Now JMH dependencies can use the jmh configuration.",16,68507,2020-06-01 20:20:42-07:00,"['dependencies.lock', 'dependencies.lock', 'build.gradle', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'settings.gradle', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'versions.props']"
"Split Snapshot.manifests into dataManifests and deleteManifests (#1080)

This replaces all calls to Snapshot.manifests with calls to one of 3 new methods:

* `Snapshot.allManifests` returns both delete and data manifests
* `Snapshot.deleteManifests` returns only delete manifests
* `Snapshot.dataManifests` returns only data manifests

Existing references mostly use either `allManifests` or `dataManifests`, depending on the context. For example, tests with assertions for the number of manifests use `allManifests` because the test cases should validate there are no new delete manifests, but other tests that validate rewritten manifests are deleted use `dataManifests` because only data manifests are rewritten and deleted.

This tries to make minimal changes that preserve the current behavior. Operations are not updated to support delete manifests (rewrite still only rewrites data manifests), but will carry through the list of delete manifests correctly.",47,828,2020-06-02 12:43:03-07:00,"['Snapshot.java', 'AllDataFilesTable.java', 'AllEntriesTable.java', 'AllManifestsTable.java', 'BaseMetastoreCatalog.java', 'BaseRewriteManifests.java', 'BaseSnapshot.java', 'BaseTransaction.java', 'DataFilesTable.java', 'DataTableScan.java', 'FastAppend.java', 'FileHistory.java', 'FindFiles.java', 'IncrementalDataTableScan.java', 'ManifestEntriesTable.java', 'ManifestsTable.java', 'MergingSnapshotProducer.java', 'RemoveSnapshots.java', 'ScanSummary.java', 'SnapshotParser.java', 'SnapshotProducer.java', 'TableTestBase.java', 'TestDeleteFiles.java', 'TestEntriesMetadataTable.java', 'TestFastAppend.java', 'TestManifestCleanup.java', 'TestMergeAppend.java', 'TestOverwrite.java', 'TestRemoveSnapshots.java', 'TestReplacePartitions.java', 'TestRewriteFiles.java', 'TestRewriteManifests.java', 'TestSnapshotJson.java', 'TestTableMetadata.java', 'TestTimestampPartitions.java', 'TestTransaction.java', 'TestWapWorkflow.java', 'TestHadoopCommits.java', 'HiveCreateReplaceTableTest.java', 'HiveTableTest.java', 'TestHiveTableConcurrency.java', 'RewriteManifestsAction.java', 'TestRewriteManifestsAction.java', 'TestSparkDataFile.java', 'TestDataSourceOptions.java', 'TestIcebergSourceTablesBase.java', 'TestSparkDataWrite.java']"
ORC: Support metrics in Iceberg metadata (#199),7,445,2020-06-02 15:25:44-07:00,"['DateTimeUtil.java', 'TestMetrics.java', 'TestOrcMetrics.java', 'TestParquetMetrics.java', 'ORCSchemaUtil.java', 'OrcFileAppender.java', 'OrcMetrics.java']"
Add unit tests for sequence numbers (#974),5,462,2020-06-02 15:39:25-07:00,"['BaseRewriteManifests.java', 'FastAppend.java', 'MergeAppend.java', 'MergingSnapshotProducer.java', 'TestSequenceNumberForV2Table.java']"
Update sequence number tests to use allManifests (#1087),1,56,2020-06-02 18:11:14-07:00,['TestSequenceNumberForV2Table.java']
Use correct spec while merging manifests in MergingSnapshotProducer (#1089),1,2,2020-06-02 21:30:34-07:00,['MergingSnapshotProducer.java']
Add ignoreResiduals option to TableScan (#1094),16,485,2020-06-05 09:17:36-07:00,"['TableScan.java', 'AllDataFilesTable.java', 'AllEntriesTable.java', 'AllManifestsTable.java', 'BaseAllMetadataTableScan.java', 'BaseTableScan.java', 'DataFilesTable.java', 'DataTableScan.java', 'IncrementalDataTableScan.java', 'ManifestEntriesTable.java', 'ManifestGroup.java', 'StaticTableScan.java', 'TableTestBase.java', 'TestDataTableScan.java', 'TestIncrementalDataTableScan.java', 'TestMetadataTableScans.java']"
Combine ManifestReaders into one parameterized class. (#1099),14,703,2020-06-09 10:43:32-07:00,"['BaseManifestReader.java', 'BaseMetastoreCatalog.java', 'BaseRewriteManifests.java', 'DeleteManifestReader.java', 'ManifestFiles.java', 'ManifestGroup.java', 'ManifestReader.java', 'MergingSnapshotProducer.java', 'RemoveSnapshots.java', 'SnapshotProducer.java', 'TestManifestReader.java', 'TestRewriteManifests.java', 'TestTransaction.java', 'TestSparkDataFile.java']"
Make table metadata serializable (#1085),17,162,2020-06-09 13:19:13-07:00,"['HistoryEntry.java', 'Snapshot.java', 'AllManifestsTable.java', 'BaseMetastoreCatalog.java', 'BaseSnapshot.java', 'HistoryTable.java', 'ManifestsTable.java', 'PartitionsTable.java', 'SnapshotParser.java', 'SnapshotProducer.java', 'SnapshotsTable.java', 'TableMetadata.java', 'TestSnapshotJson.java', 'TestTableMetadataSerialization.java', 'HiveTableOperations.java', 'HiveTableTest.java', 'RemoveOrphanFilesAction.java']"
Update dependency locks (#1086),13,8852,2020-06-09 13:19:43-07:00,"['dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock']"
Add test case for deleting column in Hive metastore  (#1097),2,33,2020-06-09 14:16:35-07:00,"['HiveTableTest.java', 'TestHiveMetastore.java']"
Refactor MergingSnapshotProducer (#1098),10,1301,2020-06-10 08:43:19-07:00,"['StrictMetricsEvaluator.java', 'CharSequenceSet.java', 'BaseReplacePartitions.java', 'ManifestFilterManager.java', 'ManifestMergeManager.java', 'MergingSnapshotProducer.java', 'SnapshotSummary.java', 'Exceptions.java', 'TableTestBase.java', 'TestSequenceNumberForV2Table.java']"
Refactor RandomData classes to extract common methods (#1102),4,683,2020-06-10 10:14:39-07:00,"['RandomUtil.java', 'RandomAvroData.java', 'RandomGenericData.java', 'RandomData.java']"
"Support cherry-pick for dynamic partition overwrites (#1073)

* Add support to cherry-pick dynamic partition overwrites.

* Add replace-partitions property.

* Fix checkstyle.",6,369,2020-06-10 12:47:53-07:00,"['BaseOverwriteFiles.java', 'BaseReplacePartitions.java', 'SnapshotManager.java', 'SnapshotSummary.java', 'SnapshotUtil.java', 'TestSnapshotManager.java']"
Add DataFile rewrite Action (#1083),10,909,2020-06-11 13:29:24-07:00,"['BaseTableScan.java', 'TableScanUtil.java', 'Actions.java', 'BaseAction.java', 'RewriteDataFilesAction.java', 'RewriteDataFilesActionResult.java', 'RewriteManifestsAction.java', 'RowDataRewriter.java', 'Writer.java', 'TestRewriteDataFilesAction.java']"
Spark: Support vectorized Parquet reads for flat projections (#828),33,2475,2020-06-15 15:16:19-07:00,"['ArrowAllocation.java', 'IcebergArrowVectors.java', 'VectorHolder.java', 'VectorizedArrowReader.java', 'VectorizedColumnIterator.java', 'VectorizedDictionaryEncodedParquetValuesReader.java', 'VectorizedPageIterator.java', 'VectorizedParquetDefinitionLevelReader.java', 'build.gradle', 'TableProperties.java', 'ParquetUtil.java', 'VectorizedParquetReader.java', 'VectorizedReader.java', 'IcebergSourceBenchmark.java', 'ArrowVectorAccessor.java', 'ArrowVectorAccessors.java', 'ColumnarBatchReader.java', 'IcebergArrowColumnVector.java', 'NullValuesColumnVector.java', 'VectorizedSparkParquetReaders.java', 'BatchDataReader.java', 'Reader.java', 'AvroDataTest.java', 'RandomData.java', 'TestHelpers.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkParquetWriter.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryFallbackToPlainEncodingVectorizedReads.java', 'TestParquetVectorizedReads.java', 'TestParquetScan.java', 'TestSparkReadProjection.java']"
Account for minor clock skew between concurrent commits (#1110),3,75,2020-06-15 15:33:10-07:00,"['TableMetadata.java', 'TableMetadataParser.java', 'TestTableMetadata.java']"
Support DeleteFile in MergingSnapshotProducer (#1105),18,1153,2020-06-16 08:27:45-07:00,"['RowDelta.java', 'Table.java', 'Transaction.java', 'BaseMetadataTable.java', 'BaseRowDelta.java', 'BaseTable.java', 'BaseTransaction.java', 'CommitCallbackTransaction.java', 'DataFiles.java', 'FileMetadata.java', 'ManifestFilterManager.java', 'ManifestReader.java', 'MergingSnapshotProducer.java', 'SnapshotProducer.java', 'SnapshotSummary.java', 'TableTestBase.java', 'TestRowDelta.java', 'V2TableTestBase.java']"
Refactor TableScan optional arguments into an immutable context object (#1115),11,472,2020-06-16 17:12:05-07:00,"['AllDataFilesTable.java', 'AllEntriesTable.java', 'AllManifestsTable.java', 'BaseAllMetadataTableScan.java', 'BaseTableScan.java', 'DataFilesTable.java', 'DataTableScan.java', 'IncrementalDataTableScan.java', 'ManifestEntriesTable.java', 'StaticTableScan.java', 'TableScanContext.java']"
Parquet: Support name mappings to recover field IDs (#830),18,569,2020-06-17 09:57:08-07:00,"['Avro.java', 'TestAvroNameMapping.java', 'ApplyNameMapping.java', 'Parquet.java', 'ParquetReadSupport.java', 'ParquetReader.java', 'ParquetSchemaUtil.java', 'PruneColumns.java', 'ReadConf.java', 'VectorizedParquetReader.java', 'TestParquetSchemaUtil.java', 'SparkParquetReaders.java', 'VectorizedSparkParquetReaders.java', 'BatchDataReader.java', 'Reader.java', 'RowDataReader.java', 'RowDataRewriter.java', 'TestSparkTableUtil.java']"
Docs: Add slack channel to README and website (#1120),2,4,2020-06-17 10:20:08-07:00,"['README.md', 'community.md']"
Flink: Add Flink module and type converter (#1096),10,10184,2020-06-17 10:45:15-07:00,"['TypeUtil.java', 'build.gradle', 'dependencies.lock', 'FlinkSchemaUtil.java', 'FlinkTypeToType.java', 'FlinkTypeVisitor.java', 'TestFlinkSchemaUtil.java', 'settings.gradle', 'IcebergSource.java', 'versions.props']"
Add modules for Spark 3 integration (#1108),20,21868,2020-06-17 10:47:02-07:00,"['dependencies.lock', 'dependencies.lock', 'build.gradle', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'settings.gradle', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'LICENSE', 'NOTICE', 'dependencies.lock', 'dependencies.lock']"
"Docs: Add HadoopCatalog example (#1095)

Co-authored-by:  <hzfanxinxin@corp.netease.com>",2,62,2020-06-17 10:56:08-07:00,"['api-quickstart.md', 'java-api-quickstart.md']"
Spark: Update spark3 to use 3.0.0 release artifacts (#1123),3,611,2020-06-19 13:35:57-07:00,"['build.gradle', 'dependencies.lock', 'versions.props']"
Spark: Move classes that depend on 2.x DSv2 to spark2 (#1122),55,1423,2020-06-19 18:02:23-07:00,"['build.gradle', 'RewriteDataFilesAction.java', 'BaseDataReader.java', 'BaseWriter.java', 'OutputFileFactory.java', 'PartitionedWriter.java', 'RowDataRewriter.java', 'SparkAppenderFactory.java', 'TaskResult.java', 'UnpartitionedWriter.java', 'Writer.java', 'SparkFilters.java', 'IcebergSource.java', 'Reader.java', 'Stats.java', 'StreamingWriter.java', 'Writer.java', 'org.apache.spark.sql.sources.DataSourceRegister', 'SparkTableUtil.scala', 'TestRemoveOrphanFilesAction.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'ConcurrencyTest.java', 'README.md', 'ReadAndWriteTablesTest.java', 'SchemaEvolutionTest.java', 'SimpleRecord.java', 'SnapshotFunctionalityTest.java', 'TestSparkDataFile.java', 'LogMessage.java', 'SimpleRecord.java', 'TestAvroScan.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestFilteredScan.java', 'TestForwardCompatibility.java', 'TestIcebergSource.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestIdentityPartitionData.java', 'TestParquetScan.java', 'TestPartitionValues.java', 'TestReadProjection.java', 'TestSnapshotSelection.java', 'TestSparkDataWrite.java', 'TestSparkReadProjection.java', 'TestSparkSchema.java', 'TestSparkTableUtil.java', 'TestSparkTableUtilWithInMemoryCatalog.java', 'TestStructuredStreaming.java', 'TestTables.java', 'TestWriteMetricsConfig.java', 'books.json', 'new-books.json']"
MR: Pass identity values via constants map in InputFormat (#1130),3,215,2020-06-22 14:52:19-07:00,"['IdentityPartitionConverters.java', 'TableScanIterable.java', 'IcebergInputFormat.java']"
Remove existing IDs in Parquet name mapping tests (#1128),2,84,2020-06-23 09:34:40-07:00,"['RemoveIds.java', 'TestParquetSchemaUtil.java']"
Spark: Read using Avro name mapping if configured (#1129),3,161,2020-06-23 10:28:42-07:00,"['RemoveIds.java', 'RowDataReader.java', 'TestNameMappingProjection.java']"
Avro: Fix errors when reading options with non-null defaults (#1132),2,151,2020-06-23 16:27:01-07:00,"['PruneColumns.java', 'TestAvroOptionsWithNonNullDefaults.java']"
Spark: Update Avro name mapping unit test (#1135),1,9,2020-06-23 17:02:06-07:00,['TestNameMappingProjection.java']
Spark: Add benchmarks for vectorized reads (#1133),24,518,2020-06-23 17:31:29-07:00,"['build.gradle', 'jmh.gradle', 'SparkBenchmarkUtil.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'Action.java', 'IcebergSourceBenchmark.java', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java']"
ORC: Fix date metrics (#1127),4,195,2020-06-27 13:42:10-07:00,"['TestLocalScan.java', 'TestGenericData.java', 'OrcMetrics.java', 'TestExpressionToSearchArgument.java']"
"Flink: Add Parquet value reader, writer implementations (#1125)",10,599,2020-06-29 10:56:46-07:00,"['RandomUtil.java', 'build.gradle', 'GenericParquetReaders.java', 'GenericParquetWriter.java', 'RandomGenericData.java', 'FlinkParquetReaders.java', 'FlinkParquetWriters.java', 'RandomData.java', 'TestFlinkParquetReaderWriter.java', 'RandomData.java']"
Parquet: Fix executor memory leak in row group filter (#1139),1,13,2020-06-29 11:06:41-07:00,['ParquetDictionaryRowGroupFilter.java']
Spark: Add Spark 3 data source classes (#1124),72,4614,2020-06-29 17:56:05-07:00,"['build.gradle', 'HadoopInputFile.java', 'Util.java', 'HiveCatalog.java', 'BaseAction.java', 'RewriteDataFilesAction.java', 'RewriteManifestsAction.java', 'SparkUtil.java', 'LogMessage.java', 'SimpleRecord.java', 'TestAvroScan.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestForwardCompatibility.java', 'TestIdentityPartitionData.java', 'TestParquetScan.java', 'TestPartitionValues.java', 'TestReadProjection.java', 'TestSnapshotSelection.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestSparkReadProjection.java', 'TestSparkSchema.java', 'TestStructuredStreaming.java', 'TestTables.java', 'TestWriteMetricsConfig.java', 'IcebergSource.java', 'TestAvroScan24.java', 'TestDataFrameWrites24.java', 'TestDataSourceOptions24.java', 'TestForwardCompatibility24.java', 'TestIdentityPartitionData24.java', 'TestParquetScan24.java', 'TestPartitionValues24.java', 'TestSnapshotSelection24.java', 'TestSparkDataFile24.java', 'TestSparkDataWrite24.java', 'TestSparkReadProjection24.java', 'TestSparkSchema24.java', 'TestStructuredStreaming24.java', 'TestWriteMetricsConfig24.java', 'dependencies.lock', 'Spark3Util.java', 'SparkCatalog.java', 'SparkFilters.java', 'SparkSessionCatalog.java', 'IcebergSource.java', 'SparkBatchScan.java', 'SparkBatchWrite.java', 'SparkScanBuilder.java', 'SparkStreamingWrite.java', 'SparkTable.java', 'SparkWriteBuilder.java', 'StagedSparkTable.java', 'Stats.java', 'org.apache.spark.sql.sources.DataSourceRegister', 'TestAvroScan3.java', 'TestDataFrameWrites3.java', 'TestDataSourceOptions3.java', 'TestFilteredScan.java', 'TestForwardCompatibility3.java', 'TestIcebergSource.java', 'TestIdentityPartitionData3.java', 'TestParquetScan3.java', 'TestPartitionValues3.java', 'TestSnapshotSelection3.java', 'TestSparkDataFile3.java', 'TestSparkDataWrite3.java', 'TestSparkReadProjection3.java', 'TestSparkSchema3.java', 'TestStructuredStreaming3.java', 'TestWriteMetricsConfig3.java']"
Spark: Convert SparkTableUtil from Scala to Java (#1126),8,1332,2020-06-29 17:59:41-07:00,"['baseline.gradle', 'build.gradle', 'scalastyle_config.xml', 'SparkExceptionUtil.java', 'SparkTableUtil.java', 'SparkTableUtil.scala', 'TestSparkTableUtil.java', 'TestSparkTableUtilWithInMemoryCatalog.java']"
Hive: Add IcebergSerDe (#1103),24,5411,2020-07-01 09:24:16-07:00,"['build.gradle', 'dependencies.lock', 'InputFormatConfig.java', 'IcebergSerDe.java', 'IcebergWritable.java', 'TableResolver.java', 'IcebergBinaryObjectInspector.java', 'IcebergDateObjectInspector.java', 'IcebergDecimalObjectInspector.java', 'IcebergObjectInspector.java', 'IcebergRecordObjectInspector.java', 'IcebergTimestampObjectInspector.java', 'IcebergInputFormat.java', 'TestHelpers.java', 'TestIcebergSerDe.java', 'TestTableResolver.java', 'TestIcebergBinaryObjectInspector.java', 'TestIcebergDateObjectInspector.java', 'TestIcebergDecimalObjectInspector.java', 'TestIcebergObjectInspector.java', 'TestIcebergRecordObjectInspector.java', 'TestIcebergTimestampObjectInspector.java', 'TestIcebergInputFormat.java', 'versions.props']"
"Spark: Fix remaining differences from spark-3 branch (#1147)

* Add name to Hive and Hadoop catalogs.

* Minor updates to Hive table behavior.

* Fixup HiveTableOperations.

* Remove references to Genie.

* Fix checkstyle errors.

* Fix create table properties.

The provider must be iceberg for session catalog to work.",10,156,2020-07-01 14:54:20-07:00,"['NoSuchIcebergTableException.java', 'BaseMetastoreCatalog.java', 'HadoopCatalog.java', 'HiveCatalog.java', 'HiveTableOperations.java', 'Spark3Util.java', 'SparkCatalog.java', 'IcebergSource.java', 'SparkBatchWrite.java', 'SparkTable.java']"
Spark: Support namespaces in SparkCatalog (#1149),7,575,2020-07-01 16:44:37-07:00,"['HadoopCatalog.java', 'TestHadoopCatalog.java', 'HiveCatalog.java', 'SparkTestBase.java', 'SparkCatalog.java', 'SparkCatalogTestBase.java', 'TestNamespaceSQL.java']"
Hive: Use fixed IDs in TestIcebergObjectInspector (#1157),1,82,2020-07-02 09:52:05-07:00,['TestIcebergObjectInspector.java']
ORC: Omit columns without field ids in schema conversion (#1140),5,509,2020-07-02 12:15:40-07:00,"['ORCSchemaUtil.java', 'OrcSchemaVisitor.java', 'OrcSchemaWithTypeVisitor.java', 'OrcToIcebergVisitor.java', 'TestORCSchemaUtil.java']"
Add abstract BaseParquetReaders for Iceberg generics and Flink (#1162),7,1409,2020-07-02 12:42:27-07:00,"['BaseParquetReaders.java', 'BaseParquetWriter.java', 'GenericParquetReaders.java', 'GenericParquetWriter.java', 'FlinkParquetReaders.java', 'FlinkParquetWriters.java', 'TestFlinkParquetReaderWriter.java']"
"Flink: Add Avro value reader, writer implementations (#1153)",8,847,2020-07-03 09:13:54-07:00,"['DataReader.java', 'DataWriter.java', 'FlinkAvroReader.java', 'FlinkAvroWriter.java', 'RandomData.java', 'TestFlinkAvroReaderWriter.java', 'TestFlinkParquetReaderWriter.java', 'TestRowProjection.java']"
Doc: Add HDFS path examples for metadata tables (#1151),1,19,2020-07-03 09:25:44-07:00,['spark.md']
Deprecate RuntimeIOException in favor of Java 8 UncheckedIOException (#1154),6,33,2020-07-03 09:46:40-07:00,"['RuntimeIOException.java', 'TestTableMetadata.java', 'TestMetricsRowGroupFilter.java', 'TestMetricsRowGroupFilterTypes.java', 'SerializationUtil.java', 'IcebergInputFormat.java']"
ORC: Simplify logic to determine which columns have stats (#1167),1,72,2020-07-05 13:29:48-07:00,['OrcMetrics.java']
Actions: Fix removeOrphanFiles for HadoopCatalog tables (#1161),2,55,2020-07-05 13:38:17-07:00,"['BaseAction.java', 'TestRemoveOrphanFilesAction.java']"
"Add JDK 11 to CI build, disable Spark 2.4 with JDK 11 (#1168)

Co-authored-by: Fokko Driesprong <fokko@apache.org>",4,249,2020-07-06 08:53:40-07:00,"['.travis.yml', 'build.gradle', 'deploy.gradle', 'settings.gradle']"
"Parquet: Fix NPE in value reader building for projections (#1164)

Co-authored-by:  <hzfanxinxin@corp.netease.com>",2,42,2020-07-06 08:55:44-07:00,"['BaseParquetReaders.java', 'TestReadProjection.java']"
Remove thread local objects and use new visitors to fix executor memory leaks (#1169),7,83,2020-07-06 10:49:24-07:00,"['Evaluator.java', 'InclusiveMetricsEvaluator.java', 'ManifestEvaluator.java', 'ResidualEvaluator.java', 'StrictMetricsEvaluator.java', 'ParquetDictionaryRowGroupFilter.java', 'ParquetMetricsRowGroupFilter.java']"
Make CharSequenceSet thread safe (#1165),1,14,2020-07-06 10:59:35-07:00,['CharSequenceSet.java']
Docs: Update Spark documentation for Spark 3 SQL (#1172),1,503,2020-07-07 14:02:04-07:00,['spark.md']
Update .gitignore (#1181),1,6,2020-07-08 09:58:11-07:00,['.gitignore']
Cache data and delete manifest lists when either is null (#1171),1,2,2020-07-08 10:53:47-07:00,['BaseSnapshot.java']
Add Spark 3 SQL tests (#1156),16,1392,2020-07-08 16:03:50-07:00,"['BaseMetastoreCatalog.java', 'TableMetadata.java', 'TestTables.java', 'HiveCatalog.java', 'HiveCreateReplaceTableTest.java', 'SparkTestBase.java', 'SimpleRecord.java', 'SparkCatalogTestBase.java', 'TestAlterTable.java', 'TestCreateTable.java', 'TestCreateTableAsSelect.java', 'TestDeleteFrom.java', 'TestNamespaceSQL.java', 'TestPartitionedWrites.java', 'TestSelect.java', 'TestUnpartitionedWrites.java']"
Apply table import test suites to Spark 3 (#1166),16,427,2020-07-08 16:22:55-07:00,"['TestRemoveOrphanFilesAction.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestRemoveOrphanFilesAction24.java', 'TestRewriteDataFilesAction24.java', 'TestRewriteManifestsAction24.java', 'TestIcebergSourceHadoopTables24.java', 'TestIcebergSourceHiveTables24.java', 'TestRemoveOrphanFilesAction3.java', 'TestRewriteDataFilesAction3.java', 'TestRewriteManifestsAction3.java', 'TestIcebergSourceHadoopTables3.java', 'TestIcebergSourceHiveTables3.java']"
Support atomic CTAS and RTAS with SparkSessionCatalog (#1183),3,276,2020-07-08 17:25:54-07:00,"['RollbackStagedTable.java', 'SparkSessionCatalog.java', 'TestCreateTableAsSelect.java']"
"Fix NPE when counting entries (#1077)

Closes #1077",4,46,2020-07-08 17:57:39-07:00,"['Schema.java', 'AllEntriesTable.java', 'ManifestEntriesTable.java', 'TestIcebergSourceTablesBase.java']"
Add select and selectNot to TypeUtil for structs (#960),1,41,2020-07-08 18:06:20-07:00,['TypeUtil.java']
"Update runtime Jar LICENSE files to include ThreeTen (#1188)

ORC 1.6.3 added this dependency, which is now pulled into runtime Jars.",3,140,2020-07-09 14:35:16-07:00,"['build.gradle', 'LICENSE', 'LICENSE']"
Update README and scripts for the 0.9.0 release.,2,30,2020-07-09 15:06:08-07:00,"['README.md', 'source-release.sh']"
Remove project directory from source-release.sh.,1,4,2020-07-09 15:16:13-07:00,['source-release.sh']
Add version.txt for release 0.9.0,1,1,2020-07-09 15:18:02-07:00,['version.txt']
"Add Parquet back to source-release.sh.

Accidentally removed parquet instead of project in the initial update.",1,2,2020-07-09 16:03:54-07:00,['source-release.sh']
Remove version.txt from accidental commit.,1,1,2020-07-09 16:06:45-07:00,['version.txt']
Add dependency lock files to RAT excludes.,1,1,2020-07-09 16:20:59-07:00,['.rat-excludes']
Fix deploy.gradle JDK version check.,1,2,2020-07-09 16:26:38-07:00,['deploy.gradle']
Add version.txt for release 0.9.0,1,1,2020-07-09 16:31:39-07:00,['version.txt']
Add missing Spark modules to source-release.sh.,1,2,2020-07-09 18:23:31-07:00,['source-release.sh']
"Revert ""Add version.txt for release 0.9.0""

This reverts commit e54919e31aa0d12aca72fb012efb33f65605c01a.",1,1,2020-07-09 18:24:03-07:00,['version.txt']
Fix typos in spark.md (#1190),1,6,2020-07-09 20:10:36-07:00,['spark.md']
ORC: Use ConstantReader for identity partition columns (#1191),5,81,2020-07-10 17:05:39-07:00,"['TableScanIterable.java', 'IcebergInputFormat.java', 'OrcValueReaders.java', 'SparkOrcValueReaders.java', 'RowDataReader.java']"
Spar: Add spark-warehouse in spark2 and spark3 to .gitignore (#1196),1,2,2020-07-13 10:35:00-07:00,['.gitignore']
Spark: Support ORC vectorized reads (#1189),29,1060,2020-07-13 14:27:36-07:00,"['.gitignore', 'CloseableIterator.java', 'ORC.java', 'OrcBatchReader.java', 'OrcIterable.java', 'VectorizedRowBatchIterator.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'ConstantColumnVector.java', 'IcebergArrowColumnVector.java', 'VectorizedSparkOrcReaders.java', 'BaseDataReader.java', 'BatchDataReader.java', 'RowDataReader.java', 'TestHelpers.java', 'TestSparkOrcReader.java', 'TestIdentityPartitionData.java', 'TestPartitionValues.java', 'TestSparkReadProjection.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'Reader.java', 'TestFilteredScan.java', 'TestIdentityPartitionData24.java', 'TestPartitionValues24.java', 'SparkBatchScan.java', 'TestFilteredScan.java', 'TestIdentityPartitionData3.java', 'TestPartitionValues3.java']"
Remove dependency locking (#1180),19,92725,2020-07-13 14:32:40-07:00,"['.gitignore', 'dependencies.lock', 'dependencies.lock', 'build.gradle', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock', 'dependencies.lock']"
"Add PartitionKey to the public API (#1195)

* Add PartitionKey to the public API.

* Handle null values.",6,607,2020-07-13 16:04:23-07:00,"['PartitionKey.java', 'BaseWriter.java', 'InternalRowWrapper.java', 'OutputFileFactory.java', 'PartitionKey.java', 'PartitionedWriter.java']"
Spark: Fix USING clause in SparkCatalog (#1194),1,24,2020-07-14 09:37:54-07:00,['SparkCatalog.java']
Flink: Extend LogicalTypeVisitor and support MultisetType (#1173),4,307,2020-07-14 09:59:47-07:00,"['FlinkSchemaUtil.java', 'FlinkTypeToType.java', 'FlinkTypeVisitor.java', 'TestFlinkSchemaUtil.java']"
Hadoop: dropNamespace should throw NamespaceNotEmptyException when not empty (#1200),2,12,2020-07-14 10:24:19-07:00,"['HadoopCatalog.java', 'TestHadoopCatalog.java']"
Spark: Remove unnecessary null checks from ORC vectorized readers (#1199),4,58,2020-07-14 11:17:49-07:00,"['.gitignore', 'ConstantColumnVector.java', 'VectorizedSparkOrcReaders.java', 'TestHelpers.java']"
Site: Add Javadoc for 0.9.0.,581,252732,2020-07-14 14:13:32-07:00,"['allclasses-index.html', 'allclasses.html', 'allpackages-index.html', 'constant-values.html', 'deprecated-list.html', 'element-list', 'help-doc.html', 'index-all.html', 'index.html', 'jquery.js', 'ui-bg_glass_55_fbf9ee_1x400.png', 'ui-bg_glass_65_dadada_1x400.png', 'ui-bg_glass_75_dadada_1x400.png', 'ui-bg_glass_75_e6e6e6_1x400.png', 'ui-bg_glass_95_fef1ec_1x400.png', 'ui-bg_highlight-soft_75_cccccc_1x100.png', 'ui-icons_222222_256x240.png', 'ui-icons_2e83ff_256x240.png', 'ui-icons_454545_256x240.png', 'ui-icons_888888_256x240.png', 'ui-icons_cd0a0a_256x240.png', 'jquery-3.3.1.js', 'jquery-migrate-3.0.1.js', 'jquery-ui.css', 'jquery-ui.js', 'jquery-ui.min.css', 'jquery-ui.min.js', 'jquery-ui.structure.css', 'jquery-ui.structure.min.css', 'member-search-index.js', 'member-search-index.zip', 'Accessor.html', 'Accessors.html', 'AllDataFilesTable.AllDataFilesTableScan.html', 'AllDataFilesTable.html', 'AllEntriesTable.html', 'AllManifestsTable.AllManifestsTableScan.html', 'AllManifestsTable.html', 'AppendFiles.html', 'BaseCombinedScanTask.html', 'BaseMetastoreCatalog.html', 'BaseMetastoreTableOperations.html', 'BaseOverwriteFiles.html', 'BaseReplacePartitions.html', 'BaseRewriteManifests.html', 'BaseRowDelta.html', 'BaseTable.html', 'CachingCatalog.html', 'CombinedScanTask.html', 'ContentFile.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DataFilesTable.FilesTableScan.html', 'DataFilesTable.html', 'DataOperations.html', 'DataTableScan.html', 'DataTask.html', 'DeleteFile.html', 'DeleteFiles.html', 'ExpireSnapshots.html', 'FileContent.html', 'FileFormat.html', 'FileScanTask.html', 'Files.html', 'FindFiles.Builder.html', 'FindFiles.html', 'GenericManifestFile.CopyBuilder.html', 'GenericManifestFile.html', 'GenericPartitionFieldSummary.html', 'GuavaClasses.html', 'HasTableOperations.html', 'HistoryEntry.html', 'HistoryTable.html', 'LocationProviders.html', 'ManageSnapshots.html', 'ManifestContent.html', 'ManifestEntriesTable.html', 'ManifestFile.PartitionFieldSummary.html', 'ManifestFile.html', 'ManifestFiles.html', 'ManifestReader.FileType.html', 'ManifestReader.html', 'ManifestWriter.html', 'ManifestsTable.html', 'MetadataTableType.html', 'Metrics.html', 'MetricsConfig.html', 'MetricsModes.Counts.html', 'MetricsModes.Full.html', 'MetricsModes.MetricsMode.html', 'MetricsModes.None.html', 'MetricsModes.Truncate.html', 'MetricsModes.html', 'OverwriteFiles.html', 'PartitionField.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'PartitionsTable.html', 'PendingUpdate.html', 'ReplacePartitions.html', 'RewriteFiles.html', 'RewriteManifests.html', 'Rollback.html', 'RowDelta.html', 'ScanSummary.Builder.html', 'ScanSummary.PartitionMetrics.html', 'ScanSummary.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'SetLocation.html', 'Snapshot.html', 'SnapshotManager.html', 'SnapshotParser.html', 'SnapshotSummary.Builder.html', 'SnapshotSummary.html', 'SnapshotUpdate.html', 'SnapshotsTable.html', 'StructLike.html', 'SystemProperties.html', 'Table.html', 'TableMetadata.MetadataLogEntry.html', 'TableMetadata.SnapshotLogEntry.html', 'TableMetadata.html', 'TableMetadataParser.Codec.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableProperties.html', 'TableScan.html', 'Tables.html', 'Transaction.html', 'Transactions.html', 'UpdateLocation.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Action.html', 'Actions.html', 'RemoveOrphanFilesAction.html', 'RewriteDataFilesAction.html', 'RewriteDataFilesActionResult.html', 'RewriteManifestsAction.html', 'RewriteManifestsActionResult.html', 'SnapshotUpdateAction.html', 'package-summary.html', 'package-tree.html', 'ArrowAllocation.html', 'ArrowSchemaUtil.html', 'package-summary.html', 'package-tree.html', 'IcebergArrowVectors.DecimalArrowVector.html', 'IcebergArrowVectors.VarcharArrowVector.html', 'IcebergArrowVectors.html', 'NullabilityHolder.html', 'VectorHolder.html', 'VectorizedArrowReader.html', 'package-summary.html', 'package-tree.html', 'BaseVectorizedParquetValuesReader.html', 'VectorizedColumnIterator.html', 'VectorizedDictionaryEncodedParquetValuesReader.html', 'VectorizedPageIterator.html', 'VectorizedParquetDefinitionLevelReader.html', 'package-summary.html', 'package-tree.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroIterable.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'AvroSchemaWithTypeVisitor.html', 'LogicalMap.html', 'ProjectionDatumReader.html', 'RemoveIds.html', 'UUIDConversion.html', 'ValueReader.html', 'ValueReaders.StructReader.html', 'ValueReaders.html', 'ValueWriter.html', 'ValueWriters.StructWriter.html', 'ValueWriters.html', 'package-summary.html', 'package-tree.html', 'Catalog.html', 'Namespace.html', 'SupportsNamespaces.html', 'TableIdentifier.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-summary.html', 'package-tree.html', 'GenericRecord.html', 'IcebergGenerics.ScanBuilder.html', 'IcebergGenerics.html', 'IdentityPartitionConverters.html', 'Record.html', 'DataReader.html', 'DataWriter.html', 'IcebergDecoder.html', 'IcebergEncoder.html', 'package-summary.html', 'package-tree.html', 'GenericOrcReader.html', 'GenericOrcReaders.html', 'GenericOrcWriter.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'BaseParquetReaders.html', 'BaseParquetWriter.html', 'GenericParquetReaders.html', 'GenericParquetWriter.html', 'package-summary.html', 'package-tree.html', 'EncryptedFiles.html', 'EncryptedInputFile.html', 'EncryptedOutputFile.html', 'EncryptionKeyMetadata.html', 'EncryptionKeyMetadatas.html', 'EncryptionManager.html', 'PlaintextEncryptionManager.html', 'package-summary.html', 'package-tree.html', 'CreateSnapshotEvent.html', 'Listener.html', 'Listeners.html', 'ScanEvent.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CherrypickAncestorCommitException.html', 'CommitFailedException.html', 'DuplicateWAPCommitException.html', 'NamespaceNotEmptyException.html', 'NoSuchIcebergTableException.html', 'NoSuchNamespaceException.html', 'NoSuchTableException.html', 'NotFoundException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'Bound.html', 'BoundLiteralPredicate.html', 'BoundPredicate.html', 'BoundReference.html', 'BoundSetPredicate.html', 'BoundTerm.html', 'BoundTransform.html', 'BoundUnaryPredicate.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.BoundVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'InclusiveMetricsEvaluator.html', 'Literal.html', 'ManifestEvaluator.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'StrictMetricsEvaluator.html', 'Term.html', 'True.html', 'Unbound.html', 'UnboundPredicate.html', 'UnboundTerm.html', 'UnboundTransform.html', 'package-summary.html', 'package-tree.html', 'FlinkSchemaUtil.html', 'FlinkTypeToType.html', 'FlinkTypeVisitor.html', 'FlinkAvroReader.html', 'FlinkAvroWriter.html', 'FlinkParquetReaders.html', 'FlinkParquetWriters.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'HadoopCatalog.html', 'HadoopFileIO.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTableOperations.html', 'HadoopTables.html', 'HiddenPathFilter.html', 'SerializableConfiguration.html', 'Util.html', 'package-summary.html', 'package-tree.html', 'ClientPool.Action.html', 'ClientPool.html', 'HiveCatalog.html', 'HiveCatalogs.html', 'HiveClientPool.html', 'HiveTableOperations.html', 'HiveTypeConverter.html', 'RuntimeMetaException.html', 'package-summary.html', 'package-tree.html', 'CloseableGroup.html', 'CloseableIterable.ConcatCloseableIterable.html', 'CloseableIterable.html', 'CloseableIterator.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'FileAppender.html', 'FileIO.html', 'InputFile.html', 'LocationProvider.html', 'OutputFile.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'package-summary.html', 'package-tree.html', 'MappedField.html', 'MappedFields.html', 'MappingUtil.html', 'NameMapping.html', 'NameMappingParser.html', 'package-summary.html', 'package-tree.html', 'InputFormatConfig.ConfigBuilder.html', 'InputFormatConfig.InMemoryDataModel.html', 'InputFormatConfig.html', 'SerializationUtil.html', 'IcebergSerDe.html', 'IcebergWritable.html', 'package-summary.html', 'package-tree.html', 'IcebergBinaryObjectInspector.html', 'IcebergDateObjectInspector.html', 'IcebergDecimalObjectInspector.html', 'IcebergObjectInspector.html', 'IcebergRecordObjectInspector.html', 'IcebergTimestampObjectInspector.html', 'package-summary.html', 'package-tree.html', 'IcebergInputFormat.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'ORC.ReadBuilder.html', 'ORC.WriteBuilder.html', 'ORC.html', 'ORCSchemaUtil.BinaryType.html', 'ORCSchemaUtil.LongType.html', 'ORCSchemaUtil.html', 'OrcMetrics.html', 'OrcRowReader.html', 'OrcSchemaVisitor.html', 'OrcSchemaWithTypeVisitor.html', 'OrcValueReader.html', 'OrcValueReaders.StructReader.html', 'OrcValueReaders.html', 'OrcValueWriter.html', 'VectorizedRowBatchIterator.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'BaseColumnIterator.html', 'BasePageIterator.IntIterator.html', 'BasePageIterator.html', 'ColumnIterator.html', 'ColumnWriter.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetAvroReader.html', 'ParquetAvroValueReaders.TimeMillisReader.html', 'ParquetAvroValueReaders.TimestampMillisReader.html', 'ParquetAvroValueReaders.html', 'ParquetAvroWriter.html', 'ParquetDictionaryRowGroupFilter.html', 'ParquetIterable.html', 'ParquetMetricsRowGroupFilter.html', 'ParquetReader.html', 'ParquetSchemaUtil.HasIds.html', 'ParquetSchemaUtil.html', 'ParquetTypeVisitor.html', 'ParquetUtil.html', 'ParquetValueReader.html', 'ParquetValueReaders.BinaryAsDecimalReader.html', 'ParquetValueReaders.BytesReader.html', 'ParquetValueReaders.FloatAsDoubleReader.html', 'ParquetValueReaders.IntAsLongReader.html', 'ParquetValueReaders.IntegerAsDecimalReader.html', 'ParquetValueReaders.ListReader.html', 'ParquetValueReaders.LongAsDecimalReader.html', 'ParquetValueReaders.MapReader.html', 'ParquetValueReaders.PrimitiveReader.html', 'ParquetValueReaders.RepeatedKeyValueReader.html', 'ParquetValueReaders.RepeatedReader.html', 'ParquetValueReaders.ReusableEntry.html', 'ParquetValueReaders.StringReader.html', 'ParquetValueReaders.StructReader.html', 'ParquetValueReaders.UnboxedReader.html', 'ParquetValueReaders.html', 'ParquetValueWriter.html', 'ParquetValueWriters.PrimitiveWriter.html', 'ParquetValueWriters.RepeatedKeyValueWriter.html', 'ParquetValueWriters.RepeatedWriter.html', 'ParquetValueWriters.StructWriter.html', 'ParquetValueWriters.html', 'ParquetWriteAdapter.html', 'RemoveIds.html', 'TripleWriter.html', 'TypeToMessageType.html', 'TypeWithSchemaVisitor.html', 'ValuesAsBytesReader.html', 'VectorizedParquetReader.html', 'VectorizedReader.html', 'package-summary.html', 'package-tree.html', 'IcebergPigInputFormat.IcebergRecordReader.html', 'IcebergPigInputFormat.html', 'IcebergStorage.html', 'PigParquetReader.html', 'SchemaUtil.html', 'package-summary.html', 'package-tree.html', 'PruneColumnsWithReordering.html', 'PruneColumnsWithoutReordering.html', 'RollbackStagedTable.html', 'Spark3Util.DescribeSchemaVisitor.html', 'Spark3Util.html', 'SparkCatalog.html', 'SparkDataFile.html', 'SparkExceptionUtil.html', 'SparkFilters.html', 'SparkSchemaUtil.html', 'SparkSessionCatalog.html', 'SparkStructLike.html', 'SparkTableUtil.SparkPartition.html', 'SparkTableUtil.html', 'SparkUtil.html', 'SparkValueConverter.html', 'AvroWithSparkSchemaVisitor.html', 'ParquetWithSparkSchemaVisitor.html', 'SparkAvroReader.html', 'SparkAvroWriter.html', 'SparkOrcReader.html', 'SparkOrcWriter.html', 'SparkParquetReaders.html', 'SparkParquetWriters.html', 'SparkValueReaders.html', 'SparkValueWriters.html', 'package-summary.html', 'package-tree.html', 'ArrowVectorAccessor.html', 'ArrowVectorAccessors.html', 'ColumnarBatchReader.html', 'IcebergArrowColumnVector.html', 'NullValuesColumnVector.html', 'VectorizedSparkParquetReaders.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'IcebergSource.html', 'RowDataRewriter.html', 'SparkScanBuilder.html', 'SparkStreamingWrite.html', 'SparkTable.html', 'StagedSparkTable.html', 'package-summary.html', 'package-tree.html', 'PartitionSpecVisitor.html', 'Transform.html', 'Transforms.html', 'UnknownTransform.html', 'package-summary.html', 'package-tree.html', 'CheckCompatibility.html', 'Comparators.html', 'Conversions.html', 'IndexByName.html', 'IndexParents.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-summary.html', 'package-tree.html', 'BinPacking.ListPacker.html', 'BinPacking.PackingIterable.html', 'BinPacking.html', 'BinaryUtil.html', 'ByteBuffers.html', 'CharSequenceSet.html', 'CharSequenceWrapper.html', 'DateTimeUtil.html', 'ExceptionUtil.html', 'Exceptions.html', 'JsonUtil.html', 'ManifestFileUtil.html', 'Pair.html', 'ParallelIterable.html', 'PartitionUtil.html', 'PropertyUtil.html', 'SerializableSupplier.html', 'SnapshotUtil.html', 'StructLikeWrapper.html', 'TableScanUtil.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'ThreadPools.html', 'UnicodeUtil.html', 'WapUtil.html', 'package-summary.html', 'package-tree.html', 'overview-summary.html', 'overview-tree.html', 'package-search-index.js', 'package-search-index.zip', 'glass.png', 'x.png', 'script.js', 'search.js', 'serialized-form.html', 'stylesheet.css', 'type-search-index.js', 'type-search-index.zip']"
CI: Fix test timeout by logging tests that pass (#1210),1,2,2020-07-15 11:57:03-07:00,['build.gradle']
Remove unused versions.lock file (#1209),1,251,2020-07-15 11:57:28-07:00,['versions.lock']
Update the site for the 0.9.0 release (#1205),8,385,2020-07-15 11:58:45-07:00,"['api-quickstart.md', 'configuration.md', 'extra.css', 'getting-started.md', 'index.html', 'releases.md', 'spark.md', 'mkdocs.yml']"
Flink: Add conversion from Iceberg types to Flink types (#1174),3,257,2020-07-15 13:20:41-07:00,"['FlinkSchemaUtil.java', 'TypeToFlinkType.java', 'TestFlinkSchemaUtil.java']"
Flink: Add wrapper to adapt Row to StructLike (#1175),3,343,2020-07-15 13:22:06-07:00,"['RowWrapper.java', 'TestPartitionKey.java', 'RandomData.java']"
CI: Print test name only in CI environments (#1212),1,6,2020-07-16 16:27:21-07:00,['build.gradle']
Remove table cache expiration (#1203),1,6,2020-07-16 16:43:29-07:00,['CachingCatalog.java']
Bump Flink to 1.11 (#1201),1,2,2020-07-17 09:04:23-07:00,['versions.props']
ORC: Support row postition as a metadata column (#1207),17,556,2020-07-20 13:43:28-07:00,"['MetadataColumns.java', 'TableScanIterable.java', 'GenericOrcReader.java', 'GenericOrcReaders.java', 'IcebergInputFormat.java', 'OrcBatchReader.java', 'OrcIterable.java', 'OrcRowReader.java', 'OrcValueReader.java', 'OrcValueReaders.java', 'VectorizedRowBatchIterator.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'RowPostitionColumnVector.java', 'VectorizedSparkOrcReaders.java', 'RowDataReader.java', 'TestSparkOrcReadMetadataColumns.java']"
Flink: Integrate Iceberg catalog to Flink catalog (#1182),9,1220,2020-07-20 14:52:43-07:00,"['AssertHelpers.java', 'build.gradle', 'FlinkCatalog.java', 'FlinkCatalogFactory.java', 'org.apache.flink.table.factories.TableFactory', 'FlinkCatalogTestBase.java', 'FlinkTestBase.java', 'TestFlinkCatalogDatabase.java', 'TestFlinkCatalogTable.java']"
"Site: Fix Javadoc search, minor updates (#1217)",4,37,2020-07-20 15:02:39-07:00,"['api.md', 'search.js', 'reliability.md', 'tasks.gradle']"
"Python: Minor fixes for tests (#1214)

In the course of implementing create table I came across minor issues:
* rename test fixtures to suppress warnings and prevent pytest from treating them as tests
* test partition code path & fix incorrect signature when creating metadata
* handle `file:` as well as `file://` as it seems both schemas are used
* add mypy annotations in areas where I fixed code
* fix tox/mypy",8,66,2020-07-21 09:12:43-07:00,"['partition_spec.py', 'type_util.py', 'local_filesystem.py', 'table_metadata.py', 'conftest.py', 'test_helpers.py', 'conftest.py', 'test_hive_tables.py']"
"Add more tests for RemoveSnapshots (#1223)

Previously none of the tests in TestRemoveSnapshots used the code path for
valid snapshots which contained references to manifests which were created
in a snapshot that had previously expired. Although there are no bugs in that
logic, we add two tests which check this pathway to protect against future
breakage.",1,68,2020-07-21 12:13:35-07:00,['TestRemoveSnapshots.java']
Increase timeout in TestHiveTableConcurrency (#1226),1,2,2020-07-22 08:42:11-07:00,['TestHiveTableConcurrency.java']
Hive: Add mapred InputFormat (#1192),17,2183,2020-07-22 10:06:21-07:00,"['build.gradle', 'InputFormatConfig.java', 'HiveIcebergInputFormat.java', 'HiveIcebergSplit.java', 'Container.java', 'IcebergSerDe.java', 'MapredIcebergInputFormat.java', 'TableResolver.java', 'IcebergInputFormat.java', 'IcebergSplit.java', 'IcebergSplitContainer.java', 'TestHelper.java', 'TestIcebergInputFormats.java', 'TestHiveIcebergInputFormat.java', 'TestHelpers.java', 'TestIcebergSerDe.java', 'TestIcebergInputFormat.java']"
"Spark: Fix import for paths that include spaces (#1228)

In order to avoid changing the API and SparkSQL compatible types we will fix the whitespace issue by
replacing the encoded string representation with a decoded string representation. We use a
method identical to Apache Spark, taking the Hadoop Path representation of the URI and getting the
string representation from that.",3,83,2020-07-22 13:11:52-07:00,"['Util.java', 'SparkTableUtil.java', 'TestSparkTableUtil.java']"
Avro: Add row position reader (#1222),8,359,2020-07-23 14:18:50-07:00,"['AvroIO.java', 'AvroIterable.java', 'BuildAvroProjection.java', 'ProjectionDatumReader.java', 'SupportsRowPosition.java', 'ValueReaders.java', 'DataReader.java', 'TestAvroFileSplit.java']"
Fix TestHiveIcebergInputFormat.testScanTable (#1229),1,2,2020-07-23 17:19:15-07:00,['TestHiveIcebergInputFormat.java']
Hive: Add IcebergStorageHandler (#1107),3,126,2020-07-23 17:57:14-07:00,"['build.gradle', 'HiveIcebergStorageHandler.java', 'TestHiveIcebergInputFormat.java']"
Parquet: Support reading int96 timestamps in imported data (#1184),6,158,2020-07-24 13:52:25-07:00,"['BaseParquetReaders.java', 'ColumnIterator.java', 'PageIterator.java', 'ParquetValueReaders.java', 'SparkParquetReaders.java', 'TestSparkParquetReader.java']"
Spark: Support custom metadata in snapshot summary (#1241),5,52,2020-07-24 15:21:15-07:00,"['SnapshotSummary.java', 'configuration.md', 'TestDataSourceOptions.java', 'Writer.java', 'SparkBatchWrite.java']"
Fix MissingOverride warnings in BaseFile.java (#1249),1,13,2020-07-25 18:39:57-07:00,['BaseFile.java']
Hive: Add HiveIcebergOutputFormat placeholder (#1246),2,42,2020-07-25 18:41:18-07:00,"['HiveIcebergOutputFormat.java', 'HiveIcebergStorageHandler.java']"
Hive: Move Hive-related classes to mr.hive package (#1247),18,50,2020-07-25 18:42:20-07:00,"['HiveIcebergInputFormat.java', 'HiveIcebergSerDe.java', 'HiveIcebergStorageHandler.java', 'TableResolver.java', 'IcebergBinaryObjectInspector.java', 'IcebergDateObjectInspector.java', 'IcebergDecimalObjectInspector.java', 'IcebergObjectInspector.java', 'IcebergRecordObjectInspector.java', 'IcebergTimestampObjectInspector.java', 'TestHiveIcebergSerDe.java', 'TestTableResolver.java', 'TestIcebergBinaryObjectInspector.java', 'TestIcebergDateObjectInspector.java', 'TestIcebergDecimalObjectInspector.java', 'TestIcebergObjectInspector.java', 'TestIcebergRecordObjectInspector.java', 'TestIcebergTimestampObjectInspector.java']"
Avro: Extract ValueReaders.decimalBytesReader (#1233),4,66,2020-07-26 12:43:05-07:00,"['GenericAvroReader.java', 'ValueReaders.java', 'DataReader.java', 'SparkAvroReader.java']"
Avro: Extract ResolvingDecoder caching into DecoderResolver (#1234),4,187,2020-07-26 13:32:43-07:00,"['GenericAvroReader.java', 'DataReader.java', 'DecoderResolver.java', 'SparkAvroReader.java']"
Fix Guava imports (#1251),4,10,2020-07-26 13:48:29-07:00,"['checkstyle.xml', 'build.gradle', 'Spark3Util.java', 'SparkCatalog.java']"
"Docs: Note that metadata tables do not work with spark_catalog  (#1253)

Spark has different approaches to handle multi-part name, between default
catalog (spark_catalog) and custom catalog. While the metadata table format for
inspection (catalog.database.table.metadata) works for custom catalog, it does
not work for default catalog, as of Spark 3.0.0.

This patch documents the limitation so that end users can understand and take
an workaround.",1,3,2020-07-27 09:16:48-07:00,['spark.md']
Hive Catalog: Default table location using database location (#1240),3,54,2020-07-27 09:23:44-07:00,"['HiveCatalog.java', 'HiveTableOperations.java', 'HiveTableTest.java']"
Add in missing Override annotations (#1252),5,6,2020-07-27 09:32:28-07:00,"['GenericDataFile.java', 'GenericDeleteFile.java', 'PageIterator.java', 'BaseDataReader.java', 'SparkBatchWrite.java']"
Support parallel deletes in snapshot expiration (#1187),3,96,2020-07-27 10:04:13-07:00,"['ExpireSnapshots.java', 'RemoveSnapshots.java', 'TestRemoveSnapshots.java']"
Avro: Extract AvroWithPartnerSchemaVisitor base visitor (#1235),3,323,2020-07-28 10:15:30-07:00,"['AvroWithPartnerByStructureVisitor.java', 'AvroWithSparkSchemaVisitor.java', 'SparkAvroWriter.java']"
Core: Add helpers to generate incremental file batches (#1263),2,441,2020-07-28 10:22:44-07:00,"['MicroBatches.java', 'TestMicroBatchBuilder.java']"
Docs: Fix Spark catalog warehouse property name (#1259),1,2,2020-07-28 12:29:04-07:00,['getting-started.md']
Spark: Use snapshot summary data in estimateStatistics (#1221),4,95,2020-07-28 12:34:54-07:00,"['SparkSchemaUtil.java', 'TestSparkSchemaUtil.java', 'Reader.java', 'SparkBatchScan.java']"
"Core: Allow ExpireSnapshots to run without cleaning files (#1244)

Previously ExpireSnapshots would always follow the expiration of Snapshots
with a deletion of local DataFiles and Manifests which were no longer relevant
to the Table. This patch introduces an API to skip this deletion phase, which
was always run locally, and instead just expire the snapshots. This allows for
future implementations which can read and remove unused files in parallel or
on distributed frameworks.",3,63,2020-07-28 12:40:50-07:00,"['ExpireSnapshots.java', 'RemoveSnapshots.java', 'TestRemoveSnapshots.java']"
ORC: Refactor GenericOrcWriter to use OrcSchemaWithTypeVisitor (#1197),11,1137,2020-07-29 13:58:48-07:00,"['GenericOrcWriter.java', 'GenericOrcWriters.java', 'ORC.java', 'OrcFileAppender.java', 'OrcRowWriter.java', 'OrcValueWriter.java', 'SparkOrcWriter.java', 'SparkAppenderFactory.java', 'TestOrcWrite.java', 'TestSparkOrcReadMetadataColumns.java', 'TestSparkOrcReader.java']"
Add incremental scan for iceberg generics  (#1239),2,113,2020-07-29 21:45:55-07:00,"['IcebergGenerics.java', 'TestLocalScan.java']"
Add DecimalUtil for common decimal conversion (#1265),5,165,2020-07-30 18:11:08-07:00,"['ValueWriters.java', 'DecimalUtil.java', 'ParquetValueWriters.java', 'SparkParquetWriters.java', 'SparkValueWriters.java']"
Parquet: Add row position reader (#1254),7,315,2020-07-30 18:13:43-07:00,"['BaseParquetReaders.java', 'ParquetReader.java', 'ParquetValueReader.java', 'ParquetValueReaders.java', 'ReadConf.java', 'SparkParquetReaders.java', 'TestSparkParquetReadMetadataColumns.java']"
"Remove conflicting dependency and unnecessary checked exception (#1270)

* Remove conflicting dependency and unnecessary checked exception
Co-authored-by: Adrien Guillo <adrien.guillo@gmail.com>
Co-authored-by: Ryan Blue <blue@apache.org>
Co-authored-by: Adrien Guillo <adrien.guillo@gmail.com>",3,19,2020-07-30 22:23:02-07:00,"['build.gradle', 'HiveIcebergSerDe.java', 'TableResolver.java']"
"Core: Extract common task writers from Spark, add Flink (#1213)",16,1145,2020-07-31 12:38:51-07:00,"['BaseTaskWriter.java', 'FileAppenderFactory.java', 'OutputFileFactory.java', 'PartitionedWriter.java', 'TaskWriter.java', 'UnpartitionedWriter.java', 'PartitionedFanoutWriter.java', 'TaskWriterFactory.java', 'SimpleDataUtil.java', 'TestTaskWriters.java', 'BaseWriter.java', 'RowDataRewriter.java', 'SparkAppenderFactory.java', 'SparkPartitionedWriter.java', 'Writer.java', 'SparkBatchWrite.java']"
"Ban imports from org.apache.commons.compress.utils (#1278)

Co-authored-by: Chen, Junjie <chenjunjiedada@gmail.com>",2,4,2020-07-31 14:11:08-07:00,"['checkstyle.xml', 'HadoopInputFile.java']"
Implement negate in bound predicates (#1282),3,67,2020-07-31 15:06:31-07:00,"['BoundLiteralPredicate.java', 'BoundUnaryPredicate.java', 'TestExpressionHelpers.java']"
Spark: Fix Spark 3 describe with IN predicates (#1283),1,9,2020-07-31 15:57:05-07:00,['Spark3Util.java']
Spark: Improve SparkSessionCatalog error when not spark_catalog (#1276),1,37,2020-08-01 12:46:16-07:00,['SparkSessionCatalog.java']
Parquet: Support vectorized reads with identity partition values (#1287),7,143,2020-08-04 18:08:03-07:00,"['VectorHolder.java', 'VectorizedArrowReader.java', 'IcebergArrowColumnVector.java', 'VectorizedSparkParquetReaders.java', 'BatchDataReader.java', 'TestIdentityPartitionData.java', 'Reader.java']"
Core: Use array instead of list in BaseCombinedScanTask to fix serialization (#1285),4,266,2020-08-05 09:37:38-07:00,"['BaseCombinedScanTask.java', 'TestScanTaskSerialization.java', 'TestScanTaskSerialization24.java', 'TestScanTaskSerialization3.java']"
Arrow: Bump Arrow version to 1.0.0 (#1296),6,164,2020-08-05 09:44:37-07:00,"['IcebergArrowVectors.java', 'VectorizedArrowReader.java', 'VectorizedParquetDefinitionLevelReader.java', 'build.gradle', 'ArrowVectorAccessors.java', 'versions.props']"
"Update scan planning with DeleteFiles in each task (#1288)

This adds `DeleteFileIndex` to scan delete manifests and index delete files, updates `ManifestGroup` to use the index when planning tasks, and adds delete files to `FileScanTask`.

The `DeleteFileIndex` uses a map keyed by partition spec ID and partition tuple. Values of the map are sorted list of sequence numbers and corresponding `DeleteFile` instances. When looking up a `DataFile`, the potentially matching delete files are fetched using its partition tuple, then the sequence numbers are binary searched to find the matching set of delete files with sequence numbers higher than the data file.

The index also supports global equality delete files. If an equality delete file is added to the table with an unpartitioned spec, it will be returned for all data files with a lower sequence number, regardless of partition.",13,733,2020-08-05 13:22:25-07:00,"['FileScanTask.java', 'PartitionSpec.java', 'AllManifestsTable.java', 'BaseFileScanTask.java', 'DataFilesTable.java', 'DataTableScan.java', 'DeleteFileIndex.java', 'GenericManifestEntry.java', 'ManifestEntriesTable.java', 'ManifestGroup.java', 'StaticDataTask.java', 'MockFileScanTask.java', 'TestDeleteFileIndex.java']"
Flink: Update Avro reader and writer to use RowData (#1232),11,1238,2020-08-05 13:46:32-07:00,"['FlinkTypeVisitor.java', 'TaskWriterFactory.java', 'AvroWithFlinkSchemaVisitor.java', 'FlinkAvroReader.java', 'FlinkAvroWriter.java', 'FlinkValueReaders.java', 'FlinkValueWriters.java', 'FlinkTestBase.java', 'TestTaskWriters.java', 'TestFlinkAvroReaderWriter.java', 'TestRowProjection.java']"
"Generics: Refactor TestLocalScan (#1273)

* Generics: Refactor TestLocalScan",1,235,2020-08-06 00:02:28-07:00,['TestLocalScan.java']
Core: Add position delete filter and utils (#1301),5,629,2020-08-06 15:07:52-07:00,"['Deletes.java', 'Filter.java', 'FilterIterator.java', 'SortedMerge.java', 'TestPositionFilter.java']"
"Refactor the SparkOrcWriter by using OrcSchemaWithTypeVisitor#visit (#1238)

* Refactor the SparkOrcWriter by using OrcSchemaWithTypeVisitor",7,763,2020-08-06 16:07:19-07:00,"['SparkOrcValueWriter.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkAppenderFactory.java', 'TestOrcWrite.java', 'TestSparkOrcReadMetadataColumns.java', 'TestSparkOrcReader.java']"
ORC: Fix decimal and timestamp bugs (#1271),7,222,2020-08-07 08:58:24-07:00,"['build.gradle', 'GenericOrcWriter.java', 'GenericOrcWriters.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'GenericsHelpers.java', 'TestSparkRecordOrcReaderWriter.java']"
Build: Configure Github autolabeler (#1289),1,81,2020-08-07 09:18:18-07:00,['autolabeler.yml']
Flink: Implement row to output file write task (#1145),8,729,2020-08-07 09:43:14-07:00,"['BaseFile.java', 'IcebergSinkUtil.java', 'IcebergStreamWriter.java', 'RowTaskWriterFactory.java', 'TaskWriterFactory.java', 'SimpleDataUtil.java', 'TestIcebergStreamWriter.java', 'TestTaskWriters.java']"
Core: Add sequence number assertions in merge append tests (#1101),2,646,2020-08-07 18:28:52-07:00,"['TestMergeAppend.java', 'TestSequenceNumberForV2Table.java']"
Spark: Use SessionState to load Hadoop config (#1310),9,26,2020-08-10 08:31:09-07:00,"['checkstyle.xml', 'TestIcebergSourceHiveTables.java', 'Reader.java', 'ConcurrencyTest.java', 'ReadAndWriteTablesTest.java', 'SchemaEvolutionTest.java', 'SnapshotFunctionalityTest.java', 'SparkCatalog.java', 'IcebergSource.java']"
Spark3: Enable Parquet vectorized reads with identity partition values (#1312),1,7,2020-08-10 08:34:00-07:00,['SparkBatchScan.java']
Fix partitions metadata table for unpartitioned tables (#1284),2,56,2020-08-10 14:37:29-07:00,"['PartitionsTable.java', 'TestIcebergSourceTablesBase.java']"
Spark: Create shared assertions for common task validation (#1280),3,195,2020-08-10 15:39:00-07:00,"['TaskCheckHelper.java', 'TestDataFileSerialization.java', 'TestScanTaskSerialization.java']"
"Core: Fix struct comparison, add struct and partition sets (#1307)",9,657,2020-08-10 15:40:11-07:00,"['Comparators.java', 'JavaHash.java', 'JavaHashes.java', 'CharSequenceWrapper.java', 'PartitionsTable.java', 'PartitionSet.java', 'StructLikeSet.java', 'StructLikeWrapper.java', 'RewriteDataFilesAction.java']"
Flink: Support partitioning RowData (#1299),4,537,2020-08-10 15:47:00-07:00,"['InternalRecordWrapper.java', 'RowDataWrapper.java', 'RowDataConverter.java', 'TestRowDataPartitionKey.java']"
"Actions: Add expire snapshots action (#1264)

Previously the only way to expire snapshots was through a single machine table
operation with RemoveSnapshots. In this patch we add a new Spark Action which
does the same work, but does so in a scalable way. Instead of using the old
logic for analyzing files to remove, we use the Metadata Table representations
of the table both before and after Snapshot Expiration to determine un-needed
files.",9,1149,2020-08-10 17:47:02-07:00,"['Tasks.java', 'Actions.java', 'BaseAction.java', 'ExpireSnapshotsAction.java', 'ExpireSnapshotsActionResult.java', 'RemoveOrphanFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestExpireSnapshotsAction24.java', 'TestExpireSnapshotsAction3.java']"
"API: Rename ExpireSnapshots executeWith to executeDeleteWith (#1322)

The executor passed in executeWith is only used for deletes so we will rename it
to executeDeleteWith. The JavaDoc already states it will only effect deletes and
the implementation already match this name so no other changes are needed.",3,6,2020-08-11 10:20:43-07:00,"['ExpireSnapshots.java', 'RemoveSnapshots.java', 'TestRemoveSnapshots.java']"
Core: Add specId to DataFile (#1317),18,261,2020-08-11 16:02:14-07:00,"['ContentFile.java', 'TestHelpers.java', 'AllManifestsTable.java', 'BaseFile.java', 'DataFiles.java', 'FileMetadata.java', 'GenericDataFile.java', 'GenericDeleteFile.java', 'InheritableMetadataFactory.java', 'StaticDataTask.java', 'V1Metadata.java', 'V2Metadata.java', 'TestManifestWriterVersions.java', 'TestMergeAppend.java', 'TestRewriteManifests.java', 'TestLocalScan.java', 'SparkDataFile.java', 'TestPartitionValues.java']"
Core: Add set-based position and equality filters (#1309),5,355,2020-08-11 17:47:21-07:00,"['Comparators.java', 'TestHelpers.java', 'Deletes.java', 'TestEqualityFilter.java', 'TestPositionFilter.java']"
"Spark: Fix int96 timestamps, add end-to-end test (#1323)",3,54,2020-08-11 18:33:39-07:00,"['BaseParquetReaders.java', 'MessageTypeToType.java', 'TestSparkParquetReader.java']"
Core: Fix partition sets (#1308),9,292,2020-08-12 11:09:02-07:00,"['BaseReplacePartitions.java', 'DeleteFileIndex.java', 'ManifestFilterManager.java', 'ManifestGroup.java', 'MergingSnapshotProducer.java', 'SnapshotManager.java', 'ManifestFileUtil.java', 'StructLikeWrapper.java', 'TestDeleteFileIndex.java']"
Core: Add equality field IDs to DeleteFile (#1318),10,156,2020-08-12 11:12:09-07:00,"['ContentFile.java', 'DataFile.java', 'BaseFile.java', 'FileMetadata.java', 'GenericDataFile.java', 'GenericDeleteFile.java', 'V2Metadata.java', 'ArrayUtil.java', 'TestManifestWriterVersions.java', 'TestMergeAppend.java']"
Flink: Replace Row with RowData in Flink write path (#1320),11,752,2020-08-12 13:16:24-07:00,"['IcebergSinkUtil.java', 'RowDataTaskWriterFactory.java', 'RowDataWrapper.java', 'RowWrapper.java', 'RowDataConverter.java', 'SimpleDataUtil.java', 'TestIcebergStreamWriter.java', 'TestPartitionKey.java', 'TestRowDataPartitionKey.java', 'TestTaskWriters.java', 'RandomRowData.java']"
Add Avro and Parquet delete file writers (#1327),14,901,2020-08-13 12:27:26-07:00,"['FileMetadata.java', 'MetadataColumns.java', 'Avro.java', 'Deletes.java', 'EqualityDeleteWriter.java', 'PositionDelete.java', 'PositionDeleteWriter.java', 'TestAvroDeleteWriters.java', 'BaseParquetReaders.java', 'BaseParquetWriter.java', 'GenericParquetReaders.java', 'GenericParquetWriter.java', 'Parquet.java', 'ParquetValueWriters.java']"
Spark: Reject add column DDL with NOT NULL (#1325),2,10,2020-08-14 09:26:44-07:00,"['Spark3Util.java', 'TestAlterTable.java']"
Avro: Fix pruning columns when a logical-map array's value type is nested (#1321),3,48,2020-08-14 13:22:55-07:00,"['PruneColumns.java', 'TestAvroNameMapping.java', 'TestAvroReadProjection.java']"
Spark: Follow name mapping while importing Parquet tables (#1335),10,602,2020-08-15 11:21:43-07:00,"['MappedField.java', 'MappedFields.java', 'NameMapping.java', 'MessageTypeToType.java', 'ParquetSchemaUtil.java', 'ParquetUtil.java', 'TestParquetSchemaUtil.java', 'SparkTableUtil.java', 'TestSparkTableUtil.java', 'TestSparkTableUtilWithInMemoryCatalog.java']"
Hive: Add support for custom catalog to Iceberg StorageHandler (#1155) (#1243),20,1071,2020-08-18 06:52:06-07:00,"['build.gradle', 'CatalogLoader.java', 'Catalogs.java', 'InputFormatConfig.java', 'HiveIcebergInputFormat.java', 'HiveIcebergSerDe.java', 'HiveIcebergStorageHandler.java', 'TableResolver.java', 'IcebergInputFormat.java', 'TestCatalogs.java', 'TestHelper.java', 'TestIcebergInputFormats.java', 'HiveIcebergStorageHandlerBaseTest.java', 'TestHiveIcebergSerDe.java', 'TestHiveIcebergStorageHandlerWithCustomCatalog.java', 'TestHiveIcebergStorageHandlerWithHadoopCatalog.java', 'TestHiveIcebergStorageHandlerWithHadoopTables.java', 'TestHiveIcebergStorageHandlerWithHiveCatalog.java', 'TestTableResolver.java', 'TestTables.java']"
ORC: Add name mapping support (#1208),13,820,2020-08-18 13:36:13-07:00,"['ApplyNameMapping.java', 'HasIds.java', 'ORC.java', 'ORCSchemaUtil.java', 'OrcIterable.java', 'OrcSchemaVisitor.java', 'OrcToIcebergVisitor.java', 'RemoveIds.java', 'TestExpressionToSearchArgument.java', 'TestORCSchemaUtil.java', 'BatchDataReader.java', 'RowDataReader.java', 'TestNameMappingProjection.java']"
Core: Add file stats range optimizations for DeleteFileIndex (#1338),11,657,2020-08-18 14:51:48-07:00,"['Record.java', 'BaseFile.java', 'DeleteFileIndex.java', 'ManifestGroup.java', 'ManifestReader.java', 'Avro.java', 'Deletes.java', 'FilterIterator.java', 'TestTables.java', 'TestDataFileIndexStatsFilters.java', 'Parquet.java']"
Build: Skip building empty jars (#1357),1,6,2020-08-18 14:56:39-07:00,['build.gradle']
API: Fix hashCode in PartitionSpec (#1358),1,2,2020-08-18 18:50:50-07:00,['PartitionSpec.java']
"Core: Add TableOperations to read a static metadata location (#1342)

Allows for a Table Operations which references a specfic metadata version
file. This operation will not change even if the base table it was derived
from is changed. This enables it to act like a ReadOnly view of the table's
state at a given time.",3,225,2020-08-19 10:44:53-07:00,"['StaticTableOperations.java', 'HadoopTables.java', 'TestStaticTable.java']"
Add common UUIDUtil for UUID conversions (#1330),8,129,2020-08-19 16:58:45-07:00,"['Conversions.java', 'UUIDUtil.java', 'UUIDConversion.java', 'ValueReaders.java', 'GenericOrcReaders.java', 'RowDataWrapper.java', 'ParquetAvroValueReaders.java', 'SparkValueReaders.java']"
Data: Add GenericAppenderFactory and GenericAppenderHelper (#1340),8,487,2020-08-19 17:23:59-07:00,"['GenericAppenderFactory.java', 'TestSplitScan.java', 'GenericAppenderHelper.java', 'TestLocalScan.java', 'TestHelper.java', 'TestSparkReadProjection.java', 'TestFilteredScan.java', 'TestFilteredScan.java']"
Flink: Read Parquet as RowData using a schema visitor (#1266),7,1173,2020-08-19 17:36:46-07:00,"['RandomGenericData.java', 'FlinkParquetReaders.java', 'RandomData.java', 'TestFlinkParquetReader.java', 'TestHelpers.java', 'ParquetValueReaders.java', 'SparkParquetReaders.java']"
"Flink: Add Orc reader, writer implementations (#1255)",12,1159,2020-08-20 09:17:18-07:00,"['GenericOrcWriter.java', 'GenericOrcWriters.java', 'RowDataTaskWriterFactory.java', 'FlinkOrcReader.java', 'FlinkOrcReaders.java', 'FlinkOrcWriter.java', 'FlinkOrcWriters.java', 'FlinkSchemaVisitor.java', 'RowDataConverter.java', 'TestIcebergStreamWriter.java', 'TestTaskWriters.java', 'TestFlinkOrcReaderWriter.java']"
Parquet: Ignore INT96 metrics while importing tables (#1351),2,67,2020-08-20 09:22:43-07:00,"['ParquetUtil.java', 'TestSparkTableUtilWithInMemoryCatalog.java']"
"Expire snapshots action without cache (#1344)

Instead of using a cache to preserve the state from before the
expireSnapshots command, we preserve the table metadata via a
StaticTable reference. This reference doesn't change when the
Snapshosts are expired and allows us to look up all the files
referenced by the prior version of the table without holding
everything in memory.",2,96,2020-08-20 09:25:45-07:00,"['BaseAction.java', 'ExpireSnapshotsAction.java']"
"Flink: Introduce CatalogLoader and TableLoader (#1332)

* Flink: Introduce CatalogLoader and TableLoader

* Add util clusterHadoopConf

* Address comments",5,223,2020-08-20 10:59:33-07:00,"['CatalogLoader.java', 'FlinkCatalog.java', 'FlinkCatalogFactory.java', 'TableLoader.java', 'FlinkCatalogTestBase.java']"
Build: Fix the IntelliJ with relocated Guava (#1360),1,2,2020-08-20 15:21:09-07:00,['build.gradle']
"Actions: Speed up ExpireSnapshotAction test by reducing shuffle parallelism (#1362)

Because we use LocalIterator in ExpireSnapshotAction, every partition
runs it's own spark job, almost all of which are completely empty. This
leads to a lot of overhead which we don't need in the Test Suite. Setting
shuffle parallelism to 1 (from 200) greatly reduces the test runtime.",1,1,2020-08-20 16:41:58-07:00,['TestExpireSnapshotsAction.java']
Flink: Validate RowData with generated Records in Avro tests (#1363),4,185,2020-08-21 10:04:38-07:00,"['RandomData.java', 'TestFlinkAvroReaderWriter.java', 'TestFlinkOrcReaderWriter.java', 'TestFlinkParquetReader.java']"
Build: Update baselines and fix broken checks (#1350),86,398,2020-08-21 13:02:15-07:00,"['checkstyle.xml', 'Files.java', 'ExpressionVisitors.java', 'ProjectionUtil.java', 'TransformUtil.java', 'Comparators.java', 'Conversions.java', 'TypeUtil.java', 'Types.java', 'AssertHelpers.java', 'TestHelpers.java', 'ArrowSchemaUtil.java', 'VectorizedArrowReader.java', 'baseline.gradle', 'build.gradle', 'GuavaClasses.java', 'DynClasses.java', 'DynConstructors.java', 'DynFields.java', 'DynMethods.java', 'BaseMetastoreTableOperations.java', 'BaseRewriteManifests.java', 'DataFiles.java', 'IncrementalDataTableScan.java', 'InheritableMetadataFactory.java', 'LocationProviders.java', 'MetricsConfig.java', 'MetricsModes.java', 'SchemaParser.java', 'SnapshotParser.java', 'SystemProperties.java', 'TableMetadataParser.java', 'TableProperties.java', 'Transactions.java', 'AvroSchemaUtil.java', 'DecoderResolver.java', 'EncryptedFiles.java', 'EncryptionKeyMetadatas.java', 'HadoopStreams.java', 'HiddenPathFilter.java', 'BaseTaskWriter.java', 'ByteBuffers.java', 'ExceptionUtil.java', 'JsonUtil.java', 'PropertyUtil.java', 'TableScanUtil.java', 'Tasks.java', 'ThreadPools.java', 'TestRemoveSnapshots.java', 'TestRewriteManifests.java', 'TestTables.java', 'AvroTestHelpers.java', 'RandomAvroData.java', 'DataTestHelpers.java', 'RandomGenericData.java', 'FlinkValueReaders.java', 'FlinkValueWriters.java', 'TestHelpers.java', 'HiveCatalogs.java', 'Catalogs.java', 'InputFormatConfig.java', 'HiveIcebergSplit.java', 'MapredIcebergInputFormat.java', 'IcebergInputFormat.java', 'IcebergSplit.java', 'ORCSchemaUtil.java', 'ParquetValueReaders.java', 'ParquetWritingTestUtils.java', 'IcebergPigInputFormat.java', 'SchemaUtil.java', 'SparkValueConverter.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'ArrowVectorAccessors.java', 'TestExpireSnapshotsAction.java', 'AvroDataTest.java', 'RandomData.java', 'TestHelpers.java', 'TestSparkParquetReadMetadataColumns.java', 'TestParquetDictionaryFallbackToPlainEncodingVectorizedReads.java', 'TestSparkDataWrite.java', 'SparkBenchmarkUtil.java', 'Reader.java', 'Writer.java', 'SnapshotFunctionalityTest.java', 'SparkBatchWrite.java']"
Core: Add more tests for RemoveSnapshots (#1361),3,519,2020-08-21 13:05:43-07:00,"['TestRemoveSnapshots.java', 'ExpireSnapshotsAction.java', 'TestExpireSnapshotsAction.java']"
Fix typo in TestOrcMetrics (#1364),1,2,2020-08-22 08:44:48-07:00,['TestOrcMetrics.java']
Data: Support row-level deletes with IcebergGenerics (#1352),12,1341,2020-08-24 13:58:10-07:00,"['StructProjection.java', 'Deletes.java', 'StructLikeSet.java', 'StructLikeWrapper.java', 'GenericReader.java', 'IcebergGenerics.java', 'InternalRecordWrapper.java', 'TableScanIterable.java', 'FileHelpers.java', 'TestDataFileIndexStatsFilters.java', 'TestGenericReaderDeletes.java', 'TestParquetDeleteWriters.java']"
Python: Add 3.7 and 3.8 to CI testing (#1369),2,29,2020-08-24 17:20:33-07:00,"['.travis.yml', 'tox.ini']"
ORC: Respect MetricsConfig when extracting file metrics (#1339),8,271,2020-08-24 17:36:31-07:00,"['TestMetrics.java', 'TestOrcMetrics.java', 'TestParquetMetrics.java', 'ORC.java', 'OrcFileAppender.java', 'OrcMetrics.java', 'SparkTableUtil.java', 'SparkAppenderFactory.java']"
Flink: Add Parquet writer for RowData (#1272),4,728,2020-08-24 17:45:43-07:00,"['FlinkParquetWriters.java', 'ParquetWithFlinkSchemaVisitor.java', 'TestFlinkParquetWriter.java', 'TestHelpers.java']"
HOTFIX: Fix OrcMetrics errorprone problem.,1,3,2020-08-24 17:57:39-07:00,['OrcMetrics.java']
API: Use FilterIterator in CloseableIterable to avoid leaking resources (#1374),6,109,2020-08-24 22:56:26-07:00,"['CloseableIterable.java', 'FilterIterator.java', 'TestCloseableIterable.java', 'TestableCloseableIterable.java', 'Deletes.java', 'Filter.java']"
Spark: Fix NPE while estimating statistics on an empty table (#1376),3,23,2020-08-24 22:59:20-07:00,"['TestExpireSnapshotsAction.java', 'Reader.java', 'SparkBatchScan.java']"
Flink: Fix getters in Parquet writers (#1377),1,45,2020-08-25 10:25:48-07:00,['FlinkParquetWriters.java']
Spark: Estimate stats using snapshot summary only for partitioned tables (#1379),2,6,2020-08-25 12:04:50-07:00,"['Reader.java', 'SparkBatchScan.java']"
Actions: Add expire method to ExpireSnapshotsAction (#1375),2,109,2020-08-25 14:00:10-07:00,"['ExpireSnapshotsAction.java', 'TestExpireSnapshotsAction.java']"
Core: Fix new expiration tests (#1380),2,22,2020-08-25 14:23:29-07:00,"['TestRemoveSnapshots.java', 'TestExpireSnapshotsAction.java']"
Docs: Add docs for table maintenance and Spark streaming (#1261),3,240,2020-08-25 17:47:28-07:00,"['maintenance.md', 'spark-structured-streaming.md', 'mkdocs.yml']"
Python: Support creating tables (#1216),14,492,2020-08-26 08:53:53-07:00,"['tables.py', '__init__.py', 'base_metastore_tables.py', 'base_transaction.py', 'filesystem_tables.py', 'local_filesystem.py', 'table_metadata.py', 'hive_table_operations.py', 'hive_tables.py', 'hive_types.py', 'conftest.py', 'test_filesystem_tables.py', 'conftest.py', 'test_hive_tables.py']"
Build: Remove Joda test dependency (#1387),2,2,2020-08-26 16:57:45-07:00,"['build.gradle', 'versions.props']"
Build: Bump to Apache Spark 2.4.6 (#1386),1,4,2020-08-26 16:58:45-07:00,['versions.props']
Actions: Speed up expire snapshots action (#1397),4,248,2020-08-27 16:08:54-07:00,"['ClosingIterator.java', 'ManifestFiles.java', 'BaseAction.java', 'ManifestFileBean.java']"
Core: Extract FixupTypes from Spark (#1382),3,97,2020-08-27 17:17:54-07:00,"['FixupTypes.java', 'SparkFixupTypes.java', 'SparkSchemaUtil.java']"
"Changes default collect behavior of ExpireSnapshotActions (#1395)

* Changes default collect behavior of ExpireSnapshotActions

Previously ExpireSnapshotAction would always use toLocalIterator which
ends up costing significantly more time on smaller data sets. Since even
the largest lists of files are expected to fit in memory we are changing
the default to Collect. Collect will bring back the results more quickly
at the cost of additional memory. An option to streamDeleteResults will still
be available for extremely large expire operations.

* Reviewer Comments

* Fix Tests and Doc Links

Unfortunately we can't predicate accurately the exact number of jobs that will be
produced because of test run-order and caching (I think). So instead we will just make
sure that we have more jobs run than we had Shuffle Partitions.",2,57,2020-08-27 17:21:49-07:00,"['ExpireSnapshotsAction.java', 'TestExpireSnapshotsAction.java']"
Docs: Update for 0.9.1 release (#1381),594,206486,2020-08-27 17:42:06-07:00,"['extra.css', 'getting-started.md', 'allclasses-frame.html', 'allclasses-noframe.html', 'constant-values.html', 'deprecated-list.html', 'help-doc.html', 'index-all.html', 'index.html', 'Accessor.html', 'Accessors.html', 'AllDataFilesTable.AllDataFilesTableScan.html', 'AllDataFilesTable.html', 'AllEntriesTable.html', 'AllManifestsTable.AllManifestsTableScan.html', 'AllManifestsTable.html', 'AppendFiles.html', 'BaseCombinedScanTask.html', 'BaseMetastoreCatalog.html', 'BaseMetastoreTableOperations.html', 'BaseOverwriteFiles.html', 'BaseReplacePartitions.html', 'BaseRewriteManifests.html', 'BaseRowDelta.html', 'BaseTable.html', 'CachingCatalog.html', 'CombinedScanTask.html', 'ContentFile.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DataFilesTable.FilesTableScan.html', 'DataFilesTable.html', 'DataOperations.html', 'DataTableScan.html', 'DataTask.html', 'DeleteFile.html', 'DeleteFiles.html', 'ExpireSnapshots.html', 'FileContent.html', 'FileFormat.html', 'FileScanTask.html', 'Files.html', 'FindFiles.Builder.html', 'FindFiles.html', 'GenericManifestFile.CopyBuilder.html', 'GenericManifestFile.html', 'GenericPartitionFieldSummary.html', 'GuavaClasses.html', 'HasTableOperations.html', 'HistoryEntry.html', 'HistoryTable.html', 'LocationProviders.html', 'ManageSnapshots.html', 'ManifestContent.html', 'ManifestEntriesTable.html', 'ManifestFile.PartitionFieldSummary.html', 'ManifestFile.html', 'ManifestFiles.html', 'ManifestReader.FileType.html', 'ManifestReader.html', 'ManifestWriter.html', 'ManifestsTable.html', 'MetadataTableType.html', 'Metrics.html', 'MetricsConfig.html', 'MetricsModes.Counts.html', 'MetricsModes.Full.html', 'MetricsModes.MetricsMode.html', 'MetricsModes.None.html', 'MetricsModes.Truncate.html', 'MetricsModes.html', 'OverwriteFiles.html', 'PartitionField.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'PartitionsTable.html', 'PendingUpdate.html', 'ReplacePartitions.html', 'RewriteFiles.html', 'RewriteManifests.html', 'Rollback.html', 'RowDelta.html', 'ScanSummary.Builder.html', 'ScanSummary.PartitionMetrics.html', 'ScanSummary.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'SetLocation.html', 'Snapshot.html', 'SnapshotManager.html', 'SnapshotParser.html', 'SnapshotSummary.Builder.html', 'SnapshotSummary.html', 'SnapshotUpdate.html', 'SnapshotsTable.html', 'StructLike.html', 'SystemProperties.html', 'Table.html', 'TableMetadata.MetadataLogEntry.html', 'TableMetadata.SnapshotLogEntry.html', 'TableMetadata.html', 'TableMetadataParser.Codec.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableProperties.html', 'TableScan.html', 'Tables.html', 'Transaction.html', 'Transactions.html', 'UpdateLocation.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Action.html', 'Actions.html', 'RemoveOrphanFilesAction.html', 'RewriteDataFilesAction.html', 'RewriteDataFilesActionResult.html', 'RewriteManifestsAction.html', 'RewriteManifestsActionResult.html', 'SnapshotUpdateAction.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ArrowAllocation.html', 'ArrowSchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergArrowVectors.DecimalArrowVector.html', 'IcebergArrowVectors.VarcharArrowVector.html', 'IcebergArrowVectors.html', 'NullabilityHolder.html', 'VectorHolder.html', 'VectorizedArrowReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseVectorizedParquetValuesReader.html', 'VectorizedColumnIterator.html', 'VectorizedDictionaryEncodedParquetValuesReader.html', 'VectorizedPageIterator.html', 'VectorizedParquetDefinitionLevelReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroIterable.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'AvroSchemaWithTypeVisitor.html', 'LogicalMap.html', 'ProjectionDatumReader.html', 'RemoveIds.html', 'UUIDConversion.html', 'ValueReader.html', 'ValueReaders.StructReader.html', 'ValueReaders.html', 'ValueWriter.html', 'ValueWriters.StructWriter.html', 'ValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Catalog.html', 'Namespace.html', 'SupportsNamespaces.html', 'TableIdentifier.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericRecord.html', 'IcebergGenerics.ScanBuilder.html', 'IcebergGenerics.html', 'IdentityPartitionConverters.html', 'Record.html', 'DataReader.html', 'DataWriter.html', 'IcebergDecoder.html', 'IcebergEncoder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericOrcReader.html', 'GenericOrcReaders.html', 'GenericOrcWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseParquetReaders.html', 'BaseParquetWriter.html', 'GenericParquetReaders.html', 'GenericParquetWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'EncryptedFiles.html', 'EncryptedInputFile.html', 'EncryptedOutputFile.html', 'EncryptionKeyMetadata.html', 'EncryptionKeyMetadatas.html', 'EncryptionManager.html', 'PlaintextEncryptionManager.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CreateSnapshotEvent.html', 'Listener.html', 'Listeners.html', 'ScanEvent.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CherrypickAncestorCommitException.html', 'CommitFailedException.html', 'DuplicateWAPCommitException.html', 'NamespaceNotEmptyException.html', 'NoSuchIcebergTableException.html', 'NoSuchNamespaceException.html', 'NoSuchTableException.html', 'NotFoundException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'Bound.html', 'BoundLiteralPredicate.html', 'BoundPredicate.html', 'BoundReference.html', 'BoundSetPredicate.html', 'BoundTerm.html', 'BoundTransform.html', 'BoundUnaryPredicate.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.BoundVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'InclusiveMetricsEvaluator.html', 'Literal.html', 'ManifestEvaluator.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'StrictMetricsEvaluator.html', 'Term.html', 'True.html', 'Unbound.html', 'UnboundPredicate.html', 'UnboundTerm.html', 'UnboundTransform.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'FlinkSchemaUtil.html', 'FlinkTypeToType.html', 'FlinkTypeVisitor.html', 'FlinkAvroReader.html', 'FlinkAvroWriter.html', 'FlinkParquetReaders.html', 'FlinkParquetWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'HadoopCatalog.html', 'HadoopFileIO.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTableOperations.html', 'HadoopTables.html', 'HiddenPathFilter.html', 'SerializableConfiguration.html', 'Util.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ClientPool.Action.html', 'ClientPool.html', 'HiveCatalog.html', 'HiveCatalogs.html', 'HiveClientPool.html', 'HiveTableOperations.html', 'HiveTypeConverter.html', 'RuntimeMetaException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CloseableGroup.html', 'CloseableIterable.ConcatCloseableIterable.html', 'CloseableIterable.html', 'CloseableIterator.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'FileAppender.html', 'FileIO.html', 'InputFile.html', 'LocationProvider.html', 'OutputFile.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'MappedField.html', 'MappedFields.html', 'MappingUtil.html', 'NameMapping.html', 'NameMappingParser.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'InputFormatConfig.ConfigBuilder.html', 'InputFormatConfig.InMemoryDataModel.html', 'InputFormatConfig.html', 'SerializationUtil.html', 'IcebergSerDe.html', 'IcebergWritable.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergBinaryObjectInspector.html', 'IcebergDateObjectInspector.html', 'IcebergDecimalObjectInspector.html', 'IcebergObjectInspector.html', 'IcebergRecordObjectInspector.html', 'IcebergTimestampObjectInspector.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergInputFormat.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ORC.ReadBuilder.html', 'ORC.WriteBuilder.html', 'ORC.html', 'ORCSchemaUtil.BinaryType.html', 'ORCSchemaUtil.LongType.html', 'ORCSchemaUtil.html', 'OrcMetrics.html', 'OrcRowReader.html', 'OrcSchemaVisitor.html', 'OrcSchemaWithTypeVisitor.html', 'OrcValueReader.html', 'OrcValueReaders.StructReader.html', 'OrcValueReaders.html', 'OrcValueWriter.html', 'VectorizedRowBatchIterator.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseColumnIterator.html', 'BasePageIterator.IntIterator.html', 'BasePageIterator.html', 'ColumnIterator.html', 'ColumnWriter.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetAvroReader.html', 'ParquetAvroValueReaders.TimeMillisReader.html', 'ParquetAvroValueReaders.TimestampMillisReader.html', 'ParquetAvroValueReaders.html', 'ParquetAvroWriter.html', 'ParquetDictionaryRowGroupFilter.html', 'ParquetIterable.html', 'ParquetMetricsRowGroupFilter.html', 'ParquetReader.html', 'ParquetSchemaUtil.HasIds.html', 'ParquetSchemaUtil.html', 'ParquetTypeVisitor.html', 'ParquetUtil.html', 'ParquetValueReader.html', 'ParquetValueReaders.BinaryAsDecimalReader.html', 'ParquetValueReaders.BytesReader.html', 'ParquetValueReaders.FloatAsDoubleReader.html', 'ParquetValueReaders.IntAsLongReader.html', 'ParquetValueReaders.IntegerAsDecimalReader.html', 'ParquetValueReaders.ListReader.html', 'ParquetValueReaders.LongAsDecimalReader.html', 'ParquetValueReaders.MapReader.html', 'ParquetValueReaders.PrimitiveReader.html', 'ParquetValueReaders.RepeatedKeyValueReader.html', 'ParquetValueReaders.RepeatedReader.html', 'ParquetValueReaders.ReusableEntry.html', 'ParquetValueReaders.StringReader.html', 'ParquetValueReaders.StructReader.html', 'ParquetValueReaders.UnboxedReader.html', 'ParquetValueReaders.html', 'ParquetValueWriter.html', 'ParquetValueWriters.PrimitiveWriter.html', 'ParquetValueWriters.RepeatedKeyValueWriter.html', 'ParquetValueWriters.RepeatedWriter.html', 'ParquetValueWriters.StructWriter.html', 'ParquetValueWriters.html', 'ParquetWriteAdapter.html', 'RemoveIds.html', 'TripleWriter.html', 'TypeToMessageType.html', 'TypeWithSchemaVisitor.html', 'ValuesAsBytesReader.html', 'VectorizedParquetReader.html', 'VectorizedReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergPigInputFormat.IcebergRecordReader.html', 'IcebergPigInputFormat.html', 'IcebergStorage.html', 'PigParquetReader.html', 'SchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PruneColumnsWithReordering.html', 'PruneColumnsWithoutReordering.html', 'RollbackStagedTable.html', 'Spark3Util.DescribeSchemaVisitor.html', 'Spark3Util.html', 'SparkCatalog.html', 'SparkDataFile.html', 'SparkExceptionUtil.html', 'SparkFilters.html', 'SparkSchemaUtil.html', 'SparkSessionCatalog.html', 'SparkStructLike.html', 'SparkTableUtil.SparkPartition.html', 'SparkTableUtil.html', 'SparkUtil.html', 'SparkValueConverter.html', 'AvroWithSparkSchemaVisitor.html', 'ParquetWithSparkSchemaVisitor.html', 'SparkAvroReader.html', 'SparkAvroWriter.html', 'SparkOrcReader.html', 'SparkOrcWriter.html', 'SparkParquetReaders.html', 'SparkParquetWriters.html', 'SparkValueReaders.html', 'SparkValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ArrowVectorAccessor.html', 'ArrowVectorAccessors.html', 'ColumnarBatchReader.html', 'IcebergArrowColumnVector.html', 'NullValuesColumnVector.html', 'VectorizedSparkParquetReaders.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSource.html', 'RowDataRewriter.html', 'SparkScanBuilder.html', 'SparkStreamingWrite.html', 'SparkTable.html', 'StagedSparkTable.html', 'Stats.html', 'StreamingWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PartitionSpecVisitor.html', 'Transform.html', 'Transforms.html', 'UnknownTransform.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CheckCompatibility.html', 'Comparators.html', 'Conversions.html', 'IndexByName.html', 'IndexParents.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BinPacking.ListPacker.html', 'BinPacking.PackingIterable.html', 'BinPacking.html', 'BinaryUtil.html', 'ByteBuffers.html', 'CharSequenceSet.html', 'CharSequenceWrapper.html', 'DateTimeUtil.html', 'ExceptionUtil.html', 'Exceptions.html', 'JsonUtil.html', 'ManifestFileUtil.html', 'Pair.html', 'ParallelIterable.html', 'PartitionUtil.html', 'PropertyUtil.html', 'SerializableSupplier.html', 'SnapshotUtil.html', 'StructLikeWrapper.html', 'TableScanUtil.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'ThreadPools.html', 'UnicodeUtil.html', 'WapUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'overview-frame.html', 'overview-summary.html', 'overview-tree.html', 'package-list', 'script.js', 'serialized-form.html', 'stylesheet.css', 'index.html', 'releases.md']"
Parquet: Fix vectorized reads with dictionary and non-dictionary row groups (#1388),4,81,2020-08-28 10:02:52-07:00,"['VectorizedArrowReader.java', 'Parquet.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetVectorizedReads.java']"
Flink: Add operator to collect data files and append to a table (#1185),15,1360,2020-08-28 10:19:33-07:00,"['IcebergSinkUtil.java', 'FlinkParquetWriters.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'IcebergStreamWriter.java', 'PartitionedFanoutWriter.java', 'RowDataTaskWriterFactory.java', 'RowDataWrapper.java', 'TaskWriterFactory.java', 'SimpleDataUtil.java', 'TestFlinkIcebergSink.java', 'TestIcebergFilesCommitter.java', 'TestIcebergStreamWriter.java', 'TestRowDataPartitionKey.java', 'TestTaskWriters.java']"
Build: Fix ByteBuffer warnings from errorprone (#1334),6,18,2020-08-29 16:59:59-07:00,"['ValueReaders.java', 'ValueWriters.java', 'GenericOrcWriters.java', 'IcebergPigInputFormat.java', 'SparkValueReaders.java', 'SparkValueWriters.java']"
Docs: Fix typo in performance doc (#1401),1,2,2020-08-30 00:01:54-07:00,['performance.md']
Build: Ignore spark-warehouse in any module (#1400),1,9,2020-08-30 15:08:20-07:00,['.gitignore']
Hive: Add filter pushdown support (#1326),4,462,2020-08-31 18:27:30-07:00,"['DateTimeUtil.java', 'HiveIcebergFilterFactory.java', 'HiveIcebergInputFormat.java', 'TestHiveIcebergFilterFactory.java']"
License: Small fixes to LICENSE and NOTICE (#1408),6,16,2020-09-01 08:22:48-07:00,"['NOTICE', 'NOTICE', 'LICENSE', 'NOTICE', 'LICENSE', 'NOTICE']"
Hive: Add a shaded runtime Jar (#1267),4,598,2020-09-01 08:27:37-07:00,"['build.gradle', 'LICENSE', 'NOTICE', 'settings.gradle']"
Hive: Improve logging for the Hive read path (#1394),7,127,2020-09-01 13:36:08-07:00,"['BaseMetastoreCatalog.java', 'BaseMetastoreTableOperations.java', 'HadoopCatalog.java', 'HadoopTables.java', 'HiveCatalog.java', 'HiveTableOperations.java', 'Catalogs.java']"
Flink: Support CREATE and ALTER TABLE in Flink SQL (#1393),2,387,2020-09-02 15:18:17-07:00,"['FlinkCatalog.java', 'TestFlinkCatalogTable.java']"
API: Fix schema name conflicts (#1336),3,103,2020-09-02 15:57:18-07:00,"['Schema.java', 'IndexByName.java', 'TypeUtil.java']"
Hive: Rename iceberg-hive to iceberg-hive-metastore (#1418),21,30,2020-09-03 08:11:38-07:00,"['README.md', 'build.gradle', 'ClientPool.java', 'HiveCatalog.java', 'HiveCatalogs.java', 'HiveClientPool.java', 'HiveTableOperations.java', 'HiveTypeConverter.java', 'RuntimeMetaException.java', 'HiveCreateReplaceTableTest.java', 'HiveMetastoreTest.java', 'HiveTableBaseTest.java', 'HiveTableTest.java', 'ScriptRunner.java', 'TestHiveCatalog.java', 'TestHiveCommits.java', 'TestHiveMetastore.java', 'TestHiveTableConcurrency.java', 'hive-schema-3.1.0.derby.sql', 'settings.gradle', 'api.md']"
Flink: Support writing in SQL (#1348),13,620,2020-09-03 08:15:11-07:00,"['CatalogLoader.java', 'FlinkCatalog.java', 'FlinkTableFactory.java', 'IcebergTableSink.java', 'TableLoader.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'FlinkCatalogTestBase.java', 'SimpleDataUtil.java', 'TestFlinkCatalogDatabase.java', 'TestFlinkCatalogTable.java', 'TestFlinkTableSink.java', 'TestIcebergFilesCommitter.java']"
"Core: Fix transaction commit failure caused by retainLast (#1384)

Co-authored-by: simonssu <simonssu@tencent.com>",3,64,2020-09-03 09:19:45-07:00,"['BaseTransaction.java', 'RemoveSnapshots.java', 'TestRemoveSnapshots.java']"
API: Introduce a builder API in Catalog (#1409),5,505,2020-09-03 11:04:52-07:00,"['Catalog.java', 'BaseMetastoreCatalog.java', 'HadoopCatalog.java', 'TestHadoopCatalog.java', 'TestHiveCatalog.java']"
"API: Implement SortOrder (#1373)

This commit extends Iceberg metadata with a sort order that defines how data and delete files should be ordered.",26,1491,2020-09-03 22:48:01-07:00,"['checkstyle.xml', 'NullOrder.java', 'SortDirection.java', 'SortField.java', 'SortOrder.java', 'Table.java', 'Tables.java', 'Catalog.java', 'Expressions.java', 'BaseMetadataTable.java', 'BaseMetastoreCatalog.java', 'BaseTable.java', 'BaseTransaction.java', 'SortOrderParser.java', 'TableMetadata.java', 'TableMetadataParser.java', 'HadoopTables.java', 'TestReplaceTransaction.java', 'TestSortOrder.java', 'TestSortOrderParser.java', 'TestTableMetadata.java', 'TestTables.java', 'TestHadoopCatalog.java', 'TestHadoopTablesSortOrder.java', 'TestHiveCatalog.java', 'TestTables.java']"
Core: Add union by name to UpdateSchema API (#1177),5,791,2020-09-08 10:20:26-07:00,"['UpdateSchema.java', 'SchemaUpdate.java', 'SchemaWithPartnerVisitor.java', 'UnionByNameVisitor.java', 'TestSchemaUnionByFieldName.java']"
Hive: Avoid deadlock in ClientPool close after newClient failure (#1433),2,57,2020-09-08 10:26:10-07:00,"['ClientPool.java', 'TestClientPool.java']"
Core: Fix TableScan project and select handling (#1353),4,106,2020-09-08 13:36:53-07:00,"['BaseTableScan.java', 'TableScanContext.java', 'TestDataTableScan.java', 'TestMetadataTableScans.java']"
Core: Avoid unnecessary warning for NoSuchIcebergTableException (#1429),1,6,2020-09-09 16:49:33-07:00,['BaseMetastoreTableOperations.java']
Flink: Ensure the default database exists (#1435),2,29,2020-09-10 14:58:49-07:00,"['FlinkCatalog.java', 'TestFlinkCatalogDatabase.java']"
Core: Use one TableOperations per base table in CachingCatalog (#1432),5,224,2020-09-10 15:01:50-07:00,"['BaseMetastoreCatalog.java', 'CachingCatalog.java', 'MetadataTableUtils.java', 'HadoopTables.java', 'TestCachingCatalog.java']"
Build: Update autolabeler config to match any gradle file (#1449),1,2,2020-09-13 15:54:56-07:00,['autolabeler.yml']
Build: Add flink-runtime directory to autolabeler config (#1450),1,1,2020-09-13 15:56:40-07:00,['autolabeler.yml']
"Docs: Remove Appendix from Spark streaming doc, add missing links (#1390)",3,37,2020-09-13 16:47:10-07:00,"['java-api-quickstart.md', 'maintenance.md', 'spark-structured-streaming.md']"
Core: Fix Hadoop tables with corrupt version hint file (#1443),2,108,2020-09-14 10:03:46-07:00,"['HadoopTableOperations.java', 'TestHadoopCatalog.java']"
Build: Add in a .gitattributes to excluding paths from release archives (#1457),1,35,2020-09-14 17:43:25-07:00,['.gitattributes']
Build: Use .gitattributes to filter release archives (#1459),1,6,2020-09-14 17:46:04-07:00,['source-release.sh']
API: Fix Metrics with Java serialization (#1430),3,202,2020-09-14 17:48:28-07:00,"['Metrics.java', 'ByteBuffers.java', 'TestMetricsSerialization.java']"
Core: Fix ConcurrentModificationException in DeleteFileIndex (#1446),2,19,2020-09-15 10:05:27-07:00,"['DeleteFileIndex.java', 'ParallelIterable.java']"
Hive: Fix date filter test by removing Date.valueOf (#1460),1,5,2020-09-15 10:10:23-07:00,['TestHiveIcebergFilterFactory.java']
Core: Add Precondition check to match other constructor (#1452),1,1,2020-09-15 10:15:17-07:00,['BaseCombinedScanTask.java']
Flink: Add iceberg-flink-runtime Jar (#1423),4,599,2020-09-16 11:15:35-07:00,"['build.gradle', 'LICENSE', 'NOTICE', 'settings.gradle']"
Docs: Add warning about changing authority in RemoveOrphanFiles (#1466),1,8,2020-09-16 11:22:14-07:00,['maintenance.md']
Flink: Add job id to state backend for handling job redeployment (#1404),2,155,2020-09-16 13:05:55-07:00,"['IcebergFilesCommitter.java', 'TestIcebergFilesCommitter.java']"
Docs: Fix Spark time travel examples (#1467),1,23,2020-09-16 13:29:45-07:00,['spark.md']
Spark: Apply row-level delete files when reading (#1444),15,937,2020-09-17 10:14:41-07:00,"['Accessors.java', 'build.gradle', 'TableScanUtil.java', 'DeleteFilter.java', 'GenericDeleteFilter.java', 'GenericReader.java', 'TestGenericReaderDeletes.java', 'BaseDataReader.java', 'RowDataReader.java', 'SparkTestBase.java', 'TestSparkReaderDeletes.java', 'Reader.java', 'TestSparkReaderDeletes24.java', 'SparkBatchScan.java', 'TestSparkReaderDeletes3.java']"
Parquet: Close reader used to get row group positions (#1474),1,24,2020-09-18 10:01:36-07:00,['ReadConf.java']
Hadoop: Enhance version-hint.txt recovery with file listing (#1465),3,183,2020-09-18 11:45:52-07:00,"['HadoopTableOperations.java', 'HadoopTables.java', 'TestHadoopCatalog.java']"
Spark: Add test on fault tolerance during write (transactional write) (#1484),1,75,2020-09-22 12:45:50-07:00,['TestDataFrameWrites.java']
Build: Fix warnings (#1427),74,370,2020-09-22 15:35:35-07:00,"['ContentFile.java', 'DataTask.java', 'ExpireSnapshots.java', 'Files.java', 'HistoryEntry.java', 'ManifestFile.java', 'PartitionField.java', 'PartitionSpec.java', 'ScanTask.java', 'Schema.java', 'SortField.java', 'SortOrder.java', 'Table.java', 'TableIdentifier.java', 'AlreadyExistsException.java', 'CommitFailedException.java', 'NamespaceNotEmptyException.java', 'NoSuchIcebergTableException.java', 'NoSuchNamespaceException.java', 'NoSuchTableException.java', 'NotFoundException.java', 'RuntimeIOException.java', 'ValidationException.java', 'Bound.java', 'BoundTerm.java', 'Expression.java', 'Literal.java', 'Unbound.java', 'UnboundPredicate.java', 'FileAppender.java', 'InputFile.java', 'Conversions.java', 'NullabilityHolder.java', 'baseline.gradle', 'build.gradle', 'DynFields.java', 'DynMethods.java', 'BaseMetastoreCatalog.java', 'BaseRewriteManifests.java', 'DeleteFileIndex.java', 'FindFiles.java', 'IncrementalDataTableScan.java', 'ManifestEntry.java', 'ManifestFilterManager.java', 'ManifestListWriter.java', 'ManifestMergeManager.java', 'ManifestWriter.java', 'MergingSnapshotProducer.java', 'PartitionSpecParser.java', 'TableOperations.java', 'HadoopCatalog.java', 'HadoopTableOperations.java', 'HadoopTables.java', 'MappingUtil.java', 'Exceptions.java', 'Filter.java', 'SnapshotUtil.java', 'HiveCatalog.java', 'HiveTableOperations.java', 'RuntimeMetaException.java', 'Catalogs.java', 'IdToOrcName.java', 'OrcFileAppender.java', 'VectorizedRowBatchIterator.java', 'Parquet.java', 'ParquetUtil.java', 'ValuesAsBytesReader.java', 'VectorizedReader.java', 'RewriteManifestsAction.java', 'SparkExceptionUtil.java', 'SparkTableUtil.java', 'ArrowVectorAccessors.java', 'Writer.java', 'SparkBatchWrite.java']"
Core: Fix table replacement by preserving existing field IDs (#1475),4,102,2020-09-23 09:20:34-07:00,"['AssignFreshIds.java', 'TypeUtil.java', 'TableMetadata.java', 'TestReplaceTransaction.java']"
Docs: Add iceberg-flink-runtime to README (#1494),1,2,2020-09-23 17:54:17-07:00,['README.md']
Core: Suppress warning for DangerousStringInternUsage in base catalog deleteFiles (#1489),1,1,2020-09-23 18:19:20-07:00,['BaseMetastoreCatalog.java']
Parquet: Upgrade to 1.11.1 (#1506),1,2,2020-09-24 15:13:05-07:00,['versions.props']
Flink: Introduce Flink InputFormat (#1346),15,1542,2020-09-24 18:05:47-07:00,"['FlinkFixupTypes.java', 'FlinkSchemaUtil.java', 'FlinkOrcReader.java', 'FlinkOrcReaders.java', 'FlinkParquetReaders.java', 'DataIterator.java', 'FlinkInputFormat.java', 'FlinkInputSplit.java', 'FlinkSource.java', 'FlinkSplitGenerator.java', 'RowDataIterator.java', 'ScanOptions.java', 'TestFlinkOrcReaderWriter.java', 'TestFlinkInputFormat.java', 'TestFlinkScan.java']"
Docs: Fix rendering of lists for format version changes (#1507),1,3,2020-09-25 10:52:43-07:00,['spec.md']
Hive: Implement createTable and dropTable in Catalogs (#1481),9,464,2020-09-25 12:27:39-07:00,"['BaseMetastoreCatalog.java', 'CatalogUtil.java', 'HadoopCatalog.java', 'HadoopTables.java', 'TestHadoopTables.java', 'HiveCatalog.java', 'Catalogs.java', 'InputFormatConfig.java', 'TestCatalogs.java']"
Spark: Follow name mapping when importing ORC tables (#1399),3,566,2020-09-25 15:55:33-07:00,"['OrcMetrics.java', 'SparkTableUtil.java', 'TestSparkTableUtil.java']"
Core: Suppress DangerousStringInternUsage for weak key map (#1519),1,1,2020-09-28 10:52:48-07:00,['CatalogUtil.java']
Build: Set Javadoc encoding to UTF-8 (#1518),1,4,2020-09-28 10:54:55-07:00,['build.gradle']
Flink: Do not pass precision to Flink time type (#1521),2,8,2020-09-28 10:58:58-07:00,"['TypeToFlinkType.java', 'TestFlinkSchemaUtil.java']"
Core: Suppress UnnecessaryAnonymousClass warnings (#1493),3,3,2020-09-28 15:33:43-07:00,"['RemoveSnapshots.java', 'SnapshotProducer.java', 'ExpireSnapshotsAction.java']"
MR: Use HadoopFileIO instead of HadoopInputFile (#1526),1,8,2020-09-28 17:18:05-07:00,['IcebergInputFormat.java']
API: Add null check to PruneColumns (#1491),3,5,2020-09-28 17:30:46-07:00,"['PruneColumns.java', 'PruneColumns.java', 'PruneColumns.java']"
Flink: Integrate Flink reader to SQL (#1509),11,1072,2020-09-29 10:02:03-07:00,"['FlinkTableFactory.java', 'IcebergTableSource.java', 'FlinkInputFormat.java', 'FlinkSource.java', 'FlinkSplitGenerator.java', 'RowDataIterator.java', 'ScanContext.java', 'ScanOptions.java', 'TestFlinkInputFormat.java', 'TestFlinkScan.java', 'TestFlinkScanSql.java']"
Docs: Add section on writing to a partitioned table in Spark (#1523),5,246,2020-09-29 10:14:24-07:00,"['spark.md', 'IcebergSpark.java', 'TestIcebergSpark.java', 'TestIcebergSpark24.java', 'TestIcebergSpark3.java']"
Core: Replace partition field id literal with reference (#1528),1,4,2020-09-29 11:33:10-07:00,['DataFilesTable.java']
Spark: Implement equals and hashCode in SparkBatchScan (#1512),1,34,2020-09-29 17:17:46-07:00,['SparkBatchScan.java']
ORC: Fix predicate pushdown for notIn and notEqual (#1536),3,58,2020-09-30 13:35:16-07:00,"['TestMetricsRowGroupFilter.java', 'ExpressionToSearchArgument.java', 'TestExpressionToSearchArgument.java']"
Spark: Add null check for catalog in SparkTestBase (#1529),1,4,2020-09-30 15:58:17-07:00,['SparkTestBase.java']
"Hive: Fix temporary folder cleanup in TestCatalogs (#1535)

Co-authored-by: Marton Bod <mbod@cloudera.com>",1,4,2020-10-01 10:18:26-07:00,['TestCatalogs.java']
Docs: Add Hive read docs (#1490),2,57,2020-10-01 10:51:06-07:00,"['hive.md', 'mkdocs.yml']"
Docs: Add Flink sink docs (#1464),2,297,2020-10-01 10:51:59-07:00,"['flink.md', 'mkdocs.yml']"
"API: Add name to Table and Catalog APIs (#1537)

Resolves #658.",24,291,2020-10-01 13:16:31-07:00,"['Table.java', 'Catalog.java', 'AllDataFilesTable.java', 'AllEntriesTable.java', 'AllManifestsTable.java', 'BaseMetadataTable.java', 'BaseMetastoreCatalog.java', 'BaseTable.java', 'BaseTransaction.java', 'CachingCatalog.java', 'DataFilesTable.java', 'HistoryTable.java', 'ManifestEntriesTable.java', 'ManifestsTable.java', 'MetadataTableUtils.java', 'PartitionsTable.java', 'SnapshotsTable.java', 'HadoopCatalog.java', 'HadoopTables.java', 'TestCachingCatalog.java', 'TestHadoopCatalog.java', 'TestHadoopTables.java', 'HiveCatalog.java', 'TestHiveCatalog.java']"
MR: Use encryption manager for input files (#1532),2,56,2020-10-01 14:37:39-07:00,"['IcebergInputFormat.java', 'IcebergSplit.java']"
Spark: Implement equals and hashCode in SparkTable (#1530),2,80,2020-10-01 16:46:16-07:00,"['SparkTable.java', 'TestSparkTable.java']"
Tests: Add names to parameterized tests (#1539),60,638,2020-10-02 11:17:04-07:00,"['TableMetadataParserTest.java', 'TestCreateTransaction.java', 'TestDataTableScan.java', 'TestDeleteFiles.java', 'TestEntriesMetadataTable.java', 'TestFastAppend.java', 'TestFilterFiles.java', 'TestFindFiles.java', 'TestIncrementalDataTableScan.java', 'TestManifestCleanup.java', 'TestManifestReader.java', 'TestManifestWriter.java', 'TestMergeAppend.java', 'TestMetadataTableScans.java', 'TestMicroBatchBuilder.java', 'TestOverwrite.java', 'TestOverwriteWithValidation.java', 'TestPartitionSpecInfo.java', 'TestRemoveSnapshots.java', 'TestReplacePartitions.java', 'TestReplaceTransaction.java', 'TestRewriteFiles.java', 'TestRewriteManifests.java', 'TestScanSummary.java', 'TestScansAndSchemaEvolution.java', 'TestSchemaAndMappingUpdate.java', 'TestSnapshot.java', 'TestSnapshotManager.java', 'TestSnapshotSelection.java', 'TestSortOrder.java', 'TestSplitPlanning.java', 'TestTableMetadataSerialization.java', 'TestTimestampPartitions.java', 'TestTransaction.java', 'TestWapWorkflow.java', 'TestMappingUpdates.java', 'TestSplitScan.java', 'TestLocalScan.java', 'TestMetricsRowGroupFilter.java', 'TestMetricsRowGroupFilterTypes.java', 'FlinkCatalog.java', 'FlinkCatalogTestBase.java', 'TestFlinkTableSink.java', 'TestFlinkIcebergSink.java', 'TestIcebergStreamWriter.java', 'TestTaskWriters.java', 'TestIcebergInputFormats.java', 'TestRewriteManifestsAction.java', 'TestSparkOrcReadMetadataColumns.java', 'TestSparkParquetReadMetadataColumns.java', 'TestDataFrameWrites.java', 'TestIdentityPartitionData.java', 'TestParquetScan.java', 'TestPartitionValues.java', 'TestSparkDataWrite.java', 'TestSparkReadProjection.java', 'TestFilteredScan.java', 'TestSparkTableUtil.java', 'SparkCatalogTestBase.java', 'TestFilteredScan.java']"
ORC: Upgrade to 1.6.5 (#1546),1,2,2020-10-02 12:55:23-07:00,['versions.props']
MR: Apply row-level delete files when reading (#1497),6,989,2020-10-05 10:02:02-07:00,"['DeleteReadTests.java', 'TestGenericReaderDeletes.java', 'IcebergInputFormat.java', 'TestIcebergInputFormats.java', 'TestInputFormatReaderDeletes.java', 'TestSparkReaderDeletes.java']"
Build: Ignore OverloadMethodsDeclarationOrder rule (#1550),5,5,2020-10-05 11:46:36-07:00,"['checkstyle.xml', 'BaseTableScan.java', 'PositionDelete.java', 'InternalRecordWrapper.java', 'TestHelpers.java']"
Hive: Make HiveCatalog based tables readable from Hive (#1505),6,193,2020-10-05 16:03:59-07:00,"['TableProperties.java', 'ConfigProperties.java', 'HiveTableOperations.java', 'HiveTableTest.java', 'TestHelper.java', 'TestHiveIcebergStorageHandlerWithHiveCatalog.java']"
Core: Allow LocationProvider to be customized using reflection (#1531),5,245,2020-10-05 19:38:48-07:00,"['LocationProviders.java', 'TableProperties.java', 'TestLocationProvider.java', 'table_properties.py', 'configuration.md']"
Core: Fix error when a DeleteFile is used twice in a task (#1514),2,41,2020-10-06 09:34:32-07:00,"['DeleteReadTests.java', 'BaseDataReader.java']"
Spark: Add end-to-end test for partition pruning (#1487),4,500,2020-10-06 09:55:48-07:00,"['LogMessage.java', 'TestPartitionPruning.java', 'TestPartitionPruning24.java', 'TestPartitionPruning3.java']"
Core: Add partition summaries in SnapshotSummary builder (#1367),8,421,2020-10-06 12:35:34-07:00,"['BaseRewriteManifests.java', 'FastAppend.java', 'MergingSnapshotProducer.java', 'SnapshotSummary.java', 'TableProperties.java', 'TestFastAppend.java', 'TestMergeAppend.java', 'configuration.md']"
"BaseMetastoreTableOperations shouldn't disable refresh upon NoSuchTableException. Otherwise it might cause unfriendly NPE for callers that don't check null return value from current() method. (#1553)

Co-authored-by: Steven Wu <stevenwu@netflix.com>",1,2,2020-10-06 12:36:32-07:00,['BaseMetastoreTableOperations.java']
Spark3: Refresh state in SparkTable for all scans when not caching (#1545),6,97,2020-10-06 14:29:58-07:00,"['TestSparkDataWrite.java', 'SparkCatalog.java', 'IcebergSource.java', 'SparkTable.java', 'StagedSparkTable.java', 'TestPartitionedWrites.java']"
Parallelize reading manifest list files in metadata tables. (#1440),2,6,2020-10-06 16:17:18-07:00,"['AllDataFilesTable.java', 'AllEntriesTable.java']"
Add TableMetadata.updateSortOrder. (#1551),2,90,2020-10-06 16:57:30-07:00,"['TableMetadata.java', 'TestTableMetadata.java']"
Core: Add row-level delete validations (#1469),13,747,2020-10-07 09:35:43-07:00,"['OverwriteFiles.java', 'RowDelta.java', 'BaseOverwriteFiles.java', 'BaseRowDelta.java', 'MergingSnapshotProducer.java', 'SnapshotManager.java', 'SnapshotProducer.java', 'PositionDeleteWriter.java', 'TestOverwriteWithValidation.java', 'TestRowDelta.java', 'DeleteReadTests.java', 'FileHelpers.java', 'TestDataFileIndexStatsFilters.java']"
"Hive: Add Hive3 module and testing (#1478)

Hive 3 classes are included in the iceberg-hive-runtime Jar.",14,578,2020-10-07 09:53:48-07:00,"['build.gradle', 'HiveClientPool.java', 'MetastoreUtil.java', 'TestHiveMetastore.java', 'IcebergDateObjectInspectorHive3.java', 'IcebergTimestampObjectInspectorHive3.java', 'TestIcebergDateObjectInspectorHive3.java', 'TestIcebergTimestampObjectInspectorHive3.java', 'HiveIcebergFilterFactory.java', 'HiveIcebergStorageHandler.java', 'IcebergObjectInspector.java', 'HiveIcebergStorageHandlerBaseTest.java', 'TestIcebergObjectInspector.java', 'settings.gradle']"
Hive: Fix missing table schema in Hive 1.1 query (#1557),1,5,2020-10-08 10:15:15-07:00,['HiveIcebergStorageHandler.java']
"Parquet: Remove hard-coded file paths from tests (#1562)

* Remove hard-coded file paths from tests.

* Fix checkstyle in tests.",2,55,2020-10-09 08:46:12-07:00,"['TestMetricsRowGroupFilter.java', 'TestDictionaryRowGroupFilter.java']"
Docs: Move URI clarification earlier (#1571),1,2,2020-10-10 13:51:31-07:00,['spark.md']
Hive: Avoid loading catalog to initialized a serde (#1564),1,14,2020-10-10 14:09:18-07:00,['HiveIcebergSerDe.java']
Spark: Close final reader in BaseDataIterator (#1563),4,330,2020-10-10 14:13:27-07:00,"['BaseDataReader.java', 'TestSparkBaseDataReader.java', 'TestSparkBaseDataReader24.java', 'TestSparkBaseDataReader3.java']"
"Hive: Run storage handler tests for Parquet and ORC (#1570)

Co-authored-by: Marton Bod <mbod@cloudera.com>",1,57,2020-10-10 15:20:41-07:00,['HiveIcebergStorageHandlerBaseTest.java']
Build: Update autolabeler configuration for new Hive modules (#1577),1,4,2020-10-10 16:53:34-07:00,['autolabeler.yml']
Flink: Fix IntLongMath warnings (#1581),1,2,2020-10-10 22:46:37-07:00,['FlinkOrcWriters.java']
Replace Table.toString calls with Table.name (#1580),6,22,2020-10-12 10:22:52-07:00,"['BaseAllMetadataTableScan.java', 'BaseTableScan.java', 'TestHadoopCatalog.java', 'FlinkSink.java', 'BaseAction.java', 'SparkBatchScan.java']"
"Hive: Run StorageHandler tests with Avro (#1585)

Co-authored-by: Marton Bod <mbod@cloudera.com>",2,27,2020-10-12 10:25:12-07:00,"['build.gradle', 'HiveIcebergStorageHandlerBaseTest.java']"
API: Validate bucket and truncate function parameters (#1569),4,26,2020-10-12 10:33:16-07:00,"['Bucket.java', 'Truncate.java', 'TestBucketing.java', 'TestTruncate.java']"
Flink: move hadoop configuration to Loaders from Source/Sink API (#1565),14,307,2020-10-13 14:25:58+08:00,"['CatalogLoader.java', 'FlinkCatalog.java', 'FlinkCatalogFactory.java', 'FlinkTableFactory.java', 'IcebergTableSink.java', 'IcebergTableSource.java', 'TableLoader.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'FlinkInputFormat.java', 'FlinkSource.java', 'TestCatalogTableLoader.java', 'TestFlinkIcebergSink.java', 'TestIcebergFilesCommitter.java']"
Hive: Add HiveMetaHook to support Hive DDL commands (#1495),10,773,2020-10-13 09:08:25-07:00,"['HiveTableOperations.java', 'TestHiveMetastore.java', 'Catalogs.java', 'InputFormatConfig.java', 'HiveIcebergMetaHook.java', 'HiveIcebergSerDe.java', 'HiveIcebergStorageHandler.java', 'HiveIcebergStorageHandlerBaseTest.java', 'TestHiveIcebergStorageHandlerWithHadoopTables.java', 'log4j.properties']"
Spark: Add parameter name to TestPartitionPruning (#1600),1,12,2020-10-13 09:10:08-07:00,['TestPartitionPruning.java']
MR: Fix NPE when InputSplit.getLocations is called on mappers (#1582),1,6,2020-10-13 09:11:12-07:00,['IcebergSplit.java']
Hive: Fix filter conversion with Date (#1579),1,3,2020-10-13 09:16:44-07:00,['HiveIcebergFilterFactory.java']
ORC: Remove workarounds after 1.6.5 upgrade (#1561),2,38,2020-10-13 09:32:19-07:00,"['TestMetricsRowGroupFilter.java', 'OrcMetrics.java']"
Spark: Reuse containers when reading Parquet (#1522),2,4,2020-10-13 10:58:51-07:00,"['RowDataIterator.java', 'RowDataReader.java']"
Spark: Fix benchmark docs and temp files (#1606),16,36,2020-10-13 12:11:16-07:00,"['SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java']"
Spark: Move Action tests to the correct package (#1609),4,16,2020-10-13 17:07:29-07:00,"['TestExpireSnapshotsAction3.java', 'TestRemoveOrphanFilesAction3.java', 'TestRewriteDataFilesAction3.java', 'TestRewriteManifestsAction3.java']"
Flink: Apply row-level deletes when reading (#1517),15,337,2020-10-14 16:11:41-07:00,"['RowDataWrapper.java', 'FlinkParquetReaders.java', 'RowDataTaskWriterFactory.java', 'DataIterator.java', 'FlinkInputFormat.java', 'FlinkSource.java', 'RowDataIterator.java', 'TestHelpers.java', 'TestFlinkAvroReaderWriter.java', 'TestFlinkOrcReaderWriter.java', 'TestFlinkParquetReader.java', 'TestFlinkParquetWriter.java', 'TestRowDataPartitionKey.java', 'TestFlinkInputFormat.java', 'TestFlinkInputFormatReaderDeletes.java']"
Docs: Add ORC to table and writer format configs (#1615),1,4,2020-10-15 14:49:21-07:00,['configuration.md']
Hive: Fix TestHiveMetastore worker exhaustion (#1620),2,9,2020-10-16 09:55:17-07:00,"['TestHiveMetastore.java', 'HiveIcebergStorageHandlerBaseTest.java']"
Hive: Make the TestHiveMetastore connection pool size configurable (#1629),2,25,2020-10-19 18:07:23+08:00,"['TestHiveMetastore.java', 'HiveIcebergStorageHandlerBaseTest.java']"
Hive: Select ObjectInspectors based on classpath (#1632),1,30,2020-10-19 12:33:50-07:00,['IcebergObjectInspector.java']
Flink: move convertConstant method from DataIterator to RowDataUtil class (#1625),3,118,2020-10-20 10:49:42+08:00,"['RowDataUtil.java', 'DataIterator.java', 'RowDataIterator.java']"
Flink: Support configurable parallelism for write tasks (#1619),2,18,2020-10-20 18:09:35-07:00,"['FlinkSink.java', 'TestFlinkIcebergSink.java']"
Parquet: Fix row group filtering with old CDH stats (#1638),2,136,2020-10-21 17:07:37-07:00,"['ParquetMetricsRowGroupFilter.java', 'TestCDHParquetStatistics.java']"
Spark: Split Actions for Spark 2 and 3 using reflection (#1616),3,94,2020-10-22 10:14:49-07:00,"['Actions.java', 'SparkActions.java', 'SparkActions.java']"
Lint: Fix small issues (#1650),5,9,2020-10-23 11:19:43-07:00,"['BaseOverwriteFiles.java', 'FixupTypes.java', 'DeleteFilter.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java']"
Spark: Bump Spark 2 module to 2.4.7 (#1646),1,4,2020-10-23 11:22:32-07:00,['versions.props']
Docs: Document property behavior for Spark REPLACE TABLE (#1644),2,14,2020-10-23 11:24:09-07:00,"['spark.md', 'TestCreateTableAsSelect.java']"
Flink: Load hive-site.xml for HiveCatalog (#1586),12,374,2020-10-23 14:28:49-07:00,"['CatalogLoader.java', 'FlinkCatalogFactory.java', 'FlinkCatalogTestBase.java', 'FlinkTestBase.java', 'TestCatalogTableLoader.java', 'TestFlinkCatalogDatabase.java', 'TestFlinkCatalogTable.java', 'TestFlinkHiveCatalog.java', 'TestFlinkTableSink.java', 'TestFlinkInputFormatReaderDeletes.java', 'HiveCatalog.java', 'flink.md']"
Parquet: Add test for Arrow buffer reallocation (#1480),4,75,2020-10-23 14:30:49-07:00,"['TestHelpers.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryFallbackToPlainEncodingVectorizedReads.java', 'TestParquetVectorizedReads.java']"
"Hive: Update test code for Hive4 (#1645)

Co-authored-by: Marton Bod <mbod@cloudera.com>",2,22,2020-10-27 11:22:25-07:00,"['TestHiveMetastore.java', 'HiveIcebergStorageHandlerBaseTest.java']"
Docs: Fix docs typo in ParquetVectorizedReader (#1658),1,2,2020-10-27 11:23:29-07:00,['VectorizedReader.java']
Spark: Bump Spark 3 version to 3.0.1 (#1656),1,2,2020-10-27 11:24:22-07:00,['versions.props']
"Hive: Add TestHiveShell for parameterized StorageHandler tests (#1631)

Co-authored-by: Marton Bod <mbod@cloudera.com>",4,339,2020-10-27 14:29:55-07:00,"['build.gradle', 'HiveIcebergStorageHandlerBaseTest.java', 'TestHiveShell.java', 'versions.props']"
Flink: maintain the complete data files into manifest before checkpoint finished. (#1477),9,778,2020-10-28 12:06:53+08:00,"['ManifestFiles.java', 'AvroEncoderUtil.java', 'TestAvroEncoderUtil.java', 'FlinkManifestSerializer.java', 'FlinkManifestUtil.java', 'IcebergFilesCommitter.java', 'ManifestOutputFileFactory.java', 'TestFlinkManifest.java', 'TestIcebergFilesCommitter.java']"
Core: Extract the BaseRewriteDataFilesAction for implementing both flink and spark rewrite actions.,10,664,2020-10-28 12:19:30+08:00,"['Action.java', 'BaseAction.java', 'BaseRewriteDataFilesAction.java', 'BaseSnapshotUpdateAction.java', 'RewriteDataFilesActionResult.java', 'SnapshotUpdateAction.java', 'BaseSparkAction.java', 'ExpireSnapshotsAction.java', 'RemoveOrphanFilesAction.java', 'RewriteDataFilesAction.java']"
Parquet: Optimize IN predicates in ParquetDictionaryRowGroupFilter (#1664),1,23,2020-10-28 09:40:05-07:00,['ParquetDictionaryRowGroupFilter.java']
Spec: Update the spec for row-level deletes (#1499),1,370,2020-10-28 15:40:22-07:00,['spec.md']
Fix IN predicate performance (#1672),5,48,2020-10-28 15:57:56-07:00,"['InclusiveMetricsEvaluator.java', 'ManifestEvaluator.java', 'TestInclusiveMetricsEvaluator.java', 'TestMetricsRowGroupFilter.java', 'ParquetMetricsRowGroupFilter.java']"
Spark: Remove cache expiration in HiveCatalogs cache (#1674),1,7,2020-10-28 16:10:06-07:00,['HiveCatalogs.java']
Build: Add ASF licence header to .asf.yaml,1,19,2020-10-28 18:03:58-07:00,['.asf.yaml']
Build: Support builds without .git directory (#1681),1,9,2020-10-29 09:07:07-07:00,['build.gradle']
Core: Update FS table version-hint.txt atomically (#1559),1,13,2020-10-29 09:30:11-07:00,['HadoopTableOperations.java']
Build: Move PR labeler to GitHub action (#1686),3,187,2020-10-29 09:31:23-07:00,"['autolabeler.yml', 'labeler.yml', 'labeler.yml']"
Build: Change labeller to more secure pull_request_target (#1692),1,2,2020-10-29 10:14:14-07:00,['labeler.yml']
"Spark: Enable testInsertOverwrite, passing with Spark 3.0.1 (#1679)",1,3,2020-10-29 11:11:10-07:00,['TestPartitionedWrites.java']
Core: Fix ArrayIndexOutOfBounds for tables with migrated partition specs (#1676),1,2,2020-10-29 11:14:30-07:00,['ManifestsTable.java']
Core: Fix replaced partitions validation in SnapshotManager (#1677),1,2,2020-10-29 11:25:32-07:00,['SnapshotManager.java']
Core: Do not create an Evaluator in ManifestGroup unless the file filter is used (#1678),1,9,2020-10-29 11:29:11-07:00,['ManifestGroup.java']
Core: Fix entries metadata tables with delete manifests (#1673),3,54,2020-10-29 11:51:18-07:00,"['AllEntriesTable.java', 'ManifestEntriesTable.java', 'TestEntriesMetadataTable.java']"
Build: Fix source-release.sh (#1694),1,2,2020-10-30 09:57:59-07:00,['source-release.sh']
Build: Fix Javadoc in SnapshotSummary,1,2,2020-10-30 12:17:27-07:00,['SnapshotSummary.java']
ORC: OrcFileAppender#length should return file size on disk (#1697),1,2,2020-11-01 11:20:11-08:00,['OrcFileAppender.java']
ORC: Enable predicate pushdown and remove metrics workaround for Timestamps (#1696),5,43,2020-11-01 11:27:53-08:00,"['TestMetrics.java', 'TestMetricsRowGroupFilterTypes.java', 'ExpressionToSearchArgument.java', 'OrcMetrics.java', 'TestExpressionToSearchArgument.java']"
Core: Check required v2 fields in table metadata parser (#1614),7,360,2020-11-01 12:19:41-08:00,"['TableMetadataParser.java', 'TestTableMetadata.java', 'TableMetadataUnsupportedVersion.json', 'TableMetadataV1Valid.json', 'TableMetadataV2MissingPartitionSpecs.json', 'TableMetadataV2MissingSortOrder.json', 'TableMetadataV2Valid.json']"
"Revert ""Hive: Fix missing table schema in Hive 1.1 query (#1557)"" (#1707)

This reverts commit 13d94bc2e4e2dcae3d964b98dbb3aaeee19b46c2.

Co-authored-by: Marton Bod <mbod@cloudera.com>",1,5,2020-11-02 13:53:41-08:00,['HiveIcebergStorageHandler.java']
ORC: Fix non-vectorized reader incorrectly skipping rows (#1706),2,126,2020-11-02 14:00:16-08:00,"['TestOrcRowIterator.java', 'OrcIterable.java']"
"Hive: Run StorageHandler tests in both MR and Tez (#1695)

Co-authored-by: Marton Bod <mbod@cloudera.com>",4,39,2020-11-02 16:52:58-08:00,"['build.gradle', 'HiveIcebergStorageHandlerBaseTest.java', 'TestHiveShell.java', 'versions.props']"
Spark: Handle null literals in predicates (#1709),4,183,2020-11-03 09:07:26-08:00,"['SparkFilters.java', 'TestSparkFilterConversion.java', 'SparkFilters.java', 'TestSparkFilterConversion.java']"
"Revert ""Spark: Handle null literals in predicates (#1709)""

This reverts commit 552b76713fca5d34a951d2794d74d3d7b8829ff3.",4,183,2020-11-03 10:28:00-08:00,"['SparkFilters.java', 'TestSparkFilterConversion.java', 'SparkFilters.java', 'TestSparkFilterConversion.java']"
Docs: Add type compatibility tables for Spark (#1611),1,61,2020-11-03 12:19:26-08:00,['spark.md']
Build: Ignore json files in licence checks,1,1,2020-11-03 15:50:30-08:00,['.rat-excludes']
Docs:  Replace to use the raw markdown links (#1714),14,100,2020-11-04 17:00:02+08:00,"['api.md', 'configuration.md', 'evolution.md', 'flink.md', 'getting-started.md', 'hive.md', 'java-api-quickstart.md', 'maintenance.md', 'reliability.md', 'schemas.md', 'spark-structured-streaming.md', 'spark.md', 'spec.md', 'terms.md']"
Flink:  Add a rewrite datafile action for flink (#1623),8,572,2020-11-04 19:34:10+08:00,"['PropertyUtil.java', 'Actions.java', 'RewriteDataFilesAction.java', 'TaskWriterFactory.java', 'RowDataRewriter.java', 'FlinkTestBase.java', 'TestRewriteDataFilesAction.java', 'RewriteDataFilesAction.java']"
API: Extend partitioning and sort order (#1675),14,665,2020-11-04 13:49:45-08:00,"['SortField.java', 'SortOrder.java', 'Expressions.java', 'Dates.java', 'Identity.java', 'PartitionSpecVisitor.java', 'SortOrderVisitor.java', 'Timestamps.java', 'Transform.java', 'Truncate.java', 'CopySortOrderFields.java', 'Partitioning.java', 'TestSortOrder.java', 'Spark3Util.java']"
"Core: Support dynamically loaded Catalog implementations (#1640)

Co-authored-by: Jack Ye <yzhaoqin@amazon.com>",7,388,2020-11-04 14:24:22-08:00,"['Catalog.java', 'CatalogProperties.java', 'CatalogUtil.java', 'TestCatalogUtil.java', 'CatalogLoader.java', 'FlinkCatalogFactory.java', 'SparkCatalog.java']"
Build: Add workflow to run RAT checks for PRs (#1721),1,28,2020-11-05 09:51:58-08:00,['license_check.yml']
"Core: Support dynamic FileIO implementation loading (#1618)

Co-authored-by: Jack Ye <yzhaoqin@amazon.com>",16,364,2020-11-05 14:51:59-08:00,"['FileIO.java', 'CatalogProperties.java', 'CatalogUtil.java', 'HadoopCatalog.java', 'HadoopTableOperations.java', 'HadoopTables.java', 'TestCatalogUtil.java', 'CatalogLoader.java', 'FlinkCatalogFactory.java', 'FlinkCatalogTestBase.java', 'TestCatalogTableLoader.java', 'TestFlinkHiveCatalog.java', 'TestFlinkInputFormatReaderDeletes.java', 'HiveCatalog.java', 'HiveTableOperations.java', 'SparkCatalog.java']"
Hotfix: Add checkout step to rat check action (#1729),1,1,2020-11-05 14:56:21-08:00,['license_check.yml']
Build: Run license check on pull_request event.,1,2,2020-11-05 16:35:35-08:00,['license_check.yml']
Docs: Add missing licenses and remove unnecessary javadoc file (#1731),4,85,2020-11-05 16:42:21-08:00,"['how-to-release.md', 'element-list', 'releases.md', 'trademarks.md']"
Core: Fix NPE in SnapshotManager.validateCurrentSnapshot (#1725),1,2,2020-11-05 17:02:10-08:00,['SnapshotManager.java']
"Core: Fix NullPointerException in ManifestReader (#1730)

This fixes a NullPointerException that is thrown by a ManifestReader for delete files when there is a query filter. The DeleteFileIndex projects all fields of a delete manifest, so it doesn't call select to select specific columns, unlike ManifestGroup, which selects * by default. When select is not called, methods that check whether to add stats columns fail, but only if there is a row filter because stats columns are not needed if there is no row filter.

Existing tests either called select to configure the reader, or didn't pass a row filter and projected all rows. This adds a test that uses DeleteFileIndex and a test for ManifestReader. This also fixes dropStats in addition to requireStatsProjection.

Co-authored-by:  <zhongbaoluo@shxgroup.net>",3,68,2020-11-05 17:48:18-08:00,"['ManifestReader.java', 'TestManifestReader.java', 'TestSparkReaderDeletes.java']"
Build: Add Python tox action (#1733),3,141,2020-11-06 09:55:35-08:00,"['python-ci.yml', '.travis.yml', 'tox.ini']"
Build: Add Java CI action (#1732),1,41,2020-11-06 09:55:51-08:00,['java-ci.yml']
API: Fix Expressions.notNull operation (#1722),1,2,2020-11-06 12:12:45-08:00,['Expressions.java']
Parquet: Fix vectorized reads for negative decimals (#1736),6,275,2020-11-06 13:21:30-08:00,"['RandomUtil.java', 'VectorizedArrowReader.java', 'VectorizedColumnIterator.java', 'VectorizedDictionaryEncodedParquetValuesReader.java', 'VectorizedPageIterator.java', 'VectorizedParquetDefinitionLevelReader.java']"
Spark: Add Spark3 extensions module (#1728),14,929,2020-11-06 14:43:16-08:00,"['labeler.yml', 'LICENSE', 'baseline.gradle', 'build.gradle', 'scalastyle_config.xml', 'settings.gradle', 'IcebergSqlExtensions.g4', 'IcebergSparkSessionExtensions.scala', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'statements.scala', 'ExtendedDataSourceV2Strategy.scala', 'TestCallStatementParser.java', 'versions.props']"
"Docs: Add docs for dynamic class loading (#1737)

Co-authored-by: Jack Ye <yzhaoqin@amazon.com>",4,165,2020-11-06 15:28:22-08:00,"['configuration.md', 'custom-catalog.md', 'flink.md', 'spark.md']"
AWS: Add AWS subproject and initial S3FileIO implementation (#1573),15,1077,2020-11-07 14:40:17-08:00,"['LICENSE', 'BaseS3File.java', 'S3FileIO.java', 'S3InputFile.java', 'S3InputStream.java', 'S3OutputFile.java', 'S3OutputStream.java', 'S3URI.java', 'S3FileIOTest.java', 'S3InputStreamTest.java', 'S3OutputStreamTest.java', 'S3URITest.java', 'build.gradle', 'settings.gradle', 'versions.props']"
Parquet: Avoid extra footer read when position column is not needed (#1716),1,13,2020-11-07 14:46:28-08:00,['ReadConf.java']
"Docs: Update Presto documentation link (#1745)

Current and relatively complete documentation for the Iceberg Presto
connector was added to Presto in July.  This PR removes the pointer
to the obsolete Presto README.md file, and changes the link to point
to the Iceberg Presto connector documentation.",1,2,2020-11-09 15:38:22-08:00,['presto.md']
Arrow: Bump to Apache Arrow 2.0 (#1657),1,4,2020-11-09 16:06:21-08:00,['versions.props']
Core: Add position in manifest to DataFile and DeleteFile (#1723),10,87,2020-11-10 13:36:13-08:00,"['ContentFile.java', 'TestHelpers.java', 'BaseFile.java', 'ManifestReader.java', 'V1Metadata.java', 'V2Metadata.java', 'GenericAvroReader.java', 'ValueReaders.java', 'TestManifestReader.java', 'SparkDataFile.java']"
Hive: Fix casting bugs in Tez joins (#1740),7,125,2020-11-10 16:40:17-08:00,"['IcebergDateObjectInspectorHive3.java', 'IcebergTimestampObjectInspectorHive3.java', 'IcebergBinaryObjectInspector.java', 'IcebergDateObjectInspector.java', 'IcebergDecimalObjectInspector.java', 'IcebergTimestampObjectInspector.java', 'HiveIcebergStorageHandlerBaseTest.java']"
"fix bugs around using s3FileIO for table operations (#1749)

Co-authored-by: Jack Ye <yzhaoqin@amazon.com>",7,75,2020-11-11 08:36:00-08:00,"['AwsClientUtil.java', 'S3FileIO.java', 'S3OutputStream.java', 'S3OutputStreamTest.java', 'S3URITest.java', 'build.gradle', 'versions.props']"
Build: Add in an AWS label (#1752),1,2,2020-11-11 10:37:48-08:00,['labeler.yml']
Spark: Add stored procedure API and CALL syntax (#1743),12,461,2020-11-11 10:52:26-08:00,"['LICENSE', 'scalastyle_config.xml', 'IcebergSparkSessionExtensions.scala', 'ResolveProcedures.scala', 'Call.scala', 'CallExec.scala', 'ExtendedDataSourceV2Strategy.scala', 'NoSuchProcedureException.java', 'Procedure.java', 'ProcedureCatalog.java', 'ProcedureParameter.java', 'ProcedureParameterImpl.java']"
"Hive: Set format classes in HMS storage descriptor (#1751)

Some engines (e.g. Impala) depend on the Input/Output format classes
being set in the HMS storage descriptor.",2,10,2020-11-11 13:48:27-08:00,"['HiveTableOperations.java', 'HiveTableTest.java']"
"Docs: Link directly to Presto connector doc (#1753)

At @blue's suggestion, this PR changes stie/mkdocs.yml to link directly
to the Presto connector documentation.  On @electrum's advice,  it leaves
docs/presto.md in place, in case folks link to it directly.",1,2,2020-11-11 13:49:21-08:00,['mkdocs.yml']
"Flink:  Refactor the maxParallelism method to chain methods in RewriteDataFilesAction (#1741)

Co-authored-by: zhangjun <jun.zhang1@ly.com>",1,3,2020-11-12 10:25:01+08:00,['RewriteDataFilesAction.java']
"Core: Add NaN counts to Metrics, implement in Parquet (#1641)",17,1007,2020-11-12 11:36:32-08:00,"['FieldMetrics.java', 'Metrics.java', 'TestMetrics.java', 'TestMergingMetrics.java', 'TestOrcMetrics.java', 'TestParquetMergingMetrics.java', 'TestParquetMetrics.java', 'TestFlinkMergingMetrics.java', 'ParquetFieldMetrics.java', 'ParquetUtil.java', 'ParquetValueWriter.java', 'ParquetValueWriters.java', 'ParquetWriteAdapter.java', 'ParquetWriter.java', 'SparkTableUtil.java', 'StructInternalRow.java', 'TestSparkParquetMergingMetrics.java']"
Spark: Move custom connector classes to avoid conflicts (#1758),7,17,2020-11-12 12:53:59-08:00,"['ResolveProcedures.scala', 'Call.scala', 'CallExec.scala', 'Procedure.java', 'ProcedureCatalog.java', 'ProcedureParameter.java', 'ProcedureParameterImpl.java']"
Build: Ignore generated-src directory in errorprone (#1760),1,4,2020-11-12 17:34:59-08:00,['baseline.gradle']
"Flink: add clean for TestFlinkCatalogTable (#1705)

Co-authored-by: zhangjun <jun.zhang1@ly.com>",1,1,2020-11-13 10:16:23+08:00,['TestFlinkCatalogTable.java']
Spark: Add RollbackToSnapshotProcedure (#1759),9,657,2020-11-13 10:59:04-08:00,"['SparkTestBase.java', 'SparkExtensionsTestBase.java', 'TestRollbackToSnapshotProcedure.java', 'BaseCatalog.java', 'SparkCatalog.java', 'SparkSessionCatalog.java', 'BaseProcedure.java', 'RollbackToSnapshotProcedure.java', 'SparkProcedures.java']"
Spark: Add CherrypickSnapshotProcedure (#1771),3,284,2020-11-13 15:55:36-08:00,"['TestCherrypickSnapshotProcedure.java', 'CherrypickSnapshotProcedure.java', 'SparkProcedures.java']"
Spark: Add SetCurrentSnapshotProcedure (#1770),3,325,2020-11-13 17:06:15-08:00,"['TestSetCurrentSnapshotProcedure.java', 'SetCurrentSnapshotProcedure.java', 'SparkProcedures.java']"
Spark: Add RollbackToTimestampProcedure (#1769),4,391,2020-11-13 17:49:51-08:00,"['SparkTestBase.java', 'TestRollbackToTimestampProcedure.java', 'RollbackToTimestampProcedure.java', 'SparkProcedures.java']"
Spark: Skip DELETE if the condition is false (#1772),2,31,2020-11-16 10:53:26-08:00,"['SparkTable.java', 'TestDeleteFrom.java']"
"Core: Fix decimal scale issue in predicate literals (#1742)

Co-authored-by: Marton Bod <mbod@cloudera.com>",5,79,2020-11-16 12:43:33-08:00,"['Literals.java', 'TestMiscLiteralConversions.java', 'TestNumericLiteralConversions.java', 'TestStringLiteralConversions.java', 'HiveIcebergStorageHandlerBaseTest.java']"
support Server Side Encryption for S3FileIO (#1754),11,520,2020-11-16 13:17:17-08:00,"['AwsIntegTestUtil.java', 'S3FileIOTest.java', 'AwsClientUtil.java', 'AwsProperties.java', 'BaseS3File.java', 'S3FileIO.java', 'S3InputFile.java', 'S3InputStream.java', 'S3OutputFile.java', 'S3OutputStream.java', 'build.gradle']"
Docs: Update for the 0.10.0 release (#1777),717,253036,2020-11-16 16:04:28-08:00,"['getting-started.md', 'allclasses-frame.html', 'allclasses-noframe.html', 'constant-values.html', 'deprecated-list.html', 'help-doc.html', 'index-all.html', 'index.html', 'Accessor.html', 'Accessors.html', 'AllDataFilesTable.AllDataFilesTableScan.html', 'AllDataFilesTable.html', 'AllEntriesTable.html', 'AllManifestsTable.AllManifestsTableScan.html', 'AllManifestsTable.html', 'AppendFiles.html', 'BaseCombinedScanTask.html', 'BaseMetastoreCatalog.BaseMetastoreCatalogTableBuilder.html', 'BaseMetastoreCatalog.html', 'BaseMetastoreTableOperations.html', 'BaseOverwriteFiles.html', 'BaseReplacePartitions.html', 'BaseRewriteManifests.html', 'BaseTable.html', 'CachingCatalog.html', 'CatalogUtil.html', 'CombinedScanTask.html', 'ContentFile.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DataFilesTable.FilesTableScan.html', 'DataFilesTable.html', 'DataOperations.html', 'DataTableScan.html', 'DataTask.html', 'DeleteFile.html', 'DeleteFiles.html', 'ExpireSnapshots.html', 'FileContent.html', 'FileFormat.html', 'FileMetadata.Builder.html', 'FileMetadata.html', 'FileScanTask.html', 'Files.html', 'FindFiles.Builder.html', 'FindFiles.html', 'GenericManifestFile.CopyBuilder.html', 'GenericManifestFile.html', 'GenericPartitionFieldSummary.html', 'GuavaClasses.html', 'HasTableOperations.html', 'HistoryEntry.html', 'HistoryTable.html', 'LocationProviders.html', 'ManageSnapshots.html', 'ManifestContent.html', 'ManifestEntriesTable.html', 'ManifestFile.PartitionFieldSummary.html', 'ManifestFile.html', 'ManifestFiles.html', 'ManifestReader.FileType.html', 'ManifestReader.html', 'ManifestWriter.html', 'ManifestsTable.html', 'MetadataColumns.html', 'MetadataTableType.html', 'MetadataTableUtils.html', 'Metrics.html', 'MetricsConfig.html', 'MetricsModes.Counts.html', 'MetricsModes.Full.html', 'MetricsModes.MetricsMode.html', 'MetricsModes.None.html', 'MetricsModes.Truncate.html', 'MetricsModes.html', 'MicroBatches.MicroBatch.html', 'MicroBatches.MicroBatchBuilder.html', 'MicroBatches.html', 'NullOrder.html', 'OverwriteFiles.html', 'PartitionField.html', 'PartitionKey.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'PartitionsTable.html', 'PendingUpdate.html', 'ReplacePartitions.html', 'RewriteFiles.html', 'RewriteManifests.html', 'Rollback.html', 'RowDelta.html', 'ScanSummary.Builder.html', 'ScanSummary.PartitionMetrics.html', 'ScanSummary.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'SetLocation.html', 'Snapshot.html', 'SnapshotManager.html', 'SnapshotParser.html', 'SnapshotSummary.Builder.html', 'SnapshotSummary.html', 'SnapshotUpdate.html', 'SnapshotsTable.html', 'SortDirection.html', 'SortField.html', 'SortOrder.Builder.html', 'SortOrder.html', 'SortOrderParser.html', 'StaticTableOperations.html', 'StructLike.html', 'SystemProperties.html', 'Table.html', 'TableMetadata.MetadataLogEntry.html', 'TableMetadata.SnapshotLogEntry.html', 'TableMetadata.html', 'TableMetadataParser.Codec.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableProperties.html', 'TableScan.html', 'Tables.html', 'Transaction.html', 'Transactions.html', 'UpdateLocation.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Action.html', 'Actions.html', 'BaseRewriteDataFilesAction.html', 'ExpireSnapshotsAction.html', 'ExpireSnapshotsActionResult.html', 'ManifestFileBean.html', 'RemoveOrphanFilesAction.html', 'RewriteDataFilesAction.html', 'RewriteDataFilesActionResult.html', 'RewriteManifestsAction.html', 'RewriteManifestsActionResult.html', 'SnapshotUpdateAction.html', 'SparkActions.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ArrowAllocation.html', 'ArrowSchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'NullabilityHolder.html', 'VectorHolder.ConstantVectorHolder.html', 'VectorHolder.html', 'VectorizedArrowReader.ConstantVectorReader.html', 'VectorizedArrowReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseVectorizedParquetValuesReader.html', 'VectorizedColumnIterator.html', 'VectorizedDictionaryEncodedParquetValuesReader.html', 'VectorizedPageIterator.html', 'VectorizedParquetDefinitionLevelReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Avro.DeleteWriteBuilder.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroEncoderUtil.html', 'AvroIterable.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'AvroSchemaWithTypeVisitor.html', 'AvroWithPartnerByStructureVisitor.html', 'LogicalMap.html', 'ProjectionDatumReader.html', 'RemoveIds.html', 'SupportsRowPosition.html', 'UUIDConversion.html', 'ValueReader.html', 'ValueReaders.StructReader.html', 'ValueReaders.html', 'ValueWriter.html', 'ValueWriters.StructWriter.html', 'ValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Catalog.TableBuilder.html', 'Catalog.html', 'Namespace.html', 'SupportsNamespaces.html', 'TableIdentifier.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DeleteFilter.html', 'GenericAppenderFactory.html', 'GenericDeleteFilter.html', 'GenericRecord.html', 'IcebergGenerics.ScanBuilder.html', 'IcebergGenerics.html', 'IdentityPartitionConverters.html', 'InternalRecordWrapper.html', 'Record.html', 'DataReader.html', 'DataWriter.html', 'DecoderResolver.html', 'IcebergDecoder.html', 'IcebergEncoder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericOrcReader.html', 'GenericOrcReaders.html', 'GenericOrcWriter.html', 'GenericOrcWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseParquetReaders.html', 'BaseParquetWriter.html', 'GenericParquetReaders.html', 'GenericParquetWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Deletes.html', 'EqualityDeleteWriter.html', 'PositionDelete.html', 'PositionDeleteWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'EncryptedFiles.html', 'EncryptedInputFile.html', 'EncryptedOutputFile.html', 'EncryptionKeyMetadata.html', 'EncryptionKeyMetadatas.html', 'EncryptionManager.html', 'PlaintextEncryptionManager.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CreateSnapshotEvent.html', 'Listener.html', 'Listeners.html', 'ScanEvent.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CherrypickAncestorCommitException.html', 'CommitFailedException.html', 'DuplicateWAPCommitException.html', 'NamespaceNotEmptyException.html', 'NoSuchIcebergTableException.html', 'NoSuchNamespaceException.html', 'NoSuchTableException.html', 'NotFoundException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'Bound.html', 'BoundLiteralPredicate.html', 'BoundPredicate.html', 'BoundReference.html', 'BoundSetPredicate.html', 'BoundTerm.html', 'BoundTransform.html', 'BoundUnaryPredicate.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.BoundVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'InclusiveMetricsEvaluator.html', 'Literal.html', 'ManifestEvaluator.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'StrictMetricsEvaluator.html', 'Term.html', 'True.html', 'Unbound.html', 'UnboundPredicate.html', 'UnboundTerm.html', 'UnboundTransform.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CatalogLoader.HadoopCatalogLoader.html', 'CatalogLoader.HiveCatalogLoader.html', 'CatalogLoader.html', 'FlinkCatalog.html', 'FlinkCatalogFactory.html', 'FlinkSchemaUtil.html', 'FlinkTableFactory.html', 'FlinkTypeVisitor.html', 'IcebergTableSink.html', 'IcebergTableSource.html', 'RowDataWrapper.html', 'TableLoader.CatalogTableLoader.html', 'TableLoader.HadoopTableLoader.html', 'TableLoader.html', 'AvroWithFlinkSchemaVisitor.html', 'FlinkAvroReader.html', 'FlinkAvroWriter.html', 'FlinkOrcReader.html', 'FlinkOrcWriter.html', 'FlinkParquetReaders.html', 'FlinkParquetWriters.html', 'FlinkValueReaders.html', 'FlinkValueWriters.html', 'ParquetWithFlinkSchemaVisitor.html', 'RowDataUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'FlinkSink.Builder.html', 'FlinkSink.html', 'RowDataTaskWriterFactory.FlinkFileAppenderFactory.html', 'RowDataTaskWriterFactory.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'FlinkInputFormat.html', 'FlinkInputSplit.html', 'FlinkSource.Builder.html', 'FlinkSource.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ConfigProperties.html', 'HadoopCatalog.html', 'HadoopFileIO.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTableOperations.html', 'HadoopTables.html', 'HiddenPathFilter.html', 'SerializableConfiguration.html', 'Util.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ClientPool.Action.html', 'ClientPool.html', 'HiveCatalog.html', 'HiveCatalogs.html', 'HiveClientPool.html', 'HiveTableOperations.html', 'HiveTypeConverter.html', 'MetastoreUtil.html', 'RuntimeMetaException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseTaskWriter.RollingFileWriter.html', 'BaseTaskWriter.html', 'CloseableGroup.html', 'CloseableIterable.ConcatCloseableIterable.html', 'CloseableIterable.html', 'CloseableIterator.html', 'ClosingIterator.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'FileAppender.html', 'FileAppenderFactory.html', 'FileIO.html', 'FilterIterator.html', 'InputFile.html', 'LocationProvider.html', 'OutputFile.html', 'OutputFileFactory.html', 'PartitionedWriter.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'TaskWriter.html', 'UnpartitionedWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'MappedField.html', 'MappedFields.html', 'MappingUtil.html', 'NameMapping.html', 'NameMappingParser.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CatalogLoader.html', 'Catalogs.html', 'InputFormatConfig.ConfigBuilder.html', 'InputFormatConfig.InMemoryDataModel.html', 'InputFormatConfig.html', 'SerializationUtil.html', 'HiveIcebergFilterFactory.html', 'HiveIcebergInputFormat.html', 'HiveIcebergMetaHook.html', 'HiveIcebergOutputFormat.html', 'HiveIcebergSerDe.html', 'HiveIcebergSplit.html', 'HiveIcebergStorageHandler.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergBinaryObjectInspector.html', 'IcebergDateObjectInspector.html', 'IcebergDateObjectInspectorHive3.html', 'IcebergDecimalObjectInspector.html', 'IcebergObjectInspector.html', 'IcebergRecordObjectInspector.html', 'IcebergTimestampObjectInspector.html', 'IcebergTimestampObjectInspectorHive3.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Container.html', 'MapredIcebergInputFormat.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergInputFormat.html', 'IcebergSplit.html', 'IcebergSplitContainer.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ORC.ReadBuilder.html', 'ORC.WriteBuilder.html', 'ORC.html', 'ORCSchemaUtil.BinaryType.html', 'ORCSchemaUtil.LongType.html', 'ORCSchemaUtil.html', 'OrcBatchReader.html', 'OrcMetrics.html', 'OrcRowReader.html', 'OrcRowWriter.html', 'OrcSchemaVisitor.html', 'OrcSchemaWithTypeVisitor.html', 'OrcValueReader.html', 'OrcValueReaders.StructReader.html', 'OrcValueReaders.html', 'OrcValueWriter.html', 'VectorizedRowBatchIterator.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseColumnIterator.html', 'BasePageIterator.IntIterator.html', 'BasePageIterator.html', 'ColumnIterator.html', 'ColumnWriter.html', 'Parquet.DeleteWriteBuilder.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetAvroReader.html', 'ParquetAvroValueReaders.TimeMillisReader.html', 'ParquetAvroValueReaders.TimestampMillisReader.html', 'ParquetAvroValueReaders.html', 'ParquetAvroWriter.html', 'ParquetDictionaryRowGroupFilter.html', 'ParquetIterable.html', 'ParquetMetricsRowGroupFilter.html', 'ParquetReader.html', 'ParquetSchemaUtil.HasIds.html', 'ParquetSchemaUtil.html', 'ParquetTypeVisitor.html', 'ParquetUtil.html', 'ParquetValueReader.html', 'ParquetValueReaders.BinaryAsDecimalReader.html', 'ParquetValueReaders.ByteArrayReader.html', 'ParquetValueReaders.BytesReader.html', 'ParquetValueReaders.FloatAsDoubleReader.html', 'ParquetValueReaders.IntAsLongReader.html', 'ParquetValueReaders.IntegerAsDecimalReader.html', 'ParquetValueReaders.ListReader.html', 'ParquetValueReaders.LongAsDecimalReader.html', 'ParquetValueReaders.MapReader.html', 'ParquetValueReaders.PrimitiveReader.html', 'ParquetValueReaders.RepeatedKeyValueReader.html', 'ParquetValueReaders.RepeatedReader.html', 'ParquetValueReaders.ReusableEntry.html', 'ParquetValueReaders.StringReader.html', 'ParquetValueReaders.StructReader.html', 'ParquetValueReaders.UnboxedReader.html', 'ParquetValueReaders.html', 'ParquetValueWriter.html', 'ParquetValueWriters.PositionDeleteStructWriter.html', 'ParquetValueWriters.PrimitiveWriter.html', 'ParquetValueWriters.RepeatedKeyValueWriter.html', 'ParquetValueWriters.RepeatedWriter.html', 'ParquetValueWriters.StructWriter.html', 'ParquetValueWriters.html', 'ParquetWriteAdapter.html', 'RemoveIds.html', 'TripleWriter.html', 'TypeToMessageType.html', 'TypeWithSchemaVisitor.html', 'ValuesAsBytesReader.html', 'VectorizedParquetReader.html', 'VectorizedReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergPigInputFormat.IcebergRecordReader.html', 'IcebergPigInputFormat.html', 'IcebergStorage.html', 'PigParquetReader.html', 'SchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'SchemaWithPartnerVisitor.PartnerAccessors.html', 'SchemaWithPartnerVisitor.html', 'UnionByNameVisitor.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSpark.html', 'PruneColumnsWithReordering.html', 'PruneColumnsWithoutReordering.html', 'RollbackStagedTable.html', 'Spark3Util.DescribeSchemaVisitor.html', 'Spark3Util.html', 'SparkCatalog.html', 'SparkDataFile.html', 'SparkExceptionUtil.html', 'SparkFilters.html', 'SparkSchemaUtil.html', 'SparkSessionCatalog.html', 'SparkStructLike.html', 'SparkTableUtil.SparkPartition.html', 'SparkTableUtil.html', 'SparkUtil.html', 'SparkValueConverter.html', 'AvroWithSparkSchemaVisitor.html', 'ParquetWithSparkSchemaVisitor.html', 'SparkAvroReader.html', 'SparkAvroWriter.html', 'SparkOrcReader.html', 'SparkOrcValueReaders.html', 'SparkOrcWriter.html', 'SparkParquetReaders.html', 'SparkParquetWriters.html', 'SparkValueReaders.html', 'SparkValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ArrowVectorAccessor.html', 'ArrowVectorAccessors.html', 'ColumnarBatchReader.html', 'IcebergArrowColumnVector.html', 'RowPostitionColumnVector.html', 'VectorizedSparkOrcReaders.html', 'VectorizedSparkParquetReaders.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSource.html', 'RowDataRewriter.html', 'SparkPartitionedWriter.html', 'SparkScanBuilder.html', 'SparkStreamingWrite.html', 'SparkTable.html', 'StagedSparkTable.html', 'Stats.html', 'StreamingWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PartitionSpecVisitor.html', 'Transform.html', 'Transforms.html', 'UnknownTransform.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CheckCompatibility.html', 'Comparators.html', 'Conversions.html', 'FixupTypes.html', 'IndexByName.html', 'IndexParents.html', 'JavaHash.html', 'JavaHashes.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ArrayUtil.html', 'BinPacking.ListPacker.html', 'BinPacking.PackingIterable.html', 'BinPacking.html', 'BinaryUtil.html', 'ByteBuffers.html', 'CharSequenceSet.html', 'CharSequenceWrapper.html', 'DateTimeUtil.html', 'DecimalUtil.html', 'ExceptionUtil.html', 'Exceptions.html', 'Filter.html', 'JsonUtil.html', 'ManifestFileUtil.html', 'Pair.html', 'ParallelIterable.html', 'PartitionSet.html', 'PartitionUtil.html', 'PropertyUtil.html', 'SerializableSupplier.html', 'SnapshotUtil.html', 'SortedMerge.html', 'StructLikeSet.html', 'StructLikeWrapper.html', 'StructProjection.html', 'TableScanUtil.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'ThreadPools.html', 'UUIDUtil.html', 'UnicodeUtil.html', 'WapUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'overview-frame.html', 'overview-summary.html', 'overview-tree.html', 'package-list', 'script.js', 'serialized-form.html', 'stylesheet.css', 'index.html', 'releases.md', 'mkdocs.yml']"
Spark: Refactor Spark writes into separate classes (#1776),3,434,2020-11-17 08:35:55-08:00,"['SparkStreamingWrite.java', 'SparkWrite.java', 'SparkWriteBuilder.java']"
Core: Publish incremental scan event during planning (#1720),3,95,2020-11-17 17:32:14-08:00,"['IncrementalScanEvent.java', 'IncrementalDataTableScan.java', 'TestIncrementalDataTableScan.java']"
"Hive: Improve log settings in unit tests (#1712)

Co-authored-by: Marton Bod <mbod@cloudera.com>",3,77,2020-11-17 17:34:00-08:00,"['log4j2.properties', 'HiveIcebergStorageHandlerBaseTest.java', 'log4j.properties']"
Spark: Make actions compatible with V2 catalogs (#1715),5,227,2020-11-18 11:12:48-08:00,"['checkstyle.xml', 'BaseSparkAction.java', 'RewriteManifestsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction3.java']"
Core: Fix invalidation of metadata tables in CachingCatalog (#1785),2,75,2020-11-18 15:51:59-08:00,"['CachingCatalog.java', 'TestCachingCatalog.java']"
Flink: Refactor SimpleDataUtil#assertTableRecords (#1765),1,4,2020-11-19 21:40:40+08:00,['SimpleDataUtil.java']
AWS: Add Glue catalog and table operations (#1633),14,1894,2020-11-19 10:23:35-08:00,"['AwsIntegTestUtil.java', 'GlueCatalogNamespaceTest.java', 'GlueCatalogTableTest.java', 'GlueTestBase.java', 'AwsClientUtil.java', 'AwsProperties.java', 'GlueCatalog.java', 'GlueTableOperations.java', 'GlueToIcebergConverter.java', 'IcebergToGlueConverter.java', 'GlueCatalogTest.java', 'GlueToIcebergConverterTest.java', 'IcebergToGlueConverterTest.java', 'build.gradle']"
Docs: Update Hive read docs for HiveCatalog (#1748),1,34,2020-11-19 17:10:36-08:00,['hive.md']
Build: Add logs to the CI output (#1789),2,23,2020-11-20 11:56:32-08:00,"['java-ci.yml', 'build.gradle']"
Core: Add table property to disable garbage collection (#1796),7,89,2020-11-20 13:13:31-08:00,"['RemoveSnapshots.java', 'TableProperties.java', 'TestRemoveSnapshots.java', 'ExpireSnapshotsAction.java', 'RemoveOrphanFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java']"
Spark: Add SparkMergeScan (#1782),4,515,2020-11-20 14:37:57-08:00,"['SparkBatchQueryScan.java', 'SparkBatchScan.java', 'SparkMergeScan.java', 'SparkScanBuilder.java']"
Spark: Fix key error with duplicate data files (#1798),2,17,2020-11-20 14:55:58-08:00,"['DataIterator.java', 'BaseDataReader.java']"
Spark: Fix resolution of metadata tables in actions (#1784),3,224,2020-11-20 15:02:06-08:00,"['BaseSparkAction.java', 'Spark3Util.java', 'TestRemoveOrphanFilesAction3.java']"
AWS: Fix errorprone warnings in S3URI (#1787),1,14,2020-11-20 15:21:23-08:00,['S3URI.java']
"AWS: Add progressive multipart upload to S3FileIO (#1767)

* AWS: Add progressive multipart upload to S3FileIO

* Fix test after rebase

* Simply the complete and ensure parts are in order

* Add sort to stream

* Checkstyle

* Add abort attempt back to complete

* Initialize only once

* Add executor service for async tasks per errorprone

* Address comments

* Refactor setting encryption for requests

* Fix defaults to no-arg AwsProperties

* Address some failure cases and add more testing

* Checkstyle",8,633,2020-11-21 10:01:26-08:00,"['AwsProperties.java', 'S3FileIO.java', 'S3InputStream.java', 'S3OutputStream.java', 'S3RequestUtil.java', 'S3OutputStreamTest.java', 'GuavaClasses.java', 'PropertyUtil.java']"
"Docs: fix typo in flink.md (#1807)

Co-authored-by: Xi Chen <chenxi07@qiyi.com>",1,2,2020-11-23 21:45:14+08:00,['flink.md']
Nessie: Add Nessie catalog module (#1587),13,1623,2020-11-23 10:36:03-08:00,"['build.gradle', 'NessieCatalog.java', 'NessieTableOperations.java', 'NessieUtil.java', 'TableReference.java', 'UpdateableReference.java', 'BaseTestIceberg.java', 'TestBranchVisibility.java', 'TestNamespace.java', 'TestNessieTable.java', 'TestTableReference.java', 'settings.gradle', 'versions.props']"
"Hive: Add nested schema tests for map, list, and struct (#1607)",1,264,2020-11-23 11:03:36-08:00,['HiveIcebergStorageHandlerBaseTest.java']
Spark: Add connector APIs for merge-based operations (#1799),4,162,2020-11-23 13:03:30-08:00,"['ExtendedSupportsDelete.java', 'SupportsMerge.java', 'SupportsFileFilter.java', 'MergeBuilder.java']"
Docs: Fix some spelling/grammar issues in Hive (#1806),1,2,2020-11-23 13:04:29-08:00,['hive.md']
Core: Fix StructLikeSet.remove and extend AbstractSet (#1792),1,5,2020-11-23 13:15:15-08:00,['StructLikeSet.java']
"Hive: Save schema to table props to avoid HMS calls (#1794)

Co-authored-by: Marton Bod <mbod@cloudera.com>",1,7,2020-11-23 13:15:48-08:00,['HiveIcebergStorageHandler.java']
Spark: Fix optional arg validation in procedures (#1809),2,10,2020-11-23 15:25:08-08:00,"['ResolveProcedures.scala', 'ProcedureParameterImpl.java']"
Spark: Add newInternalRow to BaseProcedure (#1810),5,34,2020-11-23 15:37:46-08:00,"['BaseProcedure.java', 'CherrypickSnapshotProcedure.java', 'RollbackToSnapshotProcedure.java', 'RollbackToTimestampProcedure.java', 'SetCurrentSnapshotProcedure.java']"
Spark: Add RewriteManifestsProcedure (#1801),3,259,2020-11-23 16:29:38-08:00,"['TestRewriteManifestsProcedure.java', 'RewriteManifestsProcedure.java', 'SparkProcedures.java']"
AWS: centralize logic for setting encryption info (#1786),3,227,2020-11-23 17:42:26-08:00,"['BaseS3File.java', 'S3RequestUtil.java', 'S3RequestUtilTest.java']"
"AWS: add ACL support for S3FileIO (#1788)

+1  Thanks @jackye1995 !",5,131,2020-11-24 08:43:57-08:00,"['S3FileIOTest.java', 'AwsProperties.java', 'S3OutputStream.java', 'S3RequestUtil.java', 'AwsPropertiesTest.java']"
Spark: Add Javadoc for stored procedure API (#1813),11,118,2020-11-24 16:47:12-08:00,"['IcebergSqlExtensionsAstBuilder.scala', 'statements.scala', 'CherrypickSnapshotProcedure.java', 'RewriteManifestsProcedure.java', 'RollbackToSnapshotProcedure.java', 'RollbackToTimestampProcedure.java', 'SetCurrentSnapshotProcedure.java', 'Procedure.java', 'ProcedureCatalog.java', 'ProcedureParameter.java', 'ProcedureParameterImpl.java']"
Core: Add NaN value count to content file (#1803),19,331,2020-11-24 17:06:17-08:00,"['ContentFile.java', 'DataFile.java', 'TestHelpers.java', 'BaseFile.java', 'DataFiles.java', 'DataTableScan.java', 'FileMetadata.java', 'GenericDataFile.java', 'GenericDeleteFile.java', 'ManifestReader.java', 'MetricsModes.java', 'V1Metadata.java', 'V2Metadata.java', 'TestManifestReaderStats.java', 'TestManifestWriterVersions.java', 'TestMetrics.java', 'SparkDataFile.java', 'TestDataFileSerialization.java', 'TestSparkDataFile.java']"
Spark: Make refresh of Spark cache optional in procedures (#1811),1,13,2020-11-24 17:14:23-08:00,['BaseProcedure.java']
README: Fix links to java-api-quickstart (#1827),1,2,2020-11-25 08:42:10-08:00,['README.md']
"ORC: Allow reads of tinyint, smallint, char, varchar types (#1821)",2,61,2020-11-25 09:42:48-08:00,"['TestGenericData.java', 'ORCSchemaUtil.java']"
Python: Fix missing assert in test case (#1828),1,6,2020-11-25 13:31:16-08:00,['test_inclusive_manifest_evaluator.py']
Hive: Using Hive schema to create tables (#1612),9,820,2020-11-25 16:34:04-08:00,"['HadoopCatalog.java', 'HiveIcebergMetaHook.java', 'HiveIcebergSerDe.java', 'HiveSchemaConverter.java', 'HiveSchemaUtil.java', 'HiveIcebergStorageHandlerBaseTest.java', 'TestHiveIcebergStorageHandlerWithHadoopTables.java', 'TestHiveSchemaUtil.java', 'TestTables.java']"
Spark: Add partition fanout writer (#1774),9,286,2020-11-26 19:22:43+08:00,"['TableProperties.java', 'PartitionedFanoutWriter.java', 'RowDataTaskWriterFactory.java', 'configuration.md', 'RowDataRewriter.java', 'SparkPartitionedFanoutWriter.java', 'TestSparkDataWrite.java', 'Writer.java', 'SparkWrite.java']"
Flink : Implement the listPartitions method in FlinkCatalog (#1815),4,158,2020-11-26 20:29:48+08:00,"['FlinkCatalog.java', 'FlinkCatalogFactory.java', 'FlinkCatalogTestBase.java', 'TestFlinkCatalogTablePartitions.java']"
"Hive: Add column projection (#1417)

Co-authored-by: Adrian Woodhead <awoodhead@expediagroup.com>
Co-authored-by: awoodhead <awoodhead@expediagroup.com>
Co-authored-by: Marton Bod <marton.bod@gmail.com>
Co-authored-by: Marton Bod <mbod@cloudera.com>",5,174,2020-11-26 08:11:53-08:00,"['InputFormatConfig.java', 'HiveIcebergInputFormat.java', 'HiveIcebergSerDe.java', 'IcebergInputFormat.java', 'HiveIcebergStorageHandlerBaseTest.java']"
Core: Remove deprecated BaseMetastoreCatalog.dropTableData (#1841),1,91,2020-11-27 09:45:50-08:00,['BaseMetastoreCatalog.java']
Hive: Flaky test testScanTable (#1817) (#1824),1,4,2020-11-30 11:53:00-08:00,['TestHiveShell.java']
Build: Add nessie label (#1851),1,3,2020-11-30 11:53:49-08:00,['labeler.yml']
Avro: Support imported Avro timestamps without adjust-to-utc (#1848),3,23,2020-11-30 13:06:55-08:00,"['AvroSchemaUtil.java', 'SchemaToType.java', 'TestSchemaConversions.java']"
Docs: Add Hive docs for reading HadoopCatalog tables (#1837),1,37,2020-11-30 13:49:58-08:00,['hive.md']
Core: Add StructLikeMap (#1853),2,307,2020-12-01 11:08:21-08:00,"['StructLikeMap.java', 'TestStructLikeMap.java']"
Core: Add data and delete writers in FileAppenderFactory. (#1836),20,1290,2020-12-02 12:11:44+08:00,"['build.gradle', 'DataWriter.java', 'DeleteSchemaUtil.java', 'FileAppenderFactory.java', 'TableTestBase.java', 'GenericAppenderFactory.java', 'TestGenericAppenderFactory.java', 'TestAppenderFactory.java', 'FlinkAppenderFactory.java', 'RowDataTaskWriterFactory.java', 'SimpleDataUtil.java', 'TestFlinkAppenderFactory.java', 'TestFlinkMergingMetrics.java', 'Parquet.java', 'ParquetValueWriters.java', 'RowDataRewriter.java', 'SparkAppenderFactory.java', 'TestSparkAppenderFactory.java', 'Writer.java', 'SparkWrite.java']"
Docs:fix typos in api.md (#1859),1,10,2020-12-02 19:15:45+08:00,['api.md']
Spark: Add plans & rules for DELETE (#1852),12,558,2020-12-02 16:10:03+02:00,"['IcebergSparkSessionExtensions.scala', 'DeleteFromTablePredicateCheck.scala', 'OptimizeConditionsInRowLevelOperations.scala', 'PullupCorrelatedPredicatesInRowLevelOperations.scala', 'RewriteDelete.scala', 'DynamicFileFilter.scala', 'ReplaceData.scala', 'DynamicFileFilterExec.scala', 'ExtendedBatchScanExec.scala', 'ExtendedDataSourceV2Implicits.scala', 'ExtendedDataSourceV2Strategy.scala', 'ReplaceDataExec.scala']"
Spark: Fix resolution of procedures with expressions (#1860),7,81,2020-12-02 16:34:37-08:00,"['IcebergSparkSessionExtensions.scala', 'ProcedureArgumentCoercion.scala', 'ResolveProcedures.scala', 'TestCherrypickSnapshotProcedure.java', 'TestRollbackToSnapshotProcedure.java', 'TestRollbackToTimestampProcedure.java', 'TestSetCurrentSnapshotProcedure.java']"
"Spark: Improve extensions parser error messages (#1864)

Previously we would always delegate to the Spark parser, even when a
CALL request could not be parsed. This leads to confusing errors which
would state that ""CALL"" was not a good first token. This change has us
only using the custom parser for ""CALL"" commands and delegating for
everything else.",4,22,2020-12-02 16:35:47-08:00,"['IcebergSqlExtensions.g4', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'TestCallStatementParser.java']"
only list iceberg tables for HiveCatalog listTables method (#1835),2,51,2020-12-02 17:44:47-08:00,"['HiveCatalog.java', 'HiveTableTest.java']"
"AWS: support S3 strong consistency (#1863)

* AWS: support S3 strong consistency

* remove call to HEAD

* fix list wrong file with the same suffix

* check file exists when getting length",5,109,2020-12-03 08:48:39-08:00,"['S3FileIOTest.java', 'BaseS3File.java', 'S3InputFile.java', 'S3RequestUtil.java', 'S3FileIOTest.java']"
Core: Add table properties for default snapshot retention (#1868),4,124,2020-12-03 11:36:28-08:00,"['RemoveSnapshots.java', 'TableProperties.java', 'TestRemoveSnapshots.java', 'configuration.md']"
Spark: Add a flag to disable vectorized reads (#1778),2,18,2020-12-03 14:19:21-08:00,"['Reader.java', 'Spark3Util.java']"
"Spark: Add RemoveOrphanFilesProcedure (#1869)

Fixes #1599.

Lead-authored-by: Kun Liu <liukun@apache.org>
Co-authored-by: Anton Okolnychyi <aokolnychyi@apple.com>",4,386,2020-12-04 12:09:09+02:00,"['SparkExtensionsTestBase.java', 'TestRemoveOrphanFilesProcedure.java', 'RemoveOrphanFilesProcedure.java', 'SparkProcedures.java']"
Spark: Make procedure param resolution case insensitive (#1866),2,72,2020-12-04 09:11:11-08:00,"['ResolveProcedures.scala', 'TestRewriteManifestsProcedure.java']"
Spark: Implement copy-on-write DELETE (#1862),14,1267,2020-12-04 11:28:59-08:00,"['checkstyle.xml', 'IsolationLevel.java', 'TableProperties.java', 'RewriteDelete.scala', 'Employee.java', 'SparkRowLevelOperationsTestBase.java', 'TestCopyOnWriteDelete.java', 'TestDelete.java', 'SparkMergeBuilder.java', 'SparkMergeScan.java', 'SparkTable.java', 'SparkWrite.java', 'SparkWriteBuilder.java', 'SupportsMerge.java']"
Spark: Rename output columns in RewriteManifestsProcedure (#1876),1,4,2020-12-04 22:23:13+02:00,['RewriteManifestsProcedure.java']
Build: Increase gradle heap size (#1847),1,1,2020-12-04 13:05:11-08:00,['gradle.properties']
Spark: Add ExpireSnapshotsProcedure (#1874),3,293,2020-12-04 13:06:32-08:00,"['TestExpireSnapshotsProcedure.java', 'ExpireSnapshotsProcedure.java', 'SparkProcedures.java']"
Python: Add Parquet reads and Arrow schema conversion (#1727),19,1337,2020-12-04 16:19:04-08:00,"['expression.py', 'input_file.py', 'type.py', 'types.py', '__init__.py', 'profile.py', '__init__.py', 'exceptions.py', '__init__.py', 'dataset_utils.py', 'parquet_reader.py', 'parquet_schema_utils.py', 'parquet_to_iceberg.py', 'setup.py', '__init__.py', 'conftest.py', 'test_dataset_utils.py', 'test_parquet_reader.py', 'test_parquet_to_iceberg.py']"
Hive: Refactor HiveIcebergStorageHandler tests to use catalogs as parameters (#1840),6,494,2020-12-04 16:50:49-08:00,"['TestHiveIcebergStorageHandler.java', 'TestHiveIcebergStorageHandlerWithCustomCatalog.java', 'TestHiveIcebergStorageHandlerWithHadoopCatalog.java', 'TestHiveIcebergStorageHandlerWithHadoopTables.java', 'TestHiveIcebergStorageHandlerWithHiveCatalog.java', 'TestTables.java']"
Spark: Rename fanout configs (#1877),7,69,2020-12-05 14:43:15-08:00,"['TableProperties.java', 'configuration.md', 'SparkWriteOptions.java', 'RowDataRewriter.java', 'TestSparkDataWrite.java', 'Writer.java', 'SparkWrite.java']"
API: add isNaN and notNaN predicates (#1747),28,992,2020-12-05 17:14:27-08:00,"['BoundUnaryPredicate.java', 'Evaluator.java', 'Expression.java', 'ExpressionVisitors.java', 'Expressions.java', 'InclusiveMetricsEvaluator.java', 'ManifestEvaluator.java', 'ResidualEvaluator.java', 'StrictMetricsEvaluator.java', 'UnboundPredicate.java', 'NaNUtil.java', 'TestHelpers.java', 'TestEvaluator.java', 'TestExpressionHelpers.java', 'TestExpressionSerialization.java', 'TestInclusiveManifestEvaluator.java', 'TestInclusiveMetricsEvaluator.java', 'TestPredicateBinding.java', 'TestStrictMetricsEvaluator.java', 'TestResiduals.java', 'TestMetricsRowGroupFilter.java', 'ExpressionToSearchArgument.java', 'TestExpressionToSearchArgument.java', 'ParquetDictionaryRowGroupFilter.java', 'ParquetFilters.java', 'ParquetMetricsRowGroupFilter.java', 'TestDictionaryRowGroupFilter.java', 'Spark3Util.java']"
Core: Support TableBuilder in CachingCatalog (#1879),1,125,2020-12-07 10:33:17-08:00,['CachingCatalog.java']
Core: Add RollingEqDeleteWriter (#1867),14,530,2020-12-07 11:30:37-08:00,"['EqualityDeleteWriter.java', 'BaseTaskWriter.java', 'PartitionedFanoutWriter.java', 'PartitionedWriter.java', 'TaskWriter.java', 'UnpartitionedWriter.java', 'WriteResult.java', 'TestBaseTaskWriter.java', 'IcebergStreamWriter.java', 'RowDataRewriter.java', 'TestTaskWriters.java', 'RowDataRewriter.java', 'Writer.java', 'SparkWrite.java']"
Core: Add SortedPosDeleteWriter (#1858),3,528,2020-12-07 11:50:56-08:00,"['Avro.java', 'SortedPosDeleteWriter.java', 'TestGenericSortedPosDeleteWriter.java']"
Hive: Refactor Hive schema conversions (#1842),7,306,2020-12-07 13:56:10-08:00,"['HiveSchemaConverter.java', 'HiveSchemaUtil.java', 'HiveTableOperations.java', 'TestHiveSchemaUtil.java', 'HiveIcebergMetaHook.java', 'HiveIcebergSerDe.java', 'HiveSchemaUtil.java']"
Flink: fix projection NPE caused by timestamp type (#1882),2,57,2020-12-08 10:16:47+08:00,"['FlinkParquetReaders.java', 'TestFlinkInputFormat.java']"
Spark: Support loading paths in SparkCatalog (#1843),4,412,2020-12-08 14:20:25-08:00,"['HadoopTables.java', 'PathIdentifier.java', 'SparkCatalog.java', 'TestPathIdentifier.java']"
Hive: Implement Deserializer for Hive writes (#1854),9,733,2020-12-08 15:48:52-08:00,"['Deserializer.java', 'IcebergBinaryObjectInspector.java', 'IcebergDateObjectInspector.java', 'IcebergDecimalObjectInspector.java', 'IcebergObjectInspector.java', 'IcebergTimestampObjectInspector.java', 'WriteObjectInspector.java', 'HiveIcebergTestUtils.java', 'TestDeserializer.java']"
API: Move NaN validation from Expressions to Literals (#1892),3,65,2020-12-08 15:51:26-08:00,"['Expressions.java', 'Literals.java', 'TestExpressionHelpers.java']"
Spark: Migrate to identifiers in procedures (#1890),16,437,2020-12-09 17:37:55+02:00,"['TestCherrypickSnapshotProcedure.java', 'TestExpireSnapshotsProcedure.java', 'TestRemoveOrphanFilesProcedure.java', 'TestRewriteManifestsProcedure.java', 'TestRollbackToSnapshotProcedure.java', 'TestRollbackToTimestampProcedure.java', 'TestSetCurrentSnapshotProcedure.java', 'Spark3Util.java', 'BaseProcedure.java', 'CherrypickSnapshotProcedure.java', 'ExpireSnapshotsProcedure.java', 'RemoveOrphanFilesProcedure.java', 'RewriteManifestsProcedure.java', 'RollbackToSnapshotProcedure.java', 'RollbackToTimestampProcedure.java', 'SetCurrentSnapshotProcedure.java']"
Flink: Support limit pushdown for IcebergTableSource (#1822),5,192,2020-12-10 12:06:16+08:00,"['IcebergTableSource.java', 'FlinkInputFormat.java', 'FlinkSource.java', 'ScanContext.java', 'TestFlinkTableSource.java']"
API: Add an operation to replace sort order (#1899),12,314,2020-12-10 12:25:53+02:00,"['ReplaceSortOrder.java', 'SortOrder.java', 'SortOrderBuilder.java', 'Table.java', 'Transaction.java', 'BaseMetadataTable.java', 'BaseReplaceSortOrder.java', 'BaseTable.java', 'BaseTransaction.java', 'CommitCallbackTransaction.java', 'TableMetadata.java', 'TestTableMetadata.java']"
Spark: Speed up tests for extensions (#1903),1,1,2020-12-10 15:40:06+02:00,['SparkExtensionsTestBase.java']
Hive: Make lock check retries backoff exponentially (#1873),3,290,2020-12-10 20:01:22+02:00,"['HiveTableOperations.java', 'TestHiveCommitLocks.java', 'configuration.md']"
Hive: Add OutputCommitter implementation (#1861),7,853,2020-12-10 10:34:51-08:00,"['OutputFileFactory.java', 'InputFormatConfig.java', 'HiveIcebergOutputCommitter.java', 'HiveIcebergRecordWriter.java', 'HiveIcebergStorageHandler.java', 'HiveIcebergTestUtils.java', 'TestHiveIcebergOutputCommitter.java']"
Spark: Actions to snapshot and migrate existing tables (#1525),9,994,2020-12-10 22:03:00+02:00,"['Actions.java', 'CreateAction.java', 'SnapshotAction.java', 'SparkTestBase.java', 'Spark3CreateAction.java', 'Spark3MigrateAction.java', 'Spark3SnapshotAction.java', 'SparkActions.java', 'TestCreateActions.java']"
"Docs: Update iceberg.hive.engine.enabled docs (#1902)

Co-authored-by: Adrian Woodhead <massdosage@gmail.com>",1,2,2020-12-10 13:28:08-08:00,['hive.md']
Spark: Rewrite equals NaN filters to isNaN (#1857),10,327,2020-12-10 15:57:16-08:00,"['Literals.java', 'TestExpressionHelpers.java', 'HiveIcebergFilterFactory.java', 'TestHiveIcebergFilterFactory.java', 'IcebergStorage.java', 'SparkFilters.java', 'TestSelect.java', 'Spark3Util.java', 'SparkFilters.java', 'TestSelect.java']"
Spark: Add snapshot and migrate procedures (#1906),10,528,2020-12-11 08:56:45-08:00,"['CreateAction.java', 'IcebergSqlExtensions.g4', 'TestMigrateTableProcedure.java', 'TestSnapshotTableProcedure.java', 'Spark3MigrateAction.java', 'Spark3SnapshotAction.java', 'BaseProcedure.java', 'MigrateTableProcedure.java', 'SnapshotTableProcedure.java', 'SparkProcedures.java']"
"AWS: add more S3FileIO tests, cleanup related codebase (#1900)

* AWS: add more S3FileIO tests, cleanup codebase

* refactor upload test",6,265,2020-12-11 09:08:41-08:00,"['S3MultipartUploadTest.java', 'AwsProperties.java', 'S3FileIO.java', 'S3OutputStream.java', 'S3RequestUtil.java', 'AwsPropertiesTest.java']"
Build: Remove Sun's Jersey for tests (#1905),1,2,2020-12-11 09:37:00-08:00,['build.gradle']
ORC: Upgrade to 1.6.6 (#1907),1,2,2020-12-11 09:52:40-08:00,['versions.props']
Core: Add BaseDeltaWriter (#1888),4,753,2020-12-11 09:59:49-08:00,"['BaseTaskWriter.java', 'StructCopy.java', 'WriteResult.java', 'TestTaskEqualityDeltaWriter.java']"
AWS: Fix missing table type after Glue update (#1910),2,5,2020-12-11 10:01:30-08:00,"['GlueCatalogTableTest.java', 'GlueTableOperations.java']"
Hive: Support timestamp with local zone in Hive3 (#1897),14,528,2020-12-12 13:09:45-08:00,"['build.gradle', 'HiveSchemaConverter.java', 'HiveSchemaUtil.java', 'IcebergTimestampObjectInspectorHive3.java', 'IcebergTimestampWithZoneObjectInspectorHive3.java', 'TestHiveSchemaUtilHive3.java', 'TestIcebergTimestampObjectInspectorHive3.java', 'TestIcebergTimestampWithZoneObjectInspectorHive3.java', 'IcebergObjectInspector.java', 'IcebergTimestampObjectInspector.java', 'IcebergTimestampWithZoneObjectInspector.java', 'TestIcebergObjectInspector.java', 'TestIcebergTimestampObjectInspector.java', 'TestIcebergTimestampWithZoneObjectInspector.java']"
Build: Remove duplicate Arrow dependency (#1930),1,1,2020-12-14 10:33:53-08:00,['build.gradle']
Docs: Document fanout writer for Spark streaming (#1929),1,23,2020-12-14 10:35:51-08:00,['spark-structured-streaming.md']
Flink: Add PartitionedDeltaTaskWriter and UnpartitionedDeltaTaskWriter (#1896),10,650,2020-12-14 15:25:27-08:00,"['BaseTaskWriter.java', 'BaseDeltaTaskWriter.java', 'FlinkSink.java', 'PartitionedDeltaWriter.java', 'RowDataTaskWriterFactory.java', 'UnpartitionedDeltaWriter.java', 'RowDataRewriter.java', 'SimpleDataUtil.java', 'TestDeltaTaskWriter.java', 'TestTaskWriters.java']"
Spark: Refactor schema evolution examples  (#1932),1,46,2020-12-15 13:08:42-08:00,['SchemaEvolutionTest.java']
Core: Add UpdatePartitionSpec implementation (#1919),5,1087,2020-12-15 17:52:18-08:00,"['PartitionSpec.java', 'UpdatePartitionSpec.java', 'PartitionSpecVisitor.java', 'BaseUpdatePartitionSpec.java', 'TestUpdatePartitionSpec.java']"
"Core: Add partition spec update operation (#1942)

Co-authored-by: Jun He <jun-he@users.noreply.github.com>",10,139,2020-12-16 13:19:06-08:00,"['Table.java', 'Transaction.java', 'UpdatePartitionSpec.java', 'BaseMetadataTable.java', 'BaseTable.java', 'BaseTransaction.java', 'BaseUpdatePartitionSpec.java', 'CommitCallbackTransaction.java', 'TableMetadata.java', 'TestTableMetadata.java']"
"Revert ""AWS: support S3 strong consistency (#1863)"" (#1945)

This reverts commit c882ac9249229078bf89caf48de688c399e858f9.",5,109,2020-12-16 16:25:55-08:00,"['S3FileIOTest.java', 'BaseS3File.java', 'S3InputFile.java', 'S3RequestUtil.java', 'S3FileIOTest.java']"
Spark: Fix delete test with IN and NOT IN condition (#1937),1,2,2020-12-16 17:25:03-08:00,['TestDelete.java']
Spark: Fix list behavior in StructInternalRow (#1943),1,2,2020-12-16 17:43:31-08:00,['StructInternalRow.java']
Core: Refactor metrics related classes for NaN support (#1829),10,188,2020-12-16 18:01:59-08:00,"['FieldMetrics.java', 'FloatFieldMetrics.java', 'MetricsUtil.java', 'TestGenericMergingMetrics.java', 'TestMergingMetrics.java', 'TestFlinkMergingMetrics.java', 'ParquetUtil.java', 'ParquetValueWriters.java', 'StructInternalRow.java', 'TestSparkMergingMetrics.java']"
Build: Remove unused test dependencies (#1950),1,8,2020-12-17 09:15:56-08:00,['build.gradle']
Core: Add ExceptionUtil.runSafely (#1909),2,265,2020-12-17 12:26:22-08:00,"['ExceptionUtil.java', 'TestExceptionUtil.java']"
Docs: Fix typo in Java API Quickstart (#1953),1,2,2020-12-17 12:33:32-08:00,['java-api-quickstart.md']
Flink: Commit both data files and delete files (#1939),12,1147,2020-12-18 09:57:04-08:00,"['WriteResult.java', 'DeltaManifests.java', 'DeltaManifestsSerializer.java', 'FlinkManifestSerializer.java', 'FlinkManifestUtil.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'IcebergStreamWriter.java', 'SimpleDataUtil.java', 'TestFlinkManifest.java', 'TestIcebergFilesCommitter.java', 'TestIcebergStreamWriter.java']"
Parquet: Add vectorized position reader (#1356),8,111,2020-12-18 10:39:19-08:00,"['VectorHolder.java', 'VectorizedArrowReader.java', 'VectorizedParquetReader.java', 'VectorizedReader.java', 'ArrowVectorAccessors.java', 'ColumnarBatchReader.java', 'VectorizedSparkParquetReaders.java', 'TestSparkParquetReadMetadataColumns.java']"
Hive: Support PARTITIONED BY clause using identity partitions (#1917),5,202,2020-12-18 10:44:18-08:00,"['build.gradle', 'HiveSchemaUtil.java', 'HiveIcebergMetaHook.java', 'HiveIcebergTestUtils.java', 'TestHiveIcebergStorageHandler.java']"
Spark: Add SQL commands evolve partition specs (#1948),11,649,2020-12-18 15:11:41-08:00,"['IcebergSqlExtensions.g4', 'IcebergSparkSessionExtensions.scala', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'AddPartitionField.scala', 'DropPartitionField.scala', 'AddPartitionFieldExec.scala', 'DropPartitionFieldExec.scala', 'ExtendedDataSourceV2Strategy.scala', 'TestAlterTablePartitionFields.java', 'Spark3Util.java']"
"AWS: support custom client configuration (#1844)

* AWS: support custom client configuration

* fix checkstyle",11,423,2020-12-19 08:28:07-08:00,"['GlueTestBase.java', 'S3FileIOTest.java', 'S3MultipartUploadTest.java', 'AwsClientFactories.java', 'AwsClientFactory.java', 'AwsClientUtil.java', 'AwsProperties.java', 'GlueCatalog.java', 'S3FileIO.java', 'AwsClientFactoriesTest.java', 'GlueCatalogTest.java']"
Spark: Log file location for read errors (#1957),1,33,2020-12-19 14:24:52-08:00,['BaseDataReader.java']
Docs: Fix Flink download location (#1967),1,2,2020-12-20 14:18:33-08:00,['flink.md']
"Docs: Fix Flink typo, batch mode (#1966)",1,2,2020-12-20 14:19:32-08:00,['flink.md']
"Parquet: Fix vectorized position reader (#1962)

The vectorized position reader would fail to read correct positions when batch size is less than row group size.",2,11,2020-12-20 14:21:14-08:00,"['VectorizedArrowReader.java', 'TestSparkParquetReadMetadataColumns.java']"
Hive: Fix test failures from IcebergTimestampWithZoneObjectInspector (#1965),2,14,2020-12-20 14:23:20-08:00,"['IcebergTimestampWithZoneObjectInspector.java', 'TestIcebergTimestampWithZoneObjectInspector.java']"
Spark: Add WRITE ORDERED BY command to set table order (#1961),7,284,2020-12-21 11:54:17+02:00,"['IcebergSqlExtensions.g4', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'SetWriteOrder.scala', 'ExtendedDataSourceV2Strategy.scala', 'SetWriteOrderExec.scala', 'TestSetWriteOrder.java']"
Flink: Fix missing List parameter in tests (#1970),1,2,2020-12-21 10:16:10-08:00,['TestFlinkTableSource.java']
"Parquet: Remove unnecessary Encoding parameter (#1969)

Explicit type argument Encoding can be replaced with <>",1,2,2020-12-21 10:17:07-08:00,['ParquetUtil.java']
Flink: Remove unnecessary variable (#1968),1,3,2020-12-21 10:17:58-08:00,['RewriteDataFilesAction.java']
Spark: Sort retained rows in DELETE FROM by file and position (#1955),11,225,2020-12-21 13:19:14-08:00,"['VectorizedArrowReader.java', 'MetadataColumns.java', 'BuildAvroProjection.java', 'PartitionUtil.java', 'VectorizedSparkParquetReaders.java', 'BatchDataReader.java', 'RewriteDelete.scala', 'DynamicFileFilter.scala', 'DynamicFileFilterExec.scala', 'ExtendedDataSourceV2Strategy.scala', 'SparkScanBuilder.java']"
Spark: 3.x: Support custom catalogs in IcebergSource (#1783),9,219,2020-12-22 10:09:13-08:00,"['spark.md', 'TestIdentityPartitionData.java', 'TestSparkReadProjection.java', 'Spark3Util.java', 'SparkCatalog.java', 'IcebergSource.java', 'TestRemoveOrphanFilesAction3.java', 'TestIcebergSource.java', 'TestSparkCatalog.java']"
Flink: Add ChangeLog DataStream end-to-end unit tests. (#1974),8,556,2020-12-23 14:55:38+08:00,"['FlinkSink.java', 'SimpleDataUtil.java', 'TestTableLoader.java', 'TestDeltaTaskWriter.java', 'TestFlinkIcebergSinkV2.java', 'TestIcebergFilesCommitter.java', 'TestIcebergStreamWriter.java', 'BoundedTestSource.java']"
Spark: Add table properties to control UPDATE mode and isolation level (#1987),3,14,2020-12-26 21:24:04+02:00,"['TableProperties.java', 'SparkMergeBuilder.java', 'SparkTable.java']"
LICENSE: Fix Spark home page and switch links to https (#1989),1,22,2020-12-28 11:04:16+02:00,['LICENSE']
Spark: Add table properties to control MERGE mode and isolation level (#1988),3,14,2020-12-28 11:05:48+02:00,"['TableProperties.java', 'SparkMergeBuilder.java', 'SparkTable.java']"
Docs: Fix spelling errors in hive.md (#1990),1,6,2020-12-28 10:38:45-08:00,['hive.md']
Hive: Ensure unlock is called when uncommitted metadata delete fails (#1998),1,20,2020-12-28 10:42:46-08:00,['HiveTableOperations.java']
Avro: Schema conversions should preserve field docs (#1991),4,28,2020-12-28 10:47:58-08:00,"['SchemaToType.java', 'TypeToSchema.java', 'TestMergeAppend.java', 'TestSchemaConversions.java']"
Flink: Replace FiniteTestSource with BoundedTestSource (#1982),1,20,2020-12-28 11:41:37-08:00,['TestFlinkIcebergSink.java']
AWS: Clean up AwsProperties style (#1997),4,26,2020-12-28 11:45:23-08:00,"['AwsClientFactories.java', 'AwsProperties.java', 'S3OutputStream.java', 'AwsClientFactoriesTest.java']"
Flink: Use Namespace in the parameterized args (#1984),7,49,2020-12-28 11:47:06-08:00,"['FlinkCatalogTestBase.java', 'TestFlinkCatalogDatabase.java', 'TestFlinkCatalogTable.java', 'TestFlinkCatalogTablePartitions.java', 'TestFlinkTableSink.java', 'TestFlinkTableSource.java', 'TestRewriteDataFilesAction.java']"
"Flink: Add test for CREATE TABLE LIKE (#1901)

Co-authored-by: zhangjun <jun.zhang1@ly.com>",2,33,2020-12-28 13:49:27-08:00,"['TestFlinkCatalogTable.java', 'flink.md']"
Spark: Use constants for DF read and write options (#1933),24,322,2020-12-28 13:55:09-08:00,"['configuration.md', 'SparkReadOptions.java', 'SparkWriteOptions.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestIdentityPartitionData.java', 'TestPartitionPruning.java', 'TestPartitionValues.java', 'TestSnapshotSelection.java', 'TestSparkDataWrite.java', 'TestSparkReadProjection.java', 'TestWriteMetricsConfig.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSource.java', 'Reader.java', 'Writer.java', 'TestFilteredScan.java', 'Spark3Util.java', 'SparkBatchQueryScan.java', 'SparkMergeScan.java', 'SparkWrite.java', 'SparkWriteBuilder.java', 'TestFilteredScan.java']"
Spark: Support custom catalogs in Spark 2 (#1875),10,697,2020-12-28 15:05:34-08:00,"['CatalogUtil.java', 'HadoopCatalog.java', 'HiveCatalog.java', 'SparkUtil.java', 'CustomCatalogs.java', 'IcebergSource.java', 'TestCatalog.java', 'TestCustomCatalog.java', 'Spark3Util.java', 'SparkCatalog.java']"
AWS: Add iceberg-aws to Spark and Flink runtime Jars (#2000),1,11,2020-12-28 15:09:06-08:00,['build.gradle']
Core: Increase target size in testManifestMergeMinCount (#1999),1,4,2020-12-28 15:09:43-08:00,['TestMergeAppend.java']
Core: Add additional partition spec update tests (#1993),1,184,2020-12-29 12:02:09+02:00,['TestTableUpdatePartitionSpec.java']
"Docs: Rename Presto SQL to Trino (#2003)

PrestoSQL was rebranded as Trino: https://trino.io/blog/2020/12/27/announcing-trino.html",2,6,2020-12-29 16:38:55-08:00,"['trino.md', 'mkdocs.yml']"
Core: Fix sort order in HadoopTables replace transactions (#2009),1,4,2020-12-30 11:10:38-08:00,['HadoopTables.java']
Flink : Avoid useless files rewrite in RewriteDataFilesAction (#1704),2,98,2020-12-31 17:53:52+08:00,"['BaseRewriteDataFilesAction.java', 'TestRewriteDataFilesAction.java']"
Build: Add path config to control github actions (#2005),2,38,2020-12-31 16:02:59+02:00,"['java-ci.yml', 'python-ci.yml']"
Nessie: Bump version to 0.3.0 (#2016),3,37,2020-12-31 12:08:37-08:00,"['build.gradle', 'NessieCatalog.java', 'versions.props']"
Core: Allow spec updates with only renames (#2007),2,22,2020-12-31 12:09:47-08:00,"['PartitionSpec.java', 'TestTableUpdatePartitionSpec.java']"
Build: Add separate CI steps for javadoc and errorprone/checkstyle. (#1971),1,21,2020-12-31 12:10:29-08:00,['java-ci.yml']
Spark: Add Nessie catalog to Spark runtime jars (#1895),5,44,2020-12-31 13:28:05-08:00,"['build.gradle', 'LICENSE', 'NOTICE', 'LICENSE', 'NOTICE']"
Build: Remove additional logging for Travis CI. (#2013),1,6,2020-12-31 15:42:50-08:00,['build.gradle']
Spark: Fix Javadoc in IcebergSource (#2018),1,12,2021-01-01 15:32:06-08:00,['IcebergSource.java']
Core: Add equals and hashcode to BaseSnapshot (#2011),1,27,2021-01-01 15:32:55-08:00,['BaseSnapshot.java']
Core: Avoid NPE in BaseSnapshot.equals (#2020),1,2,2021-01-04 11:57:56-08:00,['BaseSnapshot.java']
Core: Fix static analysis warnings (#2012),8,29,2021-01-04 15:19:52-08:00,"['BaseTable.java', 'BaseTableScan.java', 'ScanSummary.java', 'BaseRewriteDataFilesAction.java', 'BaseTaskWriter.java', 'PartitionedWriter.java', 'SparkBatchScan.java', 'SparkMergeBuilder.java']"
Hive: Fix minor issues issues from #1917 (#2029),1,26,2021-01-05 09:22:43-08:00,['HiveIcebergMetaHook.java']
"Hive: Set formats and serde for tables created from Hive (#2025)

Co-authored-by: Marton Bod <mbod@cloudera.com>",2,10,2021-01-05 10:39:30-08:00,"['HiveIcebergMetaHook.java', 'TestHiveIcebergStorageHandler.java']"
Hive: Serialize Table to avoid a load for split planning (#1920),4,88,2021-01-05 11:14:35-08:00,"['BaseTable.java', 'InputFormatConfig.java', 'HiveIcebergStorageHandler.java', 'IcebergInputFormat.java']"
AWS: Add LockManager interface and update Glue (#1823),10,623,2021-01-05 13:08:28-08:00,"['GlueTestBase.java', 'S3FileIOTest.java', 'GlueCatalog.java', 'GlueTableOperations.java', 'LockManager.java', 'LockManagers.java', 'GlueCatalogTest.java', 'InMemoryLockManagerTest.java', 'LockManagersTest.java', 'CatalogProperties.java']"
Parquet: Return correct length after writer is closed (#2001),3,122,2021-01-05 14:06:54-08:00,"['ParquetWriter.java', 'ParquetWritingTestUtils.java', 'TestParquet.java']"
"AWS: add client factory for assume role use case (#2002)

* AWS: add client factory for assume role use case

* fix tests",5,304,2021-01-06 09:25:59-08:00,"['AssumeRoleAwsClientFactoryTest.java', 'AwsIntegTestUtil.java', 'AssumeRoleAwsClientFactory.java', 'AwsProperties.java', 'build.gradle']"
Hive: Run fewer combinations in TestHiveIcebergStorageHandler (#1924) (#2030),5,2422,2021-01-06 11:21:21-08:00,"['HiveIcebergStorageHandlerTestUtils.java', 'TestHiveIcebergStorageHandler.java', 'TestHiveIcebergStorageHandlerLocalScan.java', 'TestHiveIcebergStorageHandlerNoScan.java', 'TestHiveIcebergStorageHandlerWithEngine.java']"
"Core: Make ExceptionUtil interfaces public (#2035)

Otherwise the utility can't actually be used.",1,6,2021-01-06 16:49:28-08:00,['ExceptionUtil.java']
AWS: Fix S3FileIO executor service synchronization (#2036),1,4,2021-01-06 16:50:49-08:00,['S3OutputStream.java']
Core: Fix projected transform expression names (#2027),3,107,2021-01-06 16:58:28-08:00,"['Dates.java', 'Timestamps.java', 'TestProjection.java']"
Spark: Add a rule to align updates in MERGE operations (#1986),10,791,2021-01-06 17:24:57-08:00,"['LICENSE', 'scalastyle_config.xml', 'SparkTestBase.java', 'IcebergSparkSessionExtensions.scala', 'AlignMergeIntoTable.scala', 'AssignmentAlignmentSupport.scala', 'SparkRowLevelOperationsTestBase.java', 'TestCopyOnWriteMerge.java', 'TestDelete.java', 'TestMerge.java']"
AWS: add DynamoDB implementation of Glue lock manager (#2034),9,760,2021-01-06 18:03:35-08:00,"['DynamoLockManagerTest.java', 'GlueCatalogLockTest.java', 'AssumeRoleAwsClientFactory.java', 'AwsClientFactories.java', 'AwsClientFactory.java', 'DynamoLockManager.java', 'LockManager.java', 'AwsClientFactoriesTest.java', 'build.gradle']"
ORC: Respect metrics config in Flink and Generic Appenders (#1960),2,2,2021-01-06 19:19:00-08:00,"['GenericAppenderFactory.java', 'FlinkAppenderFactory.java']"
Docs: Add redirect from presto/ to trino/ (#2004),1,1,2021-01-06 19:20:20-08:00,['mkdocs.yml']
Flink: Add Nessie to runtime Jar (#2032),3,27,2021-01-07 17:50:24-08:00,"['build.gradle', 'LICENSE', 'NOTICE']"
AWS: consolidate config key names before release (#2050),2,22,2021-01-08 10:08:58-08:00,"['AwsProperties.java', 'CatalogProperties.java']"
Docs: Add page for AWS integration (#1891),4,278,2021-01-08 16:50:05-08:00,"['aws.md', 'configuration.md', 'extra.css', 'mkdocs.yml']"
Core: Add HadoopTables.exists (#2056),4,22,2021-01-11 10:22:53-08:00,"['Tables.java', 'HadoopTables.java', 'TestHadoopTables.java', 'TestTables.java']"
Spark: Override simpleString in dynamic file filter nodes (#2066),2,10,2021-01-11 10:26:30-08:00,"['DynamicFileFilter.scala', 'DynamicFileFilterExec.scala']"
Core: Fix HadoopCatalog listing with Azure permission failure #1941 (#1979),1,71,2021-01-12 15:27:40-08:00,['HadoopCatalog.java']
Core: Fix partition field id assignment for v2 (#2083),2,25,2021-01-13 14:23:01-08:00,"['BaseUpdatePartitionSpec.java', 'TestTableUpdatePartitionSpec.java']"
Flink: Support streaming reader. (#1793),13,1624,2021-01-14 12:35:25+08:00,"['GenericAppenderHelper.java', 'FlinkInputFormat.java', 'FlinkInputSplit.java', 'FlinkSource.java', 'FlinkSplitGenerator.java', 'ScanContext.java', 'StreamingMonitorFunction.java', 'StreamingReaderOperator.java', 'FlinkTestBase.java', 'TestTableLoader.java', 'TestStreamScanSql.java', 'TestStreamingMonitorFunction.java', 'TestStreamingReaderOperator.java']"
Flink: Support catalogs with custom properties (#2031),1,14,2021-01-14 12:52:53-08:00,['FlinkCatalogFactory.java']
"Hive: Fix join issues when CBO is enabled (#2052)

Co-authored-by:  <luochong@corp.netease.com>",3,98,2021-01-15 09:27:25-08:00,"['HiveIcebergSerDe.java', 'TestHiveIcebergStorageHandlerWithEngine.java', 'TestHiveShell.java']"
Hive: Fix Deserializer to use source deserializer (#2078),15,295,2021-01-15 17:48:15-08:00,"['IcebergTimestampObjectInspectorHive3.java', 'IcebergTimestampWithZoneObjectInspectorHive3.java', 'TestIcebergTimestampObjectInspectorHive3.java', 'TestIcebergTimestampWithZoneObjectInspectorHive3.java', 'Deserializer.java', 'IcebergBinaryObjectInspector.java', 'IcebergDateObjectInspector.java', 'IcebergDecimalObjectInspector.java', 'IcebergTimestampObjectInspector.java', 'IcebergTimestampWithZoneObjectInspector.java', 'WriteObjectInspector.java', 'HiveIcebergTestUtils.java', 'TestDeserializer.java', 'TestIcebergTimestampObjectInspector.java', 'TestIcebergTimestampWithZoneObjectInspector.java']"
Core: Add comments for Position2Accessor and Position3Accessor (#2074),1,14,2021-01-15 17:53:09-08:00,['Accessors.java']
Spark: Add a parent trait for row-level rewrite rules (#2095),3,211,2021-01-15 18:33:23-08:00,"['IcebergSparkSessionExtensions.scala', 'RewriteDelete.scala', 'RewriteRowLevelOperationHelper.scala']"
Spark: Refactor RewriteRowLevelOperationHelper to support MERGE operations (#2097),2,44,2021-01-15 19:47:46-08:00,"['RewriteDelete.scala', 'RewriteRowLevelOperationHelper.scala']"
Core: Fix truncate with zero-length strings (#2081),5,62,2021-01-16 11:48:59-08:00,"['BinaryUtil.java', 'TestInclusiveMetricsEvaluator.java', 'TestMetricsTruncation.java', 'TestFilteredScan.java', 'TestFilteredScan.java']"
"Hive: Add inspectors for UUID, Fixed, and Time types (#2077)",13,564,2021-01-16 11:53:07-08:00,"['IcebergBinaryObjectInspector.java', 'IcebergFixedObjectInspector.java', 'IcebergObjectInspector.java', 'IcebergTimeObjectInspector.java', 'IcebergUUIDObjectInspector.java', 'HiveIcebergTestUtils.java', 'TestDeserializer.java', 'TestHiveIcebergStorageHandlerWithEngine.java', 'TestIcebergBinaryObjectInspector.java', 'TestIcebergFixedObjectInspector.java', 'TestIcebergObjectInspector.java', 'TestIcebergTimeObjectInspector.java', 'TestIcebergUUIDObjectInspector.java']"
"Hive: Queries should be case insensitive (#2053)

Co-authored-by: dixingxing <dixingxing@autohome.com.cn>",6,55,2021-01-16 13:30:43-08:00,"['InputFormatConfig.java', 'HiveIcebergSerDe.java', 'IcebergRecordObjectInspector.java', 'IcebergInputFormat.java', 'HiveIcebergStorageHandlerTestUtils.java', 'TestHiveIcebergStorageHandlerLocalScan.java']"
Hive: Support INSERT INTO using HiveIcebergRecordWriter (#2038),7,498,2021-01-18 10:30:24-08:00,"['InputFormatConfig.java', 'HiveIcebergOutputFormat.java', 'HiveIcebergSerDe.java', 'HiveIcebergStorageHandler.java', 'TestHiveIcebergOutputCommitter.java', 'TestHiveIcebergStorageHandlerWithEngine.java', 'TestTables.java']"
Core: Reject duplicate identity partitions (#2061),5,54,2021-01-18 12:43:55-08:00,"['PartitionSpec.java', 'Dates.java', 'Timestamps.java', 'Transform.java', 'TestPartitionSpecValidation.java']"
Flink: Support filter pushdown (#1893),5,1363,2021-01-18 12:49:47-08:00,"['FlinkFilters.java', 'IcebergTableSource.java', 'FlinkTestBase.java', 'TestFlinkFilters.java', 'TestFlinkTableSource.java']"
Hive: Fix ORC projection with orc.force.positional.evolution=true (#2111),4,45,2021-01-18 13:39:33-08:00,"['TestHiveMetastore.java', 'HiveIcebergStorageHandlerTestUtils.java', 'TestHiveShell.java', 'ORC.java']"
Docs: Update copyright to include 2021 (#2106),1,2,2021-01-18 14:17:42-08:00,['mkdocs.yml']
Docs: Update module list in API docs (#2107),1,8,2021-01-18 14:20:43-08:00,['api.md']
Spark: Fix parquet vectorized reads with promoted types (#2091),4,78,2021-01-18 16:51:06-08:00,"['VectorizedArrowReader.java', 'ArrowVectorAccessors.java', 'TestHelpers.java', 'TestParquetVectorizedReads.java']"
"Spark: Support MERGE INTO (#1947)

Co-authored-by: Dilip Biswal <dbiswal@adobe.com>",8,587,2021-01-18 22:08:17-08:00,"['IcebergSparkSessionExtensions.scala', 'RewriteDelete.scala', 'RewriteMergeInto.scala', 'MergeInto.scala', 'RewriteRowLevelOperationHelper.scala', 'ExtendedDataSourceV2Strategy.scala', 'MergeIntoExec.scala', 'TestMergeIntoTable.java']"
Build: Update NOTICE to include copyright for 2021 (#2112),6,12,2021-01-18 22:12:09-08:00,"['NOTICE', 'NOTICE', 'NOTICE', 'NOTICE', 'NOTICE', 'NOTICE']"
Build: Add RAT download to .gitignore (#2113),1,3,2021-01-19 13:18:25-08:00,['.gitignore']
API: Add missing overrides in SortOrder (#2104),1,2,2021-01-19 13:19:31-08:00,['SortOrder.java']
Hive: Support converting Hive types to wider Iceberg types in CREATE TABLE (#2054),6,125,2021-01-19 14:00:44-08:00,"['HiveSchemaConverter.java', 'HiveSchemaUtil.java', 'InputFormatConfig.java', 'HiveIcebergMetaHook.java', 'HiveIcebergSerDe.java', 'TestHiveIcebergStorageHandlerNoScan.java']"
Spark: Optimize join types for MERGE INTO (#2116),5,211,2021-01-19 17:55:21-08:00,"['RewriteDelete.scala', 'RewriteMergeInto.scala', 'MergeInto.scala', 'RewriteRowLevelOperationHelper.scala', 'MergeIntoExec.scala']"
Flink: Support write.distribution-mode (#2064),8,385,2021-01-20 08:59:55-08:00,"['DistributionMode.java', 'TableProperties.java', 'FlinkSink.java', 'PartitionKeySelector.java', 'FlinkCatalogTestBase.java', 'TestFlinkTableSink.java', 'TestFlinkIcebergSink.java', 'TestIcebergStreamWriter.java']"
API: Handle NaN lower or upper bound in stats evaluators (#2069),3,487,2021-01-20 09:03:55-08:00,"['InclusiveMetricsEvaluator.java', 'StrictMetricsEvaluator.java', 'TestMetricsEvaluatorsNaNHandling.java']"
"Spark: Detect ambiguous target row changes in MERGE INTO (#2021)

Co-authored-by: Dilip Biswal <dbiswal@adobe.com>",12,337,2021-01-20 10:37:46-08:00,"['LICENSE', 'TableProperties.java', 'IcebergSparkSessionExtensions.scala', 'AccumulateFiles.scala', 'RewriteDelete.scala', 'RewriteMergeInto.scala', 'DynamicFileFilter.scala', 'RewriteRowLevelOperationHelper.scala', 'SetAccumulator.scala', 'DynamicFileFilterExec.scala', 'ExtendedDataSourceV2Strategy.scala', 'TestMergeIntoTable.java']"
Spark: Replace spec.fields().isEmpty() to isUnpartitioned() (#2114),3,6,2021-01-20 16:18:54-08:00,"['RowDataRewriter.java', 'Writer.java', 'SparkWrite.java']"
Core: Rename catalog properties that are not specific to Hive (#2088),9,44,2021-01-20 17:08:59-08:00,"['CatalogProperties.java', 'CatalogLoader.java', 'FlinkCatalogTestBase.java', 'TestFlinkHiveCatalog.java', 'TestFlinkInputFormatReaderDeletes.java', 'HiveCatalog.java', 'configuration.md', 'TestCatalog.java', 'TestCustomCatalog.java']"
Core: Add validation for metrics config (#2048),6,83,2021-01-20 18:01:36-08:00,"['MetricsConfig.java', 'PropertiesUpdate.java', 'SchemaUpdate.java', 'TableMetadata.java', 'TestSchemaAndMappingUpdate.java', 'TestWriteMetricsConfig.java']"
Spark: Prohibit subqueries in conditions of MERGE operations (#2118),3,105,2021-01-20 18:04:28-08:00,"['IcebergSparkSessionExtensions.scala', 'MergeIntoTablePredicateCheck.scala', 'TestMerge.java']"
Spark: Add Spark extensions to iceberg-spark3-runtime (#2127),3,25,2021-01-20 19:55:27-08:00,"['build.gradle', 'spark.md', 'LICENSE']"
"Spark: Distribute and sort writes in MERGE queries (#2022)

Co-authored-by: Ashish Mehta<mehta.ashish23@gmail.com>
Co-authored-by: Dilip Biswal <dbiswal@adobe.com>",24,1197,2021-01-21 10:53:12-08:00,"['LICENSE', 'TableProperties.java', 'TransformExpressions.scala', 'RewriteMergeInto.scala', 'MergeInto.scala', 'RewriteRowLevelOperationHelper.scala', 'ExtendedDataSourceV2Strategy.scala', 'MergeIntoExec.scala', 'TestMergeIntoTable.java', 'CopySortOrderFields.java', 'OrderField.java', 'SortOrderToSpark.java', 'Spark3Util.java', 'ClusteredDistribution.java', 'Distribution.java', 'Distributions.java', 'OrderedDistribution.java', 'UnspecifiedDistribution.java', 'ClusterDistributionImpl.java', 'OrderedDistributionImpl.java', 'UnspecifiedDistributionImpl.java', 'NullOrdering.java', 'SortDirection.java', 'SortOrder.java']"
Spark: Minor refactoring for the cardinality check in MERGE (#2132),8,139,2021-01-21 16:24:36-08:00,"['TableProperties.java', 'AccumulateFiles.scala', 'RewriteMergeInto.scala', 'DynamicFileFilter.scala', 'RewriteRowLevelOperationHelper.scala', 'DynamicFileFilterExec.scala', 'ExtendedDataSourceV2Strategy.scala', 'TestMergeIntoTable.java']"
API: Fix date and timestamp transforms (#1981),9,890,2021-01-21 17:14:39-08:00,"['Dates.java', 'ProjectionUtil.java', 'Timestamps.java', 'TransformUtil.java', 'TestStringLiteralConversions.java', 'TestDates.java', 'TestDatesProjection.java', 'TestTimestamps.java', 'TestTimestampsProjection.java']"
Core: Remove non-test uses of commons-lang3 (#2102),18,342,2021-01-21 17:22:44-08:00,"['LICENSE', 'build.gradle', 'ArrayUtil.java', 'SerializationUtil.java', 'LICENSE', 'FlinkParquetReaders.java', 'LICENSE', 'InputFormatConfig.java', 'HiveIcebergInputFormat.java', 'HiveIcebergSplit.java', 'HiveIcebergStorageHandler.java', 'IcebergInputFormat.java', 'IcebergSplit.java', 'IcebergPigInputFormat.java', 'LICENSE', 'LICENSE', 'Spark3Util.java', 'versions.props']"
Core: Make Metadata tables serializable (#2046),12,285,2021-01-21 17:25:54-08:00,"['AllDataFilesTable.java', 'AllEntriesTable.java', 'AllManifestsTable.java', 'BaseMetadataTable.java', 'BaseTable.java', 'DataFilesTable.java', 'HistoryTable.java', 'ManifestEntriesTable.java', 'ManifestsTable.java', 'PartitionsTable.java', 'SnapshotsTable.java', 'TestTableSerialization.java']"
Docs: Add partition spec and sort order evolution doc (#2101),3,81,2021-01-21 17:43:46-08:00,"['evolution.md', 'partitioning.md', 'spark.md']"
Flink: Support inferring parallelism for batch read. (#1936),6,185,2021-01-22 18:17:39+08:00,"['FlinkTableFactory.java', 'FlinkTableOptions.java', 'IcebergTableSource.java', 'FlinkSource.java', 'FlinkTestBase.java', 'TestFlinkScanSql.java']"
ORC: Fix NarrowingCompoundAssignment warnings (#2103),3,12,2021-01-22 10:17:49-08:00,"['GenericOrcWriters.java', 'FlinkOrcWriters.java', 'SparkOrcValueWriters.java']"
Hive: Support field comments in schema conversion (#2086),9,173,2021-01-22 10:21:56-08:00,"['HiveSchemaConverter.java', 'HiveSchemaUtil.java', 'TestHiveSchemaUtil.java', 'TestHiveSchemaUtilHive3.java', 'HiveIcebergSerDe.java', 'HiveIcebergStorageHandlerTestUtils.java', 'TestHiveIcebergStorageHandlerLocalScan.java', 'TestHiveIcebergStorageHandlerNoScan.java', 'TestHiveIcebergStorageHandlerWithEngine.java']"
Docs: Add HTTP client to AWS docs (#2072),1,18,2021-01-22 10:24:10-08:00,['aws.md']
"Spec: Add requirements for floating point number ordering, NaN semantics (#348)",1,14,2021-01-22 10:45:26-08:00,['spec.md']
Spark: Fix bucketed transform expression (#2138),1,2,2021-01-22 11:13:22-08:00,['TransformExpressions.scala']
Spec: Add sort order to spec (#2055),1,51,2021-01-22 11:43:21-08:00,['spec.md']
Flink: Support SQL IF EXISTS and IF NOT EXISTS clauses (#2135),3,57,2021-01-22 12:41:45-08:00,"['FlinkCatalog.java', 'TestFlinkCatalogDatabase.java', 'TestFlinkCatalogTable.java']"
"Spark: Rewrite MERGE INTO and DELETE for only Iceberg tables (#2134)

Co-authored-by: Dilip Biswal <dbiswal@adobe.com>",10,98,2021-01-22 12:48:23-08:00,"['AlignMergeIntoTable.scala', 'DeleteFromTablePredicateCheck.scala', 'MergeIntoTablePredicateCheck.scala', 'OptimizeConditionsInRowLevelOperations.scala', 'PullupCorrelatedPredicatesInRowLevelOperations.scala', 'RewriteDelete.scala', 'RewriteMergeInto.scala', 'PlanUtils.scala', 'TestDelete.java', 'TestMerge.java']"
Spark: Do not redistribute MERGE INTO rows unless the table is sorted (#2139),1,9,2021-01-22 13:58:00-08:00,['RewriteMergeInto.scala']
ORC: Bump version to 1.6.7 (#2140),1,2,2021-01-24 13:43:15-08:00,['versions.props']
API: Add a constant for none distribution mode (#2142),1,3,2021-01-25 10:31:31+08:00,['TableProperties.java']
Docs: Update documentation references for Trino (#2143),2,4,2021-01-24 20:06:51-08:00,"['README.md', 'index.md']"
"Hive: Fix writing of Date, Decimal, Time and UUID types. (#2126)",8,103,2021-01-25 15:33:15+01:00,"['IcebergDateObjectInspectorHive3.java', 'IcebergDecimalObjectInspector.java', 'IcebergTimeObjectInspector.java', 'IcebergUUIDObjectInspector.java', 'HiveIcebergTestUtils.java', 'TestHiveIcebergStorageHandlerWithEngine.java', 'TestIcebergTimeObjectInspector.java', 'TestIcebergUUIDObjectInspector.java']"
Hive: Push Iceberg table property values to HMS table properties (#2123),4,231,2021-01-25 15:41:20+01:00,"['HiveTableOperations.java', 'TestHiveMetastore.java', 'HiveIcebergMetaHook.java', 'TestHiveIcebergStorageHandlerNoScan.java']"
"Docs: Document stored procedures in Spark (#2067)

Co-authored-by: Adrian Woodhead <massdosage@gmail.com>",1,327,2021-01-26 12:23:55-08:00,['spark.md']
"Core: Improve error message in Avro wrapper classes (#2152)

Co-authored-by: Steven Wu <stevenwu@netflix.com>",2,12,2021-01-26 12:25:16-08:00,"['V1Metadata.java', 'V2Metadata.java']"
Docs: Update Flink docs for 0.11.0 (#2147),2,107,2021-01-26 12:42:31-08:00,"['configuration.md', 'flink.md']"
Spark: Refresh relation cache in DELETE and MERGE (#2154),5,106,2021-01-26 12:42:56-08:00,"['ExtendedDataSourceV2Strategy.scala', 'ReplaceDataExec.scala', 'SparkRowLevelOperationsTestBase.java', 'TestDelete.java', 'TestMerge.java']"
Spark: Add DistributionAndOrderingUtils (#2141),7,612,2021-01-26 12:45:58-08:00,"['CopySortOrderFields.java', 'SortOrderUtil.java', 'RewriteMergeInto.scala', 'DistributionAndOrderingUtils.scala', 'RewriteRowLevelOperationHelper.scala', 'CopySortOrderFields.java', 'Spark3Util.java']"
Docs: Add 0.11.0 to releases (#2157),4,91,2021-01-26 14:53:19-08:00,"['README.md', 'how-to-release.md', 'index.html', 'releases.md']"
Docs: Add Javadoc for 0.11.0 (#2158),888,326497,2021-01-26 14:59:23-08:00,"['allclasses-frame.html', 'allclasses-noframe.html', 'constant-values.html', 'deprecated-list.html', 'help-doc.html', 'index-all.html', 'index.html', 'Accessor.html', 'Accessors.html', 'AllDataFilesTable.AllDataFilesTableScan.html', 'AllDataFilesTable.html', 'AllEntriesTable.html', 'AllManifestsTable.AllManifestsTableScan.html', 'AllManifestsTable.html', 'AppendFiles.html', 'BaseCombinedScanTask.html', 'BaseMetastoreCatalog.BaseMetastoreCatalogTableBuilder.html', 'BaseMetastoreCatalog.html', 'BaseMetastoreTableOperations.html', 'BaseOverwriteFiles.html', 'BaseReplacePartitions.html', 'BaseReplaceSortOrder.html', 'BaseRewriteManifests.html', 'BaseTable.html', 'CachingCatalog.html', 'CatalogProperties.html', 'CatalogUtil.html', 'CombinedScanTask.html', 'ContentFile.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DataFilesTable.FilesTableScan.html', 'DataFilesTable.html', 'DataOperations.html', 'DataTableScan.html', 'DataTask.html', 'DeleteFile.html', 'DeleteFiles.html', 'DistributionMode.html', 'ExpireSnapshots.html', 'FieldMetrics.html', 'FileContent.html', 'FileFormat.html', 'FileMetadata.Builder.html', 'FileMetadata.html', 'FileScanTask.html', 'Files.html', 'FindFiles.Builder.html', 'FindFiles.html', 'FloatFieldMetrics.html', 'GenericManifestFile.CopyBuilder.html', 'GenericManifestFile.html', 'GenericPartitionFieldSummary.html', 'GuavaClasses.html', 'HasTableOperations.html', 'HistoryEntry.html', 'HistoryTable.html', 'IsolationLevel.html', 'LocationProviders.html', 'ManageSnapshots.html', 'ManifestContent.html', 'ManifestEntriesTable.html', 'ManifestFile.PartitionFieldSummary.html', 'ManifestFile.html', 'ManifestFiles.html', 'ManifestReader.FileType.html', 'ManifestReader.html', 'ManifestWriter.html', 'ManifestsTable.html', 'MetadataColumns.html', 'MetadataTableType.html', 'MetadataTableUtils.html', 'Metrics.html', 'MetricsConfig.html', 'MetricsModes.Counts.html', 'MetricsModes.Full.html', 'MetricsModes.MetricsMode.html', 'MetricsModes.None.html', 'MetricsModes.Truncate.html', 'MetricsModes.html', 'MetricsUtil.html', 'MicroBatches.MicroBatch.html', 'MicroBatches.MicroBatchBuilder.html', 'MicroBatches.html', 'NullOrder.html', 'OverwriteFiles.html', 'PartitionField.html', 'PartitionKey.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'Partitioning.html', 'PartitionsTable.html', 'PendingUpdate.html', 'ReplacePartitions.html', 'ReplaceSortOrder.html', 'RewriteFiles.html', 'RewriteManifests.html', 'Rollback.html', 'RowDelta.html', 'ScanSummary.Builder.html', 'ScanSummary.PartitionMetrics.html', 'ScanSummary.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'SetLocation.html', 'Snapshot.html', 'SnapshotManager.html', 'SnapshotParser.html', 'SnapshotSummary.Builder.html', 'SnapshotSummary.html', 'SnapshotUpdate.html', 'SnapshotsTable.html', 'SortDirection.html', 'SortField.html', 'SortOrder.Builder.html', 'SortOrder.html', 'SortOrderBuilder.html', 'SortOrderParser.html', 'StaticTableOperations.html', 'StructLike.html', 'SystemProperties.html', 'Table.html', 'TableMetadata.MetadataLogEntry.html', 'TableMetadata.SnapshotLogEntry.html', 'TableMetadata.html', 'TableMetadataParser.Codec.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableProperties.html', 'TableScan.html', 'Tables.html', 'Transaction.html', 'Transactions.html', 'UpdateLocation.html', 'UpdatePartitionSpec.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Action.html', 'Actions.html', 'BaseRewriteDataFilesAction.html', 'CreateAction.html', 'ExpireSnapshotsAction.html', 'ExpireSnapshotsActionResult.html', 'ManifestFileBean.html', 'RemoveOrphanFilesAction.html', 'RewriteDataFilesAction.html', 'RewriteDataFilesActionResult.html', 'RewriteManifestsAction.html', 'RewriteManifestsActionResult.html', 'SnapshotAction.html', 'SnapshotUpdateAction.html', 'Spark3MigrateAction.html', 'Spark3SnapshotAction.html', 'SparkActions.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ArrowAllocation.html', 'ArrowSchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'NullabilityHolder.html', 'VectorHolder.ConstantVectorHolder.html', 'VectorHolder.PositionVectorHolder.html', 'VectorHolder.html', 'VectorizedArrowReader.ConstantVectorReader.html', 'VectorizedArrowReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseVectorizedParquetValuesReader.html', 'VectorizedColumnIterator.html', 'VectorizedDictionaryEncodedParquetValuesReader.html', 'VectorizedPageIterator.html', 'VectorizedParquetDefinitionLevelReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Avro.DeleteWriteBuilder.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroEncoderUtil.html', 'AvroIterable.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'AvroSchemaWithTypeVisitor.html', 'AvroWithPartnerByStructureVisitor.html', 'LogicalMap.html', 'ProjectionDatumReader.html', 'RemoveIds.html', 'SupportsRowPosition.html', 'UUIDConversion.html', 'ValueReader.html', 'ValueReaders.StructReader.html', 'ValueReaders.html', 'ValueWriter.html', 'ValueWriters.StructWriter.html', 'ValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AssumeRoleAwsClientFactory.html', 'AwsClientFactories.html', 'AwsClientFactory.html', 'AwsProperties.html', 'GlueCatalog.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'S3FileIO.html', 'S3InputFile.html', 'S3OutputFile.html', 'S3RequestUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Catalog.TableBuilder.html', 'Catalog.html', 'Namespace.html', 'SupportsNamespaces.html', 'TableIdentifier.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DeleteFilter.html', 'GenericAppenderFactory.html', 'GenericDeleteFilter.html', 'GenericRecord.html', 'IcebergGenerics.ScanBuilder.html', 'IcebergGenerics.html', 'IdentityPartitionConverters.html', 'InternalRecordWrapper.html', 'Record.html', 'DataReader.html', 'DataWriter.html', 'DecoderResolver.html', 'IcebergDecoder.html', 'IcebergEncoder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericOrcReader.html', 'GenericOrcReaders.html', 'GenericOrcWriter.html', 'GenericOrcWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseParquetReaders.html', 'BaseParquetWriter.html', 'GenericParquetReaders.html', 'GenericParquetWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Deletes.html', 'EqualityDeleteWriter.html', 'PositionDelete.html', 'PositionDeleteWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'EncryptedFiles.html', 'EncryptedInputFile.html', 'EncryptedOutputFile.html', 'EncryptionKeyMetadata.html', 'EncryptionKeyMetadatas.html', 'EncryptionManager.html', 'PlaintextEncryptionManager.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CreateSnapshotEvent.html', 'IncrementalScanEvent.html', 'Listener.html', 'Listeners.html', 'ScanEvent.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CherrypickAncestorCommitException.html', 'CommitFailedException.html', 'DuplicateWAPCommitException.html', 'NamespaceNotEmptyException.html', 'NoSuchIcebergTableException.html', 'NoSuchNamespaceException.html', 'NoSuchTableException.html', 'NotFoundException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'Bound.html', 'BoundLiteralPredicate.html', 'BoundPredicate.html', 'BoundReference.html', 'BoundSetPredicate.html', 'BoundTerm.html', 'BoundTransform.html', 'BoundUnaryPredicate.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.BoundVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'InclusiveMetricsEvaluator.html', 'Literal.html', 'ManifestEvaluator.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'StrictMetricsEvaluator.html', 'Term.html', 'True.html', 'Unbound.html', 'UnboundPredicate.html', 'UnboundTerm.html', 'UnboundTransform.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CatalogLoader.CustomCatalogLoader.html', 'CatalogLoader.HadoopCatalogLoader.html', 'CatalogLoader.HiveCatalogLoader.html', 'CatalogLoader.html', 'FlinkCatalog.html', 'FlinkCatalogFactory.html', 'FlinkFilters.html', 'FlinkSchemaUtil.html', 'FlinkTableFactory.html', 'FlinkTableOptions.html', 'FlinkTypeVisitor.html', 'IcebergTableSink.html', 'IcebergTableSource.html', 'RowDataWrapper.html', 'TableLoader.CatalogTableLoader.html', 'TableLoader.HadoopTableLoader.html', 'TableLoader.html', 'Actions.html', 'RewriteDataFilesAction.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AvroWithFlinkSchemaVisitor.html', 'FlinkAvroReader.html', 'FlinkAvroWriter.html', 'FlinkOrcReader.html', 'FlinkOrcWriter.html', 'FlinkParquetReaders.html', 'FlinkParquetWriters.html', 'FlinkValueReaders.html', 'FlinkValueWriters.html', 'ParquetWithFlinkSchemaVisitor.html', 'RowDataUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'FlinkAppenderFactory.html', 'FlinkSink.Builder.html', 'FlinkSink.html', 'RowDataTaskWriterFactory.html', 'TaskWriterFactory.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'FlinkInputFormat.html', 'FlinkInputSplit.html', 'FlinkSource.Builder.html', 'FlinkSource.html', 'RowDataRewriter.RewriteMap.html', 'RowDataRewriter.html', 'StreamingMonitorFunction.html', 'StreamingReaderOperator.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ConfigProperties.html', 'HadoopCatalog.html', 'HadoopFileIO.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTableOperations.html', 'HadoopTables.html', 'HiddenPathFilter.html', 'SerializableConfiguration.html', 'Util.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ClientPool.Action.html', 'ClientPool.html', 'HiveCatalog.html', 'HiveCatalogs.html', 'HiveClientPool.html', 'HiveSchemaUtil.html', 'HiveTableOperations.html', 'MetastoreUtil.html', 'RuntimeMetaException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseTaskWriter.BaseEqualityDeltaWriter.html', 'BaseTaskWriter.RollingEqDeleteWriter.html', 'BaseTaskWriter.RollingFileWriter.html', 'BaseTaskWriter.html', 'CloseableGroup.html', 'CloseableIterable.ConcatCloseableIterable.html', 'CloseableIterable.html', 'CloseableIterator.html', 'ClosingIterator.html', 'DataWriter.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'DeleteSchemaUtil.html', 'FileAppender.html', 'FileAppenderFactory.html', 'FileIO.html', 'FilterIterator.html', 'InputFile.html', 'LocationProvider.html', 'OutputFile.html', 'OutputFileFactory.html', 'PartitionedFanoutWriter.html', 'PartitionedWriter.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'TaskWriter.html', 'UnpartitionedWriter.html', 'WriteResult.Builder.html', 'WriteResult.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'MappedField.html', 'MappedFields.html', 'MappingUtil.html', 'NameMapping.html', 'NameMappingParser.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CatalogLoader.html', 'Catalogs.html', 'InputFormatConfig.ConfigBuilder.html', 'InputFormatConfig.InMemoryDataModel.html', 'InputFormatConfig.html', 'HiveIcebergFilterFactory.html', 'HiveIcebergInputFormat.html', 'HiveIcebergMetaHook.html', 'HiveIcebergOutputCommitter.html', 'HiveIcebergOutputFormat.html', 'HiveIcebergSerDe.html', 'HiveIcebergSplit.html', 'HiveIcebergStorageHandler.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergBinaryObjectInspector.html', 'IcebergDateObjectInspector.html', 'IcebergDateObjectInspectorHive3.html', 'IcebergDecimalObjectInspector.html', 'IcebergFixedObjectInspector.html', 'IcebergObjectInspector.html', 'IcebergRecordObjectInspector.html', 'IcebergTimeObjectInspector.html', 'IcebergTimestampObjectInspector.html', 'IcebergTimestampObjectInspectorHive3.html', 'IcebergTimestampWithZoneObjectInspector.html', 'IcebergTimestampWithZoneObjectInspectorHive3.html', 'IcebergUUIDObjectInspector.html', 'WriteObjectInspector.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Container.html', 'MapredIcebergInputFormat.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergInputFormat.html', 'IcebergSplit.html', 'IcebergSplitContainer.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'NessieCatalog.html', 'NessieTableOperations.html', 'NessieUtil.html', 'TableReference.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ORC.ReadBuilder.html', 'ORC.WriteBuilder.html', 'ORC.html', 'ORCSchemaUtil.BinaryType.html', 'ORCSchemaUtil.LongType.html', 'ORCSchemaUtil.html', 'OrcBatchReader.html', 'OrcMetrics.html', 'OrcRowReader.html', 'OrcRowWriter.html', 'OrcSchemaVisitor.html', 'OrcSchemaWithTypeVisitor.html', 'OrcValueReader.html', 'OrcValueReaders.StructReader.html', 'OrcValueReaders.html', 'OrcValueWriter.html', 'VectorizedRowBatchIterator.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseColumnIterator.html', 'BasePageIterator.IntIterator.html', 'BasePageIterator.html', 'ColumnIterator.html', 'ColumnWriter.html', 'Parquet.DeleteWriteBuilder.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetAvroReader.html', 'ParquetAvroValueReaders.TimeMillisReader.html', 'ParquetAvroValueReaders.TimestampMillisReader.html', 'ParquetAvroValueReaders.html', 'ParquetAvroWriter.html', 'ParquetDictionaryRowGroupFilter.html', 'ParquetIterable.html', 'ParquetMetricsRowGroupFilter.html', 'ParquetReader.html', 'ParquetSchemaUtil.HasIds.html', 'ParquetSchemaUtil.html', 'ParquetTypeVisitor.html', 'ParquetUtil.html', 'ParquetValueReader.html', 'ParquetValueReaders.BinaryAsDecimalReader.html', 'ParquetValueReaders.ByteArrayReader.html', 'ParquetValueReaders.BytesReader.html', 'ParquetValueReaders.FloatAsDoubleReader.html', 'ParquetValueReaders.IntAsLongReader.html', 'ParquetValueReaders.IntegerAsDecimalReader.html', 'ParquetValueReaders.ListReader.html', 'ParquetValueReaders.LongAsDecimalReader.html', 'ParquetValueReaders.MapReader.html', 'ParquetValueReaders.PrimitiveReader.html', 'ParquetValueReaders.RepeatedKeyValueReader.html', 'ParquetValueReaders.RepeatedReader.html', 'ParquetValueReaders.ReusableEntry.html', 'ParquetValueReaders.StringReader.html', 'ParquetValueReaders.StructReader.html', 'ParquetValueReaders.UnboxedReader.html', 'ParquetValueReaders.html', 'ParquetValueWriter.html', 'ParquetValueWriters.PositionDeleteStructWriter.html', 'ParquetValueWriters.PrimitiveWriter.html', 'ParquetValueWriters.RepeatedKeyValueWriter.html', 'ParquetValueWriters.RepeatedWriter.html', 'ParquetValueWriters.StructWriter.html', 'ParquetValueWriters.html', 'ParquetWriteAdapter.html', 'RemoveIds.html', 'TripleWriter.html', 'TypeToMessageType.html', 'TypeWithSchemaVisitor.html', 'ValuesAsBytesReader.html', 'VectorizedParquetReader.html', 'VectorizedReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergPigInputFormat.IcebergRecordReader.html', 'IcebergPigInputFormat.html', 'IcebergStorage.html', 'PigParquetReader.html', 'SchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'SchemaWithPartnerVisitor.PartnerAccessors.html', 'SchemaWithPartnerVisitor.html', 'UnionByNameVisitor.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSpark.html', 'PathIdentifier.html', 'PruneColumnsWithReordering.html', 'PruneColumnsWithoutReordering.html', 'RollbackStagedTable.html', 'Spark3Util.CatalogAndIdentifier.html', 'Spark3Util.DescribeSchemaVisitor.html', 'Spark3Util.html', 'SparkCatalog.html', 'SparkDataFile.html', 'SparkExceptionUtil.html', 'SparkFilters.html', 'SparkReadOptions.html', 'SparkSchemaUtil.html', 'SparkSessionCatalog.html', 'SparkStructLike.html', 'SparkTableUtil.SparkPartition.html', 'SparkTableUtil.html', 'SparkUtil.html', 'SparkValueConverter.html', 'SparkWriteOptions.html', 'AvroWithSparkSchemaVisitor.html', 'ParquetWithSparkSchemaVisitor.html', 'SparkAvroReader.html', 'SparkAvroWriter.html', 'SparkOrcReader.html', 'SparkOrcValueReaders.html', 'SparkOrcWriter.html', 'SparkParquetReaders.html', 'SparkParquetWriters.html', 'SparkValueReaders.html', 'SparkValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ArrowVectorAccessor.html', 'ArrowVectorAccessors.html', 'ColumnarBatchReader.html', 'IcebergArrowColumnVector.html', 'RowPostitionColumnVector.html', 'VectorizedSparkOrcReaders.html', 'VectorizedSparkParquetReaders.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ExpireSnapshotsProcedure.html', 'RemoveOrphanFilesProcedure.html', 'SparkProcedures.ProcedureBuilder.html', 'SparkProcedures.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CustomCatalogs.html', 'IcebergSource.html', 'RowDataRewriter.html', 'SparkPartitionedFanoutWriter.html', 'SparkPartitionedWriter.html', 'SparkScanBuilder.html', 'SparkTable.html', 'StagedSparkTable.html', 'Stats.html', 'StreamingWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PartitionSpecVisitor.html', 'SortOrderVisitor.html', 'Transform.html', 'Transforms.html', 'UnknownTransform.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CheckCompatibility.html', 'Comparators.html', 'Conversions.html', 'FixupTypes.html', 'IndexByName.html', 'IndexParents.html', 'JavaHash.html', 'JavaHashes.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ArrayUtil.html', 'BinPacking.ListPacker.html', 'BinPacking.PackingIterable.html', 'BinPacking.html', 'BinaryUtil.html', 'ByteBuffers.html', 'CharSequenceSet.html', 'CharSequenceWrapper.html', 'DateTimeUtil.html', 'DecimalUtil.html', 'ExceptionUtil.Block.html', 'ExceptionUtil.CatchBlock.html', 'ExceptionUtil.FinallyBlock.html', 'ExceptionUtil.html', 'Exceptions.html', 'Filter.html', 'JsonUtil.html', 'ManifestFileUtil.html', 'NaNUtil.html', 'Pair.html', 'ParallelIterable.html', 'PartitionSet.html', 'PartitionUtil.html', 'PropertyUtil.html', 'SerializableSupplier.html', 'SerializationUtil.html', 'SnapshotUtil.html', 'SortedMerge.html', 'StructLikeMap.html', 'StructLikeSet.html', 'StructLikeWrapper.html', 'StructProjection.html', 'TableScanUtil.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'ThreadPools.html', 'UUIDUtil.html', 'UnicodeUtil.html', 'WapUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'NoSuchProcedureException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSqlExtensionsBaseListener.html', 'IcebergSqlExtensionsBaseVisitor.html', 'IcebergSqlExtensionsLexer.html', 'IcebergSqlExtensionsListener.html', 'IcebergSqlExtensionsParser.AddPartitionFieldContext.html', 'IcebergSqlExtensionsParser.ApplyTransformContext.html', 'IcebergSqlExtensionsParser.BigDecimalLiteralContext.html', 'IcebergSqlExtensionsParser.BigIntLiteralContext.html', 'IcebergSqlExtensionsParser.BooleanLiteralContext.html', 'IcebergSqlExtensionsParser.BooleanValueContext.html', 'IcebergSqlExtensionsParser.CallArgumentContext.html', 'IcebergSqlExtensionsParser.CallContext.html', 'IcebergSqlExtensionsParser.ConstantContext.html', 'IcebergSqlExtensionsParser.DecimalLiteralContext.html', 'IcebergSqlExtensionsParser.DoubleLiteralContext.html', 'IcebergSqlExtensionsParser.DropPartitionFieldContext.html', 'IcebergSqlExtensionsParser.ExponentLiteralContext.html', 'IcebergSqlExtensionsParser.ExpressionContext.html', 'IcebergSqlExtensionsParser.FloatLiteralContext.html', 'IcebergSqlExtensionsParser.IdentifierContext.html', 'IcebergSqlExtensionsParser.IdentityTransformContext.html', 'IcebergSqlExtensionsParser.IntegerLiteralContext.html', 'IcebergSqlExtensionsParser.MultipartIdentifierContext.html', 'IcebergSqlExtensionsParser.NamedArgumentContext.html', 'IcebergSqlExtensionsParser.NonReservedContext.html', 'IcebergSqlExtensionsParser.NumberContext.html', 'IcebergSqlExtensionsParser.NumericLiteralContext.html', 'IcebergSqlExtensionsParser.OrderContext.html', 'IcebergSqlExtensionsParser.OrderFieldContext.html', 'IcebergSqlExtensionsParser.PositionalArgumentContext.html', 'IcebergSqlExtensionsParser.QuotedIdentifierAlternativeContext.html', 'IcebergSqlExtensionsParser.QuotedIdentifierContext.html', 'IcebergSqlExtensionsParser.SetTableOrderContext.html', 'IcebergSqlExtensionsParser.SingleStatementContext.html', 'IcebergSqlExtensionsParser.SmallIntLiteralContext.html', 'IcebergSqlExtensionsParser.StatementContext.html', 'IcebergSqlExtensionsParser.StringLiteralContext.html', 'IcebergSqlExtensionsParser.StringMapContext.html', 'IcebergSqlExtensionsParser.TinyIntLiteralContext.html', 'IcebergSqlExtensionsParser.TransformArgumentContext.html', 'IcebergSqlExtensionsParser.TransformContext.html', 'IcebergSqlExtensionsParser.TypeConstructorContext.html', 'IcebergSqlExtensionsParser.UnquotedIdentifierContext.html', 'IcebergSqlExtensionsParser.html', 'IcebergSqlExtensionsVisitor.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ExtendedSupportsDelete.html', 'Procedure.html', 'ProcedureCatalog.html', 'ProcedureParameter.html', 'SupportsMerge.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ClusteredDistribution.html', 'Distribution.html', 'Distributions.html', 'OrderedDistribution.html', 'UnspecifiedDistribution.html', 'ClusterDistributionImpl.html', 'OrderedDistributionImpl.html', 'UnspecifiedDistributionImpl.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'NullOrdering.html', 'SortDirection.html', 'SortOrder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'SupportsFileFilter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'MergeBuilder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'overview-frame.html', 'overview-summary.html', 'overview-tree.html', 'package-list', 'script.js', 'serialized-form.html', 'stylesheet.css']"
Spark: Introduce companion objects for DELETE and MERGE rewrite rules (#2156),3,41,2021-01-26 15:43:14-08:00,"['RewriteDelete.scala', 'RewriteMergeInto.scala', 'RewriteRowLevelOperationHelper.scala']"
Hive: Fix file extensions for written files (#2155),2,5,2021-01-27 09:08:15+01:00,"['HiveIcebergOutputFormat.java', 'TestHiveIcebergStorageHandlerWithEngine.java']"
Hive: Fix identity partitioned writes (#2151),3,153,2021-01-27 15:56:55+01:00,"['HiveIcebergOutputFormat.java', 'TestHiveIcebergStorageHandlerWithEngine.java', 'TestTables.java']"
Core: Allow building unsorted orders (#2164),2,25,2021-01-27 15:05:40-08:00,"['SortOrder.java', 'TestSortOrder.java']"
Spark: Don't distribute records in DELETE if mode is none (#2166),2,26,2021-01-27 18:05:58-08:00,"['RewriteDelete.scala', 'Spark3Util.java']"
"Spark: Add truncate expression for sorting  (#2153)

Co-authored-by: Dilip Biswal <dbiswal@adobe.com>",3,118,2021-01-28 09:49:28-08:00,"['TransformExpressions.scala', 'DistributionAndOrderingUtils.scala', 'TestMergeIntoTable.java']"
"Core: Use listStatusIterator in HadoopCatalog to improve performance #2124 (#2125)

Move to RemoteIterator for scanning directories.
It's not as elegant as using the java8 streaming, but it works with
the prefetching that the s3a and (soon) abfs connectors do, as well
as bailing out more efficiently.",2,48,2021-01-28 09:51:26-08:00,"['HadoopCatalog.java', 'TestHadoopCatalog.java']"
Core: Improve error messages in CatalogUtil.loadCatalog (#2146),3,100,2021-01-28 11:54:19-08:00,"['CatalogUtil.java', 'TestCatalogErrorConstructor.java', 'TestCatalogUtil.java']"
Doc: Add blog page (#2177),2,52,2021-01-28 12:24:26-08:00,"['blogs.md', 'mkdocs.yml']"
Spark: Refactor metadata column projection in merge plans (#2117),3,28,2021-01-28 13:34:29-08:00,"['RewriteRowLevelOperationHelper.scala', 'ExtendedDataSourceV2Implicits.scala', 'SparkScanBuilder.java']"
"Docs: Refactor Spark pages (#2160)

This breaks the Spark page across several smaller pages. The Spark page is currently still available for existing permalinks.",10,2128,2021-01-28 13:51:19-08:00,"['configuration.md', 'evolution.md', 'getting-started.md', 'spark-configuration.md', 'spark-ddl.md', 'spark-procedures.md', 'spark-queries.md', 'spark-writes.md', 'spark.md', 'mkdocs.yml']"
Spark: Add a test for MERGE modifying a null struct (#2179),2,58,2021-01-28 17:17:23-08:00,"['SparkTestBase.java', 'TestMerge.java']"
"Docs: Add to release notes for 0.11.0, misc fixes (#2178)",4,34,2021-01-28 17:19:17-08:00,"['aws.md', 'flink.md', 'releases.md', 'spark.md']"
Hive: Use default client pool size from CatalogProperties (#2180),1,5,2021-01-28 18:20:13-08:00,['HiveCatalog.java']
Spark: Do not modify location in HadoopInputFile (#2170),1,40,2021-01-29 09:58:02-08:00,['HadoopInputFile.java']
Spark: Extend write distribution and ordering with more options (#2165),8,526,2021-01-29 14:17:25-08:00,"['IcebergSqlExtensions.g4', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'SetWriteDistributionAndOrdering.scala', 'ExtendedDataSourceV2Strategy.scala', 'SetWriteDistributionAndOrderingExec.scala', 'TestSetWriteDistributionAndOrdering.java', 'TestSetWriteOrder.java']"
Spark: Add more tests for action alignment in MERGE (#2185),2,82,2021-01-29 14:51:14-08:00,"['SparkTestBase.java', 'TestMerge.java']"
Spark: Add more tests for the migrate action (#2087),1,295,2021-01-29 16:28:36-08:00,['TestCreateActions.java']
Core: Add lastAssignedPartitionId to TableMetadata (#2089),8,188,2021-01-30 13:48:52-08:00,"['BaseUpdatePartitionSpec.java', 'TableMetadata.java', 'TableMetadataParser.java', 'TestTableMetadata.java', 'TestTableUpdatePartitionSpec.java', 'TableMetadataV2MissingLastAssignedPartitionId.json', 'TableMetadataV2MissingSortOrder.json', 'TableMetadataV2Valid.json']"
Core: Bump Jackson to 2.11.4 (#2084),2,8,2021-02-01 09:56:41-08:00,"['build.gradle', 'versions.props']"
Hive: Update to 2.3.8 (#2110),2,12,2021-02-01 10:43:24-08:00,"['build.gradle', 'versions.props']"
Format: Rename last-assigned-partition-id to last-partition-id in table metadata (#2188),5,18,2021-02-01 12:51:54-08:00,"['TableMetadataParser.java', 'TestTableMetadata.java', 'TableMetadataV2MissingLastPartitionId.json', 'TableMetadataV2MissingSortOrder.json', 'TableMetadataV2Valid.json']"
Flink: Upgrade version from 1.11.0 to 1.12.1 (#1956),18,343,2021-02-02 15:57:24+08:00,"['FlinkCatalog.java', 'Actions.java', 'FlinkSink.java', 'FlinkSource.java', 'FlinkCompatibilityUtil.java', 'FlinkCatalogTestBase.java', 'FlinkTestBase.java', 'MiniClusterResource.java', 'TestFlinkCatalogTable.java', 'TestFlinkTableSink.java', 'TestFlinkTableSource.java', 'TestHelpers.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkV2.java', 'TestFlinkScan.java', 'TestFlinkScanSql.java', 'TestStreamScanSql.java', 'versions.props']"
Spark: Optimize insert only case in MERGE (#2189),3,96,2021-02-02 12:01:03-08:00,"['scalastyle_config.xml', 'RewriteMergeInto.scala', 'TestMerge.java']"
"Spark: Make merge row conditions positive for readability (#2187)

Co-authored-by: Dilip Biswal <dbiswal@adobe.com>",3,26,2021-02-02 13:01:20-08:00,"['RewriteMergeInto.scala', 'MergeInto.scala', 'MergeIntoExec.scala']"
Build: Enforce one import per line in Scalastyle (#2199),15,119,2021-02-02 14:08:50-08:00,"['scalastyle_config.xml', 'IcebergSparkSessionExtensions.scala', 'AlignMergeIntoTable.scala', 'AssignmentAlignmentSupport.scala', 'DeleteFromTablePredicateCheck.scala', 'ProcedureArgumentCoercion.scala', 'ResolveProcedures.scala', 'OptimizeConditionsInRowLevelOperations.scala', 'PullupCorrelatedPredicatesInRowLevelOperations.scala', 'IcebergSparkSqlExtensionsParser.scala', 'Call.scala', 'DynamicFileFilter.scala', 'DynamicFileFilterExec.scala', 'ExtendedBatchScanExec.scala', 'SetWriteDistributionAndOrderingExec.scala']"
Hive: Add test case for writes with projection and column specification (#2121),3,44,2021-02-02 16:08:24-08:00,"['HiveIcebergTestUtils.java', 'TestHiveIcebergStorageHandlerWithEngine.java', 'TestHiveShell.java']"
"Hive: Avoid closing null writer in output committer abortTask (#2150)

Co-authored-by: Marton Bod <mbod@cloudera.com>",3,58,2021-02-02 16:12:34-08:00,"['HiveIcebergOutputCommitter.java', 'HiveIcebergRecordWriter.java', 'TestHiveIcebergOutputCommitter.java']"
Spec: Add metadata-log (#2200),1,2,2021-02-02 16:16:40-08:00,['spec.md']
Core: Include record_count with stats in ManifestReader (#1820),3,116,2021-02-02 17:04:17-08:00,"['ManifestGroup.java', 'ManifestReader.java', 'TestManifestReaderStats.java']"
ORC: Collect NaN counts in ORC writers (#1790),17,331,2021-02-02 17:30:38-08:00,"['TestMetrics.java', 'GenericOrcWriter.java', 'GenericOrcWriters.java', 'TestMergingMetrics.java', 'TestGenericMergingMetrics.java', 'FlinkOrcWriter.java', 'FlinkOrcWriters.java', 'FlinkSchemaVisitor.java', 'ORCSchemaUtil.java', 'OrcFileAppender.java', 'OrcMetrics.java', 'OrcRowWriter.java', 'OrcValueWriter.java', 'ParquetValueWriter.java', 'SparkOrcValueWriter.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java']"
Core: Add sort order id to DataFile and DeleteFile (#1975),13,113,2021-02-02 17:46:51-08:00,"['ContentFile.java', 'DataFile.java', 'BaseFile.java', 'DataFiles.java', 'FileMetadata.java', 'GenericDataFile.java', 'GenericDeleteFile.java', 'V1Metadata.java', 'V2Metadata.java', 'TestManifestWriterVersions.java', 'SparkDataFile.java', 'TestDataFileSerialization.java', 'TestSparkDataFile.java']"
Avro: Add MetricsAwareDatumWriter (#1946),12,204,2021-02-02 18:00:37-08:00,"['Comparators.java', 'Avro.java', 'AvroFileAppender.java', 'AvroMetrics.java', 'GenericAvroWriter.java', 'MetricsAwareDatumWriter.java', 'ValueWriter.java', 'DataWriter.java', 'GenericAppenderFactory.java', 'FlinkAvroWriter.java', 'FlinkAppenderFactory.java', 'SparkAvroWriter.java']"
Spark: Support UPDATE statements without subqueries (#2193),11,851,2021-02-02 20:24:03-08:00,"['IcebergSparkSessionExtensions.scala', 'AlignRowLevelOperations.scala', 'OptimizeConditionsInRowLevelOperations.scala', 'RewriteDelete.scala', 'RewriteMergeInto.scala', 'RewriteUpdate.scala', 'RewriteRowLevelOperationHelper.scala', 'SparkRowLevelOperationsTestBase.java', 'TestCopyOnWriteUpdate.java', 'TestDelete.java', 'TestUpdate.java']"
Spark: Remove irrelevant TODO items for row-level ops (#2207),2,3,2021-02-03 14:42:04-08:00,"['IcebergSparkSessionExtensions.scala', 'RewriteDelete.scala']"
Spark: Add more tests with multiple subqueries in DELETE (#2205),1,28,2021-02-03 14:42:49-08:00,['TestDelete.java']
"Core: Fix data loss in compact action (#2196)

Fixes #2195.",2,65,2021-02-03 17:19:14-08:00,"['BaseRewriteDataFilesAction.java', 'TestRewriteDataFilesAction.java']"
Spark: Support UPDATE statements with subqueries (#2206),9,454,2021-02-03 20:11:29-08:00,"['IcebergSparkSessionExtensions.scala', 'DeleteFromTablePredicateCheck.scala', 'RowLevelOperationsPredicateCheck.scala', 'PullupCorrelatedPredicatesInRowLevelOperations.scala', 'RewriteUpdate.scala', 'SparkRowLevelOperationsTestBase.java', 'TestDelete.java', 'TestUpdate.java', 'SparkMergeScan.java']"
"Flink:  Add job name for RewriteDataFilesAction (#2197)

Co-authored-by: zhangjun <jun.zhang1@ly.com>",2,13,2021-02-04 16:10:14+08:00,"['RewriteDataFilesAction.java', 'RowDataRewriter.java']"
"Hive: Update Hive write path for Tez (#2163)

Co-authored-by: Marton Bod <mbod@cloudera.com>",5,162,2021-02-04 14:34:05-08:00,"['HiveIcebergOutputCommitter.java', 'HiveIcebergOutputFormat.java', 'TezUtil.java', 'TestHiveIcebergOutputCommitter.java', 'TestHiveIcebergStorageHandlerWithEngine.java']"
Spark: Fix _pos metadata column in SparkAvroReader (#2215),1,11,2021-02-04 16:53:26-08:00,['SparkAvroReader.java']
Hive: Avoid drop table related exceptions in MetaHook (#2191),3,104,2021-02-05 11:23:02+01:00,"['HiveIcebergMetaHook.java', 'TestHiveIcebergStorageHandlerNoScan.java', 'TestTables.java']"
Core: Add contains_nan to manifest list partition summaries (#1872),13,305,2021-02-05 09:38:12-08:00,"['ManifestFile.java', 'ManifestEvaluator.java', 'TestHelpers.java', 'TestInclusiveManifestEvaluator.java', 'AllManifestsTable.java', 'GenericPartitionFieldSummary.java', 'ManifestsTable.java', 'PartitionSummary.java', 'ManifestFileUtil.java', 'TestManifestListVersions.java', 'TestManifestWriter.java', 'TestManifestFileSerialization.java', 'TestIcebergSourceTablesBase.java']"
ORC: Grow list and map child vectors with a growth factor of 3 (#2218),6,283,2021-02-05 18:04:47-08:00,"['GenericOrcWriters.java', 'FlinkOrcWriters.java', 'SparkOrcValueWriters.java', 'IcebergSourceNestedListDataBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java']"
Spark: Add more tests for MERGE (#2213),1,379,2021-02-05 18:13:22-08:00,['TestMerge.java']
Spark: Consolidate MERGE tests (#2222),3,1097,2021-02-08 10:04:44-08:00,"['TestIcebergExpressions.java', 'TestMerge.java', 'TestMergeIntoTable.java']"
Hive: Fix connection pool fails to reconnect to the Hive Metastore #1994 (#2119),3,122,2021-02-09 09:16:59+01:00,"['ClientPool.java', 'HiveClientPool.java', 'TestClientPool.java']"
Core: Support adding columns deleted in the same operation (#2204),2,61,2021-02-09 14:05:27-08:00,"['SchemaUpdate.java', 'TestSchemaUpdate.java']"
Spac: Add last-partition-id in table metadata (#2224),2,4,2021-02-10 10:55:13-08:00,"['spec.md', 'README.md']"
"Core: Change default write.target-file-size-bytes to 512 MB (#2220)

Co-authored-by: Szehon Ho <szehon_ho@apple.com>",1,2,2021-02-10 10:57:04-08:00,['TableProperties.java']
Spark: Remove hardcoded file size from data source options test (#2234),1,17,2021-02-12 20:37:24-08:00,['TestDataSourceOptions.java']
"Parquet: Fix row group filters with promoted types (#2232)

This fixes Parquet row group filters when types have been promoted from int to long or from float to double.

The filters are passed the file schema after ids are added, which is used to convert dictionary values or lower/upper bounds. That conversion currently uses the file's types to deserialize, but the filter expression is bound to the table types. If the types differ, then comparison in the evaluator fails.

This updates the conversion to first deserialize the Parquet value and then promote it if the table's type has changed. Only int to long and float to double are needed because those are the only type promotions that use a different representation.",5,58,2021-02-12 20:38:57-08:00,"['TestMetricsRowGroupFilter.java', 'ParquetConversions.java', 'ParquetDictionaryRowGroupFilter.java', 'ParquetMetricsRowGroupFilter.java', 'TestDictionaryRowGroupFilter.java']"
ORC: Fix vectorized reads with metadata columns (#2241),2,28,2021-02-16 10:39:25-08:00,"['BatchDataReader.java', 'TestUpdate.java']"
Hive: skip projection pushdown for output tables (#2246),3,65,2021-02-18 11:35:12+01:00,"['HiveIcebergSerDe.java', 'HiveIcebergStorageHandler.java', 'TestHiveIcebergStorageHandlerWithEngine.java']"
Docs: Add Adobe blog on read optimizations (#2250),1,4,2021-02-18 12:20:49-08:00,['blogs.md']
Hive: enable inserting data from joins (#2251),2,25,2021-02-19 11:28:42+01:00,"['HiveIcebergStorageHandler.java', 'TestHiveIcebergStorageHandlerWithEngine.java']"
Hive: removed Iceberg props should be removed from HMS table props too (#2252),2,32,2021-02-19 11:29:15+01:00,"['HiveTableOperations.java', 'TestHiveIcebergStorageHandlerNoScan.java']"
Spark: Make ignored UPDATE tests deterministic (#2243),1,6,2021-02-19 13:16:06-08:00,['TestUpdate.java']
Spark: Use nullSafeEval in transform expressions (#2238),1,35,2021-02-19 13:21:39-08:00,['TransformExpressions.scala']
Spark: Don't use resolveOperators in optimizer rules (#2242),3,6,2021-02-19 13:57:08-08:00,"['RewriteDelete.scala', 'RewriteMergeInto.scala', 'RewriteUpdate.scala']"
Spark: Add StreamingOffset for structured streaming reader (#2092),2,189,2021-02-21 15:36:49-08:00,"['StreamingOffset.java', 'TestStreamingOffset.java']"
Core: Add current-schema-id and schemas to table metadata (#2096),14,666,2021-02-22 16:16:04-08:00,"['Schema.java', 'TypeUtil.java', 'TestHelpers.java', 'SchemaParser.java', 'TableMetadata.java', 'TableMetadataParser.java', 'TestTableMetadata.java', 'TestTableMetadataSerialization.java', 'TableMetadataV2CurrentSchemaNotFound.json', 'TableMetadataV2MissingLastPartitionId.json', 'TableMetadataV2MissingPartitionSpecs.json', 'TableMetadataV2MissingSchemas.json', 'TableMetadataV2MissingSortOrder.json', 'TableMetadataV2Valid.json']"
"AWS: Use v2 single object delete, not bulk delete in S3FileIO (#2237)",1,12,2021-02-24 09:58:55-08:00,['S3FileIO.java']
Hive: Ensure unlock is called in HiveTableOperations to fix zombie locking (#2263),1,14,2021-02-24 10:12:09-08:00,['HiveTableOperations.java']
Core: Support unpartitioned specs in SortOrderUtil (#2239),2,100,2021-02-25 14:44:09-08:00,"['SortOrderUtil.java', 'TestSortOrderUtil.java']"
Hive: Fix predicate pushdown for Date (#2254),5,202,2021-02-26 12:51:10+01:00,"['HiveIcebergFilterFactory.java', 'IcebergInputFormat.java', 'TestHiveIcebergFilterFactory.java', 'TestHiveIcebergStorageHandlerTimezone.java', 'TestHiveIcebergStorageHandlerWithEngine.java']"
Hive: Quick fix for broken TestHiveIcebergFilterFactory.testTimestampType test (#2283),1,3,2021-02-28 21:45:57+01:00,['TestHiveIcebergFilterFactory.java']
Core: Add DeleteManifest position unit test. (#2271),2,30,2021-03-03 20:48:00+08:00,"['TableTestBase.java', 'TestManifestReader.java']"
AWS: Do not list non-iceberg table in GlueCatalog (#2267),3,123,2021-03-03 16:23:29-08:00,"['GlueCatalogNamespaceTest.java', 'GlueCatalog.java', 'GlueCatalogTest.java']"
"Python: Update docs for table create (#2291)

Fixes #2226",2,34,2021-03-03 17:08:03-08:00,"['python-api-intro.md', 'python-feature-support.md']"
API: Refactor Actions API (#2255),16,667,2021-03-04 12:28:21-08:00,"['Action.java', 'ActionsProvider.java', 'ExpireSnapshots.java', 'MigrateTable.java', 'RemoveOrphanFiles.java', 'RewriteDataFiles.java', 'RewriteManifests.java', 'SnapshotTable.java', 'SnapshotUpdate.java', 'BaseAction.java', 'BaseSnapshotUpdateAction.java', 'SnapshotUpdateAction.java', 'BaseSparkAction.java', 'CreateAction.java', 'ExpireSnapshotsAction.java', 'RemoveOrphanFilesAction.java']"
Flink: Refactor flink source tests for FLIP-27 unified source. (#2047),11,611,2021-03-05 11:21:11+08:00,"['RowDataUtil.java', 'TestFixtures.java', 'TestHelpers.java', 'TestFlinkInputFormat.java', 'TestFlinkInputFormatReaderDeletes.java', 'TestFlinkReaderDeletesBase.java', 'TestFlinkScan.java', 'TestFlinkScanSql.java', 'TestFlinkSource.java', 'TestStreamingMonitorFunction.java', 'TestStreamingReaderOperator.java']"
Python: Fix build and pin dependencies (#2268),5,33,2021-03-05 17:23:33-08:00,"['python-ci.yml', 'literals.py', 'parquet_to_iceberg.py', 'setup.py', 'tox.ini']"
Spark: Fix vectorization flags (#2248),3,109,2021-03-05 17:53:28-08:00,"['Reader.java', 'Spark3Util.java', 'SparkBatchScan.java']"
"Flink: Add FlinkCatalog.catalog accessor (#2259)

Co-authored-by: zhangjun <jun.zhang1@ly.com>",1,4,2021-03-05 17:54:44-08:00,['FlinkCatalog.java']
Spark: Refactor BaseSparkAction (#2297),5,172,2021-03-08 17:26:35-08:00,"['BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java', 'ExpireSnapshotsAction.java', 'RemoveOrphanFilesAction.java', 'RewriteManifestsAction.java']"
Core: Replace PartitionKey with StructLike in iceberg writers (#2310),3,35,2021-03-10 16:15:18+08:00,"['BaseTaskWriter.java', 'OutputFileFactory.java', 'SortedPosDeleteWriter.java']"
Core: Add prorperty to enable/disable vectorized ORC reads (#2315),3,15,2021-03-10 17:30:04-08:00,"['TableProperties.java', 'Reader.java', 'Spark3Util.java']"
Flink :  Refactor FlinkTableFactory to implement DynamicTableSinkFactory and DynamicTableSourceFactory (#2229),8,392,2021-03-11 14:43:08+08:00,"['FlinkCatalog.java', 'FlinkDynamicTableFactory.java', 'IcebergTableSink.java', 'IcebergTableSource.java', 'TestFlinkTableSource.java', 'TestRewriteDataFilesAction.java', 'FlinkTableFactory.html', 'FlinkTableFactory.html']"
Spark: Improve the test case testEqualityDeleteWithFilter (#2321),2,5,2021-03-12 10:30:30+08:00,"['DeleteReadTests.java', 'TestSparkReaderDeletes.java']"
Hive: Refactor HiveCatalog and HiveClientPool constructors (#2203),11,126,2021-03-11 21:53:17-08:00,"['CatalogLoader.java', 'FlinkTestBase.java', 'TestFlinkReaderDeletesBase.java', 'HiveCatalog.java', 'HiveCatalogs.java', 'HiveClientPool.java', 'HiveMetastoreTest.java', 'HiveTableTest.java', 'SparkTestBase.java', 'TestSparkReaderDeletes.java', 'SparkExtensionsTestBase.java']"
Core: Refactor HadoopCatalog constructors (#2323),2,52,2021-03-11 22:19:21-08:00,"['HadoopCatalog.java', 'CatalogLoader.java']"
Core: Add EqualityDeleteRowReader (#2320),5,177,2021-03-13 10:40:24+08:00,"['DeleteFilter.java', 'DeleteReadTests.java', 'EqualityDeleteRowReader.java', 'RowDataReader.java', 'TestSparkReaderDeletes.java']"
"Bump Nessie to version 0.4.0 (#2307)

* Bump Nessie to version 0.4.0

Contains some ""noise"" due to the renamed package `com.dremio.nessie` -> `org.projectnessie`.

Implicitly bumps Quarkus to 1.12.1.Final

Quarkus image building requires us to set the system property `quarkus.build.native-image`, which is not particularly
great and should be changed in the future on the Nessie-Quarkus-Gradle-Plugin side. It is a change in the behavior
since Quarkus 1.10 (Nessie 0.3.0 used Quarkus 1.9.1.Final) regarding how the Quarkus platform properties are applied,
which sadly also affects Quarkus builds that do not build a native image. Playing around with applying the Quarkus
bom, as suggested by Quarkus project, in various places (Gradle configs) didn't help here. I suspect, that's some
transitive dependency resolving issue.

* review comments",9,109,2021-03-15 08:53:36-07:00,"['build.gradle', 'NessieCatalog.java', 'NessieTableOperations.java', 'NessieUtil.java', 'UpdateableReference.java', 'BaseTestIceberg.java', 'TestBranchVisibility.java', 'TestNessieTable.java', 'versions.props']"
Spark: Add Spark UI description for actions (#2287),9,170,2021-03-15 16:36:32-07:00,"['BaseSparkAction.java', 'ExpireSnapshotsAction.java', 'RemoveOrphanFilesAction.java', 'RewriteManifestsAction.java', 'JobGroupInfo.java', 'JobGroupUtils.java', 'Spark3CreateAction.java', 'Spark3MigrateAction.java', 'Spark3SnapshotAction.java']"
Build: Remove JCenter repo (#2339),1,1,2021-03-16 12:35:22-07:00,['build.gradle']
Build: Remove redundant spark-hive dep (#2338),1,2,2021-03-16 13:47:39-07:00,['build.gradle']
Build: Relocate Antlr4 in Spark 3 runtime module (#2331),1,1,2021-03-16 15:26:58-07:00,['build.gradle']
Spark: Refactor action for expiring snapshots (#2314),8,514,2021-03-16 21:43:17-07:00,"['BaseExpireSnapshotsActionResult.java', 'Actions.java', 'BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java', 'ExpireSnapshotsAction.java', 'ExpireSnapshotsActionResult.java', 'RemoveOrphanFilesAction.java', 'BaseExpireSnapshotsSparkAction.java']"
Core/Hive: Introduce total-files-size snapshot metric and populate HMS (#2329),5,146,2021-03-17 11:45:27+01:00,"['SnapshotProducer.java', 'SnapshotSummary.java', 'TestSnapshotSummary.java', 'HiveTableOperations.java', 'TestHiveIcebergStorageHandlerNoScan.java']"
"Hive: Avoid reset hive configuration to default value. (#2075)



* Add test for iceberg-[2070]

* Fix test and codestyle

* Add TestHiveClientPool

* Delete unnecessary test case

* Delete unnecessary test case

* Delete misunderstanding test code.

Co-authored-by: dixingxing <dixingxing@autohome.com.cn>",3,83,2021-03-18 08:03:16+01:00,"['ClientPool.java', 'HiveClientPool.java', 'TestHiveClientPool.java']"
Hive: Fix broken TestHiveClientPool (#2350),1,4,2021-03-18 13:24:52+01:00,['TestHiveClientPool.java']
Hive: Remove unnecessary SerializationUtil.serializeToBase64 from HiveIcebergStorageHandler.overlayTableProperties (#2340),8,139,2021-03-22 12:46:21+01:00,"['BaseMetadataTable.java', 'BaseTable.java', 'StaticTableOperations.java', 'InputFormatConfig.java', 'HiveIcebergOutputCommitter.java', 'HiveIcebergOutputFormat.java', 'HiveIcebergStorageHandler.java', 'TestHiveIcebergOutputCommitter.java']"
Core: Add missing tests and comments for sort order parsing (#2355),2,10,2021-03-22 09:32:51-07:00,"['TableMetadataParser.java', 'TestTableMetadata.java']"
Spark: Refactor action for removing orphan files (#2353),4,501,2021-03-22 18:08:20-07:00,"['BaseRemoveOrphanFilesActionResult.java', 'Actions.java', 'RemoveOrphanFilesAction.java', 'BaseRemoveOrphanFilesSparkAction.java']"
"Spark: Implement add_files procedure (#2210)

Fixes 2068",5,874,2021-03-22 23:24:11-07:00,"['SparkTableUtil.java', 'TestAddFilesProcedure.java', 'Spark3Util.java', 'AddFilesProcedure.java', 'SparkProcedures.java']"
Core: Add a way to set sort order in writer classes (#2214),4,35,2021-03-23 13:41:12-07:00,"['Avro.java', 'EqualityDeleteWriter.java', 'DataWriter.java', 'Parquet.java']"
"Hive: Don't delete files when commit state is unknown (#2328)

Fixes #2317",6,403,2021-03-23 13:47:12-07:00,"['CommitStateUnknownException.java', 'SnapshotProducer.java', 'TableOperations.java', 'TableProperties.java', 'HiveTableOperations.java', 'TestHiveCommits.java']"
Hive: Use HiveClientPool cache instead of HiveCatalog global cache. (#2325),18,495,2021-03-24 12:40:07+01:00,"['CatalogProperties.java', 'FlinkTestBase.java', 'TestFlinkReaderDeletesBase.java', 'CachedClientPool.java', 'ClientPool.java', 'ClientPoolImpl.java', 'HiveCatalog.java', 'HiveCatalogs.java', 'HiveClientPool.java', 'HiveTableOperations.java', 'HiveMetastoreTest.java', 'TestCachedClientPool.java', 'TestClientPoolImpl.java', 'TestHiveCommitLocks.java', 'Catalogs.java', 'TestTables.java', 'SparkTestBase.java', 'TestSparkReaderDeletes.java']"
Spark: Refactor action for rewriting manifests (#2361),6,754,2021-03-24 11:18:05-07:00,"['BaseRewriteManifestsActionResult.java', 'Actions.java', 'BaseSnapshotUpdateSparkAction.java', 'RewriteManifestsAction.java', 'RewriteManifestsActionResult.java', 'BaseRewriteManifestsSparkAction.java']"
Spark: Remove softValues for Spark 2 catalog cache (#2363),1,3,2021-03-24 11:29:56-07:00,['CustomCatalogs.java']
Spark: Move base actions to new package (#2376),5,14,2021-03-24 12:45:24-07:00,"['BaseExpireSnapshotsSparkAction.java', 'BaseRemoveOrphanFilesSparkAction.java', 'BaseRewriteManifestsSparkAction.java', 'BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java']"
Core: Don't delete data files on DROP if GC is disabled (#2367),2,31,2021-03-24 17:25:14-07:00,"['CatalogUtil.java', 'TestSnapshotTableProcedure.java']"
Flink: Fix manifest serialization with Kryo (#2349),5,327,2021-03-25 11:36:51-07:00,"['GenericManifestFile.java', 'TestHelpers.java', 'TestManifestFileSerialization.java', 'TestFlinkManifest.java', 'TestIcebergFilesCommitter.java']"
API: Add targetSplitSize to TableScan (#2299),9,37,2021-03-25 11:46:29-07:00,"['TableScan.java', 'AllDataFilesTable.java', 'AllEntriesTable.java', 'AllManifestsTable.java', 'BaseTableScan.java', 'DataFilesTable.java', 'DataTableScan.java', 'ManifestEntriesTable.java', 'StaticTableScan.java']"
Docs: Add Nessie documentation (#2292),2,127,2021-03-25 11:48:12-07:00,"['nessie.md', 'mkdocs.yml']"
Core: Support dynamic loading for HadoopFileIO (#2333),2,33,2021-03-26 14:28:30-07:00,"['HadoopFileIO.java', 'TestCatalogUtil.java']"
Flink: Fix flaky testHashDistributeMode (#2385),3,80,2021-03-26 14:33:07-07:00,"['SimpleDataUtil.java', 'TestFlinkTableSink.java', 'TestFlinkIcebergSink.java']"
Core: Support rewriting delete files. (#2294),4,398,2021-03-29 11:11:09+08:00,"['RewriteFiles.java', 'BaseRewriteFiles.java', 'TableTestBase.java', 'TestRewriteFiles.java']"
Spark: Add REPLACE PARTITION FIELD command to DDL extensions (#2365),7,227,2021-03-29 13:52:30-07:00,"['IcebergSqlExtensions.g4', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'ReplacePartitionField.scala', 'ExtendedDataSourceV2Strategy.scala', 'ReplacePartitionFieldExec.scala', 'TestAlterTablePartitionFields.java']"
Spark: Fix RewriteDataFilesAction with custom outputSpecId (#2293),7,244,2021-03-29 17:24:02-07:00,"['MergingSnapshotProducer.java', 'BaseRewriteDataFilesAction.java', 'TestDeleteFileIndex.java', 'TestMergeAppend.java', 'TestRewriteManifests.java', 'RewriteDataFilesAction.java', 'TestRewriteDataFilesAction.java']"
Hive: Implement multi-table inserts (#2228),9,472,2021-03-30 14:07:23+02:00,"['InputFormatConfig.java', 'HiveIcebergOutputCommitter.java', 'HiveIcebergOutputFormat.java', 'HiveIcebergRecordWriter.java', 'HiveIcebergStorageHandler.java', 'IcebergInputFormat.java', 'HiveIcebergTestUtils.java', 'TestHiveIcebergOutputCommitter.java', 'TestHiveIcebergStorageHandlerWithEngine.java']"
Docs: Show the correct default value of write.target-file-size-bytes. (#2393),1,2,2021-03-30 12:16:14-05:00,['configuration.md']
"Spark: Add table location to reserved table properties (#2330)

Co-authored-by: Yufei Gu <yufei_gu@apple.com>",2,25,2021-03-30 10:51:36-07:00,"['SparkTable.java', 'TestCreateActions.java']"
Core: Fix Kryo serialization for DataFile and DeleteFile (#2343),4,365,2021-03-30 10:56:52-07:00,"['BaseFile.java', 'SerializableMap.java', 'TestDataFileSerialization.java', 'TestHelpers.java']"
Core: Fix circular default call in BaseMetastoreCatalog (#2368),1,3,2021-03-30 11:17:36-07:00,['BaseMetastoreCatalog.java']
Flink: Use Namespace in FlinkCatalog. (#2392),2,25,2021-03-31 16:36:03+08:00,"['FlinkCatalog.java', 'FlinkCatalogFactory.java']"
Docs: Document non-atomicity of Hive multi-table inserts (#2394),1,10,2021-03-31 11:01:05-07:00,['hive.md']
Core: Optimize SerializableMap (#2396),2,11,2021-03-31 11:11:09-07:00,"['BaseFile.java', 'SerializableMap.java']"
Spark: Add override annotations to rewrite manifests action (#2401),1,15,2021-03-31 15:49:23-07:00,['BaseRewriteManifestsSparkAction.java']
Spark: Remove redundant casts in actions (#2400),2,4,2021-03-31 15:49:59-07:00,"['BaseRemoveOrphanFilesSparkAction.java', 'BaseRewriteManifestsSparkAction.java']"
Core: Implement HasTableOperations in metadata and txn tables (#2398),11,297,2021-03-31 18:38:09-07:00,"['AllDataFilesTable.java', 'AllEntriesTable.java', 'AllManifestsTable.java', 'BaseMetadataTable.java', 'BaseTransaction.java', 'DataFilesTable.java', 'HistoryTable.java', 'ManifestEntriesTable.java', 'ManifestsTable.java', 'PartitionsTable.java', 'SnapshotsTable.java']"
Tests: Get row collection from flink sql query. (#2386),3,274,2021-04-01 14:26:14+08:00,"['FlinkTestBase.java', 'TestFlinkCatalogDatabase.java', 'TestFlinkTableSource.java']"
"Use <code> tag rather than <tt> as <tt> is deprecated (#2406)

Co-authored-by: dixingxing <dixingxing@autohome.com.cn>",2,22,2021-04-01 13:20:06+02:00,"['FlinkCatalogFactory.java', 'SparkCatalog.java']"
Python: Implement python drop_table (#2266),6,227,2021-04-01 17:39:34+02:00,"['snapshot.py', 'base_metastore_table_operations.py', 'base_snapshot.py', 'hive_tables.py', 'test_helpers.py', 'test_hive_tables.py']"
Core: Add SerializableTable (#2403),10,808,2021-04-05 14:46:02-07:00,"['TestHelpers.java', 'BaseMetadataTable.java', 'BaseTable.java', 'BaseTransaction.java', 'SerializableTable.java', 'SortOrderParser.java', 'TestTableSerialization.java', 'KryoHelpers.java', 'TestFileIOSerialization.java', 'TestTableSerialization.java']"
"Doc: add AWS Flink usage details (#2408)

* Doc: add AWS Flink usage details

* add bootstrap action example for EMR",1,127,2021-04-05 18:02:25-07:00,['aws.md']
AWS: handle uncertain catalog state for glue (#2402),4,433,2021-04-05 18:04:36-07:00,"['GlueCatalogCommitFailureTest.java', 'GlueTableOperations.java', 'BaseMetastoreTableOperations.java', 'HiveTableOperations.java']"
Docs: Fix typo in Flink docs (#2419),1,2,2021-04-06 09:59:08+08:00,['flink.md']
Spark: Handle name mapping assignment errors in snapshot action (#2417),1,4,2021-04-06 15:57:03-07:00,['Spark3SnapshotAction.java']
Spark: Refactor backing up and restoring logic in migrate action (#2418),1,57,2021-04-06 16:45:33-07:00,['Spark3MigrateAction.java']
Spark: Abort changes in migrate action only if staging was successful (#2416),2,26,2021-04-06 18:41:29-07:00,"['TestMigrateTableProcedure.java', 'Spark3MigrateAction.java']"
Spark: Show sort order as a table property (#2421),4,152,2021-04-06 21:01:30-07:00,"['Spark3Util.java', 'SparkTable.java', 'TestCreateActions.java', 'TestSpark3Util.java']"
Remove literal false boolean value (#2412),1,4,2021-04-07 10:20:31+02:00,['HiveCatalog.java']
Spark: Don't set parquet-enabled in IcebergSource default catalog (#2432),1,1,2021-04-07 10:47:16-07:00,['IcebergSource.java']
Spark: Refine logging in snapshot and migrate actions (#2431),2,18,2021-04-07 11:57:27-07:00,"['Spark3MigrateAction.java', 'Spark3SnapshotAction.java']"
Spark: Override provided props in snapshot and migrate actions (#2420),4,63,2021-04-09 00:11:57-07:00,"['TestMigrateTableProcedure.java', 'TestSnapshotTableProcedure.java', 'Spark3MigrateAction.java', 'Spark3SnapshotAction.java']"
Hive: Synchronize equivalent HMS and Iceberg properties (#2407),3,79,2021-04-09 14:27:33+02:00,"['HiveTableOperations.java', 'HiveIcebergMetaHook.java', 'TestHiveIcebergStorageHandlerNoScan.java']"
"[python] Updating Expressions with the Term object used in Predicates (#2399)

Co-authored-by: tgooch <tgooch@netflix.com>",14,587,2021-04-09 14:58:39+02:00,"['__init__.py', 'expression.py', 'expressions.py', 'inclusive_metrics_evaluator.py', 'predicate.py', 'projections.py', 'reference.py', 'strict_metrics_evaluator.py', 'term.py', 'transform.py', 'schema.py', 'test_evaluator.py', 'test_expression_binding.py', 'test_predicate_binding.py']"
"[BUILD] Fix the java.net.BindException when testing with Github Action (#2451)

[BUILD] Fix the java.net.BindException when testing with Github Action

Switches to using localhost from 127.0.0.1 for the Spark driver bind address in CI tests",1,3,2021-04-09 14:58:01-05:00,['java-ci.yml']
"Nessie: change commit operation type (#2411)

This minor fix changes how the Nessie Table ops commits a table.
Instead of using the single table commit endpoint,
it will now use the multi-table endpoint. This is more
stable long-term as the single table commit may be deprecated",1,12,2021-04-11 15:10:36+02:00,['NessieTableOperations.java']
Hive: Configure catalog type on table level. (#2129),16,814,2021-04-12 09:36:22+02:00,"['CatalogLoader.java', 'Catalogs.java', 'InputFormatConfig.java', 'HiveIcebergMetaHook.java', 'HiveIcebergOutputCommitter.java', 'HiveIcebergStorageHandler.java', 'TestCatalogs.java', 'TestIcebergInputFormats.java', 'TestInputFormatReaderDeletes.java', 'HiveIcebergStorageHandlerTestUtils.java', 'TestHiveIcebergOutputCommitter.java', 'TestHiveIcebergSerDe.java', 'TestHiveIcebergStorageHandlerLocalScan.java', 'TestHiveIcebergStorageHandlerNoScan.java', 'TestHiveIcebergStorageHandlerWithMultipleCatalogs.java', 'TestTables.java']"
Flink:  Avoid to commit too frequently for checkpoints that produce no data (#2042),2,52,2021-04-12 15:39:46+08:00,"['IcebergFilesCommitter.java', 'TestIcebergFilesCommitter.java']"
Hive: Capitalize write format value when creating writer (#2449),2,27,2021-04-12 09:50:12+02:00,"['HiveIcebergOutputFormat.java', 'TestHiveIcebergStorageHandlerWithEngine.java']"
Hive: Fix compilation failure in TestHiveIcebergStorageHandlerNoScan and TestHiveIcebergStorageHandlerWithEngine. (#2459),2,6,2021-04-12 16:42:21+02:00,"['TestHiveIcebergStorageHandlerNoScan.java', 'TestHiveIcebergStorageHandlerWithEngine.java']"
"Spark: Prevent setting sort-order by using ""ALTER TABLE ... SET TBLPROPERTIES"" (#2438)

 Spark: Prevent setting sort-order by using ""ALTER TABLE ... SET TBLPROPERTIES""",2,7,2021-04-12 17:48:54-05:00,"['SparkCatalog.java', 'TestAlterTable.java']"
Spark: Refactor snapshot and migrate actions (#2437),9,831,2021-04-12 21:02:48-07:00,"['BaseMigrateTableActionResult.java', 'BaseSnapshotTableActionResult.java', 'CreateAction.java', 'SnapshotAction.java', 'Spark3MigrateAction.java', 'Spark3SnapshotAction.java', 'BaseMigrateTableSparkAction.java', 'BaseSnapshotTableSparkAction.java', 'BaseTableCreationSparkAction.java']"
Doc: Fix broken Flink DataStream snippets (#2467),1,12,2021-04-13 12:38:57+08:00,['flink.md']
Docs: Add Javadoc for 0.11.1 (#2426),888,326664,2021-04-12 22:07:12-07:00,"['allclasses-frame.html', 'allclasses-noframe.html', 'constant-values.html', 'deprecated-list.html', 'help-doc.html', 'index-all.html', 'index.html', 'Accessor.html', 'Accessors.html', 'AllDataFilesTable.AllDataFilesTableScan.html', 'AllDataFilesTable.html', 'AllEntriesTable.html', 'AllManifestsTable.AllManifestsTableScan.html', 'AllManifestsTable.html', 'AppendFiles.html', 'BaseCombinedScanTask.html', 'BaseMetastoreCatalog.BaseMetastoreCatalogTableBuilder.html', 'BaseMetastoreCatalog.html', 'BaseMetastoreTableOperations.html', 'BaseOverwriteFiles.html', 'BaseReplacePartitions.html', 'BaseReplaceSortOrder.html', 'BaseRewriteManifests.html', 'BaseTable.html', 'CachingCatalog.html', 'CatalogProperties.html', 'CatalogUtil.html', 'CombinedScanTask.html', 'ContentFile.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DataFilesTable.FilesTableScan.html', 'DataFilesTable.html', 'DataOperations.html', 'DataTableScan.html', 'DataTask.html', 'DeleteFile.html', 'DeleteFiles.html', 'DistributionMode.html', 'ExpireSnapshots.html', 'FieldMetrics.html', 'FileContent.html', 'FileFormat.html', 'FileMetadata.Builder.html', 'FileMetadata.html', 'FileScanTask.html', 'Files.html', 'FindFiles.Builder.html', 'FindFiles.html', 'FloatFieldMetrics.html', 'GenericManifestFile.CopyBuilder.html', 'GenericManifestFile.html', 'GenericPartitionFieldSummary.html', 'GuavaClasses.html', 'HasTableOperations.html', 'HistoryEntry.html', 'HistoryTable.html', 'IsolationLevel.html', 'LocationProviders.html', 'ManageSnapshots.html', 'ManifestContent.html', 'ManifestEntriesTable.html', 'ManifestFile.PartitionFieldSummary.html', 'ManifestFile.html', 'ManifestFiles.html', 'ManifestReader.FileType.html', 'ManifestReader.html', 'ManifestWriter.html', 'ManifestsTable.html', 'MetadataColumns.html', 'MetadataTableType.html', 'MetadataTableUtils.html', 'Metrics.html', 'MetricsConfig.html', 'MetricsModes.Counts.html', 'MetricsModes.Full.html', 'MetricsModes.MetricsMode.html', 'MetricsModes.None.html', 'MetricsModes.Truncate.html', 'MetricsModes.html', 'MetricsUtil.html', 'MicroBatches.MicroBatch.html', 'MicroBatches.MicroBatchBuilder.html', 'MicroBatches.html', 'NullOrder.html', 'OverwriteFiles.html', 'PartitionField.html', 'PartitionKey.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'Partitioning.html', 'PartitionsTable.html', 'PendingUpdate.html', 'ReplacePartitions.html', 'ReplaceSortOrder.html', 'RewriteFiles.html', 'RewriteManifests.html', 'Rollback.html', 'RowDelta.html', 'ScanSummary.Builder.html', 'ScanSummary.PartitionMetrics.html', 'ScanSummary.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'SetLocation.html', 'Snapshot.html', 'SnapshotManager.html', 'SnapshotParser.html', 'SnapshotSummary.Builder.html', 'SnapshotSummary.html', 'SnapshotUpdate.html', 'SnapshotsTable.html', 'SortDirection.html', 'SortField.html', 'SortOrder.Builder.html', 'SortOrder.html', 'SortOrderBuilder.html', 'SortOrderParser.html', 'StaticTableOperations.html', 'StructLike.html', 'SystemProperties.html', 'Table.html', 'TableMetadata.MetadataLogEntry.html', 'TableMetadata.SnapshotLogEntry.html', 'TableMetadata.html', 'TableMetadataParser.Codec.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableProperties.html', 'TableScan.html', 'Tables.html', 'Transaction.html', 'Transactions.html', 'UpdateLocation.html', 'UpdatePartitionSpec.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Action.html', 'Actions.html', 'BaseRewriteDataFilesAction.html', 'CreateAction.html', 'ExpireSnapshotsAction.html', 'ExpireSnapshotsActionResult.html', 'ManifestFileBean.html', 'RemoveOrphanFilesAction.html', 'RewriteDataFilesAction.html', 'RewriteDataFilesActionResult.html', 'RewriteManifestsAction.html', 'RewriteManifestsActionResult.html', 'SnapshotAction.html', 'SnapshotUpdateAction.html', 'Spark3MigrateAction.html', 'Spark3SnapshotAction.html', 'SparkActions.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ArrowAllocation.html', 'ArrowSchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'NullabilityHolder.html', 'VectorHolder.ConstantVectorHolder.html', 'VectorHolder.PositionVectorHolder.html', 'VectorHolder.html', 'VectorizedArrowReader.ConstantVectorReader.html', 'VectorizedArrowReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseVectorizedParquetValuesReader.html', 'VectorizedColumnIterator.html', 'VectorizedDictionaryEncodedParquetValuesReader.html', 'VectorizedPageIterator.html', 'VectorizedParquetDefinitionLevelReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Avro.DeleteWriteBuilder.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroEncoderUtil.html', 'AvroIterable.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'AvroSchemaWithTypeVisitor.html', 'AvroWithPartnerByStructureVisitor.html', 'LogicalMap.html', 'ProjectionDatumReader.html', 'RemoveIds.html', 'SupportsRowPosition.html', 'UUIDConversion.html', 'ValueReader.html', 'ValueReaders.StructReader.html', 'ValueReaders.html', 'ValueWriter.html', 'ValueWriters.StructWriter.html', 'ValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AssumeRoleAwsClientFactory.html', 'AwsClientFactories.html', 'AwsClientFactory.html', 'AwsProperties.html', 'GlueCatalog.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'S3FileIO.html', 'S3InputFile.html', 'S3OutputFile.html', 'S3RequestUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Catalog.TableBuilder.html', 'Catalog.html', 'Namespace.html', 'SupportsNamespaces.html', 'TableIdentifier.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DeleteFilter.html', 'GenericAppenderFactory.html', 'GenericDeleteFilter.html', 'GenericRecord.html', 'IcebergGenerics.ScanBuilder.html', 'IcebergGenerics.html', 'IdentityPartitionConverters.html', 'InternalRecordWrapper.html', 'Record.html', 'DataReader.html', 'DataWriter.html', 'DecoderResolver.html', 'IcebergDecoder.html', 'IcebergEncoder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericOrcReader.html', 'GenericOrcReaders.html', 'GenericOrcWriter.html', 'GenericOrcWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseParquetReaders.html', 'BaseParquetWriter.html', 'GenericParquetReaders.html', 'GenericParquetWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Deletes.html', 'EqualityDeleteWriter.html', 'PositionDelete.html', 'PositionDeleteWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'EncryptedFiles.html', 'EncryptedInputFile.html', 'EncryptedOutputFile.html', 'EncryptionKeyMetadata.html', 'EncryptionKeyMetadatas.html', 'EncryptionManager.html', 'PlaintextEncryptionManager.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CreateSnapshotEvent.html', 'IncrementalScanEvent.html', 'Listener.html', 'Listeners.html', 'ScanEvent.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CherrypickAncestorCommitException.html', 'CommitFailedException.html', 'DuplicateWAPCommitException.html', 'NamespaceNotEmptyException.html', 'NoSuchIcebergTableException.html', 'NoSuchNamespaceException.html', 'NoSuchTableException.html', 'NotFoundException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'Bound.html', 'BoundLiteralPredicate.html', 'BoundPredicate.html', 'BoundReference.html', 'BoundSetPredicate.html', 'BoundTerm.html', 'BoundTransform.html', 'BoundUnaryPredicate.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.BoundVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'InclusiveMetricsEvaluator.html', 'Literal.html', 'ManifestEvaluator.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'StrictMetricsEvaluator.html', 'Term.html', 'True.html', 'Unbound.html', 'UnboundPredicate.html', 'UnboundTerm.html', 'UnboundTransform.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CatalogLoader.CustomCatalogLoader.html', 'CatalogLoader.HadoopCatalogLoader.html', 'CatalogLoader.HiveCatalogLoader.html', 'CatalogLoader.html', 'FlinkCatalog.html', 'FlinkCatalogFactory.html', 'FlinkFilters.html', 'FlinkSchemaUtil.html', 'FlinkTableFactory.html', 'FlinkTableOptions.html', 'FlinkTypeVisitor.html', 'IcebergTableSink.html', 'IcebergTableSource.html', 'RowDataWrapper.html', 'TableLoader.CatalogTableLoader.html', 'TableLoader.HadoopTableLoader.html', 'TableLoader.html', 'Actions.html', 'RewriteDataFilesAction.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AvroWithFlinkSchemaVisitor.html', 'FlinkAvroReader.html', 'FlinkAvroWriter.html', 'FlinkOrcReader.html', 'FlinkOrcWriter.html', 'FlinkParquetReaders.html', 'FlinkParquetWriters.html', 'FlinkValueReaders.html', 'FlinkValueWriters.html', 'ParquetWithFlinkSchemaVisitor.html', 'RowDataUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'FlinkAppenderFactory.html', 'FlinkSink.Builder.html', 'FlinkSink.html', 'RowDataTaskWriterFactory.html', 'TaskWriterFactory.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'FlinkInputFormat.html', 'FlinkInputSplit.html', 'FlinkSource.Builder.html', 'FlinkSource.html', 'RowDataRewriter.RewriteMap.html', 'RowDataRewriter.html', 'StreamingMonitorFunction.html', 'StreamingReaderOperator.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ConfigProperties.html', 'HadoopCatalog.html', 'HadoopFileIO.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTableOperations.html', 'HadoopTables.html', 'HiddenPathFilter.html', 'SerializableConfiguration.html', 'Util.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ClientPool.Action.html', 'ClientPool.html', 'HiveCatalog.html', 'HiveCatalogs.html', 'HiveClientPool.html', 'HiveSchemaUtil.html', 'HiveTableOperations.html', 'MetastoreUtil.html', 'RuntimeMetaException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseTaskWriter.BaseEqualityDeltaWriter.html', 'BaseTaskWriter.RollingEqDeleteWriter.html', 'BaseTaskWriter.RollingFileWriter.html', 'BaseTaskWriter.html', 'CloseableGroup.html', 'CloseableIterable.ConcatCloseableIterable.html', 'CloseableIterable.html', 'CloseableIterator.html', 'ClosingIterator.html', 'DataWriter.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'DeleteSchemaUtil.html', 'FileAppender.html', 'FileAppenderFactory.html', 'FileIO.html', 'FilterIterator.html', 'InputFile.html', 'LocationProvider.html', 'OutputFile.html', 'OutputFileFactory.html', 'PartitionedFanoutWriter.html', 'PartitionedWriter.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'TaskWriter.html', 'UnpartitionedWriter.html', 'WriteResult.Builder.html', 'WriteResult.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'MappedField.html', 'MappedFields.html', 'MappingUtil.html', 'NameMapping.html', 'NameMappingParser.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CatalogLoader.html', 'Catalogs.html', 'InputFormatConfig.ConfigBuilder.html', 'InputFormatConfig.InMemoryDataModel.html', 'InputFormatConfig.html', 'HiveIcebergFilterFactory.html', 'HiveIcebergInputFormat.html', 'HiveIcebergMetaHook.html', 'HiveIcebergOutputCommitter.html', 'HiveIcebergOutputFormat.html', 'HiveIcebergSerDe.html', 'HiveIcebergSplit.html', 'HiveIcebergStorageHandler.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergBinaryObjectInspector.html', 'IcebergDateObjectInspector.html', 'IcebergDateObjectInspectorHive3.html', 'IcebergDecimalObjectInspector.html', 'IcebergFixedObjectInspector.html', 'IcebergObjectInspector.html', 'IcebergRecordObjectInspector.html', 'IcebergTimeObjectInspector.html', 'IcebergTimestampObjectInspector.html', 'IcebergTimestampObjectInspectorHive3.html', 'IcebergTimestampWithZoneObjectInspector.html', 'IcebergTimestampWithZoneObjectInspectorHive3.html', 'IcebergUUIDObjectInspector.html', 'WriteObjectInspector.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Container.html', 'MapredIcebergInputFormat.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergInputFormat.html', 'IcebergSplit.html', 'IcebergSplitContainer.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'NessieCatalog.html', 'NessieTableOperations.html', 'NessieUtil.html', 'TableReference.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ORC.ReadBuilder.html', 'ORC.WriteBuilder.html', 'ORC.html', 'ORCSchemaUtil.BinaryType.html', 'ORCSchemaUtil.LongType.html', 'ORCSchemaUtil.html', 'OrcBatchReader.html', 'OrcMetrics.html', 'OrcRowReader.html', 'OrcRowWriter.html', 'OrcSchemaVisitor.html', 'OrcSchemaWithTypeVisitor.html', 'OrcValueReader.html', 'OrcValueReaders.StructReader.html', 'OrcValueReaders.html', 'OrcValueWriter.html', 'VectorizedRowBatchIterator.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseColumnIterator.html', 'BasePageIterator.IntIterator.html', 'BasePageIterator.html', 'ColumnIterator.html', 'ColumnWriter.html', 'Parquet.DeleteWriteBuilder.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetAvroReader.html', 'ParquetAvroValueReaders.TimeMillisReader.html', 'ParquetAvroValueReaders.TimestampMillisReader.html', 'ParquetAvroValueReaders.html', 'ParquetAvroWriter.html', 'ParquetDictionaryRowGroupFilter.html', 'ParquetIterable.html', 'ParquetMetricsRowGroupFilter.html', 'ParquetReader.html', 'ParquetSchemaUtil.HasIds.html', 'ParquetSchemaUtil.html', 'ParquetTypeVisitor.html', 'ParquetUtil.html', 'ParquetValueReader.html', 'ParquetValueReaders.BinaryAsDecimalReader.html', 'ParquetValueReaders.ByteArrayReader.html', 'ParquetValueReaders.BytesReader.html', 'ParquetValueReaders.FloatAsDoubleReader.html', 'ParquetValueReaders.IntAsLongReader.html', 'ParquetValueReaders.IntegerAsDecimalReader.html', 'ParquetValueReaders.ListReader.html', 'ParquetValueReaders.LongAsDecimalReader.html', 'ParquetValueReaders.MapReader.html', 'ParquetValueReaders.PrimitiveReader.html', 'ParquetValueReaders.RepeatedKeyValueReader.html', 'ParquetValueReaders.RepeatedReader.html', 'ParquetValueReaders.ReusableEntry.html', 'ParquetValueReaders.StringReader.html', 'ParquetValueReaders.StructReader.html', 'ParquetValueReaders.UnboxedReader.html', 'ParquetValueReaders.html', 'ParquetValueWriter.html', 'ParquetValueWriters.PositionDeleteStructWriter.html', 'ParquetValueWriters.PrimitiveWriter.html', 'ParquetValueWriters.RepeatedKeyValueWriter.html', 'ParquetValueWriters.RepeatedWriter.html', 'ParquetValueWriters.StructWriter.html', 'ParquetValueWriters.html', 'ParquetWriteAdapter.html', 'RemoveIds.html', 'TripleWriter.html', 'TypeToMessageType.html', 'TypeWithSchemaVisitor.html', 'ValuesAsBytesReader.html', 'VectorizedParquetReader.html', 'VectorizedReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergPigInputFormat.IcebergRecordReader.html', 'IcebergPigInputFormat.html', 'IcebergStorage.html', 'PigParquetReader.html', 'SchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'SchemaWithPartnerVisitor.PartnerAccessors.html', 'SchemaWithPartnerVisitor.html', 'UnionByNameVisitor.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSpark.html', 'PathIdentifier.html', 'PruneColumnsWithReordering.html', 'PruneColumnsWithoutReordering.html', 'RollbackStagedTable.html', 'Spark3Util.CatalogAndIdentifier.html', 'Spark3Util.DescribeSchemaVisitor.html', 'Spark3Util.html', 'SparkCatalog.html', 'SparkDataFile.html', 'SparkExceptionUtil.html', 'SparkFilters.html', 'SparkReadOptions.html', 'SparkSchemaUtil.html', 'SparkSessionCatalog.html', 'SparkStructLike.html', 'SparkTableUtil.SparkPartition.html', 'SparkTableUtil.html', 'SparkUtil.html', 'SparkValueConverter.html', 'SparkWriteOptions.html', 'AvroWithSparkSchemaVisitor.html', 'ParquetWithSparkSchemaVisitor.html', 'SparkAvroReader.html', 'SparkAvroWriter.html', 'SparkOrcReader.html', 'SparkOrcValueReaders.html', 'SparkOrcWriter.html', 'SparkParquetReaders.html', 'SparkParquetWriters.html', 'SparkValueReaders.html', 'SparkValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ArrowVectorAccessor.html', 'ArrowVectorAccessors.html', 'ColumnarBatchReader.html', 'IcebergArrowColumnVector.html', 'RowPostitionColumnVector.html', 'VectorizedSparkOrcReaders.html', 'VectorizedSparkParquetReaders.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ExpireSnapshotsProcedure.html', 'RemoveOrphanFilesProcedure.html', 'SparkProcedures.ProcedureBuilder.html', 'SparkProcedures.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CustomCatalogs.html', 'IcebergSource.html', 'RowDataRewriter.html', 'SparkPartitionedFanoutWriter.html', 'SparkPartitionedWriter.html', 'SparkScanBuilder.html', 'SparkTable.html', 'StagedSparkTable.html', 'Stats.html', 'StreamingWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PartitionSpecVisitor.html', 'SortOrderVisitor.html', 'Transform.html', 'Transforms.html', 'UnknownTransform.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CheckCompatibility.html', 'Comparators.html', 'Conversions.html', 'FixupTypes.html', 'IndexByName.html', 'IndexParents.html', 'JavaHash.html', 'JavaHashes.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ArrayUtil.html', 'BinPacking.ListPacker.html', 'BinPacking.PackingIterable.html', 'BinPacking.html', 'BinaryUtil.html', 'ByteBuffers.html', 'CharSequenceSet.html', 'CharSequenceWrapper.html', 'DateTimeUtil.html', 'DecimalUtil.html', 'ExceptionUtil.Block.html', 'ExceptionUtil.CatchBlock.html', 'ExceptionUtil.FinallyBlock.html', 'ExceptionUtil.html', 'Exceptions.html', 'Filter.html', 'JsonUtil.html', 'ManifestFileUtil.html', 'NaNUtil.html', 'Pair.html', 'ParallelIterable.html', 'PartitionSet.html', 'PartitionUtil.html', 'PropertyUtil.html', 'SerializableSupplier.html', 'SerializationUtil.html', 'SnapshotUtil.html', 'SortedMerge.html', 'StructLikeMap.html', 'StructLikeSet.html', 'StructLikeWrapper.html', 'StructProjection.html', 'TableScanUtil.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'ThreadPools.html', 'UUIDUtil.html', 'UnicodeUtil.html', 'WapUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'NoSuchProcedureException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSqlExtensionsBaseListener.html', 'IcebergSqlExtensionsBaseVisitor.html', 'IcebergSqlExtensionsLexer.html', 'IcebergSqlExtensionsListener.html', 'IcebergSqlExtensionsParser.AddPartitionFieldContext.html', 'IcebergSqlExtensionsParser.ApplyTransformContext.html', 'IcebergSqlExtensionsParser.BigDecimalLiteralContext.html', 'IcebergSqlExtensionsParser.BigIntLiteralContext.html', 'IcebergSqlExtensionsParser.BooleanLiteralContext.html', 'IcebergSqlExtensionsParser.BooleanValueContext.html', 'IcebergSqlExtensionsParser.CallArgumentContext.html', 'IcebergSqlExtensionsParser.CallContext.html', 'IcebergSqlExtensionsParser.ConstantContext.html', 'IcebergSqlExtensionsParser.DecimalLiteralContext.html', 'IcebergSqlExtensionsParser.DoubleLiteralContext.html', 'IcebergSqlExtensionsParser.DropPartitionFieldContext.html', 'IcebergSqlExtensionsParser.ExponentLiteralContext.html', 'IcebergSqlExtensionsParser.ExpressionContext.html', 'IcebergSqlExtensionsParser.FloatLiteralContext.html', 'IcebergSqlExtensionsParser.IdentifierContext.html', 'IcebergSqlExtensionsParser.IdentityTransformContext.html', 'IcebergSqlExtensionsParser.IntegerLiteralContext.html', 'IcebergSqlExtensionsParser.MultipartIdentifierContext.html', 'IcebergSqlExtensionsParser.NamedArgumentContext.html', 'IcebergSqlExtensionsParser.NonReservedContext.html', 'IcebergSqlExtensionsParser.NumberContext.html', 'IcebergSqlExtensionsParser.NumericLiteralContext.html', 'IcebergSqlExtensionsParser.OrderContext.html', 'IcebergSqlExtensionsParser.OrderFieldContext.html', 'IcebergSqlExtensionsParser.PositionalArgumentContext.html', 'IcebergSqlExtensionsParser.QuotedIdentifierAlternativeContext.html', 'IcebergSqlExtensionsParser.QuotedIdentifierContext.html', 'IcebergSqlExtensionsParser.SetTableOrderContext.html', 'IcebergSqlExtensionsParser.SingleStatementContext.html', 'IcebergSqlExtensionsParser.SmallIntLiteralContext.html', 'IcebergSqlExtensionsParser.StatementContext.html', 'IcebergSqlExtensionsParser.StringLiteralContext.html', 'IcebergSqlExtensionsParser.StringMapContext.html', 'IcebergSqlExtensionsParser.TinyIntLiteralContext.html', 'IcebergSqlExtensionsParser.TransformArgumentContext.html', 'IcebergSqlExtensionsParser.TransformContext.html', 'IcebergSqlExtensionsParser.TypeConstructorContext.html', 'IcebergSqlExtensionsParser.UnquotedIdentifierContext.html', 'IcebergSqlExtensionsParser.html', 'IcebergSqlExtensionsVisitor.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ExtendedSupportsDelete.html', 'Procedure.html', 'ProcedureCatalog.html', 'ProcedureParameter.html', 'SupportsMerge.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ClusteredDistribution.html', 'Distribution.html', 'Distributions.html', 'OrderedDistribution.html', 'UnspecifiedDistribution.html', 'ClusterDistributionImpl.html', 'OrderedDistributionImpl.html', 'UnspecifiedDistributionImpl.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'NullOrdering.html', 'SortDirection.html', 'SortOrder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'SupportsFileFilter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'MergeBuilder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'overview-frame.html', 'overview-summary.html', 'overview-tree.html', 'package-list', 'script.js', 'serialized-form.html', 'stylesheet.css']"
Hive: Add timeout for TestHiveIcebergStorageHandlerWithEngine tests (#2448),2,13,2021-04-14 09:33:34+02:00,"['TestHiveIcebergStorageHandlerWithEngine.java', 'TestHiveShell.java']"
"[INFRA] Workaround for Reverse DNS lookup on Ubuntu GitHub runners (#2480)

See https://github.com/apache/iceberg/pull/2451#issuecomment-819674109
See https://lists.apache.org/thread.html/r40b2da182952f21a3b94696e6f1bf8594e7ff16e1c5979fe8b2d51c8%40%3Cbuilds.apache.org%3E

Fixes #2475",1,1,2021-04-14 14:51:13-05:00,['java-ci.yml']
"[Build] Fix Antlr Shadowing and add Integration Tests (#2428)

* Reverts Antlr Shadowing and adds Integration Test to Check Proper Shading

Previously we had no test suites which checked if the Spark3Runtime jar was actually
usable with Spark3 builds. To check that the shadowJar is doing the right thing we
add a new integration test which runs using only Spark3 and the ShadowJar. Only a
few tests are included to prove that the jar is stable while we still rely on our
unit tests for the majority of test coverage.

* Shades Antlr Runtime

This reintroduces the shading of Antlr along with a set of integration tests to verify that it is correctly
shaded and working as expected. To accomplish this we copy several utility classes from Apache Spark so we
can break our dependency on Spark Internal's accessing Antlr classes.",6,346,2021-04-14 19:03:38-05:00,"['java-ci.yml', 'build.gradle', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'TestCallStatementParser.java', 'SmokeTest.java']"
"Bump Nessie to 0.5.1 & only run Nessie tests, when code/dependencies have changed (#2450)",4,39,2021-04-15 13:08:33+02:00,"['build.gradle', 'NessieCatalog.java', 'NessieTableOperations.java', 'versions.props']"
"Simplify Docs release by adding a version template (#2433)

* Simplify Docs release by adding a version template

This uses `mkdocs-markdownextradata-plugin` to template things like
versions. Hopefully this will simplify updating docs on releases

* add licence header",8,68,2021-04-15 13:19:53+02:00,"['README.md', 'aws.md', 'getting-started.md', 'nessie.md', 'releases.md', 'spark-configuration.md', 'mkdocs.yml', 'requirements.txt']"
[Site][Doc] fix performance pdf url (#2477),1,3,2021-04-15 13:29:59+02:00,['performance.md']
"Spark: Add new actions entry point, SparkActions (#2473)",3,164,2021-04-15 16:50:51-07:00,"['BaseSparkActions.java', 'SparkActions.java', 'SparkActions.java']"
Docs: Mark drop in python as supported (#2478),1,2,2021-04-15 16:51:38-07:00,['python-feature-support.md']
Spark: Use new actions entry point in procedures (#2489),4,94,2021-04-17 17:56:04-07:00,"['BaseProcedure.java', 'ExpireSnapshotsProcedure.java', 'RemoveOrphanFilesProcedure.java', 'RewriteManifestsProcedure.java']"
Core: Move ClientPool and ClientPoolImpl to core (#2491),8,236,2021-04-17 18:00:41-07:00,"['ClientPool.java', 'ClientPoolImpl.java', 'CachedClientPool.java', 'HiveCatalog.java', 'HiveClientPool.java', 'HiveTableOperations.java', 'TestClientPoolImpl.java', 'TestHiveClientPool.java']"
"Spark: Remove relocations for org.codehaus.jackson (#2479)

Avro and Parquet no longer depend on the old Jackson version.",1,4,2021-04-19 09:44:19-07:00,['build.gradle']
Spark: Pass Table to executors (#2362),18,483,2021-04-19 23:32:55-07:00,"['OutputFileFactory.java', 'RewriteDataFilesAction.java', 'BatchDataReader.java', 'EqualityDeleteRowReader.java', 'RowDataReader.java', 'RowDataRewriter.java', 'SparkAppenderFactory.java', 'TestSparkReaderDeletes.java', 'IcebergSource.java', 'Reader.java', 'StreamingWriter.java', 'Writer.java', 'SparkBatchQueryScan.java', 'SparkBatchScan.java', 'SparkMergeScan.java', 'SparkScanBuilder.java', 'SparkWrite.java', 'SparkWriteBuilder.java']"
Spark: Remove Antlr4 workaround (#2497),1,13,2021-04-20 09:31:32-07:00,['IcebergSparkSqlExtensionsParser.scala']
Spark: Add SparkFilesScan for querying a set of files (#2472),6,364,2021-04-20 11:39:19-07:00,"['SparkReadOptions.java', 'FileScanTaskSetManager.java', 'SparkFilesScan.java', 'SparkFilesScanBuilder.java', 'SparkTable.java', 'TestSparkFilesScan.java']"
"Core: Fix NPE caused by Unboxing a Null in ManifestFileUtil (#2492) (#2495)

* Core: Fix NPE caused by Unboxing a Null in ManifestFileUtil

Previously the boxed value of containsNaN would be null if the table
was made before NaN stats were implemented. This leads to an NPE when
being unboxed. To fix this on null we report ""true"" since we do not know if the
 partition contains any NaN values.",1,2,2021-04-20 15:20:29-05:00,['ManifestFileUtil.java']
Spark: Add SparkRewriteBuilder for rewriting a set of files (#2500),6,482,2021-04-22 09:14:12-07:00,"['SparkWriteOptions.java', 'FileRewriteCoordinator.java', 'SparkRewriteBuilder.java', 'SparkTable.java', 'SparkWrite.java', 'TestFileRewriteCoordinator.java']"
"add Nessie to Hive runtime (#2505)

Note: updates the flink notice+license files, as #2032 updated the hive notice-license files ;)",3,25,2021-04-23 08:59:19+02:00,"['build.gradle', 'LICENSE', 'NOTICE']"
Upgrade mockito version (#2514),3,14,2021-04-26 15:38:19+02:00,"['GlueCatalogCommitFailureTest.java', 'TestHiveCommits.java', 'versions.props']"
Hive: Fix multi-table insert issue with Tez (#2502),3,47,2021-04-26 17:00:11+02:00,"['HiveIcebergOutputCommitter.java', 'TestHiveIcebergStorageHandlerWithEngine.java', 'TestTables.java']"
"Use `CommitStatusUnknownException` for Nessie (#2515)

In case the Nessie endpoint did not respond or some other network error that makes it impossible
to detect whether the Nessie server got the request and, more importantly, get the response.

This PR adds a `catch (org.projectnessie.client.http.HttpClientException)` and re-throws it as
the new `CommitStateUnknownException`.

Related to #2328",1,26,2021-04-26 17:24:34+02:00,['NessieTableOperations.java']
Core: Ensure snapshot ID is positive (#2506),1,2,2021-04-27 10:14:14+08:00,['TableOperations.java']
Spark: Add builder to SparkAppenderFactory to handle increasing number of arguments (#2499),6,111,2021-04-27 19:11:12+08:00,"['RowDataRewriter.java', 'SparkAppenderFactory.java', 'TestSparkAppenderFactory.java', 'TestSparkMergingMetrics.java', 'Writer.java', 'SparkWrite.java']"
"Core: Extract listPartition methods from SparkTableUtil into DataUtil class in core module. (#2494)

Extract listPartition methods from SparkTableUtil into TableMigrationUtil class in core module for use with
other frameworks.",2,350,2021-04-27 09:54:27-05:00,"['TableMigrationUtil.java', 'SparkTableUtil.java']"
Hive: fix issue of inserting empty data on Tez (#2516),2,45,2021-04-28 09:45:09+02:00,"['HiveIcebergOutputCommitter.java', 'TestHiveIcebergStorageHandlerWithEngine.java']"
Hive: increase and standardize test time out (#2529),1,8,2021-04-28 09:45:25+02:00,['TestHiveIcebergStorageHandlerWithEngine.java']
"Core: fix NPE in manifests table for contains_nan column, update spec (#2521)",3,38,2021-04-28 14:32:59-07:00,"['ManifestsTable.java', 'spark-queries.md', 'spec.md']"
"AWS: Remove S3URI usage from public constructors (#2539)

* AWS: Make S3URI public

* Revert ""AWS: Make S3URI public""

This reverts commit df801736880870a2410a38dc0687198fc4f66e16.

* Remove S3URI usage from public constructors

* Use static methods",3,24,2021-04-29 09:39:29-07:00,"['S3FileIO.java', 'S3InputFile.java', 'S3OutputFile.java']"
"Add Arrow vectorized reader (#2286)

Co-authored-by: Mayur Srivastava <mayur.opensource@gmail.com>",16,3340,2021-04-29 19:35:50+02:00,"['ArrowBatchReader.java', 'ArrowReader.java', 'ArrowVectorAccessor.java', 'ArrowVectorAccessors.java', 'ColumnVector.java', 'ColumnarBatch.java', 'GenericArrowVectorAccessorFactory.java', 'VectorizedArrowReader.java', 'VectorizedReaderBuilder.java', 'VectorizedTableScanIterable.java', 'ArrowReaderTest.java', 'build.gradle', 'ArrowVectorAccessorFactory.java', 'ArrowVectorAccessors.java', 'IcebergArrowColumnVector.java', 'VectorizedSparkParquetReaders.java']"
Core: Add row identifier to schema (#2465),9,569,2021-05-02 13:52:56-07:00,"['Schema.java', 'UpdateSchema.java', 'SchemaParser.java', 'SchemaUpdate.java', 'TableMetadata.java', 'JsonUtil.java', 'TestSchemaUpdate.java', 'TestTableMetadata.java', 'TableMetadataV2Valid.json']"
"Spark: Handle Instant and LocalDate in filter expressions (#2543)

Fixes #2530.",2,73,2021-05-02 15:00:14-07:00,"['SparkFilters.java', 'TestSparkFilters.java']"
Build: Remove bintray from repositories (#2523),1,3,2021-05-02 15:01:22-07:00,['build.gradle']
Hive: add iceberg-aws to Hive runtime (#2549),2,31,2021-05-03 14:08:18-07:00,"['build.gradle', 'aws.md']"
Core: use Collection for input of UpdateSchema.setIdentifierFields (#2548),2,10,2021-05-06 11:23:59+08:00,"['UpdateSchema.java', 'SchemaUpdate.java']"
Docs: Add release notes for 0.11.1 and update references (#2427),2,17,2021-05-06 13:38:44-07:00,"['index.html', 'releases.md']"
"Hive: Add table-level JVM lock on commits (#2547)

Co-authored-by: Marton Bod <mbod@cloudera.com>",2,59,2021-05-07 12:37:02-07:00,"['HiveTableOperations.java', 'TestHiveCommitLocks.java']"
Spark: Add Spark UI description to action jobs (#2503),5,49,2021-05-07 17:30:47-07:00,"['BaseExpireSnapshotsSparkAction.java', 'BaseRemoveOrphanFilesSparkAction.java', 'BaseRewriteManifestsSparkAction.java', 'BaseMigrateTableSparkAction.java', 'BaseSnapshotTableSparkAction.java']"
"Hive: Use default values of client pool configuration (Laszlo Pinter reviewed by Marton Bod and Peter Vary)

Closes #2550",1,6,2021-05-10 13:29:41+02:00,['HiveCatalog.java']
"Spark: Fix the typo in the list method of DescribeSchemaVisitor in Spark3Util. (#2568)

Closes #2526",2,16,2021-05-10 10:29:18-05:00,"['Spark3Util.java', 'TestSpark3Util.java']"
Core: Update schema constructor callers to include fresh identifier (#2556),6,183,2021-05-11 08:28:30+08:00,"['Schema.java', 'TypeUtil.java', 'TestTypeUtil.java', 'SchemaUpdate.java', 'TestCreateTransaction.java', 'TestHadoopCommits.java']"
API: Add RewriteDataFiles action (#2501),2,218,2021-05-11 18:15:43-07:00,"['RewriteDataFiles.java', 'RewriteStrategy.java']"
Doc: refactor Hive documentation with catalog loading examples (#2544),3,377,2021-05-12 10:36:10-07:00,"['Catalogs.java', 'InputFormatConfig.java', 'hive.md']"
Core: Add abstract BinPackStrategy (#2585),4,420,2021-05-13 12:10:26-07:00,"['RewriteStrategy.java', 'BinPackStrategy.java', 'MockFileScanTask.java', 'TestBinPackStrategy.java']"
"Spark: Fix MERGE INTO with SinglePartition partitioning (#2584)

Previously there was an exception when both the source and target of a MERGE INTO
command shared the same distribution, causing an join without an exchange but
partitioning was changed by DynamicFileFilterExec. This could only happen
if both the target and source happend to have a single partition
and output partitioning was equal to SinglePartition. If the filter removes
the partition from the target then there is an unbalance between the number of
partitions but the exchange is also missing. This situation breaks the join.

We do not currently expose any other distribution information so in most cases
the source and target will return unknown distribution which avoids this problem.
In those situations an exchange always follows the DynamicFileFilterExec which makes
sure the number of partitions always matches for the join.",2,83,2021-05-17 09:39:32-07:00,"['DynamicFileFilterExec.scala', 'TestMerge.java']"
Core: Add ReachableFileUtil (#2564),7,311,2021-05-17 15:53:39-07:00,"['ReachableFileUtil.java', 'BaseAction.java', 'HadoopTableOperations.java', 'Util.java', 'TestReachableFileUtil.java', 'BaseRemoveOrphanFilesSparkAction.java', 'BaseSparkAction.java']"
API: Refactor RewriteDataFiles and BinPackStrategy (#2600),3,88,2021-05-17 16:35:20-07:00,"['RewriteDataFiles.java', 'BinPackStrategy.java', 'TestBinPackStrategy.java']"
Flink: Support SQL primary key (#2410),13,832,2021-05-18 18:01:29+08:00,"['Schema.java', 'FlinkCatalog.java', 'FlinkSchemaUtil.java', 'IcebergTableSink.java', 'SimpleDataUtil.java', 'TestChangeLogTable.java', 'TestFlinkCatalogTable.java', 'TestFlinkSchemaUtil.java', 'BoundedTableFactory.java', 'BoundedTestSource.java', 'ChangeLogTableTestBase.java', 'TestBoundedTableFactory.java', 'org.apache.flink.table.factories.Factory']"
Hive: unify catalog experience across engines (#2565),11,338,2021-05-18 13:23:16+02:00,"['CatalogUtil.java', 'Catalogs.java', 'InputFormatConfig.java', 'TestCatalogs.java', 'TestIcebergInputFormats.java', 'TestHiveIcebergStorageHandlerLocalScan.java', 'TestHiveIcebergStorageHandlerNoScan.java', 'TestHiveIcebergStorageHandlerWithMultipleCatalogs.java', 'TestTables.java', 'aws.md', 'hive.md']"
Hive: enable dropping HMS tables despite metadata problems (#2583),3,51,2021-05-18 13:26:32+02:00,"['TestHiveMetastore.java', 'HiveIcebergMetaHook.java', 'TestHiveIcebergStorageHandlerNoScan.java']"
Core: Rewrite metrics during schema transformation (#2257),3,97,2021-05-18 19:51:28-07:00,"['MetricsConfig.java', 'SchemaUpdate.java', 'TestSchemaAndMappingUpdate.java']"
Docs: Fix the broken links in the Table Maintenance page (#2616),1,6,2021-05-19 16:24:47-07:00,['maintenance.md']
Build: Add .out folders to gitignore (#2592),1,2,2021-05-19 16:55:43-07:00,['.gitignore']
API: Fix typo in ProjectionUtil (#2581),1,2,2021-05-19 17:04:19-07:00,['ProjectionUtil.java']
Build: Allow customizing maven publication repo (#2574),1,6,2021-05-19 17:16:12-07:00,['deploy.gradle']
Spark: Fix describing v1 table with void transforms (#2454),2,52,2021-05-19 17:44:36-07:00,"['TestAlterTablePartitionFields.java', 'Spark3Util.java']"
Core: Fix NPE in update notification when table metadata cannot be loaded (#2552),2,16,2021-05-19 17:55:40-07:00,"['MergingSnapshotProducer.java', 'TableMetadata.java']"
"Spark: Create Spark2 and Spark3 StreamingOffset classes (#2615)

* Make a Copy of StreamingOffset implementation from Spark2 into Spark3 to avoid naming conflicts
* Move Spark2 implementation of StreamingOffset from iceberg-spark to iceberg-Spark2",4,195,2021-05-19 21:14:59-05:00,"['StreamingOffset.java', 'TestStreamingOffset.java', 'StreamingOffset.java', 'TestStreamingOffset.java']"
Parquet: Fix filtering with dictionary-encoded fixed (#2551),3,83,2021-05-20 12:30:58-07:00,"['Parquet.java', 'ParquetDictionaryRowGroupFilter.java', 'TestDictionaryRowGroupFilter.java']"
Core: Add check-status config to TableProperties (#2596),2,27,2021-05-21 15:02:32-07:00,"['BaseMetastoreTableOperations.java', 'TableProperties.java']"
Upgrade ORC to 1.6.8 (#2624),1,2,2021-05-22 20:46:00-05:00,['versions.props']
Core: Fix typo in delete read test (#2623),2,4,2021-05-23 15:14:20-07:00,"['DeleteReadTests.java', 'TestSparkReaderDeletes.java']"
Spark: Fix typo for row position vector name (#2625),2,6,2021-05-23 15:15:15-07:00,"['RowPositionColumnVector.java', 'VectorizedSparkOrcReaders.java']"
Fix null tableName when logging in checkCommitStatus for Nessie tables and enforce tableName is implemented at compile time (#2630),2,9,2021-05-24 16:21:34+02:00,"['BaseMetastoreTableOperations.java', 'NessieTableOperations.java']"
Let NessieCatalog handle HttpClientException and clean up retry-handling (#2519),1,32,2021-05-24 16:48:37+02:00,['NessieCatalog.java']
"Spark: Minor refactor in MicroBatches class (#2620)

* minor refactoring in MicroBatches class to prep for Spark3 streaming change",1,28,2021-05-24 13:19:36-05:00,['MicroBatches.java']
Core: Remove unused methods in BaseAction (#2606),1,43,2021-05-25 13:30:36-07:00,['BaseAction.java']
Docs: Improve Nessie docs (#2637),1,27,2021-05-26 15:06:10+02:00,['nessie.md']
"Nessie: Explicitly log warning, when mandatory `warehouse` option is missing (#2646)",1,20,2021-05-27 21:10:06+02:00,['NessieCatalog.java']
"Hive: Improve code style (#2641)

Co-authored-by: xiepengjie <xiepengjie@didiglobal.com>",4,18,2021-05-27 21:11:08+02:00,"['HiveSchemaUtil.java', 'HiveIcebergMetaHook.java', 'HiveIcebergOutputCommitter.java', 'HiveIcebergOutputFormat.java']"
Docs: Make SQL multiline to avoid having a single long line (#2656),1,7,2021-06-01 17:14:42+02:00,['nessie.md']
Use Guava Splitter to fix StringSplitter warnings (#2663),1,9,2021-06-02 13:59:32+02:00,['TableReference.java']
Nessie: Set author when performing a commit and application.type=iceberg (#2662),4,46,2021-06-02 16:29:46+02:00,"['NessieCatalog.java', 'NessieTableOperations.java', 'NessieUtil.java', 'TestNessieTable.java']"
[Python] add to_byte_buffer to literal classes (#2655),5,128,2021-06-03 09:29:05+02:00,"['literals.py', 'conversions.py', 'partition_summary.py', 'conftest.py', 'test_conversions.py']"
"Enable Github Wiki and Project Board features (#2665)

This patch enables the Wiki and Project Board features for the Iceberg
repository.

Please consult the following links for more information about these
features:

 - https://docs.github.com/en/issues/organizing-your-work-with-project-boards
 - https://docs.github.com/en/communities/documenting-your-project-with-wikis/about-wikis",1,4,2021-06-03 13:07:51-07:00,['.asf.yaml']
Upgrade Caffeine version (#2671),1,2,2021-06-04 12:43:21+02:00,['versions.props']
Core: Support retrieving version hint location for static tables (#2677),2,26,2021-06-04 16:00:37-07:00,"['ReachableFileUtil.java', 'TestReachableFileUtil.java']"
Docs: Improve docs and mention how to get started with Iceberg + Flink's Python API (#2634),1,89,2021-06-07 09:58:42+02:00,['flink.md']
Clarify preconditions in spark 2 TestCatalog initialization (#2674),2,13,2021-06-07 09:59:26+02:00,"['TestCatalog.java', 'TestCustomCatalog.java']"
Update to_byte_buff_mapping and from_byte_buff_mapping to be consistent and add additional tests. (#2672),2,86,2021-06-07 10:02:06+02:00,"['conversions.py', 'test_conversions.py']"
Hive: Vectorized ORC reads for Hive (#2613),14,926,2021-06-07 10:53:59+02:00,"['build.gradle', 'CompatibilityHiveVectorUtils.java', 'HiveIcebergVectorizedRecordReader.java', 'HiveVectorizedReader.java', 'VectorizedRowBatchIterator.java', 'VectorizedSupport.java', 'HiveIcebergInputFormat.java', 'HiveIcebergSerDe.java', 'HiveIcebergStorageHandler.java', 'AbstractMapredIcebergRecordReader.java', 'MapredIcebergInputFormat.java', 'IcebergInputFormat.java', 'TestHiveIcebergStorageHandlerWithEngine.java', 'settings.gradle']"
Spark: Add RemoveReachableFiles action (#2415),8,746,2021-06-08 20:04:47-07:00,"['ActionsProvider.java', 'RemoveReachableFiles.java', 'BaseRemoveFilesActionResult.java', 'BaseRemoveReachableFilesSparkAction.java', 'BaseSparkActions.java', 'TestRemoveReachableFilesAction.java', 'TestRemoveReachableFilesAction24.java', 'TestRemoveFilesAction3.java']"
Nessie: Extract Spark AppId / User from SparkContext and not from Snapshot (#2664),7,174,2021-06-10 22:58:07+02:00,"['CatalogProperties.java', 'NessieCatalog.java', 'NessieTableOperations.java', 'NessieUtil.java', 'NessieUtilTest.java', 'TestNessieTable.java', 'SparkCatalog.java']"
Docs: Fix variable name in Flink doc (#2668),1,4,2021-06-12 16:21:49-07:00,['flink.md']
"Nessie: Use AssertJ assertions (#2684)

This also adds AssertJ to testCompile in all modules so assertions can be used elsewhere.",8,346,2021-06-14 14:33:02-07:00,"['AssertHelpers.java', 'build.gradle', 'NessieUtilTest.java', 'TestBranchVisibility.java', 'TestNamespace.java', 'TestNessieTable.java', 'TestTableReference.java', 'versions.props']"
Core: add key_metadata to ManifestFile schema and classes (#2675),10,77,2021-06-14 14:42:38-07:00,"['ManifestFile.java', 'TestHelpers.java', 'TestInclusiveManifestEvaluator.java', 'GenericManifestFile.java', 'ManifestWriter.java', 'SnapshotProducer.java', 'V2Metadata.java', 'TestManifestListVersions.java', 'TestIcebergFilesCommitter.java', 'ManifestFileBean.java']"
Docs: Add cache-enabled to catalog property list (#2648),4,4,2021-06-15 10:20:08-07:00,"['FlinkCatalogFactory.java', 'flink.md', 'spark-configuration.md', 'SparkCatalog.java']"
ORC: Remove unused constants in generic readers (#2695),1,2,2021-06-16 12:24:41-07:00,['GenericOrcReaders.java']
AWS: Fix typo in S3OutputFile.createOrOverwrite exception message (#2699),1,2,2021-06-16 12:26:02-07:00,['S3OutputFile.java']
"Update spec for v2 changes (#2654)

* Spec: Add identifier-field-ids to schema.
* Spec: Add section for partition evolution.
* Spec: Add schemas list and current-schema-id to table metadata.
* Spec: Add key_metadata to manifest list.
* Spec: Add schema-id to Snapshot metadata.",1,65,2021-06-16 13:02:08-07:00,['spec.md']
"Parquet: Update to 1.12.0 (#2441)

Parquet changelog: https://github.com/apache/parquet-mr/blob/master/CHANGES.md#version-1120",1,2,2021-06-16 13:55:25-07:00,['versions.props']
[python] Adding type ignores for dependencies without type support (#2698),1,2,2021-06-17 09:43:39-07:00,['tox.ini']
"Core: Use .as() with AssertJ (#2706)

`.withFailMessage(..)` was mistakenly used and was therefore overriding
the actual error reporting, making debugging difficult.",1,6,2021-06-17 11:24:43-07:00,['AssertHelpers.java']
API: Add more null checks to TableIdentifier (#2703),2,32,2021-06-17 11:31:47-07:00,"['TableIdentifier.java', 'TestTableIdentifier.java']"
API: Fix Namespace null handling (#2704),2,49,2021-06-17 11:33:29-07:00,"['Namespace.java', 'TestNamespace.java']"
Docs: Add Adobe Migration article (#2707),1,5,2021-06-17 11:34:16-07:00,['blogs.md']
"Core: Do not allow optional, double, or float identifier fields (#2705)",4,96,2021-06-17 12:59:57-07:00,"['Schema.java', 'SchemaUpdate.java', 'TestCreateTransaction.java', 'TestSchemaUpdate.java']"
"[Python] support custom target name in partition spec builder (#2689)

* support custom target name in partition spec builder

* address the comments.",5,245,2021-06-17 16:31:56-07:00,"['partition_spec.py', 'dates.py', 'timestamps.py', 'transform.py', 'test_partition_spec.py']"
"Docs: updating README to link to github actions instead of travis-ci.org (#2709)

Co-authored-by: tgooch <tgooch@netflix.com>",1,3,2021-06-18 09:32:11-07:00,['README.md']
"Core: Use equals instead of reference equality (#2714)

See also https://errorprone.info/bugpattern/ReferenceEquality",2,14,2021-06-18 09:46:34-07:00,"['ParquetAvro.java', 'PruneColumns.java']"
"Tests: Add unit tests for InternalRecordWrapper, RowDataWrapper, InternalRowWrapper (#2683)",4,279,2021-06-18 10:00:29-07:00,"['InternalRecordWrapper.java', 'RecordWrapperTest.java', 'TestRowDataWrapper.java', 'TestInternalRowWrapper.java']"
"Spark: Fix scanAllFiles in MicroBatch.open (#2667)

Param scanAllFiles Used to check whether all the data files should be processed, or only added files.Here we should replace  scanAllFiles to  !scanAllFiles.",1,2,2021-06-18 10:05:00-07:00,['MicroBatches.java']
"Docs: Add commit.status-check.* properties (#2661)

Co-authored-by: Ryan Blue <blue@apache.org>",1,4,2021-06-18 10:07:24-07:00,['configuration.md']
Core: Add delete marker metadata column (#2538),12,70,2021-06-18 16:38:18-07:00,"['VectorizedReaderBuilder.java', 'MetadataColumns.java', 'ValueReaders.java', 'DeleteFilter.java', 'FlinkParquetReaders.java', 'SimpleDataUtil.java', 'OrcValueReaders.java', 'BaseParquetReaders.java', 'SparkParquetReaders.java', 'VectorizedSparkOrcReaders.java', 'TestSparkOrcReadMetadataColumns.java', 'TestSparkParquetReadMetadataColumns.java']"
"[python] Adding Unknown and Void transforms (#2697)

Co-authored-by: tgooch <tgooch@netflix.com>",3,124,2021-06-19 16:51:18-07:00,"['transforms.py', 'unknown_transform.py', 'void_transform.py']"
fix: add and remove partition transform on same column failed when use v1 metadata (#2691),2,141,2021-06-21 13:28:25+02:00,"['BaseUpdatePartitionSpec.java', 'TestUpdatePartitionSpec.java']"
"[SPARK][BUILD] Allow existing spark2 JMH benchmarks to work with either Spark 2 or Spark 3 (#2595)

Moves spark2 JMH tests to spark directory and update jmh.gradle and build.gradle to allow for running on spark3 and spark2
Makes spark 2 and 3 work with Java 8",30,140,2021-06-21 15:36:08-05:00,"['.gitignore', 'build.gradle', 'jmh.gradle', 'SparkBenchmarkUtil.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'Action.java', 'IcebergSourceBenchmark.java', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'IcebergSourceNestedListDataBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', '.gitkeep', '.gitkeep']"
"Core: Replace LinkedList usage with ArrayDeque (#2713)

See also https://errorprone.info/bugpattern/JdkObsolete

This also suppresses the same warning for `SchemaUpdate.moveField` as we can't move to an `ArrayDeque` there.",2,8,2021-06-21 14:09:48-07:00,"['SchemaUpdate.java', 'TypeWithSchemaVisitor.java']"
Core: Add JDBC catalog implementation (#1870),12,1564,2021-06-21 14:48:49-07:00,"['build.gradle', 'BaseMetastoreTableOperations.java', 'JdbcCatalog.java', 'JdbcClientPool.java', 'JdbcTableOperations.java', 'JdbcUtil.java', 'UncheckedInterruptedException.java', 'UncheckedSQLException.java', 'TestJdbcCatalog.java', 'TestJdbcTableConcurrency.java', 'TestRemoveOrphanFilesAction3.java', 'versions.props']"
Core: Throw an error for incremental scans of metadata tables (#2617),12,103,2021-06-22 08:47:06-07:00,"['AllDataFilesTable.java', 'AllEntriesTable.java', 'AllManifestsTable.java', 'BaseAllMetadataTableScan.java', 'DataFilesTable.java', 'HistoryTable.java', 'ManifestEntriesTable.java', 'ManifestsTable.java', 'PartitionsTable.java', 'SnapshotsTable.java', 'StaticTableScan.java', 'TestStaticTable.java']"
"Core: Use CharSequenceSet instead of Set<CharSequence> (#2712)

This also adds a test that makes sure a CharSequenceSet doesn't suffer
from undefined equality behavior as reported by https://errorprone.info/bugpattern/CollectionUndefinedEquality",12,111,2021-06-22 09:42:23-07:00,"['CharSequenceSet.java', 'TestCharSequenceSet.java', 'BaseRowDelta.java', 'ManifestFilterManager.java', 'MergingSnapshotProducer.java', 'PositionDeleteWriter.java', 'BaseTaskWriter.java', 'SortedPosDeleteWriter.java', 'WriteResult.java', 'DeleteReadTests.java', 'FileHelpers.java', 'TestDataFileIndexStatsFilters.java']"
Spark: Add extensions DDL to set identifier fields (#2560),9,373,2021-06-22 12:33:12-07:00,"['IcebergSqlExtensions.g4', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'DropIdentifierFields.scala', 'SetIdentifierFields.scala', 'DropIdentifierFieldsExec.scala', 'ExtendedDataSourceV2Strategy.scala', 'SetIdentifierFieldsExec.scala', 'TestAlterTableSchema.java']"
[AWS] Fix MissingFail error prone warning by cleaning up GlueCatalogCommitFailureTest (#2721),1,11,2021-06-22 13:08:38-07:00,['GlueCatalogCommitFailureTest.java']
"Core: Add predicate push down for partitions metadata table (#2358)

Co-authored-by: Szehon Ho <szehon_ho@apple.com>",4,309,2021-06-22 13:16:45-07:00,"['PartitionsTable.java', 'TableTestBase.java', 'TestMetadataTableScans.java', 'TestIcebergSourceTablesBase.java']"
Core: Add HadoopConfigurable interface to serialize custom FileIO (#2678),6,112,2021-06-22 17:25:25-07:00,"['SerializableTable.java', 'HadoopConfigurable.java', 'HadoopFileIO.java', 'SerializationUtil.java', 'IcebergSplit.java', 'SparkUtil.java']"
Docs: Add catalog and metadata files to metadata structure diagram (#2622),1,0,2021-06-22 17:28:26-07:00,['iceberg-metadata.png']
"AWS: add DynamoDb catalog (#2688)

* AWS: add DynamoDb catalog

* fix spacing, add comment",4,1139,2021-06-22 20:33:23-07:00,"['DynamoDbCatalogTest.java', 'AwsProperties.java', 'DynamoDbCatalog.java', 'DynamoDbTableOperations.java']"
Use bulk decryption interface in ArrowReader (#2720),3,31,2021-06-24 12:11:06+02:00,"['ArrowReader.java', 'DataIterator.java', 'BaseDataReader.java']"
"[Spark] Support building against both Spark 3.0 and Spark 3.1. (#2512)

Code changes that allow spark3 and spark3-extensions to be tested against
both Spark 3.0 and Spark 3.1 while still built against a single Spark 3.0 version.

Although additional tests are are created we still only produce a single set of Spark3 binaries which 
are compatible with Spark 3.0 and 3.1",18,361,2021-06-24 10:16:41-05:00,"['build.gradle', 'DateTimeUtil.java', 'IcebergSparkSessionExtensions.scala', 'AlignRowLevelOperations.scala', 'AssignmentAlignmentSupport.scala', 'RewriteDelete.scala', 'RewriteMergeInto.scala', 'RewriteUpdate.scala', 'IcebergSparkSqlExtensionsParser.scala', 'ReplaceData.scala', 'DistributionAndOrderingUtils.scala', 'RewriteRowLevelOperationHelper.scala', 'Spark3VersionUtil.java', 'ExpireSnapshotsProcedure.java', 'RemoveOrphanFilesProcedure.java', 'RollbackToTimestampProcedure.java', 'TestDeleteFrom.java', 'versions.props']"
"Core: Fix float and double metrics for Parquet and ORC (#2464)

This replaces the metrics from Parquet and ORC with metrics that are accumulated by Iceberg writers to ensure that the metrics do not include NaN values.",19,650,2021-06-24 15:58:29-07:00,"['DoubleFieldMetrics.java', 'FieldMetrics.java', 'FloatFieldMetrics.java', 'MetricsUtil.java', 'TestMetrics.java', 'GenericOrcWriter.java', 'GenericOrcWriters.java', 'TestMergingMetrics.java', 'FlinkOrcWriter.java', 'FlinkOrcWriters.java', 'OrcMetrics.java', 'OrcRowWriter.java', 'OrcValueWriter.java', 'ParquetUtil.java', 'ParquetValueWriter.java', 'ParquetValueWriters.java', 'SparkOrcValueWriter.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java']"
API: Use equals instead of reference equality (#2716),10,42,2021-06-24 16:17:58-07:00,"['SortField.java', 'TypeUtil.java', 'BuildAvroProjection.java', 'PruneColumns.java', 'RemoveIds.java', 'SchemaToType.java', 'FlinkTypeToType.java', 'PruneColumns.java', 'SparkTableUtil.java', 'SparkTypeToType.java']"
Spark: Fix check for SQL extensions with extra white space (#2729),2,5,2021-06-25 09:14:45-07:00,"['IcebergSparkSqlExtensionsParser.scala', 'TestAlterTablePartitionFields.java']"
Spark: Support micro-batch streaming read for DSv2 (#2660),6,747,2021-06-25 12:43:32-07:00,"['SnapshotUtil.java', 'SparkBatchScan.java', 'SparkMicroBatchStream.java', 'SparkTable.java', 'StreamingOffset.java', 'TestStructuredStreamingRead3.java']"
Docs: Remove file spark.md since it is outdated and causes confusion (#2727),1,804,2021-06-25 16:01:29-07:00,['spark.md']
Flink: Rename FlinkTableOptions to more generic FlinkConfigOptions,4,29,2021-06-28 21:00:35+08:00,"['FlinkConfigOptions.java', 'FlinkSource.java', 'FlinkTestBase.java', 'TestFlinkScanSql.java']"
Add support for TimeType / UUIDType (#2739),10,356,2021-06-28 17:48:24+02:00,"['ArrowSchemaUtil.java', 'ArrowReader.java', 'GenericArrowVectorAccessorFactory.java', 'VectorizedArrowReader.java', 'VectorizedColumnIterator.java', 'VectorizedDictionaryEncodedParquetValuesReader.java', 'VectorizedPageIterator.java', 'VectorizedParquetDefinitionLevelReader.java', 'ArrowSchemaUtilTest.java', 'ArrowReaderTest.java']"
Spark: Fix file-open-cost in DSv2 streams (#2743),1,3,2021-06-28 10:06:08-07:00,['SparkMicroBatchStream.java']
Core: Add schema-id to snapshots (#2275),15,348,2021-06-28 17:24:47-07:00,"['Snapshot.java', 'Table.java', 'TestHelpers.java', 'BaseMetadataTable.java', 'BaseSnapshot.java', 'BaseTable.java', 'BaseTransaction.java', 'SerializableTable.java', 'SnapshotParser.java', 'SnapshotProducer.java', 'TableTestBase.java', 'TestSchemaID.java', 'TestSnapshotJson.java', 'TestTableMetadata.java', 'TableMetadataV2Valid.json']"
Spec: Fix diagram alignment and size (#2750),2,9,2021-06-28 17:26:54-07:00,"['extra.css', 'spec.md']"
Spec: Update for v2 schemas in remaining sections (#2748),1,13,2021-06-28 17:27:27-07:00,['spec.md']
Flink: Add an optional uidPrefix to FlinkSink#Builder to explicitly set operator uid. (#2745),1,45,2021-06-29 15:35:59+08:00,['FlinkSink.java']
Docs: Update directions for joining #iceberg on Slack (#2758),1,11,2021-06-29 12:16:05-07:00,['community.md']
"Core: Validate planTasks and splitFiles args in TableScanUtil (#2759)


Co-authored-by: Shardul Mahadik <smahadik@linkedin.com>",2,40,2021-06-29 16:49:11-07:00,"['TableScanUtil.java', 'TestSplitPlanning.java']"
"Core: Bin pack strategy cosmetic changes (#2770)

* Core: Refactors to BinPack and Rewrite APIs

Changes to support the implementation of the Spark RewriteDatafileAciton. Fixes JavaDoc links,
adds in BinPackStrategy comments to better binpack real world usecases.",4,136,2021-06-30 17:31:57-05:00,"['RewriteDataFiles.java', 'RewriteStrategy.java', 'BinPackStrategy.java', 'TestBinPackStrategy.java']"
Docs: Describe how to configure Code formatter for IntelliJ IDEA (#2766),1,11,2021-07-01 11:38:36-05:00,['community.md']
"Spark: Add limited support for vectorized reads for Parquet V2 (#2749)

With this change, we have added support for Parquet data written in V2 format.
The only data encodings we support are dictionary and plain.
Vectorized reads against data written using Delta/RLE and other encodings are
not supported. As of this commit, note that the Spark Parquet vectorized reads also don't
support vectorized reads for such encodings.",6,93,2021-07-01 12:00:48-05:00,"['BaseVectorizedParquetValuesReader.java', 'VectorizedPageIterator.java', 'VectorizedParquetDefinitionLevelReader.java', 'BasePageIterator.java', 'Parquet.java', 'TestParquetVectorizedReads.java']"
"Docs: Update for mkdocs 1.2 (#2747)

* Docs: Fix mkdocs use_directory_urls in 1.2.

* Fix broken links and update redirects.",5,33,2021-07-01 13:36:51-07:00,"['flink.md', 'java-api-quickstart.md', 'maintenance.md', 'spark-procedures.md', 'mkdocs.yml']"
Docs: Fix typo in flink.md (#2772),1,2,2021-07-01 17:22:39-07:00,['flink.md']
"Spark: RemoveReachableFiles action should fail if GC is disabled (#2763)

Co-authored-by: Karuppayya Rajendran <karuppayya.rajendran@apple.com>",2,29,2021-07-01 17:25:48-07:00,"['BaseRemoveReachableFilesSparkAction.java', 'TestRemoveReachableFilesAction.java']"
Docs: Describe available Benchmarks and how to run them (#2767),2,120,2021-07-02 07:04:29-05:00,"['benchmarks.md', 'community.md']"
Nessie: Properly format code in Nessie module (#2733),5,59,2021-07-05 10:59:22-07:00,"['NessieCatalog.java', 'TableReference.java', 'BaseTestIceberg.java', 'NessieUtilTest.java', 'TestBranchVisibility.java']"
Style: Delete blank line  of CachedClientPool.java (#2787),1,1,2021-07-06 09:59:29-05:00,['CachedClientPool.java']
Spec: Update v2 change summary (#2762),1,99,2021-07-06 12:57:10-07:00,['spec.md']
Build: bump up DiffPlug Spotless version (#2776),1,2,2021-07-06 13:50:37-07:00,['build.gradle']
Core: Fix JdbcCatalog CATALOG_TABLE_NAME to be lowercase (#2778),1,12,2021-07-08 15:30:18+08:00,['JdbcUtil.java']
"Build: Change Spark Versions to Support M1 Processors (#2795)

Spark's Snappy native lib support is missing M1 support in
our current build. Upgrading Spark upgrades Snappy to a version
which has these native libs. This has no effect on actual runtime
Spark for end users since we do not include Spark with our
release jars.",2,6,2021-07-09 09:45:03-05:00,"['build.gradle', 'versions.props']"
Docs: Fixes broken links to old spark doc page (#2801),3,10,2021-07-09 11:50:17-07:00,"['aws.md', 'evolution.md', 'spark-structured-streaming.md']"
Build: Upgrade to JUnit 5 (#2797),2,15,2021-07-10 16:15:27-07:00,"['build.gradle', 'versions.props']"
Spark: Reimplement RewriteDatafilesAction with partial progress (#2591),19,1840,2021-07-11 16:50:36-07:00,"['RewriteDataFiles.java', 'BaseFileGroupRewriteResult.java', 'BaseRewriteDataFilesFileGroupInfo.java', 'BaseRewriteDataFilesResult.java', 'BinPackStrategy.java', 'RewriteDataFilesCommitManager.java', 'RewriteFileGroup.java', 'RewriteStrategy.java', 'Tasks.java', 'TestBinPackStrategy.java', 'BaseRewriteDataFilesSparkAction.java', 'SparkTestBase.java', 'TestNewRewriteDataFilesAction.java', 'FileRewriteCoordinator.java', 'FileScanTaskSetManager.java', 'BaseRewriteDataFilesSpark3Action.java', 'Spark3BinPackStrategy.java', 'SparkActions.java', 'TestNewRewriteDataFilesAction3.java']"
Don't use deprecated methods,3,32,2021-07-12 12:46:03+02:00,"['VectorizedArrowReader.java', 'VectorizedDictionaryEncodedParquetValuesReader.java', 'VectorizedParquetDefinitionLevelReader.java']"
Refactor VectorizedArrowReader,1,304,2021-07-12 12:46:03+02:00,['VectorizedArrowReader.java']
Reduce code duplication in VectorizedColumnIterator,2,342,2021-07-12 12:46:03+02:00,"['VectorizedArrowReader.java', 'VectorizedColumnIterator.java']"
Reduce code duplication in VectorizedDictionaryEncodedParquetValuesReader,4,553,2021-07-12 12:46:03+02:00,"['VectorizedColumnIterator.java', 'VectorizedDictionaryEncodedParquetValuesReader.java', 'VectorizedParquetDefinitionLevelReader.java', 'TestHelpers.java']"
Reduce code duplication in VectorizedPageIterator,3,691,2021-07-12 12:46:03+02:00,"['VectorizedColumnIterator.java', 'VectorizedPageIterator.java', 'VectorizedParquetDefinitionLevelReader.java']"
Reduce code duplication in VectorizedParquetDefinitionLevelReader,3,1508,2021-07-12 12:46:03+02:00,"['VectorizedDictionaryEncodedParquetValuesReader.java', 'VectorizedPageIterator.java', 'VectorizedParquetDefinitionLevelReader.java']"
Upgrade to Tez 0.10.1 (#2790),2,11,2021-07-12 13:31:58+02:00,"['build.gradle', 'HiveIcebergStorageHandlerTestUtils.java']"
Spark: Parallelize task init when fetching locality info (#2800),3,66,2021-07-12 10:24:19-07:00,"['Reader.java', 'SparkBatchScan.java', 'SparkMicroBatchStream.java']"
Spark: Add table property to skip delete snapshots in streaming (#2752),4,123,2021-07-12 17:16:36-07:00,"['SparkReadOptions.java', 'Spark3Util.java', 'SparkMicroBatchStream.java', 'TestStructuredStreamingRead3.java']"
API: Use delete instead of remove in action names (#2810),15,210,2021-07-12 19:20:32-07:00,"['ActionsProvider.java', 'DeleteOrphanFiles.java', 'DeleteReachableFiles.java', 'BaseDeleteOrphanFilesActionResult.java', 'BaseDeleteReachableFilesActionResult.java', 'Actions.java', 'RemoveOrphanFilesAction.java', 'BaseDeleteOrphanFilesSparkAction.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseSparkActions.java', 'TestDeleteReachableFilesAction.java', 'TestNewRewriteDataFilesAction.java', 'TestDeleteReachableFilesAction24.java', 'RemoveOrphanFilesProcedure.java', 'TestRemoveFilesAction3.java']"
Spark: Use JavaSparkContext.fromSparkContext instead of constructor (#2812),7,19,2021-07-12 19:28:51-07:00,"['checkstyle.xml', 'RewriteDataFilesAction.java', 'BaseSparkAction.java', 'TestDataFrameWrites.java', 'TestPartitionPruning.java', 'TestSparkDataFile.java', 'TestWriteMetricsConfig.java']"
Spark: Add missing deprecation annotations for old actions (#2811),6,54,2021-07-12 22:49:37-07:00,"['Actions.java', 'CreateAction.java', 'RewriteDataFilesAction.java', 'SnapshotAction.java', 'SparkActions.java', 'SparkActions.java']"
Docs: Fix link to intellij-java-palantir-style.xml (#2817),1,2,2021-07-13 15:40:28+02:00,['community.md']
"Spark : Add Files Perf improvement by push down partition filter to Spark/Hive catalog (#2777)

Pushes down partition filters in Spark/Hive Import to underlying catalog instead of retrieving all partitions and then filtering.",3,122,2021-07-13 09:58:04-05:00,"['SparkTableUtil.java', 'TestSparkTableUtil.java', 'TestAddFilesProcedure.java']"
"Core: Use Avro 1.10.1 (#1648)

Co-authored-by: Fokko Driesprong <fdriesprong@ebay.com>",7,248,2021-07-13 08:59:22-07:00,"['AssertHelpers.java', 'TestManifestListVersions.java', 'TestReadProjection.java', 'ParquetAvro.java', 'TestHelpers.java', 'TestReadProjection.java', 'versions.props']"
"Add support for reading/writing timestamps without timezone.  (#2757)

Previously Spark could not handle Iceberg tables which contained Timestamp.withoutTimeZone. New parameters are introduced to allow Timestamp without TimeZone to be treated as Timestamp with Timezone.  

Co-authored-by: bkahloon <kahlonbakht@gmail.com>
Co-authored-by: shardulm94",20,820,2021-07-15 12:06:44-05:00,"['PruneColumnsWithoutReordering.java', 'SparkFixupTimestampType.java', 'SparkFixupTypes.java', 'SparkSchemaUtil.java', 'SparkUtil.java', 'TypeToSparkType.java', 'SparkOrcReader.java', 'SparkOrcWriter.java', 'VectorizedSparkOrcReaders.java', 'AvroDataTest.java', 'GenericsHelpers.java', 'TestTimestampWithoutZone.java', 'IcebergSource.java', 'Reader.java', 'TestTimestampWithoutZone24.java', 'SparkCatalog.java', 'SparkBatchScan.java', 'SparkWriteBuilder.java', 'TestTimestampWithoutZone3.java', 'TestTimestampWithoutZone.java']"
"Spark: Remove unused FileRewriteCoordinator code (#2819)

Since we changed our implementation of Spark3BinPackStrategy, we no longer need some
of the functionality that was previously in FileRewriteCoordinator. Here we remove
those functions and related test code.",3,127,2021-07-15 10:45:24-07:00,"['FileRewriteCoordinator.java', 'Spark3BinPackStrategy.java', 'TestFileRewriteCoordinator.java']"
"Bump Nessie to 0.8.2 + related changes (#2588)

* Bump Nessie to 0.8.2 + replace Gradle plugin with new JUnit extension

More changes in this PR in following commits.

Replace Gradle plugin with new JUnit extension.
See [Add JAX-RS tests and add JUnit/Jupyter extension](https://github.com/projectnessie/nessie/pull/1566)

* Changes required by Nessie-API changes

Apply changes to Iceberg required by API changes in Nessie:
* [Re-introduce wrapper classes for query params of CommitLog/Entries](https://github.com/projectnessie/nessie/pull/1595)
* [Server-side commit range filtering](https://github.com/projectnessie/nessie/pull/1596)
* [Add hashOnRef query param to support time travel on a named ref](https://github.com/projectnessie/nessie/pull/1589)
* [Only accept NamedRefs in REST API](https://github.com/projectnessie/nessie/pull/1583)

* Bugfix: must send the Contents.id of the existing table

Nessie's `Contents.id` is a random ID generated when the `Contents.Key` is first used (think:
CREATE TABLE) and must not be changed. This change addresses a bug in the Iceberg-Nesie code
that caused a new id for every change.

* Throw `CommitStateUnknownException` for `renameTable` as well

Follow-up of #2515

* Fix race-condition & save one roundtrip to Nessie during ""commit""

When commiting a change, the Nessie-API now returns the hash of the commit for the change.
This returned hash should then be used as the ""expected hash"" for the next commit.

The previous approach was to commit the change to Nessie and then do another request to
retrieve the new hash of HEAD.

This old approach is prone to a race condition, namely when another commit happens after
""this"" commit but before retrieving the ""new HEAD"", so ""this"" instance would wrongly
ignore the other commit's changes during conflict checks.

See [Let VersionStore.create()+commit() return the current hash](https://github.com/projectnessie/nessie/pull/1089)",11,155,2021-07-16 00:21:27+02:00,"['build.gradle', 'NessieCatalog.java', 'NessieTableOperations.java', 'UpdateableReference.java', 'BaseTestIceberg.java', 'NessieUtilTest.java', 'TestBranchVisibility.java', 'TestNamespace.java', 'TestNessieTable.java', 'TestTableReference.java', 'versions.props']"
ORC: Upgrade ORC dependency to 1.6.9 (#2781),1,2,2021-07-16 10:34:38-05:00,['versions.props']
Move Assert.assertTrue(..) instance checks to AssertJ assertions (#2756),25,394,2021-07-19 12:57:09+02:00,"['TestExpressionBinding.java', 'TestProjection.java', 'TestStartsWith.java', 'LockManagersTest.java', 'TestCatalogUtil.java', 'TestSortOrderParser.java', 'AvroTestHelpers.java', 'TestExceptionUtil.java', 'DataTestHelpers.java', 'TestCatalogTableLoader.java', 'TestDataFileSerialization.java', 'TestFlinkFilters.java', 'TestHelpers.java', 'TestManifestFileSerialization.java', 'TestIcebergStreamWriter.java', 'TestCatalogs.java', 'TestHelpers.java', 'TestDataFileSerialization.java', 'TestManifestFileSerialization.java', 'TestScanTaskSerialization.java', 'GenericsHelpers.java', 'TestHelpers.java', 'TestFilteredScan.java', 'TestFilteredScan.java', 'TestPathIdentifier.java']"
"SPARK: Allow spark catalogs to have hadoop configuration overrides p (#2792)

Previously Iceberg Catalogs loaded into Spark would always use the Hadoop Configuration owned by the underlying Spark Session. This made it impossible to use a different set of configuration values which may be required to connect to a remote Catalog. This patch allows Spark catalogs to have hadoop configuration overrides per catalog permitting different configuration for different underlying Iceberg catalogs.",4,180,2021-07-19 17:09:03-05:00,"['SparkUtil.java', 'CustomCatalogs.java', 'SparkCatalog.java', 'TestSparkCatalogHadoopOverrides.java']"
Nessie: Bump Nessie to 0.8.3 / Rename auth_type to auth-type (#2834),2,4,2021-07-20 10:32:40+02:00,"['BaseTestIceberg.java', 'versions.props']"
Spec: Fix missing negative in binary/fixed hash examples (#2840),1,4,2021-07-20 14:00:34-07:00,['spec.md']
Doc: add documentation for JDBC and DynamoDB catalogs (#2831),3,137,2021-07-20 18:56:57-07:00,"['aws.md', 'jdbc.md', 'mkdocs.yml']"
"Core: Adds SortRewriteStrategy (#2609)

A rewrite strategy for data files which aims to reorder data with data files to optimally lay them out
in relation to a column. For example, if the Sort strategy is used on a set of files which is ordered
by column x and original has files File A (x: 0 - 50), File B ( x: 10 - 40) and File C ( x: 30 - 60),
this Strategy will attempt to rewrite those files into File A' (x: 0-20), File B' (x: 21 - 40),
File C' (x: 41 - 60).",4,282,2021-07-21 08:47:00-05:00,"['SortOrder.java', 'SortStrategy.java', 'MockFileScanTask.java', 'TestSortStrategy.java']"
API: Fix string bucketing with non-BMP characters (#2849),2,25,2021-07-22 12:24:52-07:00,"['Bucket.java', 'TestBucketing.java']"
Core: Add table properties for Avro and Parquet delete files (#2851),3,196,2021-07-23 14:28:02-07:00,"['TableProperties.java', 'Avro.java', 'Parquet.java']"
Core: Add DataWriter builders (#2857),6,629,2021-07-23 18:03:46-07:00,"['Avro.java', 'TestAvroDataWriter.java', 'TestOrcDataWriter.java', 'ORC.java', 'Parquet.java', 'TestParquetDataWriter.java']"
Docs: Add new blog - Apache Iceberg: An Architectural Look Under the Covers (#2856),1,5,2021-07-26 10:26:35+08:00,['blogs.md']
Core: Support multiple specs in OutputFileFactory (#2858),11,209,2021-07-26 14:57:38-07:00,"['OutputFileFactory.java', 'TestOutputFileFactory.java', 'TestAppenderFactory.java', 'TestBaseTaskWriter.java', 'TestGenericSortedPosDeleteWriter.java', 'TestTaskEqualityDeltaWriter.java', 'HiveIcebergOutputFormat.java', 'TestHiveIcebergOutputCommitter.java', 'RowDataRewriter.java', 'Writer.java', 'SparkWrite.java']"
"Docs: Add security page to ASF site (#2813)

This patch adds a page to the site docs which describes the process for
reporting security vulnerabilites found in Apache Iceberg.",2,27,2021-07-26 15:30:09-07:00,"['security.md', 'mkdocs.yml']"
"Spec: Add back distinct_counts in data_file metadata (#2805)

* Spec: Add back distinct_counts in data_file metadata.

* Update for review comments.",1,3,2021-07-26 17:10:44-07:00,['spec.md']
Spec: Make contains_nan partition summary field optional in v2. (#2864),1,4,2021-07-26 17:11:01-07:00,['spec.md']
"Build: Run tests against Spark 3.0 and Spark 3.1

Due to an issue with the build.gradle both the spark test and test31 modules were both running with Spark 3.1. Removing the inter dependency fixes the issue and both grade tasks now run with the correct respective spark versions.",1,8,2021-07-26 22:11:46-05:00,['build.gradle']
Core: Add validation for row-level deletes with rewrites (#2865),10,284,2021-07-27 08:59:53-07:00,"['RewriteFiles.java', 'BaseRewriteFiles.java', 'BaseRowDelta.java', 'DeleteFileIndex.java', 'MergingSnapshotProducer.java', 'BaseRewriteDataFilesAction.java', 'RewriteDataFilesCommitManager.java', 'TestRewriteFiles.java', 'BaseRewriteDataFilesSparkAction.java', 'TestNewRewriteDataFilesAction.java']"
Docs: Add Tencent blog - Flink + Iceberg: How to Construct a Whole-scenario Real-time Data Warehouse (#2876),1,5,2021-07-28 09:26:25+08:00,['blogs.md']
Docs: Avoid insinuating other file format is supported (#2883),1,2,2021-07-28 19:42:29+08:00,['spec.md']
Docs: Update Slack invite link (#2882),1,7,2021-07-28 10:20:39-05:00,['community.md']
"[Python] support BucketByteBuffer and BucketUUID (#2836)

* [Python] support BucketByteBuffer and BucketUUID

* Add additional unit tests for bucket hash methods.",3,86,2021-07-28 12:34:22-07:00,"['bucket.py', 'test_partition_spec.py', 'test_bucket.py']"
"[python] Updating pyarrow dependencies (#2888)

Co-authored-by: tgooch <tgooch@netflix.com>",1,2,2021-07-28 16:50:51-07:00,['setup.py']
Core: Fix the NPE in DataFiles.Builder#copy (#2852),2,8,2021-07-29 15:35:07+08:00,"['DataFiles.java', 'TestSparkDataFile.java']"
Core:  Add includeColumnStats option in FindFiles API (#2875),3,44,2021-07-29 18:40:05+08:00,"['FindFiles.java', 'TableTestBase.java', 'TestFindFiles.java']"
Api#2880: Close the underlying iterator in ClosingIterator in hasNext() call (#2881),2,100,2021-07-30 13:48:22+02:00,"['ClosingIterator.java', 'TestClosingIterator.java']"
Core: Add WriterFactory (#2873),10,1094,2021-07-31 00:18:17-07:00,"['checkstyle.xml', 'MetadataColumns.java', 'Avro.java', 'WriterFactory.java', 'BaseWriterFactory.java', 'TestWriterFactory.java', 'ORC.java', 'Parquet.java', 'SparkWriterFactory.java', 'TestSparkWriterFactory.java']"
Build: Fix site publishing in .asf.yaml.,1,3,2021-08-01 11:28:23-07:00,['.asf.yaml']
"Docs: Update Slack invite link (#2904)

* Docs: Update Slack invite link.

* Update the intro paragraph as well.",1,7,2021-08-01 16:23:03-07:00,['community.md']
"Core: Fix partition field IDs in table replacement (#2906)

Co-authored-by: Jun He <jun-he@users.noreply.github.com>",7,218,2021-08-03 07:39:58-07:00,"['TableMetadata.java', 'TestReplaceTransaction.java', 'TestTableMetadata.java', 'TestHadoopCatalog.java', 'TestJdbcCatalog.java', 'HiveCreateReplaceTableTest.java', 'TestHiveCatalog.java']"
"Parquet: Annotate UUID fields (#2913)

The spec mandates that UUID fields in Parquet have logical type ""UUID""
(https://iceberg.apache.org/spec/#parquet). This is possible to fulfill
after 236615497bdc2c6fbedbd3acc41a4ed85c4a8bfd, as
`LogicalTypeAnnotation.uuidType` was added in Parquet 1.12.0.",1,5,2021-08-03 09:21:16-07:00,['TypeToMessageType.java']
Flink: Switch to using SerializableTable (#2923),5,63,2021-08-03 10:29:44-07:00,"['FlinkSink.java', 'RowDataTaskWriterFactory.java', 'RowDataRewriter.java', 'TestDeltaTaskWriter.java', 'TestTaskWriters.java']"
Core: Support nulls in StructLike collections (#2929),5,125,2021-08-03 12:47:39-07:00,"['JavaHashes.java', 'StructLikeMap.java', 'StructLikeSet.java', 'TestStructLikeMap.java', 'TestStructLikeSet.java']"
Core: Allow creating v2 tables through table property (#2887),6,265,2021-08-03 15:27:58-07:00,"['TableMetadata.java', 'TableProperties.java', 'TestTableMetadata.java', 'TestFlinkCatalogTable.java', 'TestHiveIcebergStorageHandlerNoScan.java', 'TestCreateTable.java']"
Add thenewstack.io article to list of blog posts (#2930),1,5,2021-08-03 18:21:53-07:00,['blogs.md']
Flink: Add FlinkWriterFactory (#2924),2,317,2021-08-04 22:35:22+08:00,"['FlinkWriterFactory.java', 'TestFlinkWriterFactory.java']"
Add list of Github collaborators to asf.yaml (#2909),1,14,2021-08-04 19:51:33-07:00,['.asf.yaml']
"Spark: Fix nested struct pruning (#2877)

* Spark: Support Nested Struct Pruning in DataTasks

Previously DataTasks would return full schemas for some tables and pruned schemas for others and would rely on the underlying framework to do the actual projection. This moves projection and pruning into the core responsibility of the task. This fixes an issue where Spark would be able to pushdown some nested struct predicates to a metadata table but we wouldn't recognize this when trying to do the projection in the framework. StaticDataTasks now support projection in their creation but only if it does not require pruning fields from within a struct which is an element of a List or Map.",12,377,2021-08-05 07:23:07-05:00,"['StructProjection.java', 'AllEntriesTable.java', 'AllManifestsTable.java', 'DataFilesTable.java', 'HistoryTable.java', 'ManifestEntriesTable.java', 'ManifestsTable.java', 'PartitionsTable.java', 'SnapshotsTable.java', 'StaticDataTask.java', 'RowDataReader.java', 'TestIcebergSourceTablesBase.java']"
Core: Fix nested schema projection in AllDataFilesTable (#2941),1,6,2021-08-05 10:52:11-07:00,['AllDataFilesTable.java']
Flink: Add uidPrefix to operator name so that Flink web UI can show names for different iceberg sinks in a job (#2886),2,204,2021-08-06 22:53:40+08:00,"['FlinkSink.java', 'TestFlinkIcebergSink.java']"
Docs: Add Hadoop conf overrides in Spark (#2922),1,8,2021-08-06 14:14:26-07:00,['spark-configuration.md']
Doc: update README local build instructions (#2949),1,2,2021-08-06 15:43:31-07:00,['README.md']
AWS: Fix concurrent modification integration test (#2948),2,38,2021-08-09 12:58:27-07:00,"['AssertHelpers.java', 'GlueCatalogCommitFailureTest.java']"
"Spark: Fix broken RepartitionByExpression in RewriteDelete for 3.1 (#2954)

The constructor of RepartitionByExpression changed between Spark 3.0 and 3.1.
There was an instance of constructing RepartitionByExpression that was missed in the original commit (#2512).",3,50,2021-08-09 13:55:05-07:00,"['RewriteDelete.scala', 'DistributionAndOrderingUtils.scala', 'PlanUtils.scala']"
API: Validate identifier fields in Schema (#2943),4,79,2021-08-09 13:58:25-07:00,"['Schema.java', 'SchemaUpdate.java', 'TestSchemaUpdate.java', 'TestFlinkSchemaUtil.java']"
Spark: Fix random test failures in TestDeleteReachableFilesAction (#2951),1,2,2021-08-09 14:55:41-07:00,['TestDeleteReachableFilesAction.java']
Core: Add predicate pushdown for files metadata table (#2926),4,325,2021-08-09 15:58:51-07:00,"['BaseMetadataTable.java', 'DataFilesTable.java', 'PartitionsTable.java', 'TestMetadataTableScans.java']"
Fix formatting issue on security page,1,8,2021-08-11 11:21:35-07:00,['security.md']
"Spark: Don't create empty partition replace operations (#2960)

* Spark: Don't create empty partition replace operations

When attempting to insert overwrite with an empty dataset
we would previously throw an error because of creating an 
empty replace operation. This patch causes Spark
to skip any no-op partition replacement operations instead of
attempting to commit an empty replace.",3,62,2021-08-11 14:33:01-05:00,"['TestSparkDataWrite.java', 'Writer.java', 'SparkWrite.java']"
"Core: allow default data location for ObjectStorageLocationProvider (#2845)

* Core: allow default data location for ObjectStorageLocationProvider

* add test for fallback to folder path

* update test name",2,37,2021-08-12 14:04:06-07:00,"['LocationProviders.java', 'TestLocationProvider.java']"
"Spark: Add duplicate file check in add_files (#2779)

* Spark : Add duplicate file check in add_files

Adds a check that no files being added to a table with add_files already exist within the table being added to.",4,352,2021-08-12 21:15:08-05:00,"['SparkTableUtil.java', 'BaseSparkAction.java', 'TestAddFilesProcedure.java', 'AddFilesProcedure.java']"
Core: Serialize all specs in SerializableTable (#2975),1,36,2021-08-13 23:09:45-07:00,['SerializableTable.java']
Core: Fix querying metadata tables with multiple specs (#2936),7,599,2021-08-13 23:16:13-07:00,"['AllDataFilesTable.java', 'AllEntriesTable.java', 'DataFilesTable.java', 'ManifestEntriesTable.java', 'Partitioning.java', 'TestPartitioning.java', 'TestMetadataTablesWithPartitionEvolution.java']"
"Docs: Clarify ObjectStoreLocationProvider (#2963)

Clarified the description on ObjectStoreLocationProvider on that it generates a deterministic hash based on the filename, and that the hash is placed after `write.object-storage.path`.

Added an example s3 path for ObjectStorageProvider

Docs aws.md - Updated with suggestions

Added
- path resolution information
- link to YT video on how S3 scales
- explained that 2d3905f8 is a hash in the s3 path
- changed text to ""table properties""",1,31,2021-08-15 11:24:34-07:00,['aws.md']
Update python-feature-support.md (#2982),1,3,2021-08-16 11:43:59-07:00,['python-feature-support.md']
Add release notes for 0.12.0 (#2973),7,92,2021-08-16 20:51:45-07:00,"['flink.md', 'hive.md', 'maintenance.md', 'nessie.md', 'releases.md', 'spark-procedures.md', 'mkdocs.yml']"
Doc: Fix broken time travel link on project front page (#2974),1,2,2021-08-17 11:06:51-07:00,['index.md']
MR: Use SerializableTable in IcebergSplit (#2988),2,52,2021-08-17 13:18:19-07:00,"['IcebergInputFormat.java', 'IcebergSplit.java']"
"Doc: refactor engines pages and add link to PrestoDB (#2842)

* Doc: refactor engines pages and add link to PrestoDB

* address comments",4,49,2021-08-17 16:03:31-07:00,"['getting-started.md', 'index.md', 'trino-prestodb.md', 'mkdocs.yml']"
"Miscellaneous improvements to source-release.sh (#2938)

Add command line options for the following:
* Specifying the keyId of the key to use for signing
* Setting the name of the Git remote for staging the release
* Enabling DEBUG output

Also:
* Print template announcement email.
* Improve the progress messages printed to STDOUT.",1,154,2021-08-18 09:08:13-07:00,['source-release.sh']
Add Starburst blog series (#2971),1,15,2021-08-18 09:37:47-07:00,['blogs.md']
Docs: Add Javadoc for 0.12.0 release (#2994),977,438240,2021-08-18 11:37:40-07:00,"['allclasses-index.html', 'allclasses.html', 'allpackages-index.html', 'constant-values.html', 'deprecated-list.html', 'help-doc.html', 'index-all.html', 'index.html', 'jquery.js', 'ui-bg_glass_55_fbf9ee_1x400.png', 'ui-bg_glass_65_dadada_1x400.png', 'ui-bg_glass_75_dadada_1x400.png', 'ui-bg_glass_75_e6e6e6_1x400.png', 'ui-bg_glass_95_fef1ec_1x400.png', 'ui-bg_highlight-soft_75_cccccc_1x100.png', 'ui-icons_222222_256x240.png', 'ui-icons_2e83ff_256x240.png', 'ui-icons_454545_256x240.png', 'ui-icons_888888_256x240.png', 'ui-icons_cd0a0a_256x240.png', 'jquery-3.5.1.js', 'jquery-ui.css', 'jquery-ui.js', 'jquery-ui.min.css', 'jquery-ui.min.js', 'jquery-ui.structure.css', 'jquery-ui.structure.min.css', 'member-search-index.js', 'member-search-index.zip', 'VectorizedSupport.Support.html', 'VectorizedSupport.html', 'package-summary.html', 'package-tree.html', 'Accessor.html', 'Accessors.html', 'AllDataFilesTable.AllDataFilesTableScan.html', 'AllDataFilesTable.html', 'AllEntriesTable.html', 'AllManifestsTable.AllManifestsTableScan.html', 'AllManifestsTable.html', 'AppendFiles.html', 'BaseCombinedScanTask.html', 'BaseMetastoreCatalog.BaseMetastoreCatalogTableBuilder.html', 'BaseMetastoreCatalog.html', 'BaseMetastoreTableOperations.CommitStatus.html', 'BaseMetastoreTableOperations.html', 'BaseOverwriteFiles.html', 'BaseReplacePartitions.html', 'BaseReplaceSortOrder.html', 'BaseRewriteManifests.html', 'BaseTable.html', 'CachingCatalog.html', 'CatalogProperties.html', 'CatalogUtil.html', 'ClientPool.Action.html', 'ClientPool.html', 'ClientPoolImpl.html', 'CombinedScanTask.html', 'ContentFile.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DataFilesTable.FilesTableScan.html', 'DataFilesTable.html', 'DataOperations.html', 'DataTableScan.html', 'DataTask.html', 'DeleteFile.html', 'DeleteFiles.html', 'DistributionMode.html', 'DoubleFieldMetrics.Builder.html', 'DoubleFieldMetrics.html', 'ExpireSnapshots.html', 'FieldMetrics.html', 'FileContent.html', 'FileFormat.html', 'FileMetadata.Builder.html', 'FileMetadata.html', 'FileScanTask.html', 'Files.html', 'FindFiles.Builder.html', 'FindFiles.html', 'FloatFieldMetrics.Builder.html', 'FloatFieldMetrics.html', 'GenericManifestFile.CopyBuilder.html', 'GenericManifestFile.html', 'GenericPartitionFieldSummary.html', 'GuavaClasses.html', 'HasTableOperations.html', 'HistoryEntry.html', 'HistoryTable.html', 'IsolationLevel.html', 'LocationProviders.html', 'ManageSnapshots.html', 'ManifestContent.html', 'ManifestEntriesTable.html', 'ManifestFile.PartitionFieldSummary.html', 'ManifestFile.html', 'ManifestFiles.html', 'ManifestReader.FileType.html', 'ManifestReader.html', 'ManifestWriter.html', 'ManifestsTable.html', 'MetadataColumns.html', 'MetadataTableType.html', 'MetadataTableUtils.html', 'Metrics.html', 'MetricsConfig.html', 'MetricsModes.Counts.html', 'MetricsModes.Full.html', 'MetricsModes.MetricsMode.html', 'MetricsModes.None.html', 'MetricsModes.Truncate.html', 'MetricsModes.html', 'MetricsUtil.html', 'MicroBatches.MicroBatch.html', 'MicroBatches.MicroBatchBuilder.html', 'MicroBatches.html', 'NullOrder.html', 'OverwriteFiles.html', 'PartitionField.html', 'PartitionKey.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'Partitioning.html', 'PartitionsTable.html', 'PendingUpdate.html', 'ReachableFileUtil.html', 'ReplacePartitions.html', 'ReplaceSortOrder.html', 'RewriteFiles.html', 'RewriteManifests.html', 'Rollback.html', 'RowDelta.html', 'ScanSummary.Builder.html', 'ScanSummary.PartitionMetrics.html', 'ScanSummary.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'SerializableTable.html', 'SetLocation.html', 'Snapshot.html', 'SnapshotManager.html', 'SnapshotParser.html', 'SnapshotSummary.Builder.html', 'SnapshotSummary.html', 'SnapshotUpdate.html', 'SnapshotsTable.html', 'SortDirection.html', 'SortField.html', 'SortOrder.Builder.html', 'SortOrder.html', 'SortOrderBuilder.html', 'SortOrderParser.html', 'StaticTableOperations.html', 'StructLike.html', 'SystemProperties.html', 'Table.html', 'TableMetadata.MetadataLogEntry.html', 'TableMetadata.SnapshotLogEntry.html', 'TableMetadata.html', 'TableMetadataParser.Codec.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableProperties.html', 'TableScan.html', 'Tables.html', 'Transaction.html', 'Transactions.html', 'UpdateLocation.html', 'UpdatePartitionSpec.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Action.html', 'Actions.html', 'ActionsProvider.html', 'BaseDeleteOrphanFilesActionResult.html', 'BaseDeleteReachableFilesActionResult.html', 'BaseExpireSnapshotsActionResult.html', 'BaseFileGroupRewriteResult.html', 'BaseMigrateTableActionResult.html', 'BaseRewriteDataFilesAction.html', 'BaseRewriteDataFilesFileGroupInfo.html', 'BaseRewriteDataFilesResult.html', 'BaseRewriteManifestsActionResult.html', 'BaseSnapshotTableActionResult.html', 'BinPackStrategy.html', 'CreateAction.html', 'DeleteOrphanFiles.Result.html', 'DeleteOrphanFiles.html', 'DeleteReachableFiles.Result.html', 'DeleteReachableFiles.html', 'ExpireSnapshots.Result.html', 'ExpireSnapshots.html', 'ExpireSnapshotsAction.html', 'ExpireSnapshotsActionResult.html', 'ManifestFileBean.html', 'MigrateTable.Result.html', 'MigrateTable.html', 'RemoveOrphanFilesAction.html', 'RewriteDataFiles.FileGroupInfo.html', 'RewriteDataFiles.FileGroupRewriteResult.html', 'RewriteDataFiles.Result.html', 'RewriteDataFiles.html', 'RewriteDataFilesAction.html', 'RewriteDataFilesActionResult.html', 'RewriteDataFilesCommitManager.CommitService.html', 'RewriteDataFilesCommitManager.html', 'RewriteFileGroup.html', 'RewriteManifests.Result.html', 'RewriteManifests.html', 'RewriteManifestsAction.html', 'RewriteManifestsActionResult.html', 'RewriteStrategy.html', 'SnapshotAction.html', 'SnapshotTable.Result.html', 'SnapshotTable.html', 'SnapshotUpdate.html', 'SnapshotUpdateAction.html', 'SortStrategy.html', 'Spark3MigrateAction.html', 'Spark3SnapshotAction.html', 'SparkActions.html', 'package-summary.html', 'package-tree.html', 'ArrowAllocation.html', 'ArrowSchemaUtil.html', 'package-summary.html', 'package-tree.html', 'ArrowReader.html', 'ArrowVectorAccessor.html', 'ColumnVector.html', 'ColumnarBatch.html', 'GenericArrowVectorAccessorFactory.ArrayFactory.html', 'GenericArrowVectorAccessorFactory.DecimalFactory.html', 'GenericArrowVectorAccessorFactory.StringFactory.html', 'GenericArrowVectorAccessorFactory.StructChildFactory.html', 'GenericArrowVectorAccessorFactory.html', 'NullabilityHolder.html', 'VectorHolder.ConstantVectorHolder.html', 'VectorHolder.PositionVectorHolder.html', 'VectorHolder.html', 'VectorizedArrowReader.ConstantVectorReader.html', 'VectorizedArrowReader.html', 'VectorizedReaderBuilder.html', 'VectorizedTableScanIterable.html', 'package-summary.html', 'package-tree.html', 'BaseVectorizedParquetValuesReader.html', 'VectorizedColumnIterator.BatchReader.html', 'VectorizedColumnIterator.BooleanBatchReader.html', 'VectorizedColumnIterator.DictionaryBatchReader.html', 'VectorizedColumnIterator.DoubleBatchReader.html', 'VectorizedColumnIterator.FixedLengthDecimalBatchReader.html', 'VectorizedColumnIterator.FixedSizeBinaryBatchReader.html', 'VectorizedColumnIterator.FixedWidthTypeBinaryBatchReader.html', 'VectorizedColumnIterator.FloatBatchReader.html', 'VectorizedColumnIterator.IntBackedDecimalBatchReader.html', 'VectorizedColumnIterator.IntegerBatchReader.html', 'VectorizedColumnIterator.LongBackedDecimalBatchReader.html', 'VectorizedColumnIterator.LongBatchReader.html', 'VectorizedColumnIterator.TimestampMillisBatchReader.html', 'VectorizedColumnIterator.VarWidthTypeBatchReader.html', 'VectorizedColumnIterator.html', 'VectorizedDictionaryEncodedParquetValuesReader.html', 'VectorizedPageIterator.html', 'VectorizedParquetDefinitionLevelReader.html', 'package-summary.html', 'package-tree.html', 'Avro.DataWriteBuilder.html', 'Avro.DeleteWriteBuilder.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroEncoderUtil.html', 'AvroIterable.html', 'AvroMetrics.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'AvroSchemaWithTypeVisitor.html', 'AvroWithPartnerByStructureVisitor.html', 'LogicalMap.html', 'MetricsAwareDatumWriter.html', 'ProjectionDatumReader.html', 'RemoveIds.html', 'SupportsRowPosition.html', 'UUIDConversion.html', 'ValueReader.html', 'ValueReaders.StructReader.html', 'ValueReaders.html', 'ValueWriter.html', 'ValueWriters.StructWriter.html', 'ValueWriters.html', 'package-summary.html', 'package-tree.html', 'AssumeRoleAwsClientFactory.html', 'AwsClientFactories.html', 'AwsClientFactory.html', 'AwsProperties.html', 'DynamoDbCatalog.html', 'package-summary.html', 'package-tree.html', 'GlueCatalog.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'S3FileIO.html', 'S3InputFile.html', 'S3OutputFile.html', 'S3RequestUtil.html', 'package-summary.html', 'package-tree.html', 'Catalog.TableBuilder.html', 'Catalog.html', 'Namespace.html', 'SupportsNamespaces.html', 'TableIdentifier.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-summary.html', 'package-tree.html', 'BaseWriterFactory.html', 'DeleteFilter.html', 'GenericAppenderFactory.html', 'GenericDeleteFilter.html', 'GenericRecord.html', 'IcebergGenerics.ScanBuilder.html', 'IcebergGenerics.html', 'IdentityPartitionConverters.html', 'InternalRecordWrapper.html', 'Record.html', 'TableMigrationUtil.html', 'DataReader.html', 'DataWriter.html', 'DecoderResolver.html', 'IcebergDecoder.html', 'IcebergEncoder.html', 'package-summary.html', 'package-tree.html', 'GenericOrcReader.html', 'GenericOrcReaders.html', 'GenericOrcWriter.html', 'GenericOrcWriters.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'BaseParquetReaders.html', 'BaseParquetWriter.html', 'GenericParquetReaders.html', 'GenericParquetWriter.html', 'package-summary.html', 'package-tree.html', 'Deletes.html', 'EqualityDeleteWriter.html', 'PositionDelete.html', 'PositionDeleteWriter.html', 'package-summary.html', 'package-tree.html', 'EncryptedFiles.html', 'EncryptedInputFile.html', 'EncryptedOutputFile.html', 'EncryptionKeyMetadata.html', 'EncryptionKeyMetadatas.html', 'EncryptionManager.html', 'PlaintextEncryptionManager.html', 'package-summary.html', 'package-tree.html', 'CreateSnapshotEvent.html', 'IncrementalScanEvent.html', 'Listener.html', 'Listeners.html', 'ScanEvent.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CherrypickAncestorCommitException.html', 'CommitFailedException.html', 'CommitStateUnknownException.html', 'DuplicateWAPCommitException.html', 'NamespaceNotEmptyException.html', 'NoSuchIcebergTableException.html', 'NoSuchNamespaceException.html', 'NoSuchTableException.html', 'NotFoundException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'Bound.html', 'BoundLiteralPredicate.html', 'BoundPredicate.html', 'BoundReference.html', 'BoundSetPredicate.html', 'BoundTerm.html', 'BoundTransform.html', 'BoundUnaryPredicate.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.BoundVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'InclusiveMetricsEvaluator.html', 'Literal.html', 'ManifestEvaluator.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'StrictMetricsEvaluator.html', 'Term.html', 'True.html', 'Unbound.html', 'UnboundPredicate.html', 'UnboundTerm.html', 'UnboundTransform.html', 'package-summary.html', 'package-tree.html', 'CatalogLoader.CustomCatalogLoader.html', 'CatalogLoader.HadoopCatalogLoader.html', 'CatalogLoader.HiveCatalogLoader.html', 'CatalogLoader.html', 'FlinkCatalog.html', 'FlinkCatalogFactory.html', 'FlinkConfigOptions.html', 'FlinkDynamicTableFactory.html', 'FlinkFilters.html', 'FlinkSchemaUtil.html', 'FlinkTypeVisitor.html', 'IcebergTableSink.html', 'IcebergTableSource.html', 'RowDataWrapper.html', 'TableLoader.CatalogTableLoader.html', 'TableLoader.HadoopTableLoader.html', 'TableLoader.html', 'Actions.html', 'RewriteDataFilesAction.html', 'package-summary.html', 'package-tree.html', 'AvroWithFlinkSchemaVisitor.html', 'FlinkAvroReader.html', 'FlinkAvroWriter.html', 'FlinkOrcReader.html', 'FlinkOrcWriter.html', 'FlinkParquetReaders.html', 'FlinkParquetWriters.html', 'FlinkValueReaders.html', 'FlinkValueWriters.html', 'ParquetWithFlinkSchemaVisitor.html', 'RowDataUtil.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'FlinkAppenderFactory.html', 'FlinkSink.Builder.html', 'FlinkSink.html', 'RowDataTaskWriterFactory.html', 'TaskWriterFactory.html', 'package-summary.html', 'package-tree.html', 'FlinkInputFormat.html', 'FlinkInputSplit.html', 'FlinkSource.Builder.html', 'FlinkSource.html', 'RowDataRewriter.RewriteMap.html', 'RowDataRewriter.html', 'StreamingMonitorFunction.html', 'StreamingReaderOperator.html', 'package-summary.html', 'package-tree.html', 'FlinkCompatibilityUtil.html', 'package-summary.html', 'package-tree.html', 'ConfigProperties.html', 'HadoopCatalog.html', 'HadoopConfigurable.html', 'HadoopFileIO.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTableOperations.html', 'HadoopTables.html', 'HiddenPathFilter.html', 'SerializableConfiguration.html', 'Util.html', 'package-summary.html', 'package-tree.html', 'CachedClientPool.html', 'HiveCatalog.html', 'HiveCatalogs.html', 'HiveClientPool.html', 'HiveSchemaUtil.html', 'HiveTableOperations.html', 'MetastoreUtil.html', 'RuntimeMetaException.html', 'package-summary.html', 'package-tree.html', 'BaseTaskWriter.BaseEqualityDeltaWriter.html', 'BaseTaskWriter.RollingEqDeleteWriter.html', 'BaseTaskWriter.RollingFileWriter.html', 'BaseTaskWriter.html', 'CloseableGroup.html', 'CloseableIterable.ConcatCloseableIterable.html', 'CloseableIterable.html', 'CloseableIterator.html', 'ClosingIterator.html', 'DataWriter.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'DeleteSchemaUtil.html', 'FileAppender.html', 'FileAppenderFactory.html', 'FileIO.html', 'FilterIterator.html', 'InputFile.html', 'LocationProvider.html', 'OutputFile.html', 'OutputFileFactory.Builder.html', 'OutputFileFactory.html', 'PartitionedFanoutWriter.html', 'PartitionedWriter.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'TaskWriter.html', 'UnpartitionedWriter.html', 'WriteResult.Builder.html', 'WriteResult.html', 'WriterFactory.html', 'package-summary.html', 'package-tree.html', 'JdbcCatalog.html', 'UncheckedInterruptedException.html', 'UncheckedSQLException.html', 'package-summary.html', 'package-tree.html', 'MappedField.html', 'MappedFields.html', 'MappingUtil.html', 'NameMapping.html', 'NameMappingParser.html', 'package-summary.html', 'package-tree.html', 'Catalogs.html', 'InputFormatConfig.ConfigBuilder.html', 'InputFormatConfig.InMemoryDataModel.html', 'InputFormatConfig.html', 'HiveIcebergFilterFactory.html', 'HiveIcebergInputFormat.html', 'HiveIcebergMetaHook.html', 'HiveIcebergOutputCommitter.html', 'HiveIcebergOutputFormat.html', 'HiveIcebergSerDe.html', 'HiveIcebergSplit.html', 'HiveIcebergStorageHandler.html', 'TezUtil.html', 'package-summary.html', 'package-tree.html', 'IcebergBinaryObjectInspector.html', 'IcebergDateObjectInspector.html', 'IcebergDecimalObjectInspector.html', 'IcebergFixedObjectInspector.html', 'IcebergObjectInspector.html', 'IcebergRecordObjectInspector.html', 'IcebergTimeObjectInspector.html', 'IcebergTimestampObjectInspector.html', 'IcebergTimestampWithZoneObjectInspector.html', 'IcebergUUIDObjectInspector.html', 'WriteObjectInspector.html', 'package-summary.html', 'package-tree.html', 'AbstractMapredIcebergRecordReader.html', 'Container.html', 'MapredIcebergInputFormat.CompatibilityTaskAttemptContextImpl.html', 'MapredIcebergInputFormat.html', 'package-summary.html', 'package-tree.html', 'IcebergInputFormat.html', 'IcebergSplit.html', 'IcebergSplitContainer.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'NessieCatalog.html', 'NessieTableOperations.html', 'NessieUtil.html', 'TableReference.html', 'package-summary.html', 'package-tree.html', 'ORC.DataWriteBuilder.html', 'ORC.ReadBuilder.html', 'ORC.WriteBuilder.html', 'ORC.html', 'ORCSchemaUtil.BinaryType.html', 'ORCSchemaUtil.LongType.html', 'ORCSchemaUtil.html', 'OrcBatchReader.html', 'OrcMetrics.html', 'OrcRowReader.html', 'OrcRowWriter.html', 'OrcSchemaVisitor.html', 'OrcSchemaWithTypeVisitor.html', 'OrcValueReader.html', 'OrcValueReaders.StructReader.html', 'OrcValueReaders.html', 'OrcValueWriter.html', 'VectorizedRowBatchIterator.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'BaseColumnIterator.html', 'BasePageIterator.IntIterator.html', 'BasePageIterator.html', 'ColumnIterator.html', 'ColumnWriter.html', 'Parquet.DataWriteBuilder.html', 'Parquet.DeleteWriteBuilder.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetAvroReader.html', 'ParquetAvroValueReaders.TimeMillisReader.html', 'ParquetAvroValueReaders.TimestampMillisReader.html', 'ParquetAvroValueReaders.html', 'ParquetAvroWriter.html', 'ParquetDictionaryRowGroupFilter.html', 'ParquetIterable.html', 'ParquetMetricsRowGroupFilter.html', 'ParquetReader.html', 'ParquetSchemaUtil.HasIds.html', 'ParquetSchemaUtil.html', 'ParquetTypeVisitor.html', 'ParquetUtil.html', 'ParquetValueReader.html', 'ParquetValueReaders.BinaryAsDecimalReader.html', 'ParquetValueReaders.ByteArrayReader.html', 'ParquetValueReaders.BytesReader.html', 'ParquetValueReaders.FloatAsDoubleReader.html', 'ParquetValueReaders.IntAsLongReader.html', 'ParquetValueReaders.IntegerAsDecimalReader.html', 'ParquetValueReaders.ListReader.html', 'ParquetValueReaders.LongAsDecimalReader.html', 'ParquetValueReaders.MapReader.html', 'ParquetValueReaders.PrimitiveReader.html', 'ParquetValueReaders.RepeatedKeyValueReader.html', 'ParquetValueReaders.RepeatedReader.html', 'ParquetValueReaders.ReusableEntry.html', 'ParquetValueReaders.StringReader.html', 'ParquetValueReaders.StructReader.html', 'ParquetValueReaders.UnboxedReader.html', 'ParquetValueReaders.html', 'ParquetValueWriter.html', 'ParquetValueWriters.PositionDeleteStructWriter.html', 'ParquetValueWriters.PrimitiveWriter.html', 'ParquetValueWriters.RepeatedKeyValueWriter.html', 'ParquetValueWriters.RepeatedWriter.html', 'ParquetValueWriters.StructWriter.html', 'ParquetValueWriters.html', 'ParquetWriteAdapter.html', 'RemoveIds.html', 'TripleWriter.html', 'TypeToMessageType.html', 'TypeWithSchemaVisitor.html', 'ValuesAsBytesReader.html', 'VectorizedParquetReader.html', 'VectorizedReader.html', 'package-summary.html', 'package-tree.html', 'IcebergPigInputFormat.IcebergRecordReader.html', 'IcebergPigInputFormat.html', 'IcebergStorage.html', 'PigParquetReader.html', 'SchemaUtil.html', 'package-summary.html', 'package-tree.html', 'SchemaWithPartnerVisitor.PartnerAccessors.html', 'SchemaWithPartnerVisitor.html', 'UnionByNameVisitor.html', 'package-summary.html', 'package-tree.html', 'FileRewriteCoordinator.html', 'FileScanTaskSetManager.html', 'IcebergSpark.html', 'JobGroupInfo.html', 'JobGroupUtils.html', 'PathIdentifier.html', 'PruneColumnsWithReordering.html', 'PruneColumnsWithoutReordering.html', 'RollbackStagedTable.html', 'Spark3Util.CatalogAndIdentifier.html', 'Spark3Util.DescribeSchemaVisitor.html', 'Spark3Util.html', 'Spark3VersionUtil.html', 'SparkCatalog.html', 'SparkDataFile.html', 'SparkExceptionUtil.html', 'SparkFilters.html', 'SparkReadOptions.html', 'SparkSchemaUtil.html', 'SparkSessionCatalog.html', 'SparkStructLike.html', 'SparkTableUtil.SparkPartition.html', 'SparkTableUtil.html', 'SparkUtil.html', 'SparkValueConverter.html', 'SparkWriteOptions.html', 'BaseDeleteOrphanFilesSparkAction.html', 'BaseDeleteReachableFilesSparkAction.html', 'BaseExpireSnapshotsSparkAction.html', 'BaseMigrateTableSparkAction.html', 'BaseRewriteDataFilesSpark3Action.html', 'BaseRewriteManifestsSparkAction.html', 'BaseSnapshotTableSparkAction.html', 'Spark3BinPackStrategy.html', 'SparkActions.html', 'package-summary.html', 'package-tree.html', 'AvroWithSparkSchemaVisitor.html', 'ParquetWithSparkSchemaVisitor.html', 'SparkAvroReader.html', 'SparkAvroWriter.html', 'SparkOrcReader.html', 'SparkOrcValueReaders.html', 'SparkOrcWriter.html', 'SparkParquetReaders.html', 'SparkParquetWriters.html', 'SparkValueReaders.html', 'SparkValueWriters.html', 'package-summary.html', 'package-tree.html', 'ArrowVectorAccessors.html', 'ColumnarBatchReader.html', 'IcebergArrowColumnVector.html', 'RowPositionColumnVector.html', 'VectorizedSparkOrcReaders.html', 'VectorizedSparkParquetReaders.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'ExpireSnapshotsProcedure.html', 'RemoveOrphanFilesProcedure.html', 'SparkProcedures.ProcedureBuilder.html', 'SparkProcedures.html', 'package-summary.html', 'package-tree.html', 'EqualityDeleteRowReader.html', 'IcebergSource.html', 'RowDataRewriter.html', 'SparkMicroBatchStream.html', 'SparkPartitionedFanoutWriter.html', 'SparkPartitionedWriter.html', 'SparkRewriteBuilder.html', 'SparkScanBuilder.html', 'SparkTable.html', 'StagedSparkTable.html', 'package-summary.html', 'package-tree.html', 'PartitionSpecVisitor.html', 'SortOrderVisitor.html', 'Transform.html', 'Transforms.html', 'UnknownTransform.html', 'package-summary.html', 'package-tree.html', 'CheckCompatibility.html', 'Comparators.html', 'Conversions.html', 'FixupTypes.html', 'IndexByName.html', 'IndexParents.html', 'JavaHash.html', 'JavaHashes.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-summary.html', 'package-tree.html', 'ArrayUtil.html', 'BinPacking.ListPacker.html', 'BinPacking.PackingIterable.html', 'BinPacking.html', 'BinaryUtil.html', 'ByteBuffers.html', 'CharSequenceSet.html', 'CharSequenceWrapper.html', 'DateTimeUtil.html', 'DecimalUtil.html', 'ExceptionUtil.Block.html', 'ExceptionUtil.CatchBlock.html', 'ExceptionUtil.FinallyBlock.html', 'ExceptionUtil.html', 'Exceptions.html', 'Filter.html', 'JsonUtil.html', 'ManifestFileUtil.html', 'NaNUtil.html', 'Pair.html', 'ParallelIterable.html', 'PartitionSet.html', 'PartitionUtil.html', 'PropertyUtil.html', 'SerializableMap.html', 'SerializableSupplier.html', 'SerializationUtil.html', 'SnapshotUtil.html', 'SortOrderUtil.html', 'SortedMerge.html', 'StructLikeMap.html', 'StructLikeSet.html', 'StructLikeWrapper.html', 'StructProjection.html', 'TableScanUtil.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'ThreadPools.html', 'UUIDUtil.html', 'UnicodeUtil.html', 'WapUtil.html', 'package-summary.html', 'package-tree.html', 'NoSuchProcedureException.html', 'package-summary.html', 'package-tree.html', 'IcebergSqlExtensionsBaseListener.html', 'IcebergSqlExtensionsBaseVisitor.html', 'IcebergSqlExtensionsLexer.html', 'IcebergSqlExtensionsListener.html', 'IcebergSqlExtensionsParser.AddPartitionFieldContext.html', 'IcebergSqlExtensionsParser.ApplyTransformContext.html', 'IcebergSqlExtensionsParser.BigDecimalLiteralContext.html', 'IcebergSqlExtensionsParser.BigIntLiteralContext.html', 'IcebergSqlExtensionsParser.BooleanLiteralContext.html', 'IcebergSqlExtensionsParser.BooleanValueContext.html', 'IcebergSqlExtensionsParser.CallArgumentContext.html', 'IcebergSqlExtensionsParser.CallContext.html', 'IcebergSqlExtensionsParser.ConstantContext.html', 'IcebergSqlExtensionsParser.DecimalLiteralContext.html', 'IcebergSqlExtensionsParser.DoubleLiteralContext.html', 'IcebergSqlExtensionsParser.DropIdentifierFieldsContext.html', 'IcebergSqlExtensionsParser.DropPartitionFieldContext.html', 'IcebergSqlExtensionsParser.ExponentLiteralContext.html', 'IcebergSqlExtensionsParser.ExpressionContext.html', 'IcebergSqlExtensionsParser.FieldListContext.html', 'IcebergSqlExtensionsParser.FloatLiteralContext.html', 'IcebergSqlExtensionsParser.IdentifierContext.html', 'IcebergSqlExtensionsParser.IdentityTransformContext.html', 'IcebergSqlExtensionsParser.IntegerLiteralContext.html', 'IcebergSqlExtensionsParser.MultipartIdentifierContext.html', 'IcebergSqlExtensionsParser.NamedArgumentContext.html', 'IcebergSqlExtensionsParser.NonReservedContext.html', 'IcebergSqlExtensionsParser.NumberContext.html', 'IcebergSqlExtensionsParser.NumericLiteralContext.html', 'IcebergSqlExtensionsParser.OrderContext.html', 'IcebergSqlExtensionsParser.OrderFieldContext.html', 'IcebergSqlExtensionsParser.PositionalArgumentContext.html', 'IcebergSqlExtensionsParser.QuotedIdentifierAlternativeContext.html', 'IcebergSqlExtensionsParser.QuotedIdentifierContext.html', 'IcebergSqlExtensionsParser.ReplacePartitionFieldContext.html', 'IcebergSqlExtensionsParser.SetIdentifierFieldsContext.html', 'IcebergSqlExtensionsParser.SetWriteDistributionAndOrderingContext.html', 'IcebergSqlExtensionsParser.SingleStatementContext.html', 'IcebergSqlExtensionsParser.SmallIntLiteralContext.html', 'IcebergSqlExtensionsParser.StatementContext.html', 'IcebergSqlExtensionsParser.StringLiteralContext.html', 'IcebergSqlExtensionsParser.StringMapContext.html', 'IcebergSqlExtensionsParser.TinyIntLiteralContext.html', 'IcebergSqlExtensionsParser.TransformArgumentContext.html', 'IcebergSqlExtensionsParser.TransformContext.html', 'IcebergSqlExtensionsParser.TypeConstructorContext.html', 'IcebergSqlExtensionsParser.UnquotedIdentifierContext.html', 'IcebergSqlExtensionsParser.WriteDistributionSpecContext.html', 'IcebergSqlExtensionsParser.WriteOrderingSpecContext.html', 'IcebergSqlExtensionsParser.WriteSpecContext.html', 'IcebergSqlExtensionsParser.html', 'IcebergSqlExtensionsVisitor.html', 'package-summary.html', 'package-tree.html', 'ExtendedSupportsDelete.html', 'Procedure.html', 'ProcedureCatalog.html', 'ProcedureParameter.html', 'SupportsMerge.html', 'package-summary.html', 'package-tree.html', 'ClusteredDistribution.html', 'Distribution.html', 'Distributions.html', 'OrderedDistribution.html', 'UnspecifiedDistribution.html', 'ClusterDistributionImpl.html', 'OrderedDistributionImpl.html', 'UnspecifiedDistributionImpl.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'NullOrdering.html', 'SortDirection.html', 'SortOrder.html', 'package-summary.html', 'package-tree.html', 'SupportsFileFilter.html', 'package-summary.html', 'package-tree.html', 'MergeBuilder.html', 'package-summary.html', 'package-tree.html', 'overview-summary.html', 'overview-tree.html', 'package-search-index.js', 'package-search-index.zip', 'glass.png', 'x.png', 'script.js', 'search.js', 'serialized-form.html', 'stylesheet.css', 'type-search-index.js', 'type-search-index.zip', 'index.html', 'version.txt']"
Core: Validate transforms while building partition type (#2992),2,52,2021-08-18 14:19:29-07:00,"['Partitioning.java', 'TestMetadataTablesWithPartitionEvolution.java']"
ORC: Fix metrics modes for nested fields (#2977),2,18,2021-08-18 14:51:20-07:00,"['TestMetrics.java', 'OrcMetrics.java']"
"Add 0.12.0 release notes pt 2 (#2986)

* Add 0.12.0 release notes pt 2

* Add more blurbs and fix formatting.

- Add blurbs for #2565, #2583, and #2547.
- Make formatting consistent.

* Add blurb for #2613 Hive Vectorized Reader

* Reword blurbs for #2565 and #2365

* More changes based on review comments

* More updates to the 0.12.0 release notes

* Add blurb for #2232 fix parquet row group filters

* Add blurb for #2308",1,50,2021-08-19 12:19:29-07:00,['releases.md']
Build: Remove version.txt that was accidentally added in bde2d896ac (#2995),1,1,2021-08-19 12:56:08-07:00,['version.txt']
Fix formatting of release-notes (#2997),1,88,2021-08-19 15:14:04-07:00,['releases.md']
Doc:  Improve the flink shell docs (#2920),1,28,2021-08-20 20:27:12+08:00,['flink.md']
"Spark: Add a method to load an Iceberg table by its name in Spark3. (#2983)

* Spark: Add a method to load Iceberg table by its name in Spark3.",2,38,2021-08-20 16:48:13-05:00,"['Spark3Util.java', 'TestSpark3Util.java']"
Build: Set permissions for tokens used by labeler action (#3007),1,4,2021-08-23 09:03:31-07:00,['labeler.yml']
Core: Rename WRITE_NEW_DATA_LOCATION to WRITE_FOLDER_STORAGE_LOCATION (#2965),7,30,2021-08-23 09:27:42-07:00,"['LocationProviders.java', 'TableProperties.java', 'TestLocationProvider.java', 'IcebergSourceBenchmark.java', 'TestRemoveOrphanFilesAction.java', 'TestDataFrameWrites.java', 'BaseSnapshotTableSparkAction.java']"
Hive: Fix some message typos in HiveCatalog: Matastore => Metastore (#2950),1,22,2021-08-23 18:40:31+02:00,['HiveCatalog.java']
Hive: Fix toString NPE with recommended constructor (#3021),1,2,2021-08-25 14:15:06+02:00,['HiveCatalog.java']
Build: Add workflow to cancel duplicate workflow runs (#3004),1,41,2021-08-26 08:51:06-07:00,['cancel-duplicate-workflow-runs.yml']
Bump Nessie to latest version (#3031),1,2,2021-08-27 14:41:12+02:00,['versions.props']
Bump Nessie to 0.9.2 (#3036),0,0,2021-08-27 09:39:20-07:00,[]
"[Python] Support schema field ID validation in python (#2866)

* Support schema field ID validation in python. Also fix bugs in type_util and add unit tests.

* Add license to the test file

* update unit tests

* address the comments

* only ignore NotImplementedError error during visit.",3,72,2021-08-27 15:36:50-07:00,"['schema.py', 'type_util.py', 'test_type_util.py']"
"Build: Fix deploySite Gradle task (#3008)

Fixes the deploySite Gradle task by ensuring that the `.asf.yaml` file located in the project root is included in the `site` directory before it is pushed to the `asf-site` branch. If the `.asf.yaml` file is not included, ASF INFRA's site publishing mechanism will ignore the update.

More info is available here:
* https://infra.apache.org/project-site.html
* https://infra.apache.org/asfyaml-mkdocs.html",2,23,2021-08-27 15:56:43-07:00,"['README.md', 'tasks.gradle']"
"Core: Fix null value check for table properties (#3052)

Co-authored-by: rawataaryan9 <rawataaryan9@github.com>",1,2,2021-08-30 10:51:47-07:00,['PropertiesUpdate.java']
Flink: Support create iceberg table with 'connector'='iceberg' (#2666),5,522,2021-09-02 13:29:45+08:00,"['FlinkCatalog.java', 'FlinkCatalogFactory.java', 'FlinkDynamicTableFactory.java', 'org.apache.flink.table.factories.Factory', 'TestIcebergConnector.java']"
AWS: copy Iceberg schema to Glue (#3048),4,121,2021-09-02 11:31:18-07:00,"['GlueCatalogCommitFailureTest.java', 'GlueCatalogTableTest.java', 'GlueTableOperations.java', 'IcebergToGlueConverter.java']"
"Core: Add TypeUtil.project() for Explicit Projection (#2952)

* Core: Add TypeUtil.project() for Explicit Projection

Previously we only had TypeUtil.select which would select all nested
elements of selected structs. This made it difficult to project empty
structs since they would have no selected leaf elements. The new
TypeUtil.project instead takes only the elements which are specifically
requested with no automatic selection of nested elements.",3,494,2021-09-02 21:08:10-05:00,"['PruneColumns.java', 'TypeUtil.java', 'TestTypeUtil.java']"
Flink: Fix flaky test TestFlinkTableSink (#2989),2,225,2021-09-04 15:13:58+08:00,"['SimpleDataUtil.java', 'TestFlinkTableSink.java']"
Doc: Back quote identifiers in the Flink SQL statement (#3076),1,20,2021-09-06 20:01:14+08:00,['flink.md']
Flink: Refactor DataIterator to use composition instead of inheritance (#2905),6,229,2021-09-07 11:20:09+08:00,"['InputFilesDecryptor.java', 'DataIterator.java', 'FileScanTaskReader.java', 'FlinkInputFormat.java', 'RowDataFileScanTaskReader.java', 'RowDataRewriter.java']"
"Spark: Moves Distribution and Ordering Utils to Spark3 Module (#2820)

To enable core Spark3 code to use distribution and ordering information when
performing writes or other operations. One example is to allow Sort Strategy
to transform SortOrder information so it can be used when rewriting data files.",4,2,2021-09-09 09:01:01-05:00,"['build.gradle', 'TransformExpressions.scala', 'DistributionAndOrderingUtils.scala', 'PlanUtils.scala']"
Spark: Add config needed in tests after SPARK-36128 (#3090),1,1,2021-09-09 15:01:28-07:00,['SparkExtensionsTestBase.java']
Flink: Fix warning in FlinkSink caused by incorrect parameterized type (#3061),1,28,2021-09-09 15:07:51-07:00,['FlinkSink.java']
AWS: Allow closing resources in AWS catalogs and S3FileIO (#2878),8,267,2021-09-09 15:48:16-07:00,"['CloseableGroup.java', 'FileIO.java', 'ExceptionUtil.java', 'TestCloseableGroup.java', 'TestExceptionUtil.java', 'DynamoDbCatalog.java', 'GlueCatalog.java', 'S3FileIO.java']"
Docs: Fix spelling mistake in releases.md (#3066),1,2,2021-09-09 15:49:30-07:00,['releases.md']
Spark: Exclude zstd-jni from iceberg-spark3-runtime (#3058),1,1,2021-09-09 15:49:57-07:00,['build.gradle']
Spark: Create metadata tables directly to preserve custom FileIO (#3089),3,98,2021-09-09 16:55:56-07:00,"['MetadataTableUtils.java', 'SparkTableUtil.java', 'Spark3Util.java']"
Spec: Update spec to show that version 2 is adopted (#3037),1,18,2021-09-10 08:22:05-07:00,['spec.md']
Build: Temporarily add info logs to CI to debug infrequent timeouts (#3100),1,6,2021-09-10 14:39:02-07:00,['java-ci.yml']
Spark: Improve SparkBatchScan statistics estimation (#3038),2,26,2021-09-12 09:35:17-07:00,"['SparkSchemaUtil.java', 'SparkBatchScan.java']"
Flink:  Add streaming upsert write option. (#2863),11,220,2021-09-13 19:49:30+08:00,"['TableProperties.java', 'BaseDeltaTaskWriter.java', 'FlinkSink.java', 'PartitionedDeltaWriter.java', 'RowDataTaskWriterFactory.java', 'UnpartitionedDeltaWriter.java', 'RowDataRewriter.java', 'TestDeltaTaskWriter.java', 'TestFlinkIcebergSinkV2.java', 'TestIcebergStreamWriter.java', 'TestTaskWriters.java']"
AWS: Fix DynamoDbCatalog.dropNamespace attr check (#3035),2,14,2021-09-13 08:38:16-07:00,"['DynamoDbCatalogTest.java', 'DynamoDbCatalog.java']"
Docs: Add row-level Java API example (#3083),1,24,2021-09-13 08:57:07-07:00,['api.md']
"Core: Fix HadoopCatalog drop table behavior (#3097)

Dropping a table should return false if it does not exist.

Co-authored-by: adityasingh <guardinaditya@gmail.com>",2,42,2021-09-13 10:46:10-07:00,"['HadoopCatalog.java', 'TestHadoopCatalog.java']"
Core: Fix comment in TestHadoopCatalog (#3107),1,2,2021-09-13 12:35:48-07:00,['TestHadoopCatalog.java']
"Core: Optimize check for referenced data files in BaseRowDelta (#3071)

This change optimizes our check for referenced data files in BaseRowDelta by pushing down the conflict detection filter. Previously, we would open manifests even though they belonged to partitions out of our interest.",3,131,2021-09-13 14:25:49-07:00,"['BaseRowDelta.java', 'MergingSnapshotProducer.java', 'TestRowDelta.java']"
Flink - Temporarily Ignore test that leads to infinite checkpoint loop and CI timeouts (#3110),1,2,2021-09-14 08:46:49-05:00,['TestFlinkIcebergSink.java']
Docs: Add UPDATE describtion for Spark (#2897),1,15,2021-09-14 15:48:25-07:00,['spark-writes.md']
Spark: Add test cases for row-level plans with distribution-mode (#2911),7,46,2021-09-14 15:51:59-07:00,"['SparkRowLevelOperationsTestBase.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestDelete.java', 'TestMerge.java', 'TestUpdate.java']"
Core: Promote sorted column metrics to truncate(16) (#2240),15,583,2021-09-14 17:43:53-07:00,"['MetricsConfig.java', 'Avro.java', 'SortOrderUtil.java', 'TestMetrics.java', 'TestMetricsModes.java', 'TestSortOrder.java', 'BaseWriterFactory.java', 'TestWriterMetrics.java', 'TestOrcMetrics.java', 'TestParquetMetrics.java', 'TestFlinkWriterMetrics.java', 'ORC.java', 'Parquet.java', 'SparkTableUtil.java', 'TestSparkWriterMetrics.java']"
INFRA - Remove additional logs added to Java CI for debugging timeouts (#3111),1,6,2021-09-15 14:35:05-05:00,['java-ci.yml']
Arrow: Fix assertions and correctness checks (#2933),2,70,2021-09-17 11:36:45-07:00,"['ArrowReader.java', 'ColumnVector.java']"
"Spark: Better statistics estimation for Spark 2 Reader (#3134)

Follow-up to #3038.
Use (estimated) row size * number of rows to estimate the size instead of adding up file sizes.
The row size is estimated from the pruned schema if we prune columns.",1,3,2021-09-17 11:37:44-07:00,['Reader.java']
Docs: Fix Nessie/Spark broken link (#3140),1,2,2021-09-17 11:38:26-07:00,['nessie.md']
Core: Add table property for ORC batch size (#3133),4,87,2021-09-17 11:42:22-07:00,"['TableProperties.java', 'Reader.java', 'Spark3Util.java', 'SparkBatchScan.java']"
"Build: Upgrade to Gradle 7.x (#2826)

* Build: Upgrade to Gradle 7
* Build: Properly exclude stuff from shadedJar content
This change is required after upgrading to ShadowJar plugin 7.0.0 due to
https://github.com/johnrengelman/shadow/issues/505 not excluding files
the same way it used to.
* Fix ErrorProne / errors due to newer ErrorProne version
* Fix checkstyle violations due to newer Checkstyle version",19,1038,2021-09-17 11:53:10-07:00,"['checkstyle.xml', 'VectorizedParquetDefinitionLevelReader.java', 'baseline.gradle', 'build.gradle', 'BaseTableScan.java', 'BaseTransaction.java', 'FindFiles.java', 'IncrementalDataTableScan.java', 'HadoopCatalog.java', 'TestTableMetadata.java', 'deploy.gradle', 'gradle-wrapper.properties', 'gradlew', 'HiveCatalog.java', 'CompatibilityHiveVectorUtils.java', 'TestTables.java', 'SparkTableUtil.java', 'LICENSE', 'versions.props']"
"Rename the existing python module to python_legacy. (#3074)

* Rename the existing python module to python_legacy.

* update github script to use python_legacy path.",199,16,2021-09-17 14:24:08-07:00,"['labeler.yml', 'java-ci.yml', 'python-ci.yml', '.gitignore', 'CHANGELOG.md', 'README.md', '__init__.py', '__init__.py', 'append_files.py', 'combined_scan_task.py', 'data_file.py', 'data_operations.py', 'delete_files.py', 'expire_snapshots.py', '__init__.py', 'binder.py', 'evaluator.py', 'expression.py', 'expression_parser.py', 'expressions.py', 'inclusive_manifest_evaluator.py', 'inclusive_metrics_evaluator.py', '__init__.py', 'literals.py', 'predicate.py', 'projections.py', 'reference.py', 'residual_evaluator.py', 'strict_metrics_evaluator.py', 'term.py', 'transform.py', 'file_format.py', 'file_scan_task.py', 'files.py', 'filterable.py', 'filtered_snapshot.py', '__init__.py', 'closeable_group.py', 'closeable_iterable.py', 'delegating_input_stream.py', 'delegating_output_stream.py', 'file_appender.py', 'input_file.py', 'output_file.py', 'position_output_stream.py', 'seekable_input_stream.py', 'manifest_file.py', 'metrics.py', 'overwrite_files.py', 'partition_field.py', 'partition_spec.py', 'pending_update.py', 'replace_partitions.py', 'rewrite_files.py', 'rollback.py', 'scan_task.py', 'schema.py', 'snapshot.py', 'snapshot_iterable.py', 'struct_like.py', 'table.py', 'table_scan.py', 'tables.py', 'transaction.py', '__init__.py', 'bucket.py', 'dates.py', 'identity.py', 'projection_util.py', 'timestamps.py', 'transform.py', 'transform_util.py', 'transforms.py', 'truncate.py', 'unknown_transform.py', 'void_transform.py', '__init__.py', 'conversions.py', 'type.py', 'type_util.py', 'types.py', 'update_properties.py', 'update_schema.py', '__init__.py', '__init__.py', 'avro_schema_util.py', 'avro_to_iceberg.py', 'iceberg_to_avro.py', 'base_combined_scan_task.py', 'base_file_scan_task.py', 'base_metastore_table_operations.py', 'base_metastore_tables.py', 'base_snapshot.py', 'base_table.py', 'base_table_scan.py', 'base_transaction.py', 'config_properties.py', 'data_files.py', 'data_table_scan.py', '__init__.py', 'file_status.py', 'file_system.py', 'filesystem_table_operations.py', 'filesystem_tables.py', 'local_filesystem.py', 's3_filesystem.py', 'util.py', 'filtered_manifest.py', 'generic_data_file.py', 'generic_manifest_file.py', 'generic_partition_field_summary.py', 'manifest_entry.py', 'manifest_list_writer.py', 'manifest_reader.py', 'partition_data.py', 'partition_spec_parser.py', 'partition_summary.py', 'scan_summary.py', 'schema_parser.py', 'schema_update.py', 'snapshot_parser.py', 'table_metadata.py', 'table_metadata_parser.py', 'table_operations.py', 'table_properties.py', '__init__.py', 'atomic_integer.py', 'bin_packing.py', 'profile.py', '__init__.py', 'exceptions.py', '__init__.py', 'hive_table_operations.py', 'hive_tables.py', 'hive_types.py', '__init__.py', 'dataset_utils.py', 'parquet_reader.py', 'parquet_schema_utils.py', 'parquet_to_iceberg.py', 'setup.py', '__init__.py', '__init__.py', '__init__.py', 'conftest.py', 'test_evaluator.py', 'test_expression_binding.py', 'test_expression_helpers.py', 'test_expression_serializations.py', 'test_inclusive_manifest_evaluator.py', 'test_inclusive_metrics_evaluator.py', 'test_literal_serialization.py', 'test_misc_literal_conversions.py', 'test_numeric_literal_conversions.py', 'test_predicate_binding.py', 'test_str_to_expr.py', 'test_strict_metrics_evaluator.py', 'test_string_literal_conversions.py', 'test_conversions.py', 'test_file_format.py', 'test_helpers.py', 'test_partition_spec.py', '__init__.py', 'test_bucket.py', 'test_bucketing.py', 'test_dates.py', 'test_identity.py', 'test_timestamps.py', 'test_truncate.py', '__init__.py', 'test_binary_comparator.py', 'test_char_seq_comparator.py', 'test_comparable_comparator.py', 'test_readabilty_checks.py', 'test_type_util.py', '__init__.py', '__init__.py', 'conftest.py', 'test_avro.py', 'test_read_projection.py', 'conftest.py', 'test_base_table_scan.py', 'test_filesystem_tables.py', 'test_partition_spec.py', 'test_partition_spec_parser.py', 'test_snapshot_json.py', 'test_table_metadata_json.py', 'test_table_metadata_parser.py', '__init__.py', 'test_bin_packing.py', '__init__.py', 'conftest.py', 'test_hive_tables.py', '__init__.py', 'conftest.py', 'test_dataset_utils.py', 'test_parquet_reader.py', 'test_parquet_to_iceberg.py', 'tox.ini']"
"Build: Enable zip64 to allow > 65535 files for JMH (#3145)

This started to happen after the Gradle 7 upgrade

```
> Task :iceberg-spark3:jmhJar FAILED

FAILURE: Build failed with an exception.

* What went wrong:
Execution failed for task ':iceberg-spark3:jmhJar'.
> archive contains more than 65535 entries.

  To build this archive, please enable the zip64 extension.
  See: https://docs.gradle.org/7.2/dsl/org.gradle.api.tasks.bundling.Zip.html#org.gradle.api.tasks.bundling.Zip:zip64
```",1,1,2021-09-19 09:46:25-07:00,['jmh.gradle']
Spark: Implement invalidateTable for SparkSessionCatalog (#3072),2,90,2021-09-19 13:46:53-07:00,"['SparkSessionCatalog.java', 'TestRefreshTable.java']"
Core: Add FileWriter interface (#3149),17,428,2021-09-19 22:08:11-07:00,"['EqualityDeleteWriter.java', 'PositionDeleteWriter.java', 'DataWriteResult.java', 'DataWriter.java', 'DeleteWriteResult.java', 'FileWriter.java', 'FileWriterFactory.java', 'SortedPosDeleteWriter.java', 'BaseFileWriterFactory.java', 'TestFileWriterFactory.java', 'TestWriterMetrics.java', 'FlinkFileWriterFactory.java', 'TestFlinkFileWriterFactory.java', 'TestFlinkWriterMetrics.java', 'SparkFileWriterFactory.java', 'TestSparkFileWriterFactory.java', 'TestSparkWriterMetrics.java']"
Fix exception exception message in IcebergInputFormat (#3153),1,4,2021-09-20 13:27:58+02:00,['IcebergInputFormat.java']
"Core: Enhance weightFunc of bin-packing to adapt to V2Format (#3073)

Co-authored-by: duripeng <duripeng@baidu.com>",3,102,2021-09-20 08:50:08-07:00,"['TableScanUtil.java', 'MockFileScanTask.java', 'TestTableScanUtil.java']"
Arrow: Add BaseBatchReader and reduce code duplication (#3123),3,188,2021-09-20 10:18:45-07:00,"['ArrowBatchReader.java', 'BaseBatchReader.java', 'ColumnarBatchReader.java']"
API: Test for identity in comparators (#3152),1,42,2021-09-20 12:41:16-07:00,['Comparators.java']
Core: Add new rolling file writers (#3158),8,693,2021-09-20 15:13:46-07:00,"['DeleteWriteResult.java', 'RollingDataWriter.java', 'RollingEqualityDeleteWriter.java', 'RollingFileWriter.java', 'RollingPositionDeleteWriter.java', 'TestRollingFileWriters.java', 'TestFlinkRollingFileWriters.java', 'TestSparkRollingFileWriters.java']"
Core: Upgrade ORC dependency to 1.7.0 (#3160),1,2,2021-09-20 23:06:21-05:00,['versions.props']
Core: Support committing delete files with multiple specs (#2985),5,381,2021-09-21 08:21:59-07:00,"['BaseOverwriteFiles.java', 'BaseReplacePartitions.java', 'MergingSnapshotProducer.java', 'TableTestBase.java', 'TestRowDelta.java']"
Docs: Add flink iceberg connector (#3085),2,142,2021-09-22 10:22:27+08:00,"['flink-connector.md', 'mkdocs.yml']"
Doc: fix 0.12.0 release note broken links (#3165),1,2,2021-09-22 00:13:42-07:00,['releases.md']
Docs: Add Roadmap section (#3163),2,58,2021-09-22 10:42:09-07:00,"['roadmap.md', 'mkdocs.yml']"
Python: Fix README in python_legacy module after rename (#3161),1,2,2021-09-22 10:54:12-07:00,['README.md']
Core: Prefer write.data.path to write.folder-storage.path or write.object-storage.path (#3094),8,118,2021-09-22 11:18:43-07:00,"['LocationProviders.java', 'TableProperties.java', 'TestLocationProvider.java', 'aws.md', 'IcebergSourceBenchmark.java', 'TestRemoveOrphanFilesAction.java', 'TestDataFrameWrites.java', 'BaseSnapshotTableSparkAction.java']"
Core: Add PartitioningWriter (#3164),24,1920,2021-09-23 16:25:33-07:00,"['build.gradle', 'PositionDelete.java', 'ClusteredDataWriter.java', 'ClusteredEqualityDeleteWriter.java', 'ClusteredPositionDeleteWriter.java', 'ClusteredWriter.java', 'FanoutDataWriter.java', 'FanoutWriter.java', 'PartitioningWriter.java', 'StructCopy.java', 'TableTestBase.java', 'TestAppenderFactory.java', 'TestFileWriterFactory.java', 'TestPartitioningWriters.java', 'TestRollingFileWriters.java', 'WriterTestBase.java', 'TestFlinkPartitioningWriters.java', 'TestFlinkRollingFileWriters.java', 'jmh.gradle', 'WritersBenchmark.java', 'AvroWritersBenchmark.java', 'ParquetWritersBenchmark.java', 'TestSparkPartitioningWriters.java', 'TestSparkRollingFileWriters.java']"
Core: Avoid throwing IOException in new write methods (#3170),9,82,2021-09-24 10:58:57+08:00,"['EqualityDeleteWriter.java', 'PositionDeleteWriter.java', 'ClusteredWriter.java', 'FanoutWriter.java', 'FileWriter.java', 'PartitioningWriter.java', 'RollingFileWriter.java', 'SortedPosDeleteWriter.java', 'TestPartitioningWriters.java']"
Spark: Migrate to new data writers in SparkWrite (#3171),1,134,2021-09-24 10:47:58-07:00,['SparkWrite.java']
Core: Use correct metrics config for delete files (#2942),7,100,2021-09-24 17:31:50-07:00,"['MetricsConfig.java', 'Avro.java', 'BaseFileWriterFactory.java', 'TestWriterMetrics.java', 'TestFlinkWriterMetrics.java', 'Parquet.java', 'TestSparkWriterMetrics.java']"
Flink: Upgrade to flink 1.13.2 (#3116),5,28,2021-09-26 16:06:39+08:00,"['AssertHelpers.java', 'FlinkCatalogFactory.java', 'org.apache.flink.table.factories.Factory', 'TestFlinkCatalogTable.java', 'versions.props']"
"Core: Fix JDBC properties, only keep keys with jdbc. prefix (#3078)",3,64,2021-09-26 15:55:37-07:00,"['JdbcClientPool.java', 'JdbcUtil.java', 'TestJdbcUtil.java']"
Core: Add position and equality delta writer interfaces (#3176),6,626,2021-09-26 16:08:01-07:00,"['BasePositionDeltaWriter.java', 'EqualityDeltaWriter.java', 'PositionDeltaWriter.java', 'TestPositionDeltaWriters.java', 'TestFlinkPositionDeltaWriters.java', 'TestSparkPositionDeltaWriters.java']"
Aliyun: Mock aliyun OSS(Object Storage Service) (#3067),11,1254,2021-09-27 09:34:30+08:00,"['AliyunOSSTestRule.java', 'AliyunOSSMockApp.java', 'AliyunOSSMockLocalController.java', 'AliyunOSSMockLocalStore.java', 'AliyunOSSMockRule.java', 'ObjectMetadata.java', 'Range.java', 'TestLocalAliyunOSS.java', 'build.gradle', 'settings.gradle', 'versions.props']"
Spark: Support spec ID and partition metadata columns (#2984),12,449,2021-09-27 11:41:20-07:00,"['StructProjection.java', 'MetadataColumns.java', 'PartitionUtil.java', 'BaseDataReader.java', 'BatchDataReader.java', 'EqualityDeleteRowReader.java', 'RowDataReader.java', 'TestSparkBaseDataReader.java', 'SparkScanBuilder.java', 'SparkTestTable.java', 'TestSparkCatalog.java', 'TestSparkMetadataColumns.java']"
"Spec: Add _deleted, _spec_id, _partition metadata columns (#3190)",1,3,2021-09-27 12:28:38-07:00,['spec.md']
Spark: Use FileWriter for unpartitioned writes (#3191),1,50,2021-09-27 14:18:13-07:00,['SparkWrite.java']
"Spark: Avoid calling toGroupStream if possible (#3173)

Co-authored-by: xiaojiebao <xiaojiebao@xiaomi.com>",1,3,2021-09-27 15:06:27-07:00,['BaseRewriteDataFilesSparkAction.java']
[Build] Disable Spark31 Tests in extra-checks workflow (#3182),1,2,2021-09-27 22:11:40-05:00,['java-ci.yml']
Doc: update Slack address in README (#3194),1,2,2021-09-27 23:02:17-07:00,['README.md']
Flink:  Use FlinkSink#append to construct the DAG (#3185),3,16,2021-09-28 14:32:58+08:00,"['IcebergTableSink.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkV2.java']"
Docs: Update ReadMe and Spec (#3196),2,6,2021-09-28 15:27:51+08:00,"['README.md', 'spec.md']"
Build: Opt in to hacktoberfest (#3193),1,1,2021-09-28 08:45:29-07:00,['.asf.yaml']
"Data: Fix equality deletes with date/time types (#3135)

Co-authored-by: xiaojiebao <xiaojiebao@xiaomi.com>",4,126,2021-09-28 11:05:01-07:00,"['DeleteFilter.java', 'DeleteReadTests.java', 'TestGenericReaderDeletes.java', 'TestInputFormatReaderDeletes.java']"
API: Clarify set and remove methods for namespace properties (#3198),1,8,2021-09-28 11:05:33-07:00,['SupportsNamespaces.java']
Core: Validate concurrently added delete files in RowDelta (#3195),6,319,2021-09-28 12:34:39-07:00,"['RowDelta.java', 'BaseRowDelta.java', 'DeleteFileIndex.java', 'MergingSnapshotProducer.java', 'TableTestBase.java', 'TestRowDelta.java']"
AWS: Add check to create staging directory if not exists for S3OutputStream (#3175),3,41,2021-09-28 12:46:24-07:00,"['OutputFile.java', 'S3OutputStream.java', 'S3OutputStreamTest.java']"
Aliyun: Add configurable TestRule. (#3197),2,62,2021-09-30 14:37:53+08:00,"['AliyunOSSTestUtility.java', 'TestLocalAliyunOSS.java']"
Core: Validate concurrently added delete files in OvewriteFiles (#3199),4,380,2021-10-01 11:48:43-07:00,"['OverwriteFiles.java', 'BaseOverwriteFiles.java', 'TestOverwriteWithValidation.java', 'SparkWrite.java']"
"Build: Disable errorprone ConsistentLoggerName (#3209)

This was added by the gradle upgrade, but isn't worth the change.",1,1,2021-10-01 17:02:17-07:00,['baseline.gradle']
Python: Setup new python library module structure (#3184),20,791,2021-10-03 10:17:40-07:00,"['python-ci.yml', 'python-legacy-ci.yml', '.gitignore', 'LICENSE', 'MANIFEST.in', 'NOTICE', 'README.md', 'pyproject.toml', 'setup.cfg', 'setup.py', '__init__.py', '__init__.py', '__init__.py', '__init__.py', '__init__.py', 'bin_packing.py', '__init__.py', '__init__.py', 'test_bin_packing.py', 'tox.ini']"
"Arrow: Make ArrowReader iterator idempotent (#3148)

Follow-up on https://github.com/apache/iceberg/pull/2933.",2,58,2021-10-03 10:26:59-07:00,"['ArrowReader.java', 'ArrowReaderTest.java']"
API: Update GetProjectedIds to optionally include empty structs (#2953),10,402,2021-10-03 16:23:52-07:00,"['GetProjectedIds.java', 'TypeUtil.java', 'StructProjection.java', 'TestTypeUtil.java', 'BaseTableScan.java', 'PruneColumns.java', 'TestSchemaUpdate.java', 'TestReadProjection.java', 'PruneColumns.java', 'TestIcebergSourceTablesBase.java']"
Core: Fix vararg warnings / Remove unneeded 'unchecked' suppressions (#3215),1,12,2021-10-05 13:04:51-05:00,['Tasks.java']
Spark: Do not pass numPartitions in 3.1 to let AQE size stages (#3203),1,3,2021-10-06 08:47:33-07:00,['PlanUtils.scala']
Doc: Update Nessie integration doc about Nessie SQL Extensions (#3233),2,15,2021-10-07 09:19:11-05:00,"['nessie.md', 'mkdocs.yml']"
"Nessie: Throw better exception when dropping a Namespace with NessieCatalog (#3232)

When using the `NessieCatalog` and dropping a namespace, then things fail with a `org.apache.spark.SparkException: Failed to drop a namespace: ...`, which is a bit difficult to understand for users. It makes more sense to throw an `UnsupportedOperationException` that indicates that dropping a namespace isn't supported.",2,47,2021-10-08 10:19:39-05:00,"['NessieCatalog.java', 'TestNamespace.java']"
API: Move generic catalog methods to API (#3244),3,123,2021-10-08 14:38:57-07:00,"['Catalog.java', 'BaseMetastoreCatalog.java', 'CachingCatalog.java']"
Build: Fix ErrorProne UnnecessarilyQualified warnings (#3262),16,57,2021-10-10 10:45:54-07:00,"['GenericDataFile.java', 'GenericManifestFile.java', 'PruneColumns.java', 'RemoveIds.java', 'ValueReaders.java', 'IcebergDecoder.java', 'GenericOrcReader.java', 'FlinkCatalog.java', 'FlinkParquetWriters.java', 'HiveIcebergFilterFactory.java', 'HiveIcebergInputFormat.java', 'BaseParquetWriter.java', 'ApplyNameMapping.java', 'ParquetAvro.java', 'ParquetAvroWriter.java', 'SparkParquetWriters.java']"
Build: Add Aliyun to the autolabeler config (#3261),1,2,2021-10-10 10:51:15-07:00,['labeler.yml']
"Build: Fix ErrorProne NewHashMapInt warnings (#3260)

This should improve performance by allocating the correct size directly rather than reallocating later.",4,15,2021-10-10 10:53:21-07:00,"['Metrics.java', 'Catalogs.java', 'Deserializer.java', 'HiveIcebergSerDe.java']"
Hive: Ensure tableLevelMutex is unlocked when uncommitted metadata delete fails (#3264),1,7,2021-10-11 12:27:50+02:00,['HiveTableOperations.java']
Docs: Update Java API quickstart to use no-arg Catalog constructor (#3253),1,15,2021-10-11 08:38:34-07:00,['java-api-quickstart.md']
Spark: Simplify shouldProcess in Spark3 streaming source (#3268),1,20,2021-10-11 08:55:10-07:00,['SparkMicroBatchStream.java']
"Spark: Add an argument to parallelize Expire snapshot procedure (#2921)

* Adds an argument to parallelize Expire snapshot procedure

Co-authored-by: Karuppayya Rajendran <karuppayya.rajendran@apple.com>",2,63,2021-10-11 13:22:52-05:00,"['TestExpireSnapshotsProcedure.java', 'ExpireSnapshotsProcedure.java']"
Hive: Fix NoSuchMethodError of OrcTail with Hive3.x and Vectorized ORC (#3155),2,286,2021-10-12 11:10:41+02:00,"['build.gradle', 'OrcSplit.java']"
Core: Fail if both Catalog type and catalog-impl are configured (#3162),6,49,2021-10-12 07:51:07-07:00,"['CatalogUtil.java', 'TestCatalogUtil.java', 'Catalogs.java', 'TestCatalogs.java', 'hive.md', 'spark-configuration.md']"
Spark: Add SparkReadConf and SparkWriteConf (#3132),27,1180,2021-10-12 09:16:35-07:00,"['SparkConfParser.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkSQLProperties.java', 'SparkUtil.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'AvroDataTest.java', 'TestDataFrameWrites.java', 'TestTimestampWithoutZone.java', 'IcebergSource.java', 'Reader.java', 'StreamingWriter.java', 'Writer.java', 'TestUpdate.java', 'Spark3Util.java', 'SparkBatchQueryScan.java', 'SparkBatchScan.java', 'SparkFilesScan.java', 'SparkFilesScanBuilder.java', 'SparkMergeScan.java', 'SparkMicroBatchStream.java', 'SparkRewriteBuilder.java', 'SparkScanBuilder.java', 'SparkWrite.java', 'SparkWriteBuilder.java', 'TestTimestampWithoutZone.java']"
ORC: Refactor value writers (#3248),8,742,2021-10-14 10:07:25+08:00,"['GenericOrcWriter.java', 'GenericOrcWriters.java', 'FlinkOrcWriter.java', 'FlinkOrcWriters.java', 'OrcValueWriter.java', 'SparkOrcValueWriter.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java']"
Hive: Fix Catalog initialization without Configuration (#3252),2,35,2021-10-15 13:37:29-07:00,"['HiveCatalog.java', 'TestHiveCatalog.java']"
Build: Move Spark version modules under spark directory (#3256),263,998,2021-10-15 13:51:08-07:00,"['java-ci.yml', '.gitignore', 'build.gradle', 'gradle.properties', 'jmh.gradle', 'settings.gradle', 'build.gradle', 'build.gradle', 'LICENSE', 'NOTICE', '.gitkeep', 'SparkActions.java', 'SparkFilters.java', 'SparkActions.java', 'CustomCatalogs.java', 'IcebergSource.java', 'Reader.java', 'Stats.java', 'StreamingOffset.java', 'StreamingWriter.java', 'Writer.java', 'org.apache.spark.sql.sources.DataSourceRegister', 'TestScanTaskSerialization24.java', 'TestDeleteReachableFilesAction24.java', 'TestExpireSnapshotsAction24.java', 'TestRemoveOrphanFilesAction24.java', 'TestRewriteDataFilesAction24.java', 'TestRewriteManifestsAction24.java', 'ConcurrencyTest.java', 'README.md', 'ReadAndWriteTablesTest.java', 'SchemaEvolutionTest.java', 'SimpleRecord.java', 'SnapshotFunctionalityTest.java', 'TestAvroScan24.java', 'TestCatalog.java', 'TestCustomCatalog.java', 'TestDataFrameWrites24.java', 'TestDataSourceOptions24.java', 'TestFilteredScan.java', 'TestForwardCompatibility24.java', 'TestIcebergSource.java', 'TestIcebergSourceHadoopTables24.java', 'TestIcebergSourceHiveTables24.java', 'TestIcebergSpark24.java', 'TestIdentityPartitionData24.java', 'TestNameMappingProjection.java', 'TestParquetScan24.java', 'TestPartitionPruning24.java', 'TestPartitionValues24.java', 'TestSelect.java', 'TestSnapshotSelection24.java', 'TestSparkBaseDataReader24.java', 'TestSparkDataFile24.java', 'TestSparkDataWrite24.java', 'TestSparkReadProjection24.java', 'TestSparkReaderDeletes24.java', 'TestSparkSchema24.java', 'TestSparkTableUtil.java', 'TestSparkTableUtilWithInMemoryCatalog.java', 'TestStreamingOffset.java', 'TestStructuredStreaming24.java', 'TestTimestampWithoutZone24.java', 'TestWriteMetricsConfig24.java', 'books.json', 'new-books.json', 'build.gradle', 'IcebergSqlExtensions.g4', 'IcebergSparkSessionExtensions.scala', 'AlignRowLevelOperations.scala', 'AssignmentAlignmentSupport.scala', 'ProcedureArgumentCoercion.scala', 'ResolveProcedures.scala', 'RowLevelOperationsPredicateCheck.scala', 'AccumulateFiles.scala', 'OptimizeConditionsInRowLevelOperations.scala', 'PullupCorrelatedPredicatesInRowLevelOperations.scala', 'RewriteDelete.scala', 'RewriteMergeInto.scala', 'RewriteUpdate.scala', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'AddPartitionField.scala', 'Call.scala', 'DropIdentifierFields.scala', 'DropPartitionField.scala', 'DynamicFileFilter.scala', 'MergeInto.scala', 'ReplaceData.scala', 'ReplacePartitionField.scala', 'SetIdentifierFields.scala', 'SetWriteDistributionAndOrdering.scala', 'statements.scala', 'RewriteRowLevelOperationHelper.scala', 'SetAccumulator.scala', 'AddPartitionFieldExec.scala', 'CallExec.scala', 'DropIdentifierFieldsExec.scala', 'DropPartitionFieldExec.scala', 'DynamicFileFilterExec.scala', 'ExtendedBatchScanExec.scala', 'ExtendedDataSourceV2Implicits.scala', 'ExtendedDataSourceV2Strategy.scala', 'MergeIntoExec.scala', 'ReplaceDataExec.scala', 'ReplacePartitionFieldExec.scala', 'SetIdentifierFieldsExec.scala', 'SetWriteDistributionAndOrderingExec.scala', 'Employee.java', 'SparkExtensionsTestBase.java', 'SparkRowLevelOperationsTestBase.java', 'TestAddFilesProcedure.java', 'TestAlterTablePartitionFields.java', 'TestAlterTableSchema.java', 'TestCallStatementParser.java', 'TestCherrypickSnapshotProcedure.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestDelete.java', 'TestExpireSnapshotsProcedure.java', 'TestIcebergExpressions.java', 'TestMerge.java', 'TestMigrateTableProcedure.java', 'TestRemoveOrphanFilesProcedure.java', 'TestRewriteManifestsProcedure.java', 'TestRollbackToSnapshotProcedure.java', 'TestRollbackToTimestampProcedure.java', 'TestSetCurrentSnapshotProcedure.java', 'TestSetWriteDistributionAndOrdering.java', 'TestSnapshotTableProcedure.java', 'TestUpdate.java', 'LICENSE', 'NOTICE', 'SmokeTest.java', '.gitkeep', 'Spark3MigrateAction.java', 'Spark3SnapshotAction.java', 'SparkActions.java', 'BaseCatalog.java', 'FileRewriteCoordinator.java', 'FileScanTaskSetManager.java', 'OrderField.java', 'PathIdentifier.java', 'RollbackStagedTable.java', 'SortOrderToSpark.java', 'Spark3Util.java', 'Spark3VersionUtil.java', 'SparkCatalog.java', 'SparkFilters.java', 'SparkSessionCatalog.java', 'BaseMigrateTableSparkAction.java', 'BaseRewriteDataFilesSpark3Action.java', 'BaseSnapshotTableSparkAction.java', 'BaseTableCreationSparkAction.java', 'Spark3BinPackStrategy.java', 'SparkActions.java', 'AddFilesProcedure.java', 'BaseProcedure.java', 'CherrypickSnapshotProcedure.java', 'ExpireSnapshotsProcedure.java', 'MigrateTableProcedure.java', 'RemoveOrphanFilesProcedure.java', 'RewriteManifestsProcedure.java', 'RollbackToSnapshotProcedure.java', 'RollbackToTimestampProcedure.java', 'SetCurrentSnapshotProcedure.java', 'SnapshotTableProcedure.java', 'SparkProcedures.java', 'IcebergSource.java', 'SparkBatchQueryScan.java', 'SparkBatchScan.java', 'SparkFilesScan.java', 'SparkFilesScanBuilder.java', 'SparkMergeBuilder.java', 'SparkMergeScan.java', 'SparkMicroBatchStream.java', 'SparkRewriteBuilder.java', 'SparkScanBuilder.java', 'SparkTable.java', 'SparkWrite.java', 'SparkWriteBuilder.java', 'StagedSparkTable.java', 'Stats.java', 'StreamingOffset.java', 'NoSuchProcedureException.java', 'ExtendedSupportsDelete.java', 'Procedure.java', 'ProcedureCatalog.java', 'ProcedureParameter.java', 'ProcedureParameterImpl.java', 'SupportsMerge.java', 'ClusteredDistribution.java', 'Distribution.java', 'Distributions.java', 'OrderedDistribution.java', 'UnspecifiedDistribution.java', 'ClusterDistributionImpl.java', 'OrderedDistributionImpl.java', 'UnspecifiedDistributionImpl.java', 'NullOrdering.java', 'SortDirection.java', 'SortOrder.java', 'SupportsFileFilter.java', 'MergeBuilder.java', 'org.apache.spark.sql.sources.DataSourceRegister', 'TransformExpressions.scala', 'DistributionAndOrderingUtils.scala', 'PlanUtils.scala', 'TestScanTaskSerialization3.java', 'TestCreateActions.java', 'TestExpireSnapshotsAction3.java', 'TestNewRewriteDataFilesAction3.java', 'TestRemoveFilesAction3.java', 'TestRemoveOrphanFilesAction3.java', 'TestRewriteDataFilesAction3.java', 'TestRewriteManifestsAction3.java', 'SparkCatalogTestBase.java', 'TestFileRewriteCoordinator.java', 'TestSpark3Util.java', 'TestSparkFilters.java', 'SparkTestTable.java', 'TestAvroScan3.java', 'TestDataFrameWrites3.java', 'TestDataSourceOptions3.java', 'TestFilteredScan.java', 'TestForwardCompatibility3.java', 'TestIcebergSource.java', 'TestIcebergSourceHadoopTables3.java', 'TestIcebergSourceHiveTables3.java', 'TestIcebergSpark3.java', 'TestIdentityPartitionData3.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestParquetScan3.java', 'TestPartitionPruning3.java', 'TestPartitionValues3.java', 'TestPathIdentifier.java', 'TestSnapshotSelection3.java', 'TestSparkBaseDataReader3.java', 'TestSparkCatalog.java', 'TestSparkCatalogHadoopOverrides.java', 'TestSparkDataFile3.java', 'TestSparkDataWrite3.java', 'TestSparkFilesScan.java', 'TestSparkMetadataColumns.java', 'TestSparkReadProjection3.java', 'TestSparkReaderDeletes3.java', 'TestSparkTable.java', 'TestStreamingOffset.java', 'TestStructuredStreaming3.java', 'TestStructuredStreamingRead3.java', 'TestTimestampWithoutZone3.java', 'TestWriteMetricsConfig3.java', 'TestAlterTable.java', 'TestCreateTable.java', 'TestCreateTableAsSelect.java', 'TestDeleteFrom.java', 'TestNamespaceSQL.java', 'TestPartitionedWrites.java', 'TestRefreshTable.java', 'TestSelect.java', 'TestTimestampWithoutZone.java', 'TestUnpartitionedWrites.java']"
"Build: Create separate Spark test actions for 2.4 and 3.0 (#3298)

* Build: Create separate Spark test actions for 2.4 and 3.0.

* Build: Run tests for all Spark modules.

* Build: Fix matrix.

* Build: Update to run check on each module.

* Build: Minor fix.",2,59,2021-10-15 18:36:41-07:00,"['java-ci.yml', 'settings.gradle']"
ORC: Add DeleteWriteBuilder for format v2 (#3250),20,560,2021-10-18 18:44:35+08:00,"['Avro.java', 'BaseFileWriterFactory.java', 'DeleteFilter.java', 'TestOrcRowIterator.java', 'TestFileWriterFactory.java', 'TestWriterMetrics.java', 'FlinkOrcWriter.java', 'FlinkFileWriterFactory.java', 'GenericOrcReader.java', 'GenericOrcReaders.java', 'GenericOrcWriter.java', 'GenericOrcWriters.java', 'ORC.java', 'OrcRowWriter.java', 'TestOrcDeleteWriters.java', 'Parquet.java', 'TestParquetDeleteWriters.java', 'SparkOrcWriter.java', 'SparkFileWriterFactory.java', 'TestSparkOrcReadMetadataColumns.java']"
Hive: Switch to RetryingHMSClient (allows configuration of retryDelays and retries) (#3099),9,90,2021-10-18 13:35:09+02:00,"['ClientPool.java', 'ClientPoolImpl.java', 'JdbcClientPool.java', 'CachedClientPool.java', 'HiveCatalog.java', 'HiveClientPool.java', 'HiveTableOperations.java', 'TestHiveClientPool.java', 'TestHiveCommitLocks.java']"
Core:  Add sanity check for buildPositionWriter (#3305),4,16,2021-10-18 21:34:37+08:00,"['Avro.java', 'FileHelpers.java', 'ORC.java', 'Parquet.java']"
Spark: Fix benchmark execution & docs (#3302),22,78,2021-10-18 08:31:14-07:00,"['jmh.gradle', 'benchmarks.md', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java']"
Build: Run Hive tests in separate CI actions (#3300),8,861,2021-10-18 09:03:28-07:00,"['hive-ci.yml', 'java-ci.yml', 'spark-ci.yml', 'build.gradle', 'gradle.properties', 'hive2.gradle', 'hive3.gradle', 'settings.gradle']"
Docs: Add examples of subquery support in UPDATE and DELETE (#3279),1,16,2021-10-18 10:13:41-07:00,['spark-writes.md']
"Spark: Spark3 Sort Compaction Implementation (#2829)

* Spark: Adds Spark3 Sort Based Compaction

Implements Spark3 Sort Based compaction. Uses similar logic to the
Spark3BinPack Strategy but instead of doing a direct read then write,
issues a read, sort, and then write.",10,587,2021-10-18 17:03:14-05:00,"['RewriteDataFiles.java', 'BinPackStrategy.java', 'SortStrategy.java', 'SortOrderUtil.java', 'BaseRewriteDataFilesSparkAction.java', 'TestNewRewriteDataFilesAction.java', 'build.gradle', 'BaseRewriteDataFilesSpark3Action.java', 'Spark3SortStrategy.java', 'DistributionAndOrderingUtils.scala']"
Build: Refactor Flink tests into separate CI (#3310),9,462,2021-10-18 16:38:12-07:00,"['flink-ci.yml', 'hive-ci.yml', 'java-ci.yml', 'spark-ci.yml', 'build.gradle', 'build.gradle', 'build.gradle', 'gradle.properties', 'settings.gradle']"
MR: Support imported data in InputFormat using name mapping (#3312),1,13,2021-10-18 16:40:11-07:00,['IcebergInputFormat.java']
Aliyun: Add OSSOutputStream (#3288),9,623,2021-10-19 19:53:25+08:00,"['AliyunProperties.java', 'OSSOutputStream.java', 'OSSURI.java', 'AliyunOSSTestBase.java', 'AliyunOSSTestRule.java', 'TestOSSOutputStream.java', 'TestOSSURI.java', 'AliyunOSSMockRule.java', 'build.gradle']"
Flink: Fix CDC validation errors (#3258),2,72,2021-10-19 19:56:26+08:00,"['IcebergFilesCommitter.java', 'TestIcebergFilesCommitter.java']"
Parquet: Fix map projection after map to key_value rename (#3309),2,151,2021-10-19 08:05:48-07:00,"['PruneColumns.java', 'TestPruneColumns.java']"
"Spark: Remove common module, iceberg-spark (#3313)

This also fixes some instances of source incompatibility in Spark 3",342,32888,2021-10-19 08:15:34-07:00,"['jmh.gradle', 'build.gradle', 'build.gradle', 'SparkBenchmarkUtil.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'Action.java', 'IcebergSourceBenchmark.java', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'IcebergSourceNestedListDataBenchmark.java', 'WritersBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'Actions.java', 'CreateAction.java', 'ExpireSnapshotsAction.java', 'ExpireSnapshotsActionResult.java', 'ManifestFileBean.java', 'RemoveOrphanFilesAction.java', 'RewriteDataFilesAction.java', 'RewriteManifestsAction.java', 'RewriteManifestsActionResult.java', 'SnapshotAction.java', 'IcebergSpark.java', 'JobGroupInfo.java', 'JobGroupUtils.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'SparkConfParser.java', 'SparkDataFile.java', 'SparkExceptionUtil.java', 'SparkFixupTimestampType.java', 'SparkFixupTypes.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkSQLProperties.java', 'SparkSchemaUtil.java', 'SparkStructLike.java', 'SparkTableUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'SparkUtil.java', 'SparkValueConverter.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'TypeToSparkType.java', 'BaseDeleteOrphanFilesSparkAction.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseExpireSnapshotsSparkAction.java', 'BaseRewriteDataFilesSparkAction.java', 'BaseRewriteManifestsSparkAction.java', 'BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java', 'BaseSparkActions.java', 'AvroWithSparkSchemaVisitor.java', 'ParquetWithSparkSchemaVisitor.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'ArrowVectorAccessorFactory.java', 'ArrowVectorAccessors.java', 'ColumnarBatchReader.java', 'ConstantColumnVector.java', 'IcebergArrowColumnVector.java', 'RowPositionColumnVector.java', 'VectorizedSparkOrcReaders.java', 'VectorizedSparkParquetReaders.java', 'BaseDataReader.java', 'BatchDataReader.java', 'EqualityDeleteRowReader.java', 'InternalRowWrapper.java', 'RowDataReader.java', 'RowDataRewriter.java', 'SparkAppenderFactory.java', 'SparkFileWriterFactory.java', 'SparkPartitionedFanoutWriter.java', 'SparkPartitionedWriter.java', 'StructInternalRow.java', 'KryoHelpers.java', 'TaskCheckHelper.java', 'TestDataFileSerialization.java', 'TestFileIOSerialization.java', 'TestManifestFileSerialization.java', 'TestScanTaskSerialization.java', 'TestTableSerialization.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'SparkTestBase.java', 'TestSparkSchemaUtil.java', 'TestNewRewriteDataFilesAction.java', 'AvroDataTest.java', 'GenericsHelpers.java', 'RandomData.java', 'TestHelpers.java', 'TestOrcWrite.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkAvroEnums.java', 'TestSparkAvroReader.java', 'TestSparkDateTimes.java', 'TestSparkOrcReadMetadataColumns.java', 'TestSparkOrcReader.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkParquetReader.java', 'TestSparkParquetWriter.java', 'TestSparkRecordOrcReaderWriter.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryFallbackToPlainEncodingVectorizedReads.java', 'TestParquetVectorizedReads.java', 'LogMessage.java', 'SimpleRecord.java', 'TestAvroScan.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestForwardCompatibility.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSpark.java', 'TestIdentityPartitionData.java', 'TestInternalRowWrapper.java', 'TestParquetScan.java', 'TestPartitionPruning.java', 'TestPartitionValues.java', 'TestReadProjection.java', 'TestSnapshotSelection.java', 'TestSparkAppenderFactory.java', 'TestSparkBaseDataReader.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestSparkFileWriterFactory.java', 'TestSparkMergingMetrics.java', 'TestSparkPartitioningWriters.java', 'TestSparkPositionDeltaWriters.java', 'TestSparkReadProjection.java', 'TestSparkReaderDeletes.java', 'TestSparkRollingFileWriters.java', 'TestSparkSchema.java', 'TestSparkWriterMetrics.java', 'TestStructuredStreaming.java', 'TestTables.java', 'TestTimestampWithoutZone.java', 'TestWriteMetricsConfig.java', 'ThreeColumnRecord.java', 'build.gradle', 'SparkBenchmarkUtil.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'Action.java', 'IcebergSourceBenchmark.java', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'IcebergSourceNestedListDataBenchmark.java', 'WritersBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'Actions.java', 'CreateAction.java', 'ExpireSnapshotsAction.java', 'ExpireSnapshotsActionResult.java', 'ManifestFileBean.java', 'RemoveOrphanFilesAction.java', 'RewriteDataFilesAction.java', 'RewriteManifestsAction.java', 'RewriteManifestsActionResult.java', 'SnapshotAction.java', 'IcebergSpark.java', 'JobGroupInfo.java', 'JobGroupUtils.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'SparkConfParser.java', 'SparkDataFile.java', 'SparkExceptionUtil.java', 'SparkFixupTimestampType.java', 'SparkFixupTypes.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkSQLProperties.java', 'SparkSchemaUtil.java', 'SparkStructLike.java', 'SparkTableUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'SparkUtil.java', 'SparkValueConverter.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'TypeToSparkType.java', 'BaseDeleteOrphanFilesSparkAction.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseExpireSnapshotsSparkAction.java', 'BaseRewriteDataFilesSparkAction.java', 'BaseRewriteManifestsSparkAction.java', 'BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java', 'BaseSparkActions.java', 'AvroWithSparkSchemaVisitor.java', 'ParquetWithSparkSchemaVisitor.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'ArrowVectorAccessorFactory.java', 'ArrowVectorAccessors.java', 'ColumnarBatchReader.java', 'ConstantColumnVector.java', 'IcebergArrowColumnVector.java', 'RowPositionColumnVector.java', 'VectorizedSparkOrcReaders.java', 'VectorizedSparkParquetReaders.java', 'BaseDataReader.java', 'BatchDataReader.java', 'EqualityDeleteRowReader.java', 'InternalRowWrapper.java', 'RowDataReader.java', 'RowDataRewriter.java', 'SparkAppenderFactory.java', 'SparkFileWriterFactory.java', 'SparkPartitionedFanoutWriter.java', 'SparkPartitionedWriter.java', 'StructInternalRow.java', 'KryoHelpers.java', 'TaskCheckHelper.java', 'TestDataFileSerialization.java', 'TestFileIOSerialization.java', 'TestManifestFileSerialization.java', 'TestScanTaskSerialization.java', 'TestTableSerialization.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'SparkTestBase.java', 'TestSparkSchemaUtil.java', 'TestNewRewriteDataFilesAction.java', 'AvroDataTest.java', 'GenericsHelpers.java', 'RandomData.java', 'TestHelpers.java', 'TestOrcWrite.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkAvroEnums.java', 'TestSparkAvroReader.java', 'TestSparkDateTimes.java', 'TestSparkOrcReadMetadataColumns.java', 'TestSparkOrcReader.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkParquetReader.java', 'TestSparkParquetWriter.java', 'TestSparkRecordOrcReaderWriter.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryFallbackToPlainEncodingVectorizedReads.java', 'TestParquetVectorizedReads.java', 'LogMessage.java', 'SimpleRecord.java', 'TestAvroScan.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestForwardCompatibility.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSpark.java', 'TestIdentityPartitionData.java', 'TestInternalRowWrapper.java', 'TestParquetScan.java', 'TestPartitionPruning.java', 'TestPartitionValues.java', 'TestReadProjection.java', 'TestSnapshotSelection.java', 'TestSparkAppenderFactory.java', 'TestSparkBaseDataReader.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestSparkFileWriterFactory.java', 'TestSparkMergingMetrics.java', 'TestSparkPartitioningWriters.java', 'TestSparkPositionDeltaWriters.java', 'TestSparkReadProjection.java', 'TestSparkReaderDeletes.java', 'TestSparkRollingFileWriters.java', 'TestSparkSchema.java', 'TestSparkWriterMetrics.java', 'TestStructuredStreaming.java', 'TestTables.java', 'TestTimestampWithoutZone.java', 'TestWriteMetricsConfig.java', 'ThreeColumnRecord.java']"
"Build: Move Hive builds to build.gradle files (#3311)

Using the expected structure automatically loads builds when they are enabled in settings.gradle.",5,308,2021-10-19 08:28:35-07:00,"['build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle']"
Hotfix: Fix Flink test imports. (#3319),1,2,2021-10-19 11:34:11-07:00,['TestIcebergFilesCommitter.java']
Spark: Remove redundant abstract test classes (#3321),107,1772,2021-10-19 16:12:23-07:00,"['TestScanTaskSerialization.java', 'TestScanTaskSerialization24.java', 'TestDeleteReachableFilesAction.java', 'TestDeleteReachableFilesAction24.java', 'TestExpireSnapshotsAction.java', 'TestExpireSnapshotsAction24.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction24.java', 'TestRewriteDataFilesAction.java', 'TestRewriteDataFilesAction24.java', 'TestRewriteManifestsAction.java', 'TestRewriteManifestsAction24.java', 'TestAvroScan.java', 'TestAvroScan24.java', 'TestDataFrameWrites.java', 'TestDataFrameWrites24.java', 'TestDataSourceOptions.java', 'TestDataSourceOptions24.java', 'TestForwardCompatibility.java', 'TestForwardCompatibility24.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHadoopTables24.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceHiveTables24.java', 'TestIcebergSpark.java', 'TestIcebergSpark24.java', 'TestIdentityPartitionData.java', 'TestIdentityPartitionData24.java', 'TestParquetScan.java', 'TestParquetScan24.java', 'TestPartitionPruning.java', 'TestPartitionPruning24.java', 'TestPartitionValues.java', 'TestPartitionValues24.java', 'TestSnapshotSelection.java', 'TestSnapshotSelection24.java', 'TestSparkBaseDataReader.java', 'TestSparkBaseDataReader24.java', 'TestSparkDataFile.java', 'TestSparkDataFile24.java', 'TestSparkDataWrite.java', 'TestSparkDataWrite24.java', 'TestSparkReadProjection.java', 'TestSparkReadProjection24.java', 'TestSparkReaderDeletes.java', 'TestSparkReaderDeletes24.java', 'TestSparkSchema.java', 'TestSparkSchema24.java', 'TestStructuredStreaming.java', 'TestStructuredStreaming24.java', 'TestTimestampWithoutZone.java', 'TestTimestampWithoutZone24.java', 'TestWriteMetricsConfig.java', 'TestWriteMetricsConfig24.java', 'TestScanTaskSerialization.java', 'TestScanTaskSerialization3.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestExpireSnapshotsAction3.java', 'TestNewRewriteDataFilesAction3.java', 'TestRemoveFilesAction3.java', 'TestRewriteDataFilesAction.java', 'TestRewriteDataFilesAction3.java', 'TestRewriteManifestsAction.java', 'TestRewriteManifestsAction3.java', 'TestNewRewriteDataFilesAction.java', 'TestAvroScan.java', 'TestAvroScan3.java', 'TestDataFrameWrites.java', 'TestDataFrameWrites3.java', 'TestDataSourceOptions.java', 'TestDataSourceOptions3.java', 'TestForwardCompatibility.java', 'TestForwardCompatibility3.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHadoopTables3.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceHiveTables3.java', 'TestIcebergSpark.java', 'TestIcebergSpark3.java', 'TestIdentityPartitionData.java', 'TestIdentityPartitionData3.java', 'TestParquetScan.java', 'TestParquetScan3.java', 'TestPartitionPruning.java', 'TestPartitionPruning3.java', 'TestPartitionValues.java', 'TestPartitionValues3.java', 'TestSnapshotSelection.java', 'TestSnapshotSelection3.java', 'TestSparkBaseDataReader.java', 'TestSparkBaseDataReader3.java', 'TestSparkDataFile.java', 'TestSparkDataFile3.java', 'TestSparkDataWrite.java', 'TestSparkDataWrite3.java', 'TestSparkReadProjection.java', 'TestSparkReadProjection3.java', 'TestSparkReaderDeletes.java', 'TestSparkReaderDeletes3.java', 'TestSparkSchema.java', 'TestStructuredStreaming.java', 'TestStructuredStreaming3.java', 'TestTimestampWithoutZone.java', 'TestTimestampWithoutZone3.java', 'TestWriteMetricsConfig.java', 'TestWriteMetricsConfig3.java']"
Flink: Fail if catalog type and catalog-impl are configured (#3308),3,159,2021-10-19 16:14:11-07:00,"['FlinkCatalogFactory.java', 'TestFlinkCatalogFactory.java', 'flink.md']"
Avro: Fix file import with correct row count (#3273),4,79,2021-10-20 08:09:10-07:00,"['Avro.java', 'TableMigrationUtil.java', 'build.gradle', 'TestAddFilesProcedure.java']"
"Spark: Improve setup perf of dictionary benchmarks (#3329)

Previously the benchmarking code used a number of ""when"" constructs to
generate data in rings. This became much more expensive somewhere between
Spark 2.4.5 and 2.4.6 for reasons we are not certain of. In an attempt
to improve performance we have removed all of these constructs and
replaced them with identical modulo operations and add date operations
when applicable.",2,283,2021-10-20 10:06:27-07:00,"['VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java']"
Docs: Update README.md after #3256 (#3324),1,2,2021-10-20 10:08:17-07:00,['README.md']
Spark: Fix Spark2 benchmarks (#3330),2,29,2021-10-20 10:21:47-07:00,"['VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java']"
Build: Add new CI workflows to cancel duplicate actions (#3333),1,3,2021-10-20 18:00:24-07:00,['cancel-duplicate-workflow-runs.yml']
Doc: Add docs for add_files procedure (#3334),1,42,2021-10-21 13:12:56-05:00,['spark-procedures.md']
Arrow: Bump to Apache Arrow 5.0 (#3040),2,6,2021-10-21 14:58:49-05:00,"['GenericArrowVectorAccessorFactory.java', 'versions.props']"
"Doc: Small fix to add file doc (#3343)

Some missing back quotes, and add escape so that some of these render as appropriate.",1,6,2021-10-21 15:03:31-05:00,['spark-procedures.md']
Docs: Add blog post on Debezium with Iceberg (#3339),1,4,2021-10-21 14:42:54-07:00,['blogs.md']
Python: Add all Iceberg types (#3234),2,229,2021-10-21 15:38:11-07:00,"['types.py', 'test_types.py']"
Spark 2.4: Use snapshot schema when time traveling (#1508),10,507,2021-10-21 16:24:29-07:00,"['BaseTableScan.java', 'DataTableScan.java', 'DateTimeUtil.java', 'SnapshotUtil.java', 'IcebergSource.java', 'Reader.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java']"
API: Remove deprecated APIs up to 0.12.0 (#3331),14,179,2021-10-21 16:30:08-07:00,"['Metrics.java', 'OverwriteFiles.java', 'PartitionSpecVisitor.java', 'TestMetricsSerialization.java', 'BaseOverwriteFiles.java', 'TableMetadataParser.java', 'AvroMetrics.java', 'TestFilterFiles.java', 'TestFindFiles.java', 'TestOverwrite.java', 'TestOverwriteWithValidation.java', 'TestScanDataFileColumns.java', 'TestSnapshotSelection.java', 'TableMigrationUtil.java']"
"Python: Minor changes to types classes, follow up to #3234 (#3350)",2,37,2021-10-22 08:20:30-07:00,"['types.py', 'test_types.py']"
Spark: Initial support for 3.2 (#3335),329,58163,2021-10-22 12:45:43-07:00,"['spark-ci.yml', '.gitignore', 'build.gradle', 'gradle.properties', 'jmh.gradle', 'settings.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'IcebergSqlExtensions.g4', 'IcebergSparkSessionExtensions.scala', 'ProcedureArgumentCoercion.scala', 'ResolveProcedures.scala', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'AddPartitionField.scala', 'Call.scala', 'DropIdentifierFields.scala', 'DropPartitionField.scala', 'ReplacePartitionField.scala', 'SetIdentifierFields.scala', 'SetWriteDistributionAndOrdering.scala', 'statements.scala', 'AddPartitionFieldExec.scala', 'CallExec.scala', 'DropIdentifierFieldsExec.scala', 'DropPartitionFieldExec.scala', 'ExtendedDataSourceV2Strategy.scala', 'ReplacePartitionFieldExec.scala', 'SetIdentifierFieldsExec.scala', 'SetWriteDistributionAndOrderingExec.scala', 'Employee.java', 'SparkExtensionsTestBase.java', 'SparkRowLevelOperationsTestBase.java', 'TestAddFilesProcedure.java', 'TestAlterTablePartitionFields.java', 'TestAlterTableSchema.java', 'TestCallStatementParser.java', 'TestCherrypickSnapshotProcedure.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestDelete.java', 'TestExpireSnapshotsProcedure.java', 'TestIcebergExpressions.java', 'TestMerge.java', 'TestMigrateTableProcedure.java', 'TestRemoveOrphanFilesProcedure.java', 'TestRewriteManifestsProcedure.java', 'TestRollbackToSnapshotProcedure.java', 'TestRollbackToTimestampProcedure.java', 'TestSetCurrentSnapshotProcedure.java', 'TestSetWriteDistributionAndOrdering.java', 'TestSnapshotTableProcedure.java', 'TestUpdate.java', 'LICENSE', 'NOTICE', 'SmokeTest.java', '.gitkeep', 'SparkBenchmarkUtil.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'Action.java', 'IcebergSourceBenchmark.java', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'IcebergSourceNestedListDataBenchmark.java', 'WritersBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'Actions.java', 'CreateAction.java', 'ExpireSnapshotsAction.java', 'ExpireSnapshotsActionResult.java', 'ManifestFileBean.java', 'RemoveOrphanFilesAction.java', 'RewriteDataFilesAction.java', 'RewriteManifestsAction.java', 'RewriteManifestsActionResult.java', 'SnapshotAction.java', 'Spark3MigrateAction.java', 'Spark3SnapshotAction.java', 'SparkActions.java', 'BaseCatalog.java', 'FileRewriteCoordinator.java', 'FileScanTaskSetManager.java', 'IcebergSpark.java', 'JobGroupInfo.java', 'JobGroupUtils.java', 'OrderField.java', 'PathIdentifier.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'RollbackStagedTable.java', 'SortOrderToSpark.java', 'Spark3Util.java', 'SparkCatalog.java', 'SparkConfParser.java', 'SparkDataFile.java', 'SparkExceptionUtil.java', 'SparkFilters.java', 'SparkFixupTimestampType.java', 'SparkFixupTypes.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkSQLProperties.java', 'SparkSchemaUtil.java', 'SparkSessionCatalog.java', 'SparkStructLike.java', 'SparkTableUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'SparkUtil.java', 'SparkValueConverter.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'TypeToSparkType.java', 'BaseDeleteOrphanFilesSparkAction.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseExpireSnapshotsSparkAction.java', 'BaseMigrateTableSparkAction.java', 'BaseRewriteDataFilesSpark3Action.java', 'BaseRewriteDataFilesSparkAction.java', 'BaseRewriteManifestsSparkAction.java', 'BaseSnapshotTableSparkAction.java', 'BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java', 'BaseSparkActions.java', 'BaseTableCreationSparkAction.java', 'Spark3BinPackStrategy.java', 'Spark3SortStrategy.java', 'SparkActions.java', 'AvroWithSparkSchemaVisitor.java', 'ParquetWithSparkSchemaVisitor.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'ArrowVectorAccessorFactory.java', 'ArrowVectorAccessors.java', 'ColumnarBatchReader.java', 'ConstantColumnVector.java', 'IcebergArrowColumnVector.java', 'RowPositionColumnVector.java', 'VectorizedSparkOrcReaders.java', 'VectorizedSparkParquetReaders.java', 'AddFilesProcedure.java', 'BaseProcedure.java', 'CherrypickSnapshotProcedure.java', 'ExpireSnapshotsProcedure.java', 'MigrateTableProcedure.java', 'RemoveOrphanFilesProcedure.java', 'RewriteManifestsProcedure.java', 'RollbackToSnapshotProcedure.java', 'RollbackToTimestampProcedure.java', 'SetCurrentSnapshotProcedure.java', 'SnapshotTableProcedure.java', 'SparkProcedures.java', 'BaseDataReader.java', 'BatchDataReader.java', 'EqualityDeleteRowReader.java', 'IcebergSource.java', 'InternalRowWrapper.java', 'RowDataReader.java', 'RowDataRewriter.java', 'SparkAppenderFactory.java', 'SparkBatchQueryScan.java', 'SparkBatchScan.java', 'SparkFileWriterFactory.java', 'SparkFilesScan.java', 'SparkFilesScanBuilder.java', 'SparkMergeBuilder.java', 'SparkMergeScan.java', 'SparkMicroBatchStream.java', 'SparkPartitionedFanoutWriter.java', 'SparkPartitionedWriter.java', 'SparkRewriteBuilder.java', 'SparkScanBuilder.java', 'SparkTable.java', 'SparkWrite.java', 'SparkWriteBuilder.java', 'StagedSparkTable.java', 'Stats.java', 'StreamingOffset.java', 'StructInternalRow.java', 'NoSuchProcedureException.java', 'ExtendedSupportsDelete.java', 'Procedure.java', 'ProcedureCatalog.java', 'ProcedureParameter.java', 'ProcedureParameterImpl.java', 'SupportsMerge.java', 'ClusteredDistribution.java', 'Distribution.java', 'Distributions.java', 'OrderedDistribution.java', 'UnspecifiedDistribution.java', 'ClusterDistributionImpl.java', 'OrderedDistributionImpl.java', 'UnspecifiedDistributionImpl.java', 'NullOrdering.java', 'SortDirection.java', 'SortOrder.java', 'SupportsFileFilter.java', 'MergeBuilder.java', 'org.apache.spark.sql.sources.DataSourceRegister', 'TransformExpressions.scala', 'DistributionAndOrderingUtils.scala', 'PlanUtils.scala', 'KryoHelpers.java', 'TaskCheckHelper.java', 'TestDataFileSerialization.java', 'TestFileIOSerialization.java', 'TestManifestFileSerialization.java', 'TestScanTaskSerialization.java', 'TestTableSerialization.java', 'TestCreateActions.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction3.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'SparkCatalogTestBase.java', 'SparkTestBase.java', 'TestFileRewriteCoordinator.java', 'TestSpark3Util.java', 'TestSparkFilters.java', 'TestSparkSchemaUtil.java', 'TestNewRewriteDataFilesAction.java', 'AvroDataTest.java', 'GenericsHelpers.java', 'RandomData.java', 'TestHelpers.java', 'TestOrcWrite.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkAvroEnums.java', 'TestSparkAvroReader.java', 'TestSparkDateTimes.java', 'TestSparkOrcReadMetadataColumns.java', 'TestSparkOrcReader.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkParquetReader.java', 'TestSparkParquetWriter.java', 'TestSparkRecordOrcReaderWriter.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryFallbackToPlainEncodingVectorizedReads.java', 'TestParquetVectorizedReads.java', 'LogMessage.java', 'SimpleRecord.java', 'SparkTestTable.java', 'TestAvroScan.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestFilteredScan.java', 'TestForwardCompatibility.java', 'TestIcebergSource.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSpark.java', 'TestIdentityPartitionData.java', 'TestInternalRowWrapper.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestParquetScan.java', 'TestPartitionPruning.java', 'TestPartitionValues.java', 'TestPathIdentifier.java', 'TestReadProjection.java', 'TestSnapshotSelection.java', 'TestSparkAppenderFactory.java', 'TestSparkBaseDataReader.java', 'TestSparkCatalog.java', 'TestSparkCatalogHadoopOverrides.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestSparkFileWriterFactory.java', 'TestSparkFilesScan.java', 'TestSparkMergingMetrics.java', 'TestSparkMetadataColumns.java', 'TestSparkPartitioningWriters.java', 'TestSparkPositionDeltaWriters.java', 'TestSparkReadProjection.java', 'TestSparkReaderDeletes.java', 'TestSparkRollingFileWriters.java', 'TestSparkTable.java', 'TestSparkWriterMetrics.java', 'TestStreamingOffset.java', 'TestStructuredStreaming.java', 'TestStructuredStreamingRead3.java', 'TestTables.java', 'TestTimestampWithoutZone.java', 'TestWriteMetricsConfig.java', 'ThreeColumnRecord.java', 'TestAlterTable.java', 'TestCreateTable.java', 'TestCreateTableAsSelect.java', 'TestDeleteFrom.java', 'TestNamespaceSQL.java', 'TestPartitionedWrites.java', 'TestRefreshTable.java', 'TestSelect.java', 'TestTimestampWithoutZone.java', 'TestUnpartitionedWrites.java']"
Spark: Use same folder structure for all versions (#3360),539,16,2021-10-23 13:33:35-07:00,"['.gitignore', 'settings.gradle', '.gitkeep', 'SparkBenchmarkUtil.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'Action.java', 'IcebergSourceBenchmark.java', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'IcebergSourceNestedListDataBenchmark.java', 'WritersBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'Actions.java', 'CreateAction.java', 'ExpireSnapshotsAction.java', 'ExpireSnapshotsActionResult.java', 'ManifestFileBean.java', 'RemoveOrphanFilesAction.java', 'RewriteDataFilesAction.java', 'RewriteManifestsAction.java', 'RewriteManifestsActionResult.java', 'SnapshotAction.java', 'SparkActions.java', 'IcebergSpark.java', 'JobGroupInfo.java', 'JobGroupUtils.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'SparkConfParser.java', 'SparkDataFile.java', 'SparkExceptionUtil.java', 'SparkFilters.java', 'SparkFixupTimestampType.java', 'SparkFixupTypes.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkSQLProperties.java', 'SparkSchemaUtil.java', 'SparkStructLike.java', 'SparkTableUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'SparkUtil.java', 'SparkValueConverter.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'TypeToSparkType.java', 'BaseDeleteOrphanFilesSparkAction.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseExpireSnapshotsSparkAction.java', 'BaseRewriteDataFilesSparkAction.java', 'BaseRewriteManifestsSparkAction.java', 'BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java', 'BaseSparkActions.java', 'SparkActions.java', 'AvroWithSparkSchemaVisitor.java', 'ParquetWithSparkSchemaVisitor.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'ArrowVectorAccessorFactory.java', 'ArrowVectorAccessors.java', 'ColumnarBatchReader.java', 'ConstantColumnVector.java', 'IcebergArrowColumnVector.java', 'RowPositionColumnVector.java', 'VectorizedSparkOrcReaders.java', 'VectorizedSparkParquetReaders.java', 'BaseDataReader.java', 'BatchDataReader.java', 'CustomCatalogs.java', 'EqualityDeleteRowReader.java', 'IcebergSource.java', 'InternalRowWrapper.java', 'Reader.java', 'RowDataReader.java', 'RowDataRewriter.java', 'SparkAppenderFactory.java', 'SparkFileWriterFactory.java', 'SparkPartitionedFanoutWriter.java', 'SparkPartitionedWriter.java', 'Stats.java', 'StreamingOffset.java', 'StreamingWriter.java', 'StructInternalRow.java', 'Writer.java', 'org.apache.spark.sql.sources.DataSourceRegister', 'KryoHelpers.java', 'TaskCheckHelper.java', 'TestDataFileSerialization.java', 'TestFileIOSerialization.java', 'TestManifestFileSerialization.java', 'TestScanTaskSerialization.java', 'TestTableSerialization.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'ConcurrencyTest.java', 'README.md', 'ReadAndWriteTablesTest.java', 'SchemaEvolutionTest.java', 'SimpleRecord.java', 'SnapshotFunctionalityTest.java', 'SparkTestBase.java', 'TestSparkSchemaUtil.java', 'TestNewRewriteDataFilesAction.java', 'AvroDataTest.java', 'GenericsHelpers.java', 'RandomData.java', 'TestHelpers.java', 'TestOrcWrite.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkAvroEnums.java', 'TestSparkAvroReader.java', 'TestSparkDateTimes.java', 'TestSparkOrcReadMetadataColumns.java', 'TestSparkOrcReader.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkParquetReader.java', 'TestSparkParquetWriter.java', 'TestSparkRecordOrcReaderWriter.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryFallbackToPlainEncodingVectorizedReads.java', 'TestParquetVectorizedReads.java', 'LogMessage.java', 'SimpleRecord.java', 'TestAvroScan.java', 'TestCatalog.java', 'TestCustomCatalog.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestFilteredScan.java', 'TestForwardCompatibility.java', 'TestIcebergSource.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSpark.java', 'TestIdentityPartitionData.java', 'TestInternalRowWrapper.java', 'TestNameMappingProjection.java', 'TestParquetScan.java', 'TestPartitionPruning.java', 'TestPartitionValues.java', 'TestReadProjection.java', 'TestSelect.java', 'TestSnapshotSelection.java', 'TestSparkAppenderFactory.java', 'TestSparkBaseDataReader.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestSparkFileWriterFactory.java', 'TestSparkMergingMetrics.java', 'TestSparkPartitioningWriters.java', 'TestSparkPositionDeltaWriters.java', 'TestSparkReadProjection.java', 'TestSparkReaderDeletes.java', 'TestSparkRollingFileWriters.java', 'TestSparkSchema.java', 'TestSparkTableUtil.java', 'TestSparkTableUtilWithInMemoryCatalog.java', 'TestSparkWriterMetrics.java', 'TestStreamingOffset.java', 'TestStructuredStreaming.java', 'TestTables.java', 'TestTimestampWithoutZone.java', 'TestWriteMetricsConfig.java', 'ThreeColumnRecord.java', 'books.json', 'new-books.json', 'IcebergSqlExtensions.g4', 'IcebergSparkSessionExtensions.scala', 'AlignRowLevelOperations.scala', 'AssignmentAlignmentSupport.scala', 'ProcedureArgumentCoercion.scala', 'ResolveProcedures.scala', 'RowLevelOperationsPredicateCheck.scala', 'AccumulateFiles.scala', 'OptimizeConditionsInRowLevelOperations.scala', 'PullupCorrelatedPredicatesInRowLevelOperations.scala', 'RewriteDelete.scala', 'RewriteMergeInto.scala', 'RewriteUpdate.scala', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'AddPartitionField.scala', 'Call.scala', 'DropIdentifierFields.scala', 'DropPartitionField.scala', 'DynamicFileFilter.scala', 'MergeInto.scala', 'ReplaceData.scala', 'ReplacePartitionField.scala', 'SetIdentifierFields.scala', 'SetWriteDistributionAndOrdering.scala', 'statements.scala', 'RewriteRowLevelOperationHelper.scala', 'SetAccumulator.scala', 'AddPartitionFieldExec.scala', 'CallExec.scala', 'DropIdentifierFieldsExec.scala', 'DropPartitionFieldExec.scala', 'DynamicFileFilterExec.scala', 'ExtendedBatchScanExec.scala', 'ExtendedDataSourceV2Implicits.scala', 'ExtendedDataSourceV2Strategy.scala', 'MergeIntoExec.scala', 'ReplaceDataExec.scala', 'ReplacePartitionFieldExec.scala', 'SetIdentifierFieldsExec.scala', 'SetWriteDistributionAndOrderingExec.scala', 'Employee.java', 'SparkExtensionsTestBase.java', 'SparkRowLevelOperationsTestBase.java', 'TestAddFilesProcedure.java', 'TestAlterTablePartitionFields.java', 'TestAlterTableSchema.java', 'TestCallStatementParser.java', 'TestCherrypickSnapshotProcedure.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestDelete.java', 'TestExpireSnapshotsProcedure.java', 'TestIcebergExpressions.java', 'TestMerge.java', 'TestMigrateTableProcedure.java', 'TestRemoveOrphanFilesProcedure.java', 'TestRewriteManifestsProcedure.java', 'TestRollbackToSnapshotProcedure.java', 'TestRollbackToTimestampProcedure.java', 'TestSetCurrentSnapshotProcedure.java', 'TestSetWriteDistributionAndOrdering.java', 'TestSnapshotTableProcedure.java', 'TestUpdate.java', 'LICENSE', 'NOTICE', 'SmokeTest.java', '.gitkeep', 'SparkBenchmarkUtil.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'Action.java', 'IcebergSourceBenchmark.java', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'IcebergSourceNestedListDataBenchmark.java', 'WritersBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'Actions.java', 'CreateAction.java', 'ExpireSnapshotsAction.java', 'ExpireSnapshotsActionResult.java', 'ManifestFileBean.java', 'RemoveOrphanFilesAction.java', 'RewriteDataFilesAction.java', 'RewriteManifestsAction.java', 'RewriteManifestsActionResult.java', 'SnapshotAction.java', 'Spark3MigrateAction.java', 'Spark3SnapshotAction.java', 'SparkActions.java', 'BaseCatalog.java', 'FileRewriteCoordinator.java', 'FileScanTaskSetManager.java', 'IcebergSpark.java', 'JobGroupInfo.java', 'JobGroupUtils.java', 'OrderField.java', 'PathIdentifier.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'RollbackStagedTable.java', 'SortOrderToSpark.java', 'Spark3Util.java', 'Spark3VersionUtil.java', 'SparkCatalog.java', 'SparkConfParser.java', 'SparkDataFile.java', 'SparkExceptionUtil.java', 'SparkFilters.java', 'SparkFixupTimestampType.java', 'SparkFixupTypes.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkSQLProperties.java', 'SparkSchemaUtil.java', 'SparkSessionCatalog.java', 'SparkStructLike.java', 'SparkTableUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'SparkUtil.java', 'SparkValueConverter.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'TypeToSparkType.java', 'BaseDeleteOrphanFilesSparkAction.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseExpireSnapshotsSparkAction.java', 'BaseMigrateTableSparkAction.java', 'BaseRewriteDataFilesSpark3Action.java', 'BaseRewriteDataFilesSparkAction.java', 'BaseRewriteManifestsSparkAction.java', 'BaseSnapshotTableSparkAction.java', 'BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java', 'BaseSparkActions.java', 'BaseTableCreationSparkAction.java', 'Spark3BinPackStrategy.java', 'Spark3SortStrategy.java', 'SparkActions.java', 'AvroWithSparkSchemaVisitor.java', 'ParquetWithSparkSchemaVisitor.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'ArrowVectorAccessorFactory.java', 'ArrowVectorAccessors.java', 'ColumnarBatchReader.java', 'ConstantColumnVector.java', 'IcebergArrowColumnVector.java', 'RowPositionColumnVector.java', 'VectorizedSparkOrcReaders.java', 'VectorizedSparkParquetReaders.java', 'AddFilesProcedure.java', 'BaseProcedure.java', 'CherrypickSnapshotProcedure.java', 'ExpireSnapshotsProcedure.java', 'MigrateTableProcedure.java', 'RemoveOrphanFilesProcedure.java', 'RewriteManifestsProcedure.java', 'RollbackToSnapshotProcedure.java', 'RollbackToTimestampProcedure.java', 'SetCurrentSnapshotProcedure.java', 'SnapshotTableProcedure.java', 'SparkProcedures.java', 'BaseDataReader.java', 'BatchDataReader.java', 'EqualityDeleteRowReader.java', 'IcebergSource.java', 'InternalRowWrapper.java', 'RowDataReader.java', 'RowDataRewriter.java', 'SparkAppenderFactory.java', 'SparkBatchQueryScan.java', 'SparkBatchScan.java', 'SparkFileWriterFactory.java', 'SparkFilesScan.java', 'SparkFilesScanBuilder.java', 'SparkMergeBuilder.java', 'SparkMergeScan.java', 'SparkMicroBatchStream.java', 'SparkPartitionedFanoutWriter.java', 'SparkPartitionedWriter.java', 'SparkRewriteBuilder.java', 'SparkScanBuilder.java', 'SparkTable.java', 'SparkWrite.java', 'SparkWriteBuilder.java', 'StagedSparkTable.java', 'Stats.java', 'StreamingOffset.java', 'StructInternalRow.java', 'NoSuchProcedureException.java', 'ExtendedSupportsDelete.java', 'Procedure.java', 'ProcedureCatalog.java', 'ProcedureParameter.java', 'ProcedureParameterImpl.java', 'SupportsMerge.java', 'ClusteredDistribution.java', 'Distribution.java', 'Distributions.java', 'OrderedDistribution.java', 'UnspecifiedDistribution.java', 'ClusterDistributionImpl.java', 'OrderedDistributionImpl.java', 'UnspecifiedDistributionImpl.java', 'NullOrdering.java', 'SortDirection.java', 'SortOrder.java', 'SupportsFileFilter.java', 'MergeBuilder.java', 'org.apache.spark.sql.sources.DataSourceRegister', 'TransformExpressions.scala', 'DistributionAndOrderingUtils.scala', 'PlanUtils.scala', 'KryoHelpers.java', 'TaskCheckHelper.java', 'TestDataFileSerialization.java', 'TestFileIOSerialization.java', 'TestManifestFileSerialization.java', 'TestScanTaskSerialization.java', 'TestTableSerialization.java', 'TestCreateActions.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction3.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'SparkCatalogTestBase.java', 'SparkTestBase.java', 'TestFileRewriteCoordinator.java', 'TestSpark3Util.java', 'TestSparkFilters.java', 'TestSparkSchemaUtil.java', 'TestNewRewriteDataFilesAction.java', 'AvroDataTest.java', 'GenericsHelpers.java', 'RandomData.java', 'TestHelpers.java', 'TestOrcWrite.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkAvroEnums.java', 'TestSparkAvroReader.java', 'TestSparkDateTimes.java', 'TestSparkOrcReadMetadataColumns.java', 'TestSparkOrcReader.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkParquetReader.java', 'TestSparkParquetWriter.java', 'TestSparkRecordOrcReaderWriter.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryFallbackToPlainEncodingVectorizedReads.java', 'TestParquetVectorizedReads.java', 'LogMessage.java', 'SimpleRecord.java', 'SparkTestTable.java', 'TestAvroScan.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestFilteredScan.java', 'TestForwardCompatibility.java', 'TestIcebergSource.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSpark.java', 'TestIdentityPartitionData.java', 'TestInternalRowWrapper.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestParquetScan.java', 'TestPartitionPruning.java', 'TestPartitionValues.java', 'TestPathIdentifier.java', 'TestReadProjection.java', 'TestSnapshotSelection.java', 'TestSparkAppenderFactory.java', 'TestSparkBaseDataReader.java', 'TestSparkCatalog.java', 'TestSparkCatalogHadoopOverrides.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestSparkFileWriterFactory.java', 'TestSparkFilesScan.java', 'TestSparkMergingMetrics.java', 'TestSparkMetadataColumns.java', 'TestSparkPartitioningWriters.java', 'TestSparkPositionDeltaWriters.java', 'TestSparkReadProjection.java', 'TestSparkReaderDeletes.java', 'TestSparkRollingFileWriters.java', 'TestSparkTable.java', 'TestSparkWriterMetrics.java', 'TestStreamingOffset.java', 'TestStructuredStreaming.java', 'TestStructuredStreamingRead3.java', 'TestTables.java', 'TestTimestampWithoutZone.java', 'TestWriteMetricsConfig.java', 'ThreeColumnRecord.java', 'TestAlterTable.java', 'TestCreateTable.java', 'TestCreateTableAsSelect.java', 'TestDeleteFrom.java', 'TestNamespaceSQL.java', 'TestPartitionedWrites.java', 'TestRefreshTable.java', 'TestSelect.java', 'TestTimestampWithoutZone.java', 'TestUnpartitionedWrites.java']"
Flink: Fix flaky test TestFlinkSink#testHashDistributeMode (#3365),1,36,2021-10-25 16:15:48-07:00,['SimpleDataUtil.java']
Spark: Enhance metadata deletes in 3.2 (#3369),3,152,2021-10-25 22:06:05-07:00,"['SparkFilters.java', 'SparkTable.java', 'TestDeleteFrom.java']"
Aliyun:  Add OSSInputStream (#3348),2,286,2021-10-26 15:14:11+08:00,"['OSSInputStream.java', 'TestOSSInputStream.java']"
Core: Enable ORC delete writer in the v2 write path (#3366),13,159,2021-10-26 10:00:40-07:00,"['GenericAppenderFactory.java', 'TestAppenderFactory.java', 'TestGenericSortedPosDeleteWriter.java', 'TestPositionDeltaWriters.java', 'TestTaskEqualityDeltaWriter.java', 'FlinkAppenderFactory.java', 'TestDeltaTaskWriter.java', 'TestFlinkIcebergSinkV2.java', 'TestIcebergFilesCommitter.java', 'GenericOrcWriters.java', 'SparkAppenderFactory.java', 'SparkAppenderFactory.java', 'SparkAppenderFactory.java']"
Hive: Fix Catalogs.hiveCatalog method for default catalogs (#3338),2,29,2021-10-26 15:21:43-07:00,"['Catalogs.java', 'TestCatalogs.java']"
Spark: Fix ClassCastException when using bucket UDF (#3368),3,138,2021-10-26 16:46:09-07:00,"['IcebergSpark.java', 'SparkValueConverter.java', 'TestIcebergSpark.java']"
Build: Add Sam to collaborators (#3381),1,2,2021-10-26 16:46:27-07:00,['.asf.yaml']
Flink: Fix compatibility between 1.12.x and 1.13.x (#3354),2,27,2021-10-26 16:54:59-07:00,"['FlinkDynamicTableFactory.java', 'versions.props']"
Docs: Add Alibaba Cloud Flink CDC blog (#3384),1,5,2021-10-27 12:51:14+08:00,['blogs.md']
Build: Bump Gradle JMH plugin from 0.5.3 to 0.6.6 (#3389),2,8,2021-10-27 09:47:45-05:00,"['build.gradle', 'jmh.gradle']"
Build: Publish SNAPSHOT releases (#3353),2,60,2021-10-27 08:57:34-07:00,"['publish-snapshot.yml', 'build.gradle']"
Core: Add data_file.spec_id to metadata tables (#3015),8,192,2021-10-27 09:01:16-07:00,"['DataFile.java', 'BaseFile.java', 'TestIcebergSourceTablesBase.java', 'TestPartitionPruning.java', 'TestIcebergSourceTablesBase.java', 'TestPartitionPruning.java', 'TestIcebergSourceTablesBase.java', 'TestPartitionPruning.java']"
Core: Remove deprecated APIs up to 0.13.0,7,265,2021-10-27 14:34:15-07:00,"['HadoopCatalog.java', 'OutputFileFactory.java', 'HadoopTableTestBase.java', 'TestCachingCatalog.java', 'TestHadoopCatalog.java', 'HiveCatalog.java', 'HiveCatalogs.java']"
Docs: Credit coauthors on Alibaba Cloud article (#3398),1,2,2021-10-28 09:52:05+08:00,['blogs.md']
Build: Fetch all tags before publishing SNAPSHOT (#3408),1,4,2021-10-28 14:47:25-07:00,['publish-snapshot.yml']
"Hive: Limit number of retries when metadata file is missing (#3379)

Co-authored-by: Kevin Liu <kevinjqliu@gmail.com>",3,26,2021-10-28 15:03:51-07:00,"['HiveTableOperations.java', 'HiveTableBaseTest.java', 'HiveTableTest.java']"
AWS: Add column parameters for Glue catalog table schema (#3352),3,260,2021-10-28 22:28:29-07:00,"['GlueCatalogTableTest.java', 'IcebergToGlueConverter.java', 'IcebergToGlueConverterTest.java']"
Docs: Change theme to windmill (#3382),12,376,2021-10-29 08:52:04-07:00,"['extra.css', 'GitHub-Mark.png', 'Slack_Mark_Web.png', 'asf.png', 'java.png', 'python.png', 'index.md', '404.html', 'nav-item.html', 'topbar.html', 'mkdocs.yml', 'requirements.txt']"
ORC: Fix importing ORC files with float and double columns and test (#3332),3,119,2021-10-29 12:02:24-07:00,"['OrcMetrics.java', 'build.gradle', 'TestAddFilesProcedure.java']"
Docs: Fix typo in metadata rewrite section (#3418),1,2,2021-10-29 14:49:27-07:00,['maintenance.md']
spark: CALL ancestors_of get all the snapshot ancestors (#3317),4,312,2021-10-29 22:06:55-05:00,"['spark-procedures.md', 'TestAncestorsOfProcedure.java', 'AncestorsOfProcedure.java', 'SparkProcedures.java']"
Spark: Add modules for Spark 3.1 (#3415),347,60611,2021-10-31 10:35:52-07:00,"['spark-ci.yml', 'gradle.properties', 'settings.gradle', 'build.gradle', 'IcebergSparkSqlExtensionsParser.scala', 'build.gradle', 'IcebergSqlExtensions.g4', 'IcebergSparkSessionExtensions.scala', 'AlignRowLevelOperations.scala', 'AssignmentAlignmentSupport.scala', 'ProcedureArgumentCoercion.scala', 'ResolveProcedures.scala', 'RowLevelOperationsPredicateCheck.scala', 'AccumulateFiles.scala', 'OptimizeConditionsInRowLevelOperations.scala', 'PullupCorrelatedPredicatesInRowLevelOperations.scala', 'RewriteDelete.scala', 'RewriteMergeInto.scala', 'RewriteUpdate.scala', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'AddPartitionField.scala', 'Call.scala', 'DropIdentifierFields.scala', 'DropPartitionField.scala', 'DynamicFileFilter.scala', 'MergeInto.scala', 'ReplaceData.scala', 'ReplacePartitionField.scala', 'SetIdentifierFields.scala', 'SetWriteDistributionAndOrdering.scala', 'statements.scala', 'RewriteRowLevelOperationHelper.scala', 'SetAccumulator.scala', 'AddPartitionFieldExec.scala', 'CallExec.scala', 'DropIdentifierFieldsExec.scala', 'DropPartitionFieldExec.scala', 'DynamicFileFilterExec.scala', 'ExtendedBatchScanExec.scala', 'ExtendedDataSourceV2Implicits.scala', 'ExtendedDataSourceV2Strategy.scala', 'MergeIntoExec.scala', 'ReplaceDataExec.scala', 'ReplacePartitionFieldExec.scala', 'SetIdentifierFieldsExec.scala', 'SetWriteDistributionAndOrderingExec.scala', 'Employee.java', 'SparkExtensionsTestBase.java', 'SparkRowLevelOperationsTestBase.java', 'TestAddFilesProcedure.java', 'TestAlterTablePartitionFields.java', 'TestAlterTableSchema.java', 'TestAncestorsOfProcedure.java', 'TestCallStatementParser.java', 'TestCherrypickSnapshotProcedure.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestDelete.java', 'TestExpireSnapshotsProcedure.java', 'TestIcebergExpressions.java', 'TestMerge.java', 'TestMigrateTableProcedure.java', 'TestRemoveOrphanFilesProcedure.java', 'TestRewriteManifestsProcedure.java', 'TestRollbackToSnapshotProcedure.java', 'TestRollbackToTimestampProcedure.java', 'TestSetCurrentSnapshotProcedure.java', 'TestSetWriteDistributionAndOrdering.java', 'TestSnapshotTableProcedure.java', 'TestUpdate.java', 'LICENSE', 'NOTICE', 'SmokeTest.java', '.gitkeep', 'SparkBenchmarkUtil.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'Action.java', 'IcebergSourceBenchmark.java', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'IcebergSourceNestedListDataBenchmark.java', 'WritersBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'Actions.java', 'CreateAction.java', 'ExpireSnapshotsAction.java', 'ExpireSnapshotsActionResult.java', 'ManifestFileBean.java', 'RemoveOrphanFilesAction.java', 'RewriteDataFilesAction.java', 'RewriteManifestsAction.java', 'RewriteManifestsActionResult.java', 'SnapshotAction.java', 'Spark3MigrateAction.java', 'Spark3SnapshotAction.java', 'SparkActions.java', 'BaseCatalog.java', 'FileRewriteCoordinator.java', 'FileScanTaskSetManager.java', 'IcebergSpark.java', 'JobGroupInfo.java', 'JobGroupUtils.java', 'OrderField.java', 'PathIdentifier.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'RollbackStagedTable.java', 'SortOrderToSpark.java', 'Spark3Util.java', 'Spark3VersionUtil.java', 'SparkCatalog.java', 'SparkConfParser.java', 'SparkDataFile.java', 'SparkExceptionUtil.java', 'SparkFilters.java', 'SparkFixupTimestampType.java', 'SparkFixupTypes.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkSQLProperties.java', 'SparkSchemaUtil.java', 'SparkSessionCatalog.java', 'SparkStructLike.java', 'SparkTableUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'SparkUtil.java', 'SparkValueConverter.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'TypeToSparkType.java', 'BaseDeleteOrphanFilesSparkAction.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseExpireSnapshotsSparkAction.java', 'BaseMigrateTableSparkAction.java', 'BaseRewriteDataFilesSpark3Action.java', 'BaseRewriteDataFilesSparkAction.java', 'BaseRewriteManifestsSparkAction.java', 'BaseSnapshotTableSparkAction.java', 'BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java', 'BaseSparkActions.java', 'BaseTableCreationSparkAction.java', 'Spark3BinPackStrategy.java', 'Spark3SortStrategy.java', 'SparkActions.java', 'AvroWithSparkSchemaVisitor.java', 'ParquetWithSparkSchemaVisitor.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'ArrowVectorAccessorFactory.java', 'ArrowVectorAccessors.java', 'ColumnarBatchReader.java', 'ConstantColumnVector.java', 'IcebergArrowColumnVector.java', 'RowPositionColumnVector.java', 'VectorizedSparkOrcReaders.java', 'VectorizedSparkParquetReaders.java', 'AddFilesProcedure.java', 'AncestorsOfProcedure.java', 'BaseProcedure.java', 'CherrypickSnapshotProcedure.java', 'ExpireSnapshotsProcedure.java', 'MigrateTableProcedure.java', 'RemoveOrphanFilesProcedure.java', 'RewriteManifestsProcedure.java', 'RollbackToSnapshotProcedure.java', 'RollbackToTimestampProcedure.java', 'SetCurrentSnapshotProcedure.java', 'SnapshotTableProcedure.java', 'SparkProcedures.java', 'BaseDataReader.java', 'BatchDataReader.java', 'EqualityDeleteRowReader.java', 'IcebergSource.java', 'InternalRowWrapper.java', 'RowDataReader.java', 'RowDataRewriter.java', 'SparkAppenderFactory.java', 'SparkBatchQueryScan.java', 'SparkBatchScan.java', 'SparkFileWriterFactory.java', 'SparkFilesScan.java', 'SparkFilesScanBuilder.java', 'SparkMergeBuilder.java', 'SparkMergeScan.java', 'SparkMicroBatchStream.java', 'SparkPartitionedFanoutWriter.java', 'SparkPartitionedWriter.java', 'SparkRewriteBuilder.java', 'SparkScanBuilder.java', 'SparkTable.java', 'SparkWrite.java', 'SparkWriteBuilder.java', 'StagedSparkTable.java', 'Stats.java', 'StreamingOffset.java', 'StructInternalRow.java', 'NoSuchProcedureException.java', 'ExtendedSupportsDelete.java', 'Procedure.java', 'ProcedureCatalog.java', 'ProcedureParameter.java', 'ProcedureParameterImpl.java', 'SupportsMerge.java', 'ClusteredDistribution.java', 'Distribution.java', 'Distributions.java', 'OrderedDistribution.java', 'UnspecifiedDistribution.java', 'ClusterDistributionImpl.java', 'OrderedDistributionImpl.java', 'UnspecifiedDistributionImpl.java', 'NullOrdering.java', 'SortDirection.java', 'SortOrder.java', 'SupportsFileFilter.java', 'MergeBuilder.java', 'org.apache.spark.sql.sources.DataSourceRegister', 'TransformExpressions.scala', 'DistributionAndOrderingUtils.scala', 'PlanUtils.scala', 'KryoHelpers.java', 'TaskCheckHelper.java', 'TestDataFileSerialization.java', 'TestFileIOSerialization.java', 'TestManifestFileSerialization.java', 'TestScanTaskSerialization.java', 'TestTableSerialization.java', 'TestCreateActions.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction3.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'SparkCatalogTestBase.java', 'SparkTestBase.java', 'TestFileRewriteCoordinator.java', 'TestSpark3Util.java', 'TestSparkFilters.java', 'TestSparkSchemaUtil.java', 'TestNewRewriteDataFilesAction.java', 'AvroDataTest.java', 'GenericsHelpers.java', 'RandomData.java', 'TestHelpers.java', 'TestOrcWrite.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkAvroEnums.java', 'TestSparkAvroReader.java', 'TestSparkDateTimes.java', 'TestSparkOrcReadMetadataColumns.java', 'TestSparkOrcReader.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkParquetReader.java', 'TestSparkParquetWriter.java', 'TestSparkRecordOrcReaderWriter.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryFallbackToPlainEncodingVectorizedReads.java', 'TestParquetVectorizedReads.java', 'LogMessage.java', 'SimpleRecord.java', 'SparkTestTable.java', 'TestAvroScan.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestFilteredScan.java', 'TestForwardCompatibility.java', 'TestIcebergSource.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSpark.java', 'TestIdentityPartitionData.java', 'TestInternalRowWrapper.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestParquetScan.java', 'TestPartitionPruning.java', 'TestPartitionValues.java', 'TestPathIdentifier.java', 'TestReadProjection.java', 'TestSnapshotSelection.java', 'TestSparkAppenderFactory.java', 'TestSparkBaseDataReader.java', 'TestSparkCatalog.java', 'TestSparkCatalogHadoopOverrides.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestSparkFileWriterFactory.java', 'TestSparkFilesScan.java', 'TestSparkMergingMetrics.java', 'TestSparkMetadataColumns.java', 'TestSparkPartitioningWriters.java', 'TestSparkPositionDeltaWriters.java', 'TestSparkReadProjection.java', 'TestSparkReaderDeletes.java', 'TestSparkRollingFileWriters.java', 'TestSparkTable.java', 'TestSparkWriterMetrics.java', 'TestStreamingOffset.java', 'TestStructuredStreaming.java', 'TestStructuredStreamingRead3.java', 'TestTables.java', 'TestTimestampWithoutZone.java', 'TestWriteMetricsConfig.java', 'ThreeColumnRecord.java', 'TestAlterTable.java', 'TestCreateTable.java', 'TestCreateTableAsSelect.java', 'TestDeleteFrom.java', 'TestNamespaceSQL.java', 'TestPartitionedWrites.java', 'TestRefreshTable.java', 'TestSelect.java', 'TestTimestampWithoutZone.java', 'TestUnpartitionedWrites.java']"
Build: Fix gradle printVersion (#3397),1,2,2021-10-31 10:37:27-07:00,['tasks.gradle']
Build: Add out folders to .gitignore (#3391),1,1,2021-10-31 10:39:01-07:00,['.gitignore']
Spark 3.2: Remove extra parens to fix checkstyle (#3386),1,2,2021-10-31 11:56:56-07:00,['TestIcebergSpark.java']
"Python: Add black, isort, and tox -e format command (#3383)",6,287,2021-10-31 12:00:00-07:00,"['setup.py', 'types.py', 'bin_packing.py', 'test_types.py', 'test_bin_packing.py', 'tox.ini']"
"Build: Build Flink for 1.12 and 1.13 (#3364)

This changes the iceberg-flink-runtime module to iceberg-flink-1.12-runtime and iceberg-flink-1.13-runtime.",11,1100,2021-10-31 12:26:35-07:00,"['flink-ci.yml', 'build.gradle', 'build.gradle', 'build.gradle', 'LICENSE', 'NOTICE', 'build.gradle', 'LICENSE', 'NOTICE', 'gradle.properties', 'settings.gradle']"
"Build: Only build one version of Spark, Flink, and Hive by default (#3427)",1,6,2021-10-31 15:55:24-07:00,['gradle.properties']
Spark: Support metadata columns in 3.2 (#3373),4,95,2021-10-31 16:02:55-07:00,"['SparkMetadataColumn.java', 'SparkTable.java', 'TestSparkCatalog.java', 'TestSparkMetadataColumns.java']"
Flink: Project the RowData to remove meta-columns (#3240),6,697,2021-11-01 16:54:58+08:00,"['StructProjection.java', 'RowDataProjection.java', 'RowDataFileScanTaskReader.java', 'TestChangeLogTable.java', 'TestHelpers.java', 'TestRowDataProjection.java']"
Hive: Fix RetryingMetaStoreClient for Hive 2.1 (#3403),1,11,2021-11-01 08:53:11-07:00,['HiveClientPool.java']
Core: Fix REPLACE TABLE with new partition spec (#3421),4,152,2021-11-01 09:37:20-07:00,"['TableMetadata.java', 'TestCreateTableAsSelect.java', 'TestCreateTableAsSelect.java', 'TestCreateTableAsSelect.java']"
Spark: Remove reflection workarounds from v3.1 code (#3430),12,276,2021-11-01 12:37:35-07:00,"['build.gradle', 'AssignmentAlignmentSupport.scala', 'RewriteDelete.scala', 'RewriteMergeInto.scala', 'RewriteUpdate.scala', 'IcebergSparkSqlExtensionsParser.scala', 'RewriteRowLevelOperationHelper.scala', 'Spark3VersionUtil.java', 'DistributionAndOrderingUtils.scala', 'PlanUtils.scala', 'TestDeleteFrom.java', 'TestRefreshTable.java']"
Arrow: Define explicit netty-buffer dependency (#3420),3,10,2021-11-01 13:09:01-07:00,"['build.gradle', 'build.gradle', 'versions.props']"
Build: Use macOS compatible sha512 (#3436),1,2,2021-11-01 14:16:15-07:00,['source-release.sh']
Build: Remove dev folder from CI workflows (#3437),4,12,2021-11-01 14:17:16-07:00,"['flink-ci.yml', 'hive-ci.yml', 'java-ci.yml', 'spark-ci.yml']"
Build: Run benchmarks via GH actions (#3304),2,109,2021-11-01 16:53:35-07:00,"['jmh-bechmarks.yml', 'benchmarks.md']"
"Python: Add tox commands for code format and type checking (#3423)

Closes #3282",2,97,2021-11-02 08:30:24-07:00,"['types.py', 'tox.ini']"
"Spark: Expose AncestorsOf Snapshot by procedure (#3444)

Adding AncestorsOf procedure to Spark 3.2 module.

Co-authored-by: wulingqi <wulingqi@baijiahulian.com>",3,269,2021-11-02 10:34:39-05:00,"['TestAncestorsOfProcedure.java', 'AncestorsOfProcedure.java', 'SparkProcedures.java']"
API: Add action APIs for rewriting deletes (#2841),4,270,2021-11-02 12:25:02-07:00,"['ConvertEqualityDeleteFiles.java', 'RewritePositionDeleteFiles.java', 'ConvertEqualityDeleteStrategy.java', 'RewritePositionDeleteStrategy.java']"
"Docs: Move query engines to top level, add logos (#3449)",7,70,2021-11-03 08:44:50-07:00,"['extra.css', 'flink-logo.png', 'hive-logo.png', 'prestodb-logo.png', 'trino-logo.png', 'nav-item.html', 'mkdocs.yml']"
"Build: Fix deploySite task (#3441)

* Fix deploySite task.

* Use set -e and update README.md.",3,49,2021-11-03 09:25:03-07:00,"['README.md', 'deploy.sh', 'tasks.gradle']"
Docs: Fix date function in spark procedures docs (#3458),1,8,2021-11-03 14:43:10-05:00,['spark-procedures.md']
Aliyun: Add OSSInputFile (#3404),7,292,2021-11-04 15:57:04+08:00,"['BaseOSSFile.java', 'OSSInputFile.java', 'OSSURI.java', 'TestOSSInputFile.java', 'TestOSSInputStream.java', 'TestOSSOutputStream.java', 'TestLocalAliyunOSS.java']"
Checkstyle: prevent using unshaded Guava classes in Arrow and AssertJ (#3463),8,24,2021-11-04 10:47:08-07:00,"['checkstyle.xml', 'VectorHolder.java', 'BaseProcedure.java', 'SparkMergeBuilder.java', 'BaseProcedure.java', 'SparkMergeBuilder.java', 'BaseProcedure.java', 'SparkMergeBuilder.java']"
AWS: fix the missing StorageDescriptor parameter after renameTo (#3468),2,47,2021-11-04 11:40:19-07:00,"['GlueCatalog.java', 'GlueCatalogTest.java']"
AWS: support setting location and description for Glue database (#3467),4,102,2021-11-04 11:40:36-07:00,"['GlueCatalogNamespaceTest.java', 'GlueCatalog.java', 'IcebergToGlueConverter.java', 'GlueToIcebergConverterTest.java']"
Spark: Validate table columns don't conflict with metadata columns (#3456),3,49,2021-11-05 08:50:21-07:00,"['SparkSchemaUtil.java', 'SparkBatchScan.java', 'TestSparkMetadataColumns.java']"
Core: add delete option for bin-packing (#3454),4,148,2021-11-05 09:19:46-07:00,"['BinPackStrategy.java', 'MockFileScanTask.java', 'TestBinPackStrategy.java', 'TestNewRewriteDataFilesAction.java']"
Spark: fix AddFilesProcedure throws NumberFormatException when no files are imported (#3455),6,171,2021-11-05 09:21:49-07:00,"['TestAddFilesProcedure.java', 'AddFilesProcedure.java', 'TestAddFilesProcedure.java', 'AddFilesProcedure.java', 'TestAddFilesProcedure.java', 'AddFilesProcedure.java']"
Checkstyle: remove use of Parquet Preconditions and Apache Commons IOUtils (#3472),12,41,2021-11-05 10:28:46-07:00,"['checkstyle.xml', 'AliyunOSSMockLocalController.java', 'AliyunOSSMockLocalStore.java', 'ArrowBatchReader.java', 'GenericArrowVectorAccessorFactory.java', 'DeleteFilter.java', 'BaseParquetWriter.java', 'ApplyNameMapping.java', 'ColumnarBatchReader.java', 'ColumnarBatchReader.java', 'ColumnarBatchReader.java', 'ColumnarBatchReader.java']"
API: Fix a ManageSnapshots javadoc typo  (#3489),1,2,2021-11-07 10:15:46-08:00,['ManageSnapshots.java']
Flink: Separate the 1.13 code from 1.12 (#3476),246,23407,2021-11-07 10:58:16-08:00,"['flink-ci.yml', 'build.gradle', 'build.gradle', 'CatalogLoader.java', 'FlinkCatalog.java', 'FlinkCatalogFactory.java', 'FlinkConfigOptions.java', 'FlinkDynamicTableFactory.java', 'FlinkFilters.java', 'FlinkFixupTypes.java', 'FlinkSchemaUtil.java', 'FlinkTypeToType.java', 'FlinkTypeVisitor.java', 'IcebergTableSink.java', 'IcebergTableSource.java', 'RowDataWrapper.java', 'TableLoader.java', 'TypeToFlinkType.java', 'Actions.java', 'RewriteDataFilesAction.java', 'AvroWithFlinkSchemaVisitor.java', 'FlinkAvroReader.java', 'FlinkAvroWriter.java', 'FlinkOrcReader.java', 'FlinkOrcReaders.java', 'FlinkOrcWriter.java', 'FlinkOrcWriters.java', 'FlinkParquetReaders.java', 'FlinkParquetWriters.java', 'FlinkSchemaVisitor.java', 'FlinkValueReaders.java', 'FlinkValueWriters.java', 'ParquetWithFlinkSchemaVisitor.java', 'RowDataProjection.java', 'RowDataUtil.java', 'BaseDeltaTaskWriter.java', 'DeltaManifests.java', 'DeltaManifestsSerializer.java', 'FlinkAppenderFactory.java', 'FlinkFileWriterFactory.java', 'FlinkManifestUtil.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'IcebergStreamWriter.java', 'ManifestOutputFileFactory.java', 'PartitionKeySelector.java', 'PartitionedDeltaWriter.java', 'RowDataTaskWriterFactory.java', 'TaskWriterFactory.java', 'UnpartitionedDeltaWriter.java', 'DataIterator.java', 'FileScanTaskReader.java', 'FlinkInputFormat.java', 'FlinkInputSplit.java', 'FlinkSource.java', 'FlinkSplitGenerator.java', 'RowDataFileScanTaskReader.java', 'RowDataRewriter.java', 'ScanContext.java', 'StreamingMonitorFunction.java', 'StreamingReaderOperator.java', 'FlinkCompatibilityUtil.java', 'org.apache.flink.table.factories.Factory', 'org.apache.flink.table.factories.TableFactory', 'FlinkCatalogTestBase.java', 'FlinkTestBase.java', 'MiniClusterResource.java', 'RowDataConverter.java', 'SimpleDataUtil.java', 'TestCatalogTableLoader.java', 'TestChangeLogTable.java', 'TestDataFileSerialization.java', 'TestFixtures.java', 'TestFlinkCatalogDatabase.java', 'TestFlinkCatalogFactory.java', 'TestFlinkCatalogTable.java', 'TestFlinkCatalogTablePartitions.java', 'TestFlinkFilters.java', 'TestFlinkHiveCatalog.java', 'TestFlinkSchemaUtil.java', 'TestFlinkTableSink.java', 'TestFlinkTableSource.java', 'TestHelpers.java', 'TestIcebergConnector.java', 'TestManifestFileSerialization.java', 'TestRowDataWrapper.java', 'TestTableLoader.java', 'TestRewriteDataFilesAction.java', 'RandomRowData.java', 'TestFlinkAvroReaderWriter.java', 'TestFlinkOrcReaderWriter.java', 'TestFlinkParquetReader.java', 'TestFlinkParquetWriter.java', 'TestRowDataProjection.java', 'TestRowProjection.java', 'TestDeltaTaskWriter.java', 'TestFlinkAppenderFactory.java', 'TestFlinkFileWriterFactory.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkV2.java', 'TestFlinkManifest.java', 'TestFlinkPartitioningWriters.java', 'TestFlinkPositionDeltaWriters.java', 'TestFlinkRollingFileWriters.java', 'TestFlinkWriterMetrics.java', 'TestIcebergFilesCommitter.java', 'TestIcebergStreamWriter.java', 'TestRowDataPartitionKey.java', 'TestTaskWriters.java', 'BoundedTableFactory.java', 'BoundedTestSource.java', 'ChangeLogTableTestBase.java', 'TestBoundedTableFactory.java', 'TestFlinkInputFormat.java', 'TestFlinkInputFormatReaderDeletes.java', 'TestFlinkMergingMetrics.java', 'TestFlinkReaderDeletesBase.java', 'TestFlinkScan.java', 'TestFlinkScanSql.java', 'TestFlinkSource.java', 'TestStreamScanSql.java', 'TestStreamingMonitorFunction.java', 'TestStreamingReaderOperator.java', 'org.apache.flink.table.factories.Factory', 'build.gradle', 'CatalogLoader.java', 'FlinkCatalog.java', 'FlinkCatalogFactory.java', 'FlinkConfigOptions.java', 'FlinkDynamicTableFactory.java', 'FlinkFilters.java', 'FlinkFixupTypes.java', 'FlinkSchemaUtil.java', 'FlinkTypeToType.java', 'FlinkTypeVisitor.java', 'IcebergTableSink.java', 'IcebergTableSource.java', 'RowDataWrapper.java', 'TableLoader.java', 'TypeToFlinkType.java', 'Actions.java', 'RewriteDataFilesAction.java', 'AvroWithFlinkSchemaVisitor.java', 'FlinkAvroReader.java', 'FlinkAvroWriter.java', 'FlinkOrcReader.java', 'FlinkOrcReaders.java', 'FlinkOrcWriter.java', 'FlinkOrcWriters.java', 'FlinkParquetReaders.java', 'FlinkParquetWriters.java', 'FlinkSchemaVisitor.java', 'FlinkValueReaders.java', 'FlinkValueWriters.java', 'ParquetWithFlinkSchemaVisitor.java', 'RowDataProjection.java', 'RowDataUtil.java', 'BaseDeltaTaskWriter.java', 'DeltaManifests.java', 'DeltaManifestsSerializer.java', 'FlinkAppenderFactory.java', 'FlinkFileWriterFactory.java', 'FlinkManifestUtil.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'IcebergStreamWriter.java', 'ManifestOutputFileFactory.java', 'PartitionKeySelector.java', 'PartitionedDeltaWriter.java', 'RowDataTaskWriterFactory.java', 'TaskWriterFactory.java', 'UnpartitionedDeltaWriter.java', 'DataIterator.java', 'FileScanTaskReader.java', 'FlinkInputFormat.java', 'FlinkInputSplit.java', 'FlinkSource.java', 'FlinkSplitGenerator.java', 'RowDataFileScanTaskReader.java', 'RowDataRewriter.java', 'ScanContext.java', 'StreamingMonitorFunction.java', 'StreamingReaderOperator.java', 'FlinkCompatibilityUtil.java', 'org.apache.flink.table.factories.Factory', 'org.apache.flink.table.factories.TableFactory', 'FlinkCatalogTestBase.java', 'FlinkTestBase.java', 'MiniClusterResource.java', 'RowDataConverter.java', 'SimpleDataUtil.java', 'TestCatalogTableLoader.java', 'TestChangeLogTable.java', 'TestDataFileSerialization.java', 'TestFixtures.java', 'TestFlinkCatalogDatabase.java', 'TestFlinkCatalogFactory.java', 'TestFlinkCatalogTable.java', 'TestFlinkCatalogTablePartitions.java', 'TestFlinkFilters.java', 'TestFlinkHiveCatalog.java', 'TestFlinkSchemaUtil.java', 'TestFlinkTableSink.java', 'TestFlinkTableSource.java', 'TestHelpers.java', 'TestIcebergConnector.java', 'TestManifestFileSerialization.java', 'TestRowDataWrapper.java', 'TestTableLoader.java', 'TestRewriteDataFilesAction.java', 'RandomRowData.java', 'TestFlinkAvroReaderWriter.java', 'TestFlinkOrcReaderWriter.java', 'TestFlinkParquetReader.java', 'TestFlinkParquetWriter.java', 'TestRowDataProjection.java', 'TestRowProjection.java', 'TestDeltaTaskWriter.java', 'TestFlinkAppenderFactory.java', 'TestFlinkFileWriterFactory.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkV2.java', 'TestFlinkManifest.java', 'TestFlinkPartitioningWriters.java', 'TestFlinkPositionDeltaWriters.java', 'TestFlinkRollingFileWriters.java', 'TestFlinkWriterMetrics.java', 'TestIcebergFilesCommitter.java', 'TestIcebergStreamWriter.java', 'TestRowDataPartitionKey.java', 'TestTaskWriters.java', 'BoundedTableFactory.java', 'BoundedTestSource.java', 'ChangeLogTableTestBase.java', 'TestBoundedTableFactory.java', 'TestFlinkInputFormat.java', 'TestFlinkInputFormatReaderDeletes.java', 'TestFlinkMergingMetrics.java', 'TestFlinkReaderDeletesBase.java', 'TestFlinkScan.java', 'TestFlinkScanSql.java', 'TestFlinkSource.java', 'TestStreamScanSql.java', 'TestStreamingMonitorFunction.java', 'TestStreamingReaderOperator.java', 'org.apache.flink.table.factories.Factory']"
ORC: Upgrade ORC to 1.7.1 (#3493),1,2,2021-11-07 14:13:06-08:00,['versions.props']
Build: Ignore .gitignore changes in expensive CI flows (#3452),4,8,2021-11-07 14:14:35-08:00,"['flink-ci.yml', 'hive-ci.yml', 'java-ci.yml', 'spark-ci.yml']"
Build: Add Python legacy CI to cancel duplicate action (#3442),1,1,2021-11-07 14:15:35-08:00,['cancel-duplicate-workflow-runs.yml']
"Arrow: Bump Arrow from 5.0.0 to 6.0.0 (#3446)

Release Notes: https://arrow.apache.org/release/6.0.0.html
Diff: https://github.com/apache/arrow/compare/apache-arrow-5.0.0...apache-arrow-6.0.0",2,6,2021-11-07 14:19:50-08:00,"['VectorizedArrowReader.java', 'versions.props']"
Build: Add Spark v3.1 JMH benchmarks to .gitignore (#3451),1,2,2021-11-07 14:20:41-08:00,['.gitignore']
Data: Enable TestPartitioningWriters for ORC (#3497),1,13,2021-11-08 07:59:38-08:00,['TestPartitioningWriters.java']
Spark: Support dynamic partition filtering in 3.2 (#3400),21,926,2021-11-08 10:06:47-08:00,"['TableScan.java', 'IndexByName.java', 'TypeUtil.java', 'AllDataFilesTable.java', 'AllEntriesTable.java', 'AllManifestsTable.java', 'BaseAllMetadataTableScan.java', 'BaseMetadataTableScan.java', 'BaseTableScan.java', 'DataFilesTable.java', 'DataTableScan.java', 'ManifestEntriesTable.java', 'StaticTableScan.java', 'Spark3Util.java', 'SparkConfParser.java', 'SparkFilters.java', 'SparkReadConf.java', 'SparkSchemaUtil.java', 'SparkBatchQueryScan.java', 'TestSparkFilters.java', 'TestRuntimeFiltering.java']"
AWS: cleanup all tests to obey Iceberg codestyle (#3473),23,482,2021-11-08 10:19:39-08:00,"['TestAssumeRoleAwsClientFactory.java', 'TestDynamoDbCatalog.java', 'TestDynamoLockManager.java', 'TestGlueCatalogCommitFailure.java', 'TestGlueCatalogLock.java', 'TestGlueCatalogNamespace.java', 'TestGlueCatalogTable.java', 'S3TestUtil.java', 'TestS3FileIOIntegration.java', 'TestS3MultipartUpload.java', 'TestAwsClientFactories.java', 'TestAwsProperties.java', 'GlueToIcebergConverterTest.java', 'TestGlueCatalog.java', 'TestGlueToIcebergConverter.java', 'TestIcebergToGlueConverter.java', 'TestInMemoryLockManager.java', 'TestLockManagers.java', 'TestS3FileIO.java', 'TestS3InputStream.java', 'TestS3OutputStream.java', 'TestS3RequestUtil.java', 'TestS3URI.java']"
Spark: Add overwrite-mode to SparkWriteOptions (#3491),2,4,2021-11-08 13:58:02-08:00,"['SparkWriteConf.java', 'SparkWriteOptions.java']"
Spark: Request distribution and ordering for writes (#3461),33,1730,2021-11-08 15:57:16-08:00,"['SortOrder.java', 'SortOrderUtil.java', 'IcebergSparkSessionExtensions.scala', 'ExtendedV2ExpressionUtils.scala', 'TruncateTransform.scala', 'ExtendedDistributionAndOrderingUtils.scala', 'ExtendedV2Writes.scala', 'TestRequiredDistributionAndOrdering.java', 'OrderField.java', 'Spark3Util.java', 'SparkConfParser.java', 'SparkDistributionAndOrderingUtil.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'Spark3BinPackStrategy.java', 'Spark3SortStrategy.java', 'SparkRewriteBuilder.java', 'SparkTable.java', 'SparkWrite.java', 'SparkWriteBuilder.java', 'ClusteredDistribution.java', 'Distribution.java', 'Distributions.java', 'OrderedDistribution.java', 'UnspecifiedDistribution.java', 'ClusterDistributionImpl.java', 'UnspecifiedDistributionImpl.java', 'NullOrdering.java', 'SortDirection.java', 'SortOrder.java', 'DistributionAndOrderingUtils.scala', 'TestPartitionValues.java', 'TestRequiredDistributionAndOrdering.java']"
Spark: Support vectorized reads with position deletes (#3287),28,983,2021-11-08 21:03:58-08:00,"['BaseBatchReader.java', 'VectorizedReaderBuilder.java', 'build.gradle', 'BitmapPositionDeleteIndex.java', 'Deletes.java', 'PositionDeleteIndex.java', 'TableScanUtil.java', 'DeleteFilter.java', 'DeleteReadTests.java', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'IcebergSourceBenchmark.java', 'IcebergSourceDeleteBenchmark.java', 'IcebergSourceParquetDeleteBenchmark.java', 'IcebergSourceParquetMultiDeleteFileBenchmark.java', 'IcebergSourceParquetWithUnrelatedDeleteBenchmark.java', 'ColumnVectorWithFilter.java', 'ColumnarBatchReader.java', 'IcebergArrowColumnVector.java', 'VectorizedSparkParquetReaders.java', 'BaseDataReader.java', 'BatchDataReader.java', 'SparkBatchScan.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkReaderDeletes.java', 'versions.props']"
"only run publish GH action for apache repo, not forked (#3500)

Co-authored-by: Kevin Liu <kevinliu@stripe.com>",1,1,2021-11-09 09:46:42+01:00,['publish-snapshot.yml']
Core: Rename bin packing min-deletes-per-file to delete-file-threshold (#3506),3,20,2021-11-09 09:27:32-08:00,"['BinPackStrategy.java', 'TestBinPackStrategy.java', 'TestNewRewriteDataFilesAction.java']"
Core: Add DELETE/UPDATE/MERGE distribution mode properties (#3511),2,27,2021-11-09 09:43:00-08:00,"['TableProperties.java', 'SparkWriteConf.java']"
Spark: Move more read configs to SparkReadConf (#3505),10,120,2021-11-09 10:05:31-08:00,"['Spark3Util.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkBatchQueryScan.java', 'SparkBatchScan.java', 'SparkFilesScan.java', 'SparkFilesScanBuilder.java', 'SparkMergeScan.java', 'SparkMicroBatchStream.java', 'SparkScanBuilder.java']"
Flink: Rename upsert table property (#3504),3,28,2021-11-10 16:05:07+08:00,"['TableProperties.java', 'FlinkSink.java', 'FlinkSink.java']"
"Bump Parquet from 1.12.0 to 1.12.2 (#3351)

https://github.com/apache/parquet-mr/compare/apache-parquet-1.12.0...apache-parquet-1.12.2",1,2,2021-11-10 11:49:59+01:00,['versions.props']
Python: Add Operations for expressions (#3399),2,138,2021-11-10 08:31:59-08:00,"['expressions.py', 'test_expressions.py']"
Arrow: Update netty-buffer version to 4.1.68.Final (#3512),1,2,2021-11-10 08:57:48-08:00,['versions.props']
NessieCatalog: Improve Commit Messages (#3388),3,22,2021-11-10 11:25:47-06:00,"['NessieCatalog.java', 'NessieTableOperations.java', 'TestNessieTable.java']"
Core: Only read stats for partitions metadata table if requested (#3527),2,18,2021-11-10 09:42:10-08:00,"['PartitionsTable.java', 'TestMetadataTableScans.java']"
Core: Bump RoaringBitmap version to 0.9.22 (#3513),1,2,2021-11-10 11:52:18-08:00,['versions.props']
Docs: Add 0.12.1 to releases (#3502),2,37,2021-11-10 15:12:13-08:00,"['releases.md', 'mkdocs.yml']"
Docs: Add javadoc for 0.12.1 (#3503),976,438771,2021-11-10 15:12:33-08:00,"['allclasses-index.html', 'allclasses.html', 'allpackages-index.html', 'constant-values.html', 'deprecated-list.html', 'help-doc.html', 'index-all.html', 'index.html', 'jquery.js', 'ui-bg_glass_55_fbf9ee_1x400.png', 'ui-bg_glass_65_dadada_1x400.png', 'ui-bg_glass_75_dadada_1x400.png', 'ui-bg_glass_75_e6e6e6_1x400.png', 'ui-bg_glass_95_fef1ec_1x400.png', 'ui-bg_highlight-soft_75_cccccc_1x100.png', 'ui-icons_222222_256x240.png', 'ui-icons_2e83ff_256x240.png', 'ui-icons_454545_256x240.png', 'ui-icons_888888_256x240.png', 'ui-icons_cd0a0a_256x240.png', 'jquery-3.5.1.js', 'jquery-ui.css', 'jquery-ui.js', 'jquery-ui.min.css', 'jquery-ui.min.js', 'jquery-ui.structure.css', 'jquery-ui.structure.min.css', 'member-search-index.js', 'member-search-index.zip', 'VectorizedSupport.Support.html', 'VectorizedSupport.html', 'package-summary.html', 'package-tree.html', 'Accessor.html', 'Accessors.html', 'AllDataFilesTable.AllDataFilesTableScan.html', 'AllDataFilesTable.html', 'AllEntriesTable.html', 'AllManifestsTable.AllManifestsTableScan.html', 'AllManifestsTable.html', 'AppendFiles.html', 'BaseCombinedScanTask.html', 'BaseMetastoreCatalog.BaseMetastoreCatalogTableBuilder.html', 'BaseMetastoreCatalog.html', 'BaseMetastoreTableOperations.CommitStatus.html', 'BaseMetastoreTableOperations.html', 'BaseOverwriteFiles.html', 'BaseReplacePartitions.html', 'BaseReplaceSortOrder.html', 'BaseRewriteManifests.html', 'BaseTable.html', 'CachingCatalog.html', 'CatalogProperties.html', 'CatalogUtil.html', 'ClientPool.Action.html', 'ClientPool.html', 'ClientPoolImpl.html', 'CombinedScanTask.html', 'ContentFile.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DataFilesTable.FilesTableScan.html', 'DataFilesTable.html', 'DataOperations.html', 'DataTableScan.html', 'DataTask.html', 'DeleteFile.html', 'DeleteFiles.html', 'DistributionMode.html', 'DoubleFieldMetrics.Builder.html', 'DoubleFieldMetrics.html', 'ExpireSnapshots.html', 'FieldMetrics.html', 'FileContent.html', 'FileFormat.html', 'FileMetadata.Builder.html', 'FileMetadata.html', 'FileScanTask.html', 'Files.html', 'FindFiles.Builder.html', 'FindFiles.html', 'FloatFieldMetrics.Builder.html', 'FloatFieldMetrics.html', 'GenericManifestFile.CopyBuilder.html', 'GenericManifestFile.html', 'GenericPartitionFieldSummary.html', 'GuavaClasses.html', 'HasTableOperations.html', 'HistoryEntry.html', 'HistoryTable.html', 'IsolationLevel.html', 'LocationProviders.html', 'ManageSnapshots.html', 'ManifestContent.html', 'ManifestEntriesTable.html', 'ManifestFile.PartitionFieldSummary.html', 'ManifestFile.html', 'ManifestFiles.html', 'ManifestReader.FileType.html', 'ManifestReader.html', 'ManifestWriter.html', 'ManifestsTable.html', 'MetadataColumns.html', 'MetadataTableType.html', 'MetadataTableUtils.html', 'Metrics.html', 'MetricsConfig.html', 'MetricsModes.Counts.html', 'MetricsModes.Full.html', 'MetricsModes.MetricsMode.html', 'MetricsModes.None.html', 'MetricsModes.Truncate.html', 'MetricsModes.html', 'MetricsUtil.html', 'MicroBatches.MicroBatch.html', 'MicroBatches.MicroBatchBuilder.html', 'MicroBatches.html', 'NullOrder.html', 'OverwriteFiles.html', 'PartitionField.html', 'PartitionKey.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'Partitioning.html', 'PartitionsTable.html', 'PendingUpdate.html', 'ReachableFileUtil.html', 'ReplacePartitions.html', 'ReplaceSortOrder.html', 'RewriteFiles.html', 'RewriteManifests.html', 'Rollback.html', 'RowDelta.html', 'ScanSummary.Builder.html', 'ScanSummary.PartitionMetrics.html', 'ScanSummary.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'SerializableTable.html', 'SetLocation.html', 'Snapshot.html', 'SnapshotManager.html', 'SnapshotParser.html', 'SnapshotSummary.Builder.html', 'SnapshotSummary.html', 'SnapshotUpdate.html', 'SnapshotsTable.html', 'SortDirection.html', 'SortField.html', 'SortOrder.Builder.html', 'SortOrder.html', 'SortOrderBuilder.html', 'SortOrderParser.html', 'StaticTableOperations.html', 'StructLike.html', 'SystemProperties.html', 'Table.html', 'TableMetadata.MetadataLogEntry.html', 'TableMetadata.SnapshotLogEntry.html', 'TableMetadata.html', 'TableMetadataParser.Codec.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableProperties.html', 'TableScan.html', 'Tables.html', 'Transaction.html', 'Transactions.html', 'UpdateLocation.html', 'UpdatePartitionSpec.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Action.html', 'Actions.html', 'ActionsProvider.html', 'BaseDeleteOrphanFilesActionResult.html', 'BaseDeleteReachableFilesActionResult.html', 'BaseExpireSnapshotsActionResult.html', 'BaseFileGroupRewriteResult.html', 'BaseMigrateTableActionResult.html', 'BaseRewriteDataFilesAction.html', 'BaseRewriteDataFilesFileGroupInfo.html', 'BaseRewriteDataFilesResult.html', 'BaseRewriteManifestsActionResult.html', 'BaseSnapshotTableActionResult.html', 'BinPackStrategy.html', 'CreateAction.html', 'DeleteOrphanFiles.Result.html', 'DeleteOrphanFiles.html', 'DeleteReachableFiles.Result.html', 'DeleteReachableFiles.html', 'ExpireSnapshots.Result.html', 'ExpireSnapshots.html', 'ExpireSnapshotsAction.html', 'ExpireSnapshotsActionResult.html', 'ManifestFileBean.html', 'MigrateTable.Result.html', 'MigrateTable.html', 'RemoveOrphanFilesAction.html', 'RewriteDataFiles.FileGroupInfo.html', 'RewriteDataFiles.FileGroupRewriteResult.html', 'RewriteDataFiles.Result.html', 'RewriteDataFiles.html', 'RewriteDataFilesAction.html', 'RewriteDataFilesActionResult.html', 'RewriteDataFilesCommitManager.CommitService.html', 'RewriteDataFilesCommitManager.html', 'RewriteFileGroup.html', 'RewriteManifests.Result.html', 'RewriteManifests.html', 'RewriteManifestsAction.html', 'RewriteManifestsActionResult.html', 'RewriteStrategy.html', 'SnapshotAction.html', 'SnapshotTable.Result.html', 'SnapshotTable.html', 'SnapshotUpdate.html', 'SnapshotUpdateAction.html', 'SortStrategy.html', 'Spark3MigrateAction.html', 'Spark3SnapshotAction.html', 'SparkActions.html', 'package-summary.html', 'package-tree.html', 'ArrowAllocation.html', 'ArrowSchemaUtil.html', 'package-summary.html', 'package-tree.html', 'ArrowReader.html', 'ArrowVectorAccessor.html', 'ColumnVector.html', 'ColumnarBatch.html', 'GenericArrowVectorAccessorFactory.ArrayFactory.html', 'GenericArrowVectorAccessorFactory.DecimalFactory.html', 'GenericArrowVectorAccessorFactory.StringFactory.html', 'GenericArrowVectorAccessorFactory.StructChildFactory.html', 'GenericArrowVectorAccessorFactory.html', 'NullabilityHolder.html', 'VectorHolder.ConstantVectorHolder.html', 'VectorHolder.PositionVectorHolder.html', 'VectorHolder.html', 'VectorizedArrowReader.ConstantVectorReader.html', 'VectorizedArrowReader.html', 'VectorizedReaderBuilder.html', 'VectorizedTableScanIterable.html', 'package-summary.html', 'package-tree.html', 'BaseVectorizedParquetValuesReader.html', 'VectorizedColumnIterator.BatchReader.html', 'VectorizedColumnIterator.BooleanBatchReader.html', 'VectorizedColumnIterator.DictionaryBatchReader.html', 'VectorizedColumnIterator.DoubleBatchReader.html', 'VectorizedColumnIterator.FixedLengthDecimalBatchReader.html', 'VectorizedColumnIterator.FixedSizeBinaryBatchReader.html', 'VectorizedColumnIterator.FixedWidthTypeBinaryBatchReader.html', 'VectorizedColumnIterator.FloatBatchReader.html', 'VectorizedColumnIterator.IntBackedDecimalBatchReader.html', 'VectorizedColumnIterator.IntegerBatchReader.html', 'VectorizedColumnIterator.LongBackedDecimalBatchReader.html', 'VectorizedColumnIterator.LongBatchReader.html', 'VectorizedColumnIterator.TimestampMillisBatchReader.html', 'VectorizedColumnIterator.VarWidthTypeBatchReader.html', 'VectorizedColumnIterator.html', 'VectorizedDictionaryEncodedParquetValuesReader.html', 'VectorizedPageIterator.html', 'VectorizedParquetDefinitionLevelReader.html', 'package-summary.html', 'package-tree.html', 'Avro.DataWriteBuilder.html', 'Avro.DeleteWriteBuilder.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroEncoderUtil.html', 'AvroIterable.html', 'AvroMetrics.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'AvroSchemaWithTypeVisitor.html', 'AvroWithPartnerByStructureVisitor.html', 'LogicalMap.html', 'MetricsAwareDatumWriter.html', 'ProjectionDatumReader.html', 'RemoveIds.html', 'SupportsRowPosition.html', 'UUIDConversion.html', 'ValueReader.html', 'ValueReaders.StructReader.html', 'ValueReaders.html', 'ValueWriter.html', 'ValueWriters.StructWriter.html', 'ValueWriters.html', 'package-summary.html', 'package-tree.html', 'AssumeRoleAwsClientFactory.html', 'AwsClientFactories.html', 'AwsClientFactory.html', 'AwsProperties.html', 'DynamoDbCatalog.html', 'package-summary.html', 'package-tree.html', 'GlueCatalog.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'S3FileIO.html', 'S3InputFile.html', 'S3OutputFile.html', 'S3RequestUtil.html', 'package-summary.html', 'package-tree.html', 'Catalog.TableBuilder.html', 'Catalog.html', 'Namespace.html', 'SupportsNamespaces.html', 'TableIdentifier.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-summary.html', 'package-tree.html', 'BaseWriterFactory.html', 'DeleteFilter.html', 'GenericAppenderFactory.html', 'GenericDeleteFilter.html', 'GenericRecord.html', 'IcebergGenerics.ScanBuilder.html', 'IcebergGenerics.html', 'IdentityPartitionConverters.html', 'InternalRecordWrapper.html', 'Record.html', 'TableMigrationUtil.html', 'DataReader.html', 'DataWriter.html', 'DecoderResolver.html', 'IcebergDecoder.html', 'IcebergEncoder.html', 'package-summary.html', 'package-tree.html', 'GenericOrcReader.html', 'GenericOrcReaders.html', 'GenericOrcWriter.html', 'GenericOrcWriters.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'BaseParquetReaders.html', 'BaseParquetWriter.html', 'GenericParquetReaders.html', 'GenericParquetWriter.html', 'package-summary.html', 'package-tree.html', 'Deletes.html', 'EqualityDeleteWriter.html', 'PositionDelete.html', 'PositionDeleteWriter.html', 'package-summary.html', 'package-tree.html', 'EncryptedFiles.html', 'EncryptedInputFile.html', 'EncryptedOutputFile.html', 'EncryptionKeyMetadata.html', 'EncryptionKeyMetadatas.html', 'EncryptionManager.html', 'PlaintextEncryptionManager.html', 'package-summary.html', 'package-tree.html', 'CreateSnapshotEvent.html', 'IncrementalScanEvent.html', 'Listener.html', 'Listeners.html', 'ScanEvent.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CherrypickAncestorCommitException.html', 'CommitFailedException.html', 'CommitStateUnknownException.html', 'DuplicateWAPCommitException.html', 'NamespaceNotEmptyException.html', 'NoSuchIcebergTableException.html', 'NoSuchNamespaceException.html', 'NoSuchTableException.html', 'NotFoundException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'Bound.html', 'BoundLiteralPredicate.html', 'BoundPredicate.html', 'BoundReference.html', 'BoundSetPredicate.html', 'BoundTerm.html', 'BoundTransform.html', 'BoundUnaryPredicate.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.BoundVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'InclusiveMetricsEvaluator.html', 'Literal.html', 'ManifestEvaluator.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'StrictMetricsEvaluator.html', 'Term.html', 'True.html', 'Unbound.html', 'UnboundPredicate.html', 'UnboundTerm.html', 'UnboundTransform.html', 'package-summary.html', 'package-tree.html', 'CatalogLoader.CustomCatalogLoader.html', 'CatalogLoader.HadoopCatalogLoader.html', 'CatalogLoader.HiveCatalogLoader.html', 'CatalogLoader.html', 'FlinkCatalog.html', 'FlinkCatalogFactory.html', 'FlinkConfigOptions.html', 'FlinkDynamicTableFactory.html', 'FlinkFilters.html', 'FlinkSchemaUtil.html', 'FlinkTypeVisitor.html', 'IcebergTableSink.html', 'IcebergTableSource.html', 'RowDataWrapper.html', 'TableLoader.CatalogTableLoader.html', 'TableLoader.HadoopTableLoader.html', 'TableLoader.html', 'Actions.html', 'RewriteDataFilesAction.html', 'package-summary.html', 'package-tree.html', 'AvroWithFlinkSchemaVisitor.html', 'FlinkAvroReader.html', 'FlinkAvroWriter.html', 'FlinkOrcReader.html', 'FlinkOrcWriter.html', 'FlinkParquetReaders.html', 'FlinkParquetWriters.html', 'FlinkValueReaders.html', 'FlinkValueWriters.html', 'ParquetWithFlinkSchemaVisitor.html', 'RowDataUtil.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'FlinkAppenderFactory.html', 'FlinkSink.Builder.html', 'FlinkSink.html', 'RowDataTaskWriterFactory.html', 'TaskWriterFactory.html', 'package-summary.html', 'package-tree.html', 'FlinkInputFormat.html', 'FlinkInputSplit.html', 'FlinkSource.Builder.html', 'FlinkSource.html', 'RowDataRewriter.RewriteMap.html', 'RowDataRewriter.html', 'StreamingMonitorFunction.html', 'StreamingReaderOperator.html', 'package-summary.html', 'package-tree.html', 'FlinkCompatibilityUtil.html', 'package-summary.html', 'package-tree.html', 'ConfigProperties.html', 'HadoopCatalog.html', 'HadoopConfigurable.html', 'HadoopFileIO.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTableOperations.html', 'HadoopTables.html', 'HiddenPathFilter.html', 'SerializableConfiguration.html', 'Util.html', 'package-summary.html', 'package-tree.html', 'CachedClientPool.html', 'HiveCatalog.html', 'HiveCatalogs.html', 'HiveClientPool.html', 'HiveSchemaUtil.html', 'HiveTableOperations.html', 'MetastoreUtil.html', 'RuntimeMetaException.html', 'package-summary.html', 'package-tree.html', 'BaseTaskWriter.BaseEqualityDeltaWriter.html', 'BaseTaskWriter.RollingEqDeleteWriter.html', 'BaseTaskWriter.RollingFileWriter.html', 'BaseTaskWriter.html', 'CloseableGroup.html', 'CloseableIterable.ConcatCloseableIterable.html', 'CloseableIterable.html', 'CloseableIterator.html', 'ClosingIterator.html', 'DataWriter.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'DeleteSchemaUtil.html', 'FileAppender.html', 'FileAppenderFactory.html', 'FileIO.html', 'FilterIterator.html', 'InputFile.html', 'LocationProvider.html', 'OutputFile.html', 'OutputFileFactory.Builder.html', 'OutputFileFactory.html', 'PartitionedFanoutWriter.html', 'PartitionedWriter.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'TaskWriter.html', 'UnpartitionedWriter.html', 'WriteResult.Builder.html', 'WriteResult.html', 'WriterFactory.html', 'package-summary.html', 'package-tree.html', 'JdbcCatalog.html', 'UncheckedInterruptedException.html', 'UncheckedSQLException.html', 'package-summary.html', 'package-tree.html', 'MappedField.html', 'MappedFields.html', 'MappingUtil.html', 'NameMapping.html', 'NameMappingParser.html', 'package-summary.html', 'package-tree.html', 'Catalogs.html', 'InputFormatConfig.ConfigBuilder.html', 'InputFormatConfig.InMemoryDataModel.html', 'InputFormatConfig.html', 'HiveIcebergFilterFactory.html', 'HiveIcebergInputFormat.html', 'HiveIcebergMetaHook.html', 'HiveIcebergOutputCommitter.html', 'HiveIcebergOutputFormat.html', 'HiveIcebergSerDe.html', 'HiveIcebergSplit.html', 'HiveIcebergStorageHandler.html', 'TezUtil.html', 'package-summary.html', 'package-tree.html', 'IcebergBinaryObjectInspector.html', 'IcebergDateObjectInspector.html', 'IcebergDecimalObjectInspector.html', 'IcebergFixedObjectInspector.html', 'IcebergObjectInspector.html', 'IcebergRecordObjectInspector.html', 'IcebergTimeObjectInspector.html', 'IcebergTimestampObjectInspector.html', 'IcebergTimestampWithZoneObjectInspector.html', 'IcebergUUIDObjectInspector.html', 'WriteObjectInspector.html', 'package-summary.html', 'package-tree.html', 'AbstractMapredIcebergRecordReader.html', 'Container.html', 'MapredIcebergInputFormat.CompatibilityTaskAttemptContextImpl.html', 'MapredIcebergInputFormat.html', 'package-summary.html', 'package-tree.html', 'IcebergInputFormat.html', 'IcebergSplit.html', 'IcebergSplitContainer.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'NessieCatalog.html', 'NessieTableOperations.html', 'NessieUtil.html', 'TableReference.html', 'package-summary.html', 'package-tree.html', 'ORC.DataWriteBuilder.html', 'ORC.ReadBuilder.html', 'ORC.WriteBuilder.html', 'ORC.html', 'ORCSchemaUtil.BinaryType.html', 'ORCSchemaUtil.LongType.html', 'ORCSchemaUtil.html', 'OrcBatchReader.html', 'OrcMetrics.html', 'OrcRowReader.html', 'OrcRowWriter.html', 'OrcSchemaVisitor.html', 'OrcSchemaWithTypeVisitor.html', 'OrcValueReader.html', 'OrcValueReaders.StructReader.html', 'OrcValueReaders.html', 'OrcValueWriter.html', 'VectorizedRowBatchIterator.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'BaseColumnIterator.html', 'BasePageIterator.IntIterator.html', 'BasePageIterator.html', 'ColumnIterator.html', 'ColumnWriter.html', 'Parquet.DataWriteBuilder.html', 'Parquet.DeleteWriteBuilder.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetAvroReader.html', 'ParquetAvroValueReaders.TimeMillisReader.html', 'ParquetAvroValueReaders.TimestampMillisReader.html', 'ParquetAvroValueReaders.html', 'ParquetAvroWriter.html', 'ParquetDictionaryRowGroupFilter.html', 'ParquetIterable.html', 'ParquetMetricsRowGroupFilter.html', 'ParquetReader.html', 'ParquetSchemaUtil.HasIds.html', 'ParquetSchemaUtil.html', 'ParquetTypeVisitor.html', 'ParquetUtil.html', 'ParquetValueReader.html', 'ParquetValueReaders.BinaryAsDecimalReader.html', 'ParquetValueReaders.ByteArrayReader.html', 'ParquetValueReaders.BytesReader.html', 'ParquetValueReaders.FloatAsDoubleReader.html', 'ParquetValueReaders.IntAsLongReader.html', 'ParquetValueReaders.IntegerAsDecimalReader.html', 'ParquetValueReaders.ListReader.html', 'ParquetValueReaders.LongAsDecimalReader.html', 'ParquetValueReaders.MapReader.html', 'ParquetValueReaders.PrimitiveReader.html', 'ParquetValueReaders.RepeatedKeyValueReader.html', 'ParquetValueReaders.RepeatedReader.html', 'ParquetValueReaders.ReusableEntry.html', 'ParquetValueReaders.StringReader.html', 'ParquetValueReaders.StructReader.html', 'ParquetValueReaders.UnboxedReader.html', 'ParquetValueReaders.html', 'ParquetValueWriter.html', 'ParquetValueWriters.PositionDeleteStructWriter.html', 'ParquetValueWriters.PrimitiveWriter.html', 'ParquetValueWriters.RepeatedKeyValueWriter.html', 'ParquetValueWriters.RepeatedWriter.html', 'ParquetValueWriters.StructWriter.html', 'ParquetValueWriters.html', 'ParquetWriteAdapter.html', 'RemoveIds.html', 'TripleWriter.html', 'TypeToMessageType.html', 'TypeWithSchemaVisitor.html', 'ValuesAsBytesReader.html', 'VectorizedParquetReader.html', 'VectorizedReader.html', 'package-summary.html', 'package-tree.html', 'IcebergPigInputFormat.IcebergRecordReader.html', 'IcebergPigInputFormat.html', 'IcebergStorage.html', 'PigParquetReader.html', 'SchemaUtil.html', 'package-summary.html', 'package-tree.html', 'SchemaWithPartnerVisitor.PartnerAccessors.html', 'SchemaWithPartnerVisitor.html', 'UnionByNameVisitor.html', 'package-summary.html', 'package-tree.html', 'FileRewriteCoordinator.html', 'FileScanTaskSetManager.html', 'IcebergSpark.html', 'JobGroupInfo.html', 'JobGroupUtils.html', 'PathIdentifier.html', 'PruneColumnsWithReordering.html', 'PruneColumnsWithoutReordering.html', 'RollbackStagedTable.html', 'Spark3Util.CatalogAndIdentifier.html', 'Spark3Util.DescribeSchemaVisitor.html', 'Spark3Util.html', 'Spark3VersionUtil.html', 'SparkCatalog.html', 'SparkDataFile.html', 'SparkExceptionUtil.html', 'SparkFilters.html', 'SparkReadOptions.html', 'SparkSchemaUtil.html', 'SparkSessionCatalog.html', 'SparkStructLike.html', 'SparkTableUtil.SparkPartition.html', 'SparkTableUtil.html', 'SparkUtil.html', 'SparkValueConverter.html', 'SparkWriteOptions.html', 'BaseDeleteOrphanFilesSparkAction.html', 'BaseDeleteReachableFilesSparkAction.html', 'BaseExpireSnapshotsSparkAction.html', 'BaseMigrateTableSparkAction.html', 'BaseRewriteDataFilesSpark3Action.html', 'BaseRewriteManifestsSparkAction.html', 'BaseSnapshotTableSparkAction.html', 'Spark3BinPackStrategy.html', 'SparkActions.html', 'package-summary.html', 'package-tree.html', 'AvroWithSparkSchemaVisitor.html', 'ParquetWithSparkSchemaVisitor.html', 'SparkAvroReader.html', 'SparkAvroWriter.html', 'SparkOrcReader.html', 'SparkOrcValueReaders.html', 'SparkOrcWriter.html', 'SparkParquetReaders.html', 'SparkParquetWriters.html', 'SparkValueReaders.html', 'SparkValueWriters.html', 'package-summary.html', 'package-tree.html', 'ArrowVectorAccessors.html', 'ColumnarBatchReader.html', 'IcebergArrowColumnVector.html', 'RowPositionColumnVector.html', 'VectorizedSparkOrcReaders.html', 'VectorizedSparkParquetReaders.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'ExpireSnapshotsProcedure.html', 'RemoveOrphanFilesProcedure.html', 'SparkProcedures.ProcedureBuilder.html', 'SparkProcedures.html', 'package-summary.html', 'package-tree.html', 'EqualityDeleteRowReader.html', 'IcebergSource.html', 'RowDataRewriter.html', 'SparkMicroBatchStream.html', 'SparkPartitionedFanoutWriter.html', 'SparkPartitionedWriter.html', 'SparkRewriteBuilder.html', 'SparkScanBuilder.html', 'SparkTable.html', 'StagedSparkTable.html', 'package-summary.html', 'package-tree.html', 'PartitionSpecVisitor.html', 'SortOrderVisitor.html', 'Transform.html', 'Transforms.html', 'UnknownTransform.html', 'package-summary.html', 'package-tree.html', 'CheckCompatibility.html', 'Comparators.html', 'Conversions.html', 'FixupTypes.html', 'IndexByName.html', 'IndexParents.html', 'JavaHash.html', 'JavaHashes.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-summary.html', 'package-tree.html', 'ArrayUtil.html', 'BinPacking.ListPacker.html', 'BinPacking.PackingIterable.html', 'BinPacking.html', 'BinaryUtil.html', 'ByteBuffers.html', 'CharSequenceSet.html', 'CharSequenceWrapper.html', 'DateTimeUtil.html', 'DecimalUtil.html', 'ExceptionUtil.Block.html', 'ExceptionUtil.CatchBlock.html', 'ExceptionUtil.FinallyBlock.html', 'ExceptionUtil.html', 'Exceptions.html', 'Filter.html', 'JsonUtil.html', 'ManifestFileUtil.html', 'NaNUtil.html', 'Pair.html', 'ParallelIterable.html', 'PartitionSet.html', 'PartitionUtil.html', 'PropertyUtil.html', 'SerializableMap.html', 'SerializableSupplier.html', 'SerializationUtil.html', 'SnapshotUtil.html', 'SortOrderUtil.html', 'SortedMerge.html', 'StructLikeMap.html', 'StructLikeSet.html', 'StructLikeWrapper.html', 'StructProjection.html', 'TableScanUtil.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'ThreadPools.html', 'UUIDUtil.html', 'UnicodeUtil.html', 'WapUtil.html', 'package-summary.html', 'package-tree.html', 'NoSuchProcedureException.html', 'package-summary.html', 'package-tree.html', 'IcebergSqlExtensionsBaseListener.html', 'IcebergSqlExtensionsBaseVisitor.html', 'IcebergSqlExtensionsLexer.html', 'IcebergSqlExtensionsListener.html', 'IcebergSqlExtensionsParser.AddPartitionFieldContext.html', 'IcebergSqlExtensionsParser.ApplyTransformContext.html', 'IcebergSqlExtensionsParser.BigDecimalLiteralContext.html', 'IcebergSqlExtensionsParser.BigIntLiteralContext.html', 'IcebergSqlExtensionsParser.BooleanLiteralContext.html', 'IcebergSqlExtensionsParser.BooleanValueContext.html', 'IcebergSqlExtensionsParser.CallArgumentContext.html', 'IcebergSqlExtensionsParser.CallContext.html', 'IcebergSqlExtensionsParser.ConstantContext.html', 'IcebergSqlExtensionsParser.DecimalLiteralContext.html', 'IcebergSqlExtensionsParser.DoubleLiteralContext.html', 'IcebergSqlExtensionsParser.DropIdentifierFieldsContext.html', 'IcebergSqlExtensionsParser.DropPartitionFieldContext.html', 'IcebergSqlExtensionsParser.ExponentLiteralContext.html', 'IcebergSqlExtensionsParser.ExpressionContext.html', 'IcebergSqlExtensionsParser.FieldListContext.html', 'IcebergSqlExtensionsParser.FloatLiteralContext.html', 'IcebergSqlExtensionsParser.IdentifierContext.html', 'IcebergSqlExtensionsParser.IdentityTransformContext.html', 'IcebergSqlExtensionsParser.IntegerLiteralContext.html', 'IcebergSqlExtensionsParser.MultipartIdentifierContext.html', 'IcebergSqlExtensionsParser.NamedArgumentContext.html', 'IcebergSqlExtensionsParser.NonReservedContext.html', 'IcebergSqlExtensionsParser.NumberContext.html', 'IcebergSqlExtensionsParser.NumericLiteralContext.html', 'IcebergSqlExtensionsParser.OrderContext.html', 'IcebergSqlExtensionsParser.OrderFieldContext.html', 'IcebergSqlExtensionsParser.PositionalArgumentContext.html', 'IcebergSqlExtensionsParser.QuotedIdentifierAlternativeContext.html', 'IcebergSqlExtensionsParser.QuotedIdentifierContext.html', 'IcebergSqlExtensionsParser.ReplacePartitionFieldContext.html', 'IcebergSqlExtensionsParser.SetIdentifierFieldsContext.html', 'IcebergSqlExtensionsParser.SetWriteDistributionAndOrderingContext.html', 'IcebergSqlExtensionsParser.SingleStatementContext.html', 'IcebergSqlExtensionsParser.SmallIntLiteralContext.html', 'IcebergSqlExtensionsParser.StatementContext.html', 'IcebergSqlExtensionsParser.StringLiteralContext.html', 'IcebergSqlExtensionsParser.StringMapContext.html', 'IcebergSqlExtensionsParser.TinyIntLiteralContext.html', 'IcebergSqlExtensionsParser.TransformArgumentContext.html', 'IcebergSqlExtensionsParser.TransformContext.html', 'IcebergSqlExtensionsParser.TypeConstructorContext.html', 'IcebergSqlExtensionsParser.UnquotedIdentifierContext.html', 'IcebergSqlExtensionsParser.WriteDistributionSpecContext.html', 'IcebergSqlExtensionsParser.WriteOrderingSpecContext.html', 'IcebergSqlExtensionsParser.WriteSpecContext.html', 'IcebergSqlExtensionsParser.html', 'IcebergSqlExtensionsVisitor.html', 'package-summary.html', 'package-tree.html', 'ExtendedSupportsDelete.html', 'Procedure.html', 'ProcedureCatalog.html', 'ProcedureParameter.html', 'SupportsMerge.html', 'package-summary.html', 'package-tree.html', 'ClusteredDistribution.html', 'Distribution.html', 'Distributions.html', 'OrderedDistribution.html', 'UnspecifiedDistribution.html', 'ClusterDistributionImpl.html', 'OrderedDistributionImpl.html', 'UnspecifiedDistributionImpl.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'NullOrdering.html', 'SortDirection.html', 'SortOrder.html', 'package-summary.html', 'package-tree.html', 'SupportsFileFilter.html', 'package-summary.html', 'package-tree.html', 'MergeBuilder.html', 'package-summary.html', 'package-tree.html', 'overview-summary.html', 'overview-tree.html', 'package-search-index.js', 'package-search-index.zip', 'glass.png', 'x.png', 'script.js', 'search.js', 'serialized-form.html', 'stylesheet.css', 'type-search-index.js', 'type-search-index.zip', 'index.html']"
Aliyun: Add OSSOutputFile (#3498),6,257,2021-11-12 09:35:08+08:00,"['AliyunProperties.java', 'BaseOSSFile.java', 'OSSOutputFile.java', 'TestOSSOutputFile.java', 'TestOSSOutputStream.java', 'TestLocalAliyunOSS.java']"
Add Iceberg indexing blog post. (#3544),1,4,2021-11-13 16:38:25-08:00,['blogs.md']
Flink: Add SupportsRowPosition to Avro reader to fix position deletes (#3540),3,93,2021-11-14 10:43:46-08:00,"['FileHelpers.java', 'FlinkAvroReader.java', 'FlinkAvroReader.java']"
Build: Upgrade Gradle to 7.3 (#3525),3,6,2021-11-14 11:17:18-08:00,"['README.md', 'gradle-wrapper.properties', 'gradlew']"
Build: Enable engine's checkstyle and error-prone check in Github CI (#3509),1,12,2021-11-14 13:10:04-08:00,['java-ci.yml']
"Flink: Fix and enable TestFlinkIcebergSink#testTwoSinksInDisjointedDAG (#3514)

The purpose of this test method is that we can construct two Iceberg sinks in the same job/DAG with different UIDs. The custom source BoundedTestSource is not needed for this purpose.",1,6,2021-11-14 13:14:08-08:00,['TestFlinkIcebergSink.java']
Spark: Use quoted names in required distribution and ordering (#3529),5,145,2021-11-15 13:34:52-08:00,"['TestRequiredDistributionAndOrdering.java', 'SortOrderToSpark.java', 'Spark3Util.java', 'SparkDistributionAndOrderingUtil.java', 'TestRequiredDistributionAndOrdering.java']"
"Hive: Fix create table when not all columns have comments (#3531)

Backport of HIVE-25377.",3,23,2021-11-15 13:36:59-08:00,"['HiveSchemaConverter.java', 'TestHiveSchemaUtil.java', 'TestHiveIcebergStorageHandlerNoScan.java']"
Build: Use wildcard version for Hive and Tez (#3510),2,25,2021-11-15 13:38:18-08:00,"['build.gradle', 'versions.props']"
Build: Enable checkstyle for all engine versions (#3550),1,2,2021-11-15 13:39:02-08:00,['java-ci.yml']
Arrow: Fix vectorized position reader (#3533),4,142,2021-11-15 15:24:34-08:00,"['NullabilityHolder.java', 'VectorizedArrowReader.java', 'VectorizedReaderBuilder.java', 'TestSparkMetadataColumns.java']"
Core: Optimize CharSeq equality check for path filtering (#3530),1,30,2021-11-16 12:01:24-08:00,['Deletes.java']
Spec: Document NameMapping (#3556),1,39,2021-11-17 14:23:36-06:00,['spec.md']
Core: BaseFile returns wrong field when accessing position via index (#3178),2,4,2021-11-17 16:43:40-06:00,"['BaseFile.java', 'TestManifestReader.java']"
Docs: Add CONTRIBUTING.md (#3414),1,48,2021-11-17 15:15:52-08:00,['CONTRIBUTING.md']
Core: Support rewriting data files at a sequence number (#3480),13,369,2021-11-17 15:26:36-08:00,"['RewriteFiles.java', 'RewriteDataFiles.java', 'BaseRewriteFiles.java', 'GenericManifestEntry.java', 'ManifestWriter.java', 'MergingSnapshotProducer.java', 'RewriteDataFilesCommitManager.java', 'TableTestBase.java', 'TestManifestWriter.java', 'TestRewriteFiles.java', 'TestRowDelta.java', 'BaseRewriteDataFilesSparkAction.java', 'TestNewRewriteDataFilesAction.java']"
Spark: Add SparkTestBaseWithCatalog to run tests in one catalog (#3549),4,249,2021-11-18 08:29:54-08:00,"['SparkCatalogConfig.java', 'SparkCatalogTestBase.java', 'SparkTestBaseWithCatalog.java', 'TestRuntimeFiltering.java']"
"Docs: PrestoDB and Trino links should open in a new tab (#3576)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",1,4,2021-11-18 08:32:36-08:00,['nav-item.html']
"Spark 3.1: Fix ClassCastException when using bucket UDF (#3568)

Port of #3368 to Spark 3.1.",3,138,2021-11-18 15:56:40-08:00,"['IcebergSpark.java', 'SparkValueConverter.java', 'TestIcebergSpark.java']"
"Spark 3.0: Fix ClassCastException when using bucket UDF (#3569)

Port of #3368 to Spark 3.0.",3,138,2021-11-18 15:57:20-08:00,"['IcebergSpark.java', 'SparkValueConverter.java', 'TestIcebergSpark.java']"
"Spark 2.4: Fix ClassCastException when using bucket UDF (#3570)

Port of #3368 to Spark 2.4.",3,138,2021-11-18 15:57:31-08:00,"['IcebergSpark.java', 'SparkValueConverter.java', 'TestIcebergSpark.java']"
Build: add missing hive version variable in hive3 build file (#3583),1,2,2021-11-19 16:18:45+01:00,['build.gradle']
Spark: Add test cases for SparkActions and remove deprecated Actions (#3469),29,1908,2021-11-19 12:19:54-06:00,"['maintenance.md', 'Actions.java', 'CreateAction.java', 'ExpireSnapshotsAction.java', 'ExpireSnapshotsActionResult.java', 'RemoveOrphanFilesAction.java', 'RewriteDataFilesAction.java', 'RewriteManifestsAction.java', 'RewriteManifestsActionResult.java', 'SnapshotAction.java', 'Spark3MigrateAction.java', 'Spark3SnapshotAction.java', 'SparkActions.java', 'BaseSparkAction.java', 'ManifestFileBean.java', 'ExpireSnapshotsProcedure.java', 'MigrateTableProcedure.java', 'RemoveOrphanFilesProcedure.java', 'RewriteManifestsProcedure.java', 'SnapshotTableProcedure.java', 'TestRewriteDataFilesAction.java', 'TestCreateActions.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction3.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'TestIcebergSourceTablesBase.java']"
Core: Refactor SnapshotUtil using an Iterable (#3259),18,236,2021-11-19 14:15:48-08:00,"['HistoryTable.java', 'IncrementalDataTableScan.java', 'MergingSnapshotProducer.java', 'SnapshotUtil.java', 'StreamingMonitorFunction.java', 'TestStreamingReaderOperator.java', 'StreamingMonitorFunction.java', 'TestStreamingReaderOperator.java', 'TestDataSourceOptions.java', 'AncestorsOfProcedure.java', 'SparkMicroBatchStream.java', 'TestDataSourceOptions.java', 'AncestorsOfProcedure.java', 'SparkMicroBatchStream.java', 'TestDataSourceOptions.java', 'AncestorsOfProcedure.java', 'SparkMicroBatchStream.java', 'TestDataSourceOptions.java']"
Core: Fix check for new deleted files in manifests (#3581),2,81,2021-11-19 14:18:38-08:00,"['ManifestFilterManager.java', 'TestDeleteFiles.java']"
Docs: Add a page for how to verify a release (#3479),2,152,2021-11-21 08:52:38-08:00,"['how-to-verify-a-release.md', 'mkdocs.yml']"
Aliyun: Add OSSFileIO (#3553),10,589,2021-11-22 15:53:43+08:00,"['AliyunClientFactories.java', 'AliyunClientFactory.java', 'AliyunProperties.java', 'BaseOSSFile.java', 'OSSFileIO.java', 'OSSInputFile.java', 'OSSOutputFile.java', 'TestAliyunClientFactories.java', 'TestOSSFileIO.java', 'TestOSSInputFile.java']"
Spark 3.0: Add test cases for SparkActions and remove deprecated Actions (#3594),28,1872,2021-11-22 10:47:59-08:00,"['Actions.java', 'CreateAction.java', 'ExpireSnapshotsAction.java', 'ExpireSnapshotsActionResult.java', 'RemoveOrphanFilesAction.java', 'RewriteDataFilesAction.java', 'RewriteManifestsAction.java', 'RewriteManifestsActionResult.java', 'SnapshotAction.java', 'Spark3MigrateAction.java', 'Spark3SnapshotAction.java', 'SparkActions.java', 'BaseSparkAction.java', 'ManifestFileBean.java', 'ExpireSnapshotsProcedure.java', 'MigrateTableProcedure.java', 'RemoveOrphanFilesProcedure.java', 'RewriteManifestsProcedure.java', 'SnapshotTableProcedure.java', 'TestRewriteDataFilesAction.java', 'TestCreateActions.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction3.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'TestIcebergSourceTablesBase.java']"
Spark 3.1: Add test cases for SparkActions and remove deprecated Actions (#3595),28,1872,2021-11-22 10:48:29-08:00,"['Actions.java', 'CreateAction.java', 'ExpireSnapshotsAction.java', 'ExpireSnapshotsActionResult.java', 'RemoveOrphanFilesAction.java', 'RewriteDataFilesAction.java', 'RewriteManifestsAction.java', 'RewriteManifestsActionResult.java', 'SnapshotAction.java', 'Spark3MigrateAction.java', 'Spark3SnapshotAction.java', 'SparkActions.java', 'BaseSparkAction.java', 'ManifestFileBean.java', 'ExpireSnapshotsProcedure.java', 'MigrateTableProcedure.java', 'RemoveOrphanFilesProcedure.java', 'RewriteManifestsProcedure.java', 'SnapshotTableProcedure.java', 'TestRewriteDataFilesAction.java', 'TestCreateActions.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction3.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'TestIcebergSourceTablesBase.java']"
Spark 2.4: Add test cases for SparkActions and remove deprecated Actions (#3587),19,1527,2021-11-22 10:49:26-08:00,"['Actions.java', 'CreateAction.java', 'ExpireSnapshotsAction.java', 'ExpireSnapshotsActionResult.java', 'RemoveOrphanFilesAction.java', 'RewriteDataFilesAction.java', 'RewriteManifestsAction.java', 'RewriteManifestsActionResult.java', 'SnapshotAction.java', 'SparkActions.java', 'BaseSparkAction.java', 'ManifestFileBean.java', 'TestRewriteDataFilesAction.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'TestIcebergSourceTablesBase.java']"
"Core: Add methods to parse TableMetadata from JSON strings (#3592)

* Core: Add methods to parse TableMetadata from JSON strings.

* Fix TestTableMetadata.

* Update BaseSnapshot for missing FileIO.

* Fix imports.",4,134,2021-11-22 13:19:24-08:00,"['BaseSnapshot.java', 'TableMetadata.java', 'TableMetadataParser.java', 'TestTableMetadata.java']"
"Core: Fix javadoc for delete-file-threshold, improve test (#3567)",2,89,2021-11-22 14:44:33-08:00,"['BinPackStrategy.java', 'TestRewriteDataFilesAction.java']"
"Spark: Catalog Alter Table should return the Altered Table(#3548)

Previously Alter Table returned null instead of the changed table as specified by the Spark API. Now we correctly return the newly altered table.",2,83,2021-11-22 20:00:47-06:00,"['SparkCatalog.java', 'TestSparkCatalogOperations.java']"
"Docs: Add Ververica blog post on Flink, CDC, MySQL (#3602)",1,4,2021-11-24 11:48:48-08:00,['blogs.md']
Core: Make Configurable.setConf call dynamic in CatalogUtil (#3590),4,154,2021-11-24 11:53:12-08:00,"['GlueCatalog.java', 'CatalogUtil.java', 'Configurable.java', 'JdbcCatalog.java']"
Core: Initial implementation of ResolvingFileIO (#3593),1,153,2021-11-24 11:54:03-08:00,['ResolvingFileIO.java']
Core: Fix typo form metadataTableSchena to metadataTableSchema (#3608),1,6,2021-11-30 13:42:08+01:00,['BaseMetadataTable.java']
Spark: Fix NOT IN predicates in SparkFilters (#3613),2,62,2021-11-30 21:29:12+02:00,"['SparkFilters.java', 'TestSparkFilters.java']"
Build: Append _2.12 (scala version) to Spark 3.1 and 3.2 module names (#3624),5,96,2021-11-30 13:48:15-08:00,"['spark-ci.yml', 'jmh.gradle', 'settings.gradle', 'build.gradle', 'build.gradle']"
Spark: Remove old connector APIs for row-level commands (#3635),7,317,2021-12-01 10:26:28+02:00,"['SparkMergeBuilder.java', 'SparkMergeScan.java', 'SparkTable.java', 'ExtendedSupportsDelete.java', 'SupportsMerge.java', 'SupportsFileFilter.java', 'MergeBuilder.java']"
"Core: Handle metrics-based deletes (#3600)

Co-authored-by: Ryan Blue <blue@apache.org>",6,369,2021-12-01 13:25:04+02:00,"['ExpressionVisitors.java', 'InclusiveMetricsEvaluator.java', 'StrictMetricsEvaluator.java', 'ManifestFilterManager.java', 'TestDeleteFiles.java', 'TestDeleteFrom.java']"
Spark: Add connector APIs for row-level commands (#3633),10,421,2021-12-01 20:28:58+02:00,"['DeltaBatchWrite.java', 'DeltaWrite.java', 'DeltaWriteBuilder.java', 'DeltaWriter.java', 'DeltaWriterFactory.java', 'ExtendedLogicalWriteInfo.java', 'RowLevelOperation.java', 'RowLevelOperationBuilder.java', 'RowLevelOperationInfo.java', 'SupportsDelta.java']"
Core: delete previous metadata locations in dropping table with purge enabled (#3622),2,170,2021-12-01 11:29:42-08:00,"['CatalogUtil.java', 'TestCatalogUtilDropTable.java']"
"Bump Nessie to 0.15.1 + related changes (#3257)

* Bump Nessie to 0.15.1 + related changes

* Use new NessieApiV1
* Update reference syntax to `table-identifier ( '@' reference-name )? ( '#' pointer )?` (for Nessie-Iceberg-GC)
* Slightly nicer commit message from `NessieTableOperations`
* Use new `TableIdGenerators` as the ""global state"" tracked in Nessie

* Update site/mkdocs.yml

Co-authored-by: Ajantha Bhat <ajanthabhat@gmail.com>

Co-authored-by: Ryan Murray <rymurr@gmail.com>
Co-authored-by: Ajantha Bhat <ajanthabhat@gmail.com>",14,1179,2021-12-02 15:03:48+01:00,"['build.gradle', 'BaseMetastoreTableOperations.java', 'TableMetadata.java', 'NessieCatalog.java', 'NessieTableOperations.java', 'NessieUtil.java', 'TableReference.java', 'UpdateableReference.java', 'BaseTestIceberg.java', 'TestBranchVisibility.java', 'TestNessieTable.java', 'TestTableReference.java', 'mkdocs.yml', 'versions.props']"
"Build: Set default Java version for jenv users (#3651)

Project requires Java 8 for full build.
Certain modules are not getting compiled when Gradle is run with JDK 11.

For example, in jmh.gradle there currently is:

    if (jdkVersion == '8' && sparkVersions.contains(""2.4"")) {
      jmhProjects.add(project("":iceberg-spark:iceberg-spark2""))
    }

Provide explicit default configuration for those using `jenv` to manage
multiple JDKs, to help contributors build the project.",2,2,2021-12-02 08:38:00-08:00,"['.java-version', '.rat-excludes']"
Build: Rename Spark 3.1 and 3.2 module names (#3655),4,54,2021-12-02 13:00:02-08:00,"['spark-ci.yml', 'settings.gradle', 'build.gradle', 'build.gradle']"
"Build: Add missing @Override annotations (#3654)

Just to reduce warnings output from the build.",23,37,2021-12-02 13:00:36-08:00,"['FileIO.java', 'TestIncrementalDataTableScan.java', 'TestSplitPlanning.java', 'TestAppenderFactory.java', 'TestBaseTaskWriter.java', 'TestFileWriterFactory.java', 'TestGenericSortedPosDeleteWriter.java', 'TestPartitioningWriters.java', 'TestPositionDeltaWriters.java', 'TestRollingFileWriters.java', 'TestTaskEqualityDeltaWriter.java', 'TestFlinkCatalogTable.java', 'TestFlinkCatalogTablePartitions.java', 'TestFlinkTableSink.java', 'TestRewriteDataFilesAction.java', 'TestDeltaTaskWriter.java', 'TestFlinkIcebergSinkV2.java', 'TestIcebergFilesCommitter.java', 'TestStreamScanSql.java', 'TestTables.java', 'TestNessieTable.java', 'WritersBenchmark.java', 'TestParquetVectorizedReads.java']"
Switch from new HashMap to Maps.newHashMap (#3648),36,199,2021-12-02 18:10:14-08:00,"['TestMetricsSerialization.java', 'ArrowReaderTest.java', 'TestGlueCatalog.java', 'DynConstructors.java', 'DecoderResolver.java', 'PartitionUtil.java', 'TestCatalogUtil.java', 'TestFilterFiles.java', 'TestJdbcCatalog.java', 'TestJdbcTableConcurrency.java', 'TestJdbcUtil.java', 'TestMergingMetrics.java', 'BoundedTableFactory.java', 'BoundedTableFactory.java', 'HiveTableOperations.java', 'HiveMetastoreTest.java', 'HiveTableTest.java', 'VectorizedSupport.java', 'Deserializer.java', 'TestHiveIcebergStorageHandlerLocalScan.java', 'TestHiveIcebergStorageHandlerNoScan.java', 'TestTables.java', 'ORC.java', 'OrcMetrics.java', 'ReadConf.java', 'IcebergSourceBenchmark.java', 'TestSparkBaseDataReader.java', 'IcebergSourceBenchmark.java', 'Spark3Util.java', 'TestSparkBaseDataReader.java', 'IcebergSourceBenchmark.java', 'Spark3Util.java', 'TestSparkBaseDataReader.java', 'IcebergSourceBenchmark.java', 'Spark3Util.java', 'TestSparkBaseDataReader.java']"
Core: ensure MetricsConfig is immutable (#3638),2,55,2021-12-02 18:15:15-08:00,"['MetricsConfig.java', 'MetricsModes.java']"
AWS: remove S3URI scheme restrictions (#3656),2,46,2021-12-03 10:22:11-08:00,"['S3URI.java', 'TestS3URI.java']"
Core: Change variable name to metadataFile in CatalogUtil's dropTableData (#3660),1,2,2021-12-03 10:26:33-08:00,['CatalogUtil.java']
"[Spark] Add missing Spark 3.1 to JMH configuration (#3623)

* [Spark] Add missing Spark 3.1 to JMH configuration

* Add scala version to Spark 3.1 JMH setup",1,4,2021-12-03 14:32:23-06:00,['jmh.gradle']
"Core: Throw CommitStateUnknownException in old RewriteDatafilesAction (#2932)

During the commit phase of the old RewriteDatafiles action there is a possibility that the commit fails and the state is unknown. In this case cleaning up newly created files is dangerous and must be avoided. This issue is fixed in the new API but that API is not yet available on all frameworks so the fix is backported here.",1,20,2021-12-04 10:43:33-06:00,['BaseRewriteDataFilesAction.java']
Spark: Support CALL procedure for rewrite_data_files (#3375),7,588,2021-12-04 11:09:03-06:00,"['spark-procedures.md', 'TestRewriteDataFilesProcedure.java', 'RewriteDataFilesProcedure.java', 'SparkProcedures.java', 'SetWriteDistributionAndOrdering.scala', 'SortOrderParserUtil.scala', 'SparkExpressionConverter.scala']"
"Core: Request Split_Offsets when Planning Scans (#3666)

* Core: Request Split_Offsets when Planning Scans

Previously we didn't explicitly request the split_offsets column from
manifest files when planning Scan Tasks. This meant that the datafiles
would not be split aware when they were divided. To fix this we request the
split_offset information when we read manifests. In addition tests
are added to make sure this isn't missed again in the future. Handling of
empty split_offsets is also fixed.",10,82,2021-12-05 01:44:28-06:00,"['BaseFileScanTask.java', 'DataTableScan.java', 'TestSplitPlanning.java', 'TestDataSourceOptions.java', 'TestRewriteDataFilesAction.java', 'TestDataSourceOptions.java', 'TestRewriteDataFilesAction.java', 'TestDataSourceOptions.java', 'TestRewriteDataFilesAction.java', 'TestDataSourceOptions.java']"
"Spark: Remove ImmutableMap from SparkPartition for Kryo (#3667)

Co-authored-by: Dubem Enyekwe <dubem@dubemenyekwe.com>",8,198,2021-12-05 12:21:08-08:00,"['SparkTableUtil.java', 'TestSparkTableUtil.java', 'SparkTableUtil.java', 'TestSparkTableUtil.java', 'SparkTableUtil.java', 'TestSparkTableUtil.java', 'SparkTableUtil.java', 'TestSparkTableUtil.java']"
Hive: HiveCatalog should remove HMS stats for certain engines based on config (#3652),4,59,2021-12-06 10:53:55+01:00,"['ConfigProperties.java', 'HiveTableOperations.java', 'TestHiveIcebergStorageHandlerWithEngine.java', 'TestTables.java']"
Hive: initialize serde parameters when committing table in HiveCatalog (#3653),1,1,2021-12-06 10:54:32+01:00,['HiveTableOperations.java']
Core: Add table metadata builder (#3664),9,1291,2021-12-06 11:10:51-08:00,"['PartitionSpec.java', 'SortOrder.java', 'BaseTransaction.java', 'MetadataUpdate.java', 'TableMetadata.java', 'TableMetadataParser.java', 'TestTableMetadata.java', 'TestTables.java', 'NessieTableOperations.java']"
Docs: Update contributing with some additional Java style guidelines (#3591),1,78,2021-12-06 13:56:19-08:00,['CONTRIBUTING.md']
"Spark 3.0: Make SparkCatalog#alterTable conform to TableCatalog interface (#3674)

Port of #3548 to 3.0.
Co-authored-by: Xinbin Huang <bin.huangxb@gmail.com>",2,83,2021-12-06 14:00:32-08:00,"['SparkCatalog.java', 'TestSparkCatalogOperations.java']"
"Spark 3.1: Make SparkCatalog#alterTable conform to TableCatalog interface (#3673)

Port of #3548 to 3.1.
Co-authored-by: Xinbin Huang <bin.huangxb@gmail.com>",2,83,2021-12-06 14:01:05-08:00,"['SparkCatalog.java', 'TestSparkCatalogOperations.java']"
"API: Fix typo in dropNamespace javadoc (#3643)

Minor typo in the javadoc summary of `NamespaceNotEmptyException` for `dropNamespace`.",1,2,2021-12-06 14:14:40-08:00,['SupportsNamespaces.java']
Spark 3.2: Move scala files to scala src folder (#3675),4,1,2021-12-06 14:18:31-08:00,"['TestRewriteDataFilesProcedure.java', 'SetWriteDistributionAndOrdering.scala', 'SortOrderParserUtil.scala', 'SparkExpressionConverter.scala']"
Parquet: Fix the limit handling in ParquetValueReaders#BytesReader (#3646),2,19,2021-12-06 16:23:25-08:00,"['TestGenericData.java', 'ParquetValueReaders.java']"
Aliyun: align property names with AWS module (#3659),4,45,2021-12-07 10:13:10+08:00,"['AliyunClientFactories.java', 'AliyunProperties.java', 'OSSFileIO.java', 'TestAliyunClientFactories.java']"
Spark: Remove iceberg-hive-metastore compile time dependency (#3627),4,18,2021-12-07 16:00:15+01:00,"['build.gradle', 'build.gradle', 'build.gradle', 'build.gradle']"
Flink: Support Flink 1.14.0 (#3434),129,24057,2021-12-07 08:20:16-08:00,"['flink-ci.yml', 'java-ci.yml', 'build.gradle', 'build.gradle', 'LICENSE', 'NOTICE', 'CatalogLoader.java', 'FlinkCatalog.java', 'FlinkCatalogFactory.java', 'FlinkConfigOptions.java', 'FlinkDynamicTableFactory.java', 'FlinkFilters.java', 'FlinkFixupTypes.java', 'FlinkSchemaUtil.java', 'FlinkTypeToType.java', 'FlinkTypeVisitor.java', 'IcebergTableSink.java', 'IcebergTableSource.java', 'RowDataWrapper.java', 'TableLoader.java', 'TypeToFlinkType.java', 'Actions.java', 'RewriteDataFilesAction.java', 'AvroWithFlinkSchemaVisitor.java', 'FlinkAvroReader.java', 'FlinkAvroWriter.java', 'FlinkOrcReader.java', 'FlinkOrcReaders.java', 'FlinkOrcWriter.java', 'FlinkOrcWriters.java', 'FlinkParquetReaders.java', 'FlinkParquetWriters.java', 'FlinkSchemaVisitor.java', 'FlinkValueReaders.java', 'FlinkValueWriters.java', 'ParquetWithFlinkSchemaVisitor.java', 'RowDataProjection.java', 'RowDataUtil.java', 'BaseDeltaTaskWriter.java', 'DeltaManifests.java', 'DeltaManifestsSerializer.java', 'FlinkAppenderFactory.java', 'FlinkFileWriterFactory.java', 'FlinkManifestUtil.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'IcebergStreamWriter.java', 'ManifestOutputFileFactory.java', 'PartitionKeySelector.java', 'PartitionedDeltaWriter.java', 'RowDataTaskWriterFactory.java', 'TaskWriterFactory.java', 'UnpartitionedDeltaWriter.java', 'DataIterator.java', 'FileScanTaskReader.java', 'FlinkInputFormat.java', 'FlinkInputSplit.java', 'FlinkSource.java', 'FlinkSplitGenerator.java', 'RowDataFileScanTaskReader.java', 'RowDataRewriter.java', 'ScanContext.java', 'StreamingMonitorFunction.java', 'StreamingReaderOperator.java', 'FlinkCompatibilityUtil.java', 'org.apache.flink.table.factories.Factory', 'org.apache.flink.table.factories.TableFactory', 'FlinkCatalogTestBase.java', 'FlinkTestBase.java', 'MiniClusterResource.java', 'RowDataConverter.java', 'SimpleDataUtil.java', 'TestCatalogTableLoader.java', 'TestChangeLogTable.java', 'TestDataFileSerialization.java', 'TestFixtures.java', 'TestFlinkCatalogDatabase.java', 'TestFlinkCatalogFactory.java', 'TestFlinkCatalogTable.java', 'TestFlinkCatalogTablePartitions.java', 'TestFlinkFilters.java', 'TestFlinkHiveCatalog.java', 'TestFlinkSchemaUtil.java', 'TestFlinkTableSink.java', 'TestFlinkTableSource.java', 'TestHelpers.java', 'TestIcebergConnector.java', 'TestManifestFileSerialization.java', 'TestRowDataWrapper.java', 'TestTableLoader.java', 'TestRewriteDataFilesAction.java', 'RandomRowData.java', 'TestFlinkAvroReaderWriter.java', 'TestFlinkOrcReaderWriter.java', 'TestFlinkParquetReader.java', 'TestFlinkParquetWriter.java', 'TestRowDataProjection.java', 'TestRowProjection.java', 'TestDeltaTaskWriter.java', 'TestFlinkAppenderFactory.java', 'TestFlinkFileWriterFactory.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkV2.java', 'TestFlinkManifest.java', 'TestFlinkPartitioningWriters.java', 'TestFlinkPositionDeltaWriters.java', 'TestFlinkRollingFileWriters.java', 'TestFlinkWriterMetrics.java', 'TestIcebergFilesCommitter.java', 'TestIcebergStreamWriter.java', 'TestRowDataPartitionKey.java', 'TestTaskWriters.java', 'BoundedTableFactory.java', 'BoundedTestSource.java', 'ChangeLogTableTestBase.java', 'TestBoundedTableFactory.java', 'TestFlinkInputFormat.java', 'TestFlinkInputFormatReaderDeletes.java', 'TestFlinkMergingMetrics.java', 'TestFlinkReaderDeletesBase.java', 'TestFlinkScan.java', 'TestFlinkScanSql.java', 'TestFlinkSource.java', 'TestStreamScanSql.java', 'TestStreamingMonitorFunction.java', 'TestStreamingReaderOperator.java', 'org.apache.flink.table.factories.Factory', 'gradle.properties', 'settings.gradle']"
Core: Support case sensitivity in MergingSnapshotProducer (#3640),9,222,2021-12-07 08:55:14-08:00,"['DeleteFiles.java', 'StrictMetricsEvaluator.java', 'BaseOverwriteFiles.java', 'BaseRowDelta.java', 'ManifestFilterManager.java', 'MergingSnapshotProducer.java', 'TestDeleteFiles.java', 'TestOverwriteWithValidation.java', 'TestRowDelta.java']"
NESSIE: Bump Nessie to 0.17.0 (#3690),1,2,2021-12-08 18:53:16+01:00,['versions.props']
Docs: Clarify alter column with complex types (#3683),2,70,2021-12-08 17:01:32-08:00,"['spark-ddl.md', 'TestAlterTable.java']"
Aliyun: Add OSS integration test rule (#3687),6,193,2021-12-09 09:36:55+08:00,"['TestUtility.java', 'AliyunOSSTestBase.java', 'OSSIntegrationTestRule.java', 'TestOSSFileIO.java', 'AliyunOSSMockLocalStore.java', 'TestLocalAliyunOSS.java']"
"Spark: Introduce Spark3 option to read stream from a timestamp (#3039)

Previously there was no way to specify when a stream should begin should start reading from. Now an option can be specified to start streaming at a specific timestamp.

Co-authored-by: Daksha Asrani <dakshasrani@gmail.com>
Co-authored-by: Zheng Zeng <zzeng@salesforce.com>
Co-authored-by: Rajarshi Sarkar <srajars@amazon.com>",5,283,2021-12-09 10:39:08-06:00,"['SnapshotUtil.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkMicroBatchStream.java', 'TestStructuredStreamingRead3.java']"
"Spark-3.1: support CALL procedure for rewrite_data_files (#3671)

Backport of #3375 - Support CALL procedure for rewrite_data_files",6,534,2021-12-09 14:07:12-06:00,"['TestRewriteDataFilesProcedure.java', 'RewriteDataFilesProcedure.java', 'SparkProcedures.java', 'SetWriteDistributionAndOrdering.scala', 'SortOrderParserUtil.scala', 'SparkExpressionConverter.scala']"
"Spark-3.0: support CALL procedure for rewrite_data_files (#3672)

Backport of #3375 - Support CALL procedure for rewrite_data_files",6,534,2021-12-09 14:25:22-06:00,"['TestRewriteDataFilesProcedure.java', 'RewriteDataFilesProcedure.java', 'SparkProcedures.java', 'SetWriteDistributionAndOrdering.scala', 'SortOrderParserUtil.scala', 'SparkExpressionConverter.scala']"
Core: ensure Kryo serializability of MetricsConfig (#3702),2,39,2021-12-10 09:33:26-08:00,"['MetricsConfig.java', 'TestSparkTableUtil.java']"
AWS: support S3FileIO alternative endpoint and credentials (#3658),5,193,2021-12-10 09:37:07-08:00,"['TestDefaultAwsClientFactory.java', 'AssumeRoleAwsClientFactory.java', 'AwsClientFactories.java', 'AwsProperties.java', 'TestAwsClientFactories.java']"
Flink: Add tests to check whether should remove meta columns in source reader (#3477),4,418,2021-12-10 10:12:33-08:00,"['TestHelpers.java', 'TestProjectMetaColumn.java', 'TestHelpers.java', 'TestProjectMetaColumn.java']"
"Docs: Add REPLACE with PARTITIONED BY Spark example (#3712)

Adds an example for specifying create clauses in a spark CTAS/RTAS DDL",1,7,2021-12-10 12:15:37-08:00,['spark-ddl.md']
Spark: Move WAP conf to SparkWriteConf (#3721),3,22,2021-12-12 10:24:36-08:00,"['SparkConfParser.java', 'SparkWriteConf.java', 'SparkWrite.java']"
Flink: Move iceberg-flink-runtime Flink version to match Spark (#3713),5,32,2021-12-12 10:40:32-08:00,"['flink-ci.yml', 'build.gradle', 'build.gradle', 'build.gradle', 'settings.gradle']"
Spark 3.1: Add test cases for alter column with complex types (#3692),1,48,2021-12-12 10:41:39-08:00,['TestAlterTable.java']
Spark 3.0: Add test cases for alter column with complex types (#3693),1,48,2021-12-12 10:41:59-08:00,['TestAlterTable.java']
Docs: Update total commit and status check timeout descriptions (#3694),1,4,2021-12-12 10:44:07-08:00,['configuration.md']
"Docs: Fix label for Flink streaming example (#3680)

Co-authored-by:  <wuwenchi@deepexi.com>",1,2,2021-12-12 10:50:01-08:00,['flink.md']
"Core: If status check fails, commit should be unknown (#3717)",2,18,2021-12-12 11:31:41-08:00,"['BaseMetastoreTableOperations.java', 'TestHiveCommits.java']"
Spark: Refactor building write distribution and ordering (#3720),6,505,2021-12-13 10:27:22+02:00,"['checkstyle.xml', 'OrderField.java', 'SortOrderToSpark.java', 'SparkDistributionAndOrderingUtil.java', 'SparkWriteConf.java', 'TestSparkDistributionAndOrderingUtil.java']"
Doc: add snapshot tagging and branching to spec (#3425),2,38,2021-12-13 17:14:42-08:00,"['configuration.md', 'spec.md']"
"Core: Add cache expiration option to CachingCatalog (#3543)

Adds a new catalog property, `cache.expiration-interval-ms`, which controls the duration for which entries in the catalog are cached,
with a default of 30 seconds.

When cache expiration is enabled, cached catalog entries will be expired after this interval unless they are accessed via the catalog's methods.

- If cache-enabled is set to false, this value is ignored.
- When cache.expiration-interval-ms is set to zero, caching will be turned off entirely (regardless of the `cache-enabled` config value).
- When cache.expiration-interval-ms is set to a positive value, cached entries will expire if not accessed within that period of time.
- When cache.expiration-interval-ms is set to -1, with `cache-enabled` = true, then catalog entries will be cached indefinitely.
- Metadata tables are always expired when the data table they reference is expired main table is expired.",7,538,2021-12-13 17:25:35-08:00,"['CachingCatalog.java', 'CatalogProperties.java', 'TestableCachingCatalog.java', 'TestCachingCatalog.java', 'FakeTicker.java', 'SparkCatalog.java', 'TestSparkCatalogCacheExpiration.java']"
"Spark: Support vectorized reads with equality deletes (#3557)

Previously Iceberg only supported vectorized reads with positional deletes. This patch provides support for vectorized reads with equality deletes as well as a mixture of positional and equality deletes.",7,338,2021-12-13 22:35:04-06:00,"['DeleteFilter.java', 'IcebergSourceDeleteBenchmark.java', 'IcebergSourceParquetEqDeleteBenchmark.java', 'IcebergSourceParquetPosDeleteBenchmark.java', 'ColumnarBatchReader.java', 'BatchDataReader.java', 'SparkBatchScan.java']"
"Add FileIO implementation for Google Cloud Storage (#3711)

* Add FileIO implementation for Google Cloud Storage

* Checkstyle

* Checkstyle

* Review comments

* Update version management",13,1047,2021-12-14 08:48:40-08:00,"['build.gradle', 'GCPProperties.java', 'BaseGCSFile.java', 'GCSFileIO.java', 'GCSInputFile.java', 'GCSInputStream.java', 'GCSOutputFile.java', 'GCSOutputStream.java', 'GCSFileIOTest.java', 'GCSInputStreamTest.java', 'GCSOutputStreamTest.java', 'settings.gradle', 'versions.props']"
Docs: update Nessie version to 0.17.0 (#3706),1,2,2021-12-14 18:03:09+01:00,['mkdocs.yml']
"Spark 3.1: Backport SparkReadConf.streamingSkipDeleteSnapshots and read from timestamp changes (#3727)

* Spark 3.1: Backport skip delete snapshots and read from timestamp in SparkMicroBatchStream

Backports #3039",5,248,2021-12-14 17:14:18-06:00,"['SparkReadConf.java', 'SparkReadOptions.java', 'SparkBatchScan.java', 'SparkMicroBatchStream.java', 'TestStructuredStreamingRead3.java']"
"Spark 3.0: Backport skip delete snapshots and read from timestamp in SparkMicroBatchStream (#3729)

Backports #3039 + #3505",5,248,2021-12-14 17:17:16-06:00,"['SparkReadConf.java', 'SparkReadOptions.java', 'SparkBatchScan.java', 'SparkMicroBatchStream.java', 'TestStructuredStreamingRead3.java']"
Spark: Backport SpakTestBaseWithCatalog to Spark 3.1 to simplify running tests with only one catalog (#3737),3,242,2021-12-14 15:32:30-08:00,"['SparkCatalogConfig.java', 'SparkCatalogTestBase.java', 'SparkTestBaseWithCatalog.java']"
"Doc: Update files metadata table (#3422)

Co-authored-by: Szehon Ho <szehon_ho@apple.com>",2,22,2021-12-14 15:32:59-08:00,"['extra.css', 'spark-queries.md']"
Spark: Backport SpakTestBaseWithCatalog to Spark 3.0 to simplify running tests with only one catalog (#3736),3,240,2021-12-14 15:37:28-08:00,"['SparkCatalogConfig.java', 'SparkCatalogTestBase.java', 'SparkTestBaseWithCatalog.java']"
"Core: Add total counters to CreateSnapshotEvent summary (#3696)

Co-authored-by: Aman Rawat <aman.rawat@salesforce.com>",3,129,2021-12-14 15:43:15-08:00,"['FastAppend.java', 'MergingSnapshotProducer.java', 'TestCreateSnapshotEvent.java']"
Aliyun: Add iceberg-aliyun to runtime Jars (#3725),8,40,2021-12-14 16:03:55-08:00,"['build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle']"
"build: apply publishing config after project evaluation (#3743)

Since we refactored the spark projects to have separate folders/projects
per spark version (in 811af43), gradle was evaluating the maven publish
plugin config (in `deploy.gradle`) before it applied the `shadowJar`
configs required for spark runtime projects, causing the generated POM
to include dependencies when it shouldn't (as we're publishing a shadow
jar).

This fixes it by delaying the maven publishing config to
`afterEvaluate`, when gradle has already applied the shadowJar plugin
for projects.

Fixes #3620",1,158,2021-12-14 16:12:28-08:00,['deploy.gradle']
Spark: Add back RewriteDataFilesAction in Spark 2.4 (#3685),6,2128,2021-12-14 23:18:03-08:00,"['Actions.java', 'RewriteDataFilesAction.java', 'SparkActions.java', 'BaseRewriteDataFilesSparkAction.java', 'TestRewriteDataFilesAction.java', 'TestRewriteDataFilesAction.java']"
"Spark 3.0: Add cache.expiration-interval-ms SparkCatalog (#3735)

Backports https://github.com/apache/iceberg/pull/3543 to Spark 3.0",2,162,2021-12-15 09:06:09-08:00,"['SparkCatalog.java', 'TestSparkCatalogCacheExpiration.java']"
"Spark 3.1: Add cache.expiration-interval-ms SparkCatalog (#3735)

Backports https://github.com/apache/iceberg/pull/3543 to Spark 3.1",2,162,2021-12-15 09:06:41-08:00,"['SparkCatalog.java', 'TestSparkCatalogCacheExpiration.java']"
Spark: Remove no longer needed SparkTestTable (#3754),1,60,2021-12-15 19:51:57+02:00,['SparkTestTable.java']
Core: Deprecate default distribution constant in TableProperties (#3755),6,24,2021-12-15 19:57:47+02:00,"['TableProperties.java', 'FlinkSink.java', 'FlinkSink.java', 'FlinkSink.java', 'Spark3Util.java', 'Spark3Util.java']"
Core: Use consistent constant definition in TableProperties (#3753),1,16,2021-12-15 20:36:37+02:00,['TableProperties.java']
Hive: ORC vectorization fails when split offsets are considered during split generation (#3748),6,129,2021-12-16 14:11:00+01:00,"['GenericAppenderHelper.java', 'build.gradle', 'HiveVectorizedReader.java', 'VectorizedReadUtils.java', 'TestHelper.java', 'TestHiveIcebergStorageHandlerWithEngine.java']"
Spark: Implement copy-on-write DELETE (#3661),40,2232,2021-12-16 16:25:45-08:00,"['checkstyle.xml', 'IsolationLevel.java', 'RowLevelOperationMode.java', 'IcebergSparkSessionExtensions.scala', 'RewriteDeleteFromTable.scala', 'RewriteRowLevelCommand.scala', 'ExtendedReplaceNullWithFalseInPredicate.scala', 'ExtendedSimplifyConditionalsInPredicate.scala', 'IcebergSparkSqlExtensionsParser.scala', 'RewrittenRowLevelCommand.scala', 'DeleteFromIcebergTable.scala', 'ReplaceData.scala', 'RowLevelCommand.scala', 'V2WriteCommandLike.scala', 'ExtendedLogicalWriteInfoImpl.scala', 'RowLevelOperationInfoImpl.scala', 'RowLevelOperationTable.scala', 'ExtendedDataSourceV2Implicits.scala', 'ExtendedDataSourceV2Strategy.scala', 'ExtendedV2Writes.scala', 'OptimizeMetadataOnlyDeleteFromTable.scala', 'ReplaceDataExec.scala', 'ReplaceRewrittenRowLevelCommand.scala', 'RowLevelCommandScanRelationPushDown.scala', 'RowLevelCommandDynamicPruning.scala', 'SparkExtensionsTestBase.java', 'TestCopyOnWriteDelete.java', 'TestDelete.java', 'SparkDistributionAndOrderingUtil.java', 'SparkWriteConf.java', 'SparkBatchScan.java', 'SparkCopyOnWriteOperation.java', 'SparkCopyOnWriteScan.java', 'SparkRowLevelOperationBuilder.java', 'SparkScanBuilder.java', 'SparkTable.java', 'SparkWrite.java', 'SparkWriteBuilder.java', 'SupportsRowLevelOperations.java', 'TestSparkDistributionAndOrderingUtil.java']"
Spark 3.2: Use snapshot schema for time travel queries (#3722),9,623,2021-12-17 09:52:02-08:00,"['SnapshotUtil.java', 'SparkCatalog.java', 'IcebergSource.java', 'SparkScanBuilder.java', 'SparkTable.java', 'TestIcebergSourceTablesBase.java', 'TestDeleteFrom.java', 'TestSelect.java', 'TestUnpartitionedWrites.java']"
"Parquet: Fix Iceberg's parquet reader returning nulls incorrectly for parquet files written by writers that don't use list and element as names. (#3723)

Previously parquet files made with older versions of Hive or the legacy parquet flag of Spark would be read incorrectly when imported to an Iceberg table due to assumptions made about the naming of substructures in the schema.",4,202,2021-12-17 16:00:44-06:00,"['ApplyNameMapping.java', 'TestParquetSchemaUtil.java', 'spark-procedures.md', 'TestCreateActions.java']"
Docs : Update table migration doc with notes consistent with other parts of the documentation. (#3766),1,39,2021-12-17 16:44:57-06:00,['spark-procedures.md']
Core: Remove duplicate call to properties.get in PropertyUtil (#3765),1,10,2021-12-17 16:07:25-08:00,['PropertyUtil.java']
"Build: Publish snapshot packages for all known versions (#3751)

Currently, only the default versions are being published to the
snapshots repo (e.g only spark 3.2). In order to allow testing of other
versions, we should publish packages all supported versions of spark,
flink and hive.",1,2,2021-12-17 16:11:16-08:00,['publish-snapshot.yml']
"Build: Add checkstyle rule for instantiating HashMap, HashSet, ArrayList (#3689)",59,317,2021-12-17 16:31:46-08:00,"['checkstyle.xml', 'ArrowReaderTest.java', 'BaseFileScanTask.java', 'HadoopCatalog.java', 'Tasks.java', 'TestMetrics.java', 'TestRemoveSnapshots.java', 'TestSequenceNumberForV2Table.java', 'TestHadoopTables.java', 'TestJdbcCatalog.java', 'TestMetricsRowGroupFilterTypes.java', 'HiveSchemaConverter.java', 'HiveSchemaUtil.java', 'TestHiveSchemaUtil.java', 'OrcSplit.java', 'Deserializer.java', 'HiveIcebergSerDe.java', 'TestIcebergInputFormats.java', 'HiveIcebergTestUtils.java', 'TestHiveIcebergOutputCommitter.java', 'TestHiveIcebergStorageHandlerLocalScan.java', 'TestHiveIcebergStorageHandlerNoScan.java', 'TestHiveIcebergStorageHandlerWithEngine.java', 'TestHiveIcebergStorageHandlerWithMultipleCatalogs.java', 'TestHiveShell.java', 'NessieUtil.java', 'BaseTestIceberg.java', 'TestNessieTable.java', 'ParquetUtil.java', 'TestParquet.java', 'ConcurrencyTest.java', 'TestExpireSnapshotsAction.java', 'TestSparkParquetReadMetadataColumns.java', 'TestPartitionPruning.java', 'TestPartitionValues.java', 'TestDelete.java', 'TestMerge.java', 'TestUpdate.java', 'TestCreateActions.java', 'TestExpireSnapshotsAction.java', 'TestSparkParquetReadMetadataColumns.java', 'TestPartitionPruning.java', 'TestPartitionValues.java', 'TestDelete.java', 'TestMerge.java', 'TestUpdate.java', 'TestCreateActions.java', 'TestExpireSnapshotsAction.java', 'TestSparkParquetReadMetadataColumns.java', 'TestPartitionPruning.java', 'TestPartitionValues.java', 'TestDelete.java', 'TestMerge.java', 'TestUpdate.java', 'TestCreateActions.java', 'TestExpireSnapshotsAction.java', 'TestSparkParquetReadMetadataColumns.java', 'TestPartitionPruning.java', 'TestPartitionValues.java']"
Spark 3.0: Use snapshot schema for time travel queries (#3769),8,607,2021-12-17 16:32:04-08:00,"['SparkCatalog.java', 'IcebergSource.java', 'SparkScanBuilder.java', 'SparkTable.java', 'TestIcebergSourceTablesBase.java', 'TestDeleteFrom.java', 'TestSelect.java', 'TestUnpartitionedWrites.java']"
Spark 3.1: Use snapshot schema for time travel queries (#3768),8,615,2021-12-17 16:32:13-08:00,"['SparkCatalog.java', 'IcebergSource.java', 'SparkScanBuilder.java', 'SparkTable.java', 'TestIcebergSourceTablesBase.java', 'TestDeleteFrom.java', 'TestSelect.java', 'TestUnpartitionedWrites.java']"
"Spark: Add spark's legacy mode write tests to spark3.0 and 3.1 versions. (#3767)

* Add spark's legacy mode write tests to spark3.0 and 3.1 versions backport of tests from #3723",2,264,2021-12-17 18:48:55-06:00,"['TestCreateActions.java', 'TestCreateActions.java']"
Build: Upgrade Gradle to 7.3.2 (#3771),2,4,2021-12-19 10:40:26-08:00,"['gradle-wrapper.properties', 'gradlew']"
Docs: Add Dremio link in the nav bar (#3758),3,7,2021-12-19 15:55:34-08:00,"['dremio-logo.png', 'nav-item.html', 'mkdocs.yml']"
Core: Fix file cleaning in transactions with unknown commit state (#3733),5,147,2021-12-19 15:58:28-08:00,"['BaseTransaction.java', 'TableTestBase.java', 'TestReplaceTransaction.java', 'TestTables.java', 'TestTransaction.java']"
Spark: Implement copy-on-write UPDATE (#3764),17,685,2021-12-20 16:43:32-08:00,"['IcebergSparkSessionExtensions.scala', 'AlignRowLevelCommandAssignments.scala', 'AssignmentAlignmentSupport.scala', 'RewriteDeleteFromTable.scala', 'RewriteRowLevelCommand.scala', 'RewriteUpdateTable.scala', 'AssignmentUtils.scala', 'ExtendedReplaceNullWithFalseInPredicate.scala', 'ExtendedSimplifyConditionalsInPredicate.scala', 'IcebergSparkSqlExtensionsParser.scala', 'RewrittenRowLevelCommand.scala', 'UpdateIcebergTable.scala', 'RowLevelCommandDynamicPruning.scala', 'TestCopyOnWriteUpdate.java', 'TestUpdate.java', 'SparkWriteConf.java', 'SparkWriteBuilder.java']"
Core: Add in a NOT_STARTS_WITH operator (#2062),31,819,2021-12-20 16:44:30-08:00,"['BoundLiteralPredicate.java', 'Evaluator.java', 'Expression.java', 'ExpressionVisitors.java', 'Expressions.java', 'InclusiveMetricsEvaluator.java', 'ManifestEvaluator.java', 'ResidualEvaluator.java', 'StrictMetricsEvaluator.java', 'UnboundPredicate.java', 'Truncate.java', 'TestEvaluator.java', 'TestExpressionBinding.java', 'TestExpressionHelpers.java', 'TestExpressionSerialization.java', 'TestInclusiveManifestEvaluator.java', 'TestInclusiveMetricsEvaluator.java', 'TestPredicateBinding.java', 'TestNotStartsWith.java', 'TestResiduals.java', 'TestStartsWith.java', 'TestTruncate.java', 'TestTruncatesResiduals.java', 'TestMetricsRowGroupFilter.java', 'ExpressionToSearchArgument.java', 'ParquetDictionaryRowGroupFilter.java', 'ParquetMetricsRowGroupFilter.java', 'TestDictionaryRowGroupFilter.java', 'api.md', 'Spark3Util.java', 'TestFilteredScan.java']"
"Core: Replace SnapshotUtil firstSnapshotAfterTimestamp (#3775)

Co-authored-by: Russell_Spitzer <rspitzer@apple.com>",5,565,2021-12-20 16:45:36-08:00,"['SnapshotUtil.java', 'SparkMicroBatchStream.java', 'SparkMicroBatchStream.java', 'SparkMicroBatchStream.java', 'TestStructuredStreamingRead3.java']"
Spark 3.0: Support NOT_STARTS_WITH (#3781),2,55,2021-12-21 08:32:07-08:00,"['Spark3Util.java', 'TestFilteredScan.java']"
Spark 3.1: Add NOT_STARTS_WITH (#3782),2,55,2021-12-21 08:32:52-08:00,"['Spark3Util.java', 'TestFilteredScan.java']"
ORC: Upgrade to 1.7.2 (#3779),1,2,2021-12-21 08:41:17-08:00,['versions.props']
Spark: Fix NPE in add_files with null partition values (#3778),2,72,2021-12-21 08:50:53-08:00,"['TestAddFilesProcedure.java', 'Spark3Util.java']"
Parquet: Simplify changes from #3723 (#3773),1,70,2021-12-21 09:36:35-08:00,['ApplyNameMapping.java']
Spark 3.0: Fix NPE in add_files with null partition values (#3786),2,72,2021-12-21 12:26:19-08:00,"['TestAddFilesProcedure.java', 'Spark3Util.java']"
Spark 3.1: Fix NPE in add_files with null partition values (#3785),2,72,2021-12-21 12:26:46-08:00,"['TestAddFilesProcedure.java', 'Spark3Util.java']"
Docs: Add cache.expiration-interval-ms for Spark catalogs (#3787),1,1,2021-12-21 15:54:34-08:00,['spark-configuration.md']
Spark: Fix UnresolvedException for some filters in rewrite_data_files procedure (#3757),3,188,2021-12-22 13:45:00-08:00,"['TestRewriteDataFilesProcedure.java', 'RewriteDataFilesProcedure.java', 'SparkExpressionConverter.scala']"
"Docs: Added config naming (#3800)

Closes #3678",1,7,2021-12-23 11:58:15-08:00,['CONTRIBUTING.md']
"Flink: Fix integer overflow in Avro time writer, #3738 (#3740)

Co-authored-by: chenzihao5 <chenzihao5@xiaomi.com>",4,64,2021-12-23 12:38:43-08:00,"['FlinkValueWriters.java', 'FlinkValueWriters.java', 'FlinkValueWriters.java', 'TestFlinkAvroReaderWriter.java']"
Parquet: Fix miss override in ApplyNameMapping (#3807),1,2,2021-12-27 11:39:42-08:00,['ApplyNameMapping.java']
set the worker pool size to be at least 2 threads (#3811),1,2,2021-12-28 15:23:20-08:00,['ThreadPools.java']
Build: Remove extra dependencies on assertj (#3802),1,2,2021-12-29 12:09:56-08:00,['build.gradle']
Core: Fix metadata table scans when current snapshot is null (#3812),3,22,2021-12-29 12:13:39-08:00,"['HistoryTable.java', 'SnapshotsTable.java', 'StaticTableScan.java']"
"Core: Fix deadlock in CachingCatalog (#3801)

Uses caffeine's `RemovalListener` to expire metadata tables, avoiding modifying cache entries during `compute` HashMap functions (which cause deadlocks).

Also changes caffeine's executor to make `RemovalListener` run sync
For more details, check #3791

Fixes #3791

Co-authored-by: Kyle Bendickson <kjbendickson@gmail.com>",2,71,2021-12-29 12:19:35-08:00,"['CachingCatalog.java', 'TestCachingCatalog.java']"
"API: Fix startsWith NullPointerException (#3645)

Co-authored-by: bghuang <bghuang@tencent.com>",2,5,2021-12-29 12:43:03-08:00,"['Evaluator.java', 'TestEvaluator.java']"
Hive: Add config to disable FileIO conf serialization (#3752),4,75,2021-12-29 13:45:11-08:00,"['InputFormatConfig.java', 'HiveIcebergStorageHandler.java', 'IcebergInputFormat.java', 'TestHiveShell.java']"
Docs: Update compatibility table (#3761),2,63,2021-12-29 14:07:52-08:00,"['README.md', 'flink.md']"
Core: Add LockManager to HadoopTableOperations (#3663),13,152,2021-12-30 13:55:33-08:00,"['LockManager.java', 'GlueTestBase.java', 'DynamoLockManager.java', 'GlueCatalog.java', 'GlueTableOperations.java', 'TestGlueCatalog.java', 'HadoopCatalog.java', 'HadoopTableOperations.java', 'HadoopTables.java', 'LockManagers.java', 'TestHadoopCommits.java', 'TestInMemoryLockManager.java', 'TestLockManagers.java']"
Build: Fix the -g option in source-release.sh (#3824),1,4,2021-12-30 14:26:36-08:00,['source-release.sh']
Spark 3.1: Fix UnresolvedException for some filters in rewrite_data_files (#3795),3,187,2021-12-30 14:46:18-08:00,"['TestRewriteDataFilesProcedure.java', 'RewriteDataFilesProcedure.java', 'SparkExpressionConverter.scala']"
Spark-3.0: Fix UnresolvedException for some filters in rewrite_data_files (#3794),3,187,2021-12-30 14:46:54-08:00,"['TestRewriteDataFilesProcedure.java', 'RewriteDataFilesProcedure.java', 'SparkExpressionConverter.scala']"
Docs: Add format-version table property (#3809),1,8,2022-01-03 09:59:04-08:00,['configuration.md']
Spark: Document stream reads with SparkMicroBatchStream (#3749),2,18,2022-01-03 11:18:28-08:00,"['spark-structured-streaming.md', 'SparkMicroBatchStream.java']"
Docs: Add stream-from-timestamp to Spark read options (#3732),1,1,2022-01-04 08:24:57-08:00,['spark-configuration.md']
Docs: Update Spark for incremental scans (#3796),1,21,2022-01-04 09:53:39-08:00,['spark-queries.md']
"Spark 3.0: Enable test that delete at a snapshot fails (#3840)

Co-authored-by: zhangchen <zhangchen351@jd.com>",2,5,2022-01-04 12:10:22-08:00,"['SparkTable.java', 'TestDeleteFrom.java']"
"Core: Fix lost sequence number when rewriting with manifest merge (#3842)

Co-authored-by: Jiebao Xiao <xiaojiebao@xiaomi.com>",2,58,2022-01-04 12:17:02-08:00,"['ManifestWriter.java', 'TestRowDelta.java']"
Core: Allow adding a dropped partition column name (#3632),2,45,2022-01-04 15:46:45-08:00,"['BaseUpdatePartitionSpec.java', 'TestUpdatePartitionSpec.java']"
Docs: Fix broken link of Dremio with Iceberg (#3856),1,2,2022-01-07 17:03:36+08:00,['mkdocs.yml']
Spec: Initial OpenAPI template for a REST catalog (#3770),1,930,2022-01-07 13:57:04-08:00,['rest-catalog-open-api.yaml']
"Core: Fix partitions metadata table with a column named partition (#3845)

* Partition Metadata table breaks with a partition column named 'partitition'

* address comments

* fix style

* add checkConflicts

* remove TestTables.clearTables in the end of test

* address comments

* checkConflict => checkConflicts",4,96,2022-01-07 14:12:49-08:00,"['PartitionSpec.java', 'BaseMetadataTable.java', 'TestMetadataTableScans.java', 'TestMetadataTablesWithPartitionEvolution.java']"
Build: Upgrade gradle to 7.3.3 (#3793),2,4,2022-01-07 14:26:37-08:00,"['gradle-wrapper.properties', 'gradlew']"
Flink: Add FLIP-27 Iceberg source split (#3501),9,461,2022-01-09 10:15:08-08:00,"['FlinkInputFormat.java', 'FlinkSplitPlanner.java', 'ScanContext.java', 'StreamingMonitorFunction.java', 'IcebergSourceSplit.java', 'IcebergSourceSplitSerializer.java', 'SplitHelpers.java', 'TestStreamingReaderOperator.java', 'TestIcebergSourceSplitSerializer.java']"
Flink 1.13: Fix SerializableTable with Kryo (#3857),3,137,2022-01-09 14:23:58-08:00,"['SerializableTable.java', 'TestHelpers.java', 'TestTableSerialization.java']"
Build: Update NOTICE to include copyright to 2022 (#3855),11,22,2022-01-09 14:35:43-08:00,"['NOTICE', 'NOTICE', 'NOTICE', 'NOTICE', 'NOTICE', 'NOTICE', 'NOTICE', 'NOTICE', 'NOTICE', 'NOTICE', 'NOTICE']"
Core: Replace set with bitmap for faster delete filtering (#3535),7,71,2022-01-09 14:48:39-08:00,"['BitmapPositionDeleteIndex.java', 'Deletes.java', 'PositionDeleteIndex.java', 'TestPositionFilter.java', 'DeleteFilter.java', 'ColumnarBatchReader.java', 'TestSparkParquetReadMetadataColumns.java']"
Spark: Fix table UUID exceptions with CachingCatalog (#3837),8,101,2022-01-09 14:49:39-08:00,"['Catalog.java', 'CachingCatalog.java', 'SparkCatalog.java', 'TestSparkCatalogOperations.java', 'SparkCatalog.java', 'TestSparkCatalogOperations.java', 'SparkCatalog.java', 'TestSparkCatalogOperations.java']"
Docs: Update copyright year in site mkdocs file to 2022 (#3873),1,2,2022-01-10 13:30:18-08:00,['mkdocs.yml']
"Revert ""Flink: Add FLIP-27 Iceberg source split (#3501)"" (#3871)

This reverts commit d2c26a02190a16539c8c0621c4d8aac2e9e3ec6c.",9,461,2022-01-10 13:30:44-08:00,"['FlinkInputFormat.java', 'FlinkSplitGenerator.java', 'ScanContext.java', 'StreamingMonitorFunction.java', 'IcebergSourceSplit.java', 'IcebergSourceSplitSerializer.java', 'SplitHelpers.java', 'TestStreamingReaderOperator.java', 'TestIcebergSourceSplitSerializer.java']"
Flink 1.14: Add FLIP-27 Iceberg source split (#3870),9,461,2022-01-10 13:31:38-08:00,"['FlinkInputFormat.java', 'FlinkSplitPlanner.java', 'ScanContext.java', 'StreamingMonitorFunction.java', 'IcebergSourceSplit.java', 'IcebergSourceSplitSerializer.java', 'SplitHelpers.java', 'TestStreamingReaderOperator.java', 'TestIcebergSourceSplitSerializer.java']"
Build: Only use scalastyle plugin with scala modules (#3869),4,7,2022-01-10 13:34:45-08:00,"['baseline.gradle', 'build.gradle', 'build.gradle', 'build.gradle']"
"Build: Suppress warning about Flink nanosecond access (#3868)

Co-authored-by: zhangchaoming <zhangchaoming@360.com>",1,1,2022-01-10 15:16:38-08:00,['FlinkOrcWriters.java']
"Allow using a custom NessieClientBuilder implementation (#3877)

Nessie defaults to use the HttpClientBuilder, but certain use cases
require a custom client builder implementation. This change allows
this by having a new configuration option.",5,152,2022-01-11 13:55:31+01:00,"['build.gradle', 'NessieCatalog.java', 'NessieUtil.java', 'BaseTestIceberg.java', 'TestCustomNessieClient.java']"
"Spark 3.0: Add Spark UI metrics for merge into DynamicFileFilterExec (#3863)

Co-authored-by: zhangchen351 <zhangchen351@jd.com>",5,103,2022-01-11 09:49:34-08:00,"['DynamicFileFilterExec.scala', 'TestMerge.java', 'SparkMergeScan.java', 'SupportsFileFilter.java', 'SparkTestBase.java']"
"Spark 3.1: Fix binary literals in pushdown filters (#3728)

Co-authored-by: zhangxiaotian13 <zhangxiaotian13@jd.com>",4,37,2022-01-12 08:55:44-08:00,"['Literals.java', 'Spark3Util.java', 'SparkTestBase.java', 'TestSelect.java']"
"Spark 3.1: Add Spark UI metrics for merge into DynamicFileFilterExec (#3882)

Co-authored-by: zhangchen351 <zhangchen351@jd.com>",5,103,2022-01-12 08:58:03-08:00,"['DynamicFileFilterExec.scala', 'TestMerge.java', 'SparkMergeScan.java', 'SupportsFileFilter.java', 'SparkTestBase.java']"
Spark 3.2: Push down partition filter when importing file tables (#3745),4,159,2022-01-12 15:38:54-08:00,"['TestAddFilesProcedure.java', 'Spark3Util.java', 'SparkUtil.java', 'AddFilesProcedure.java']"
Spark: Reduce requests from SparkSessionCatalog.invalidateTable (#3861),3,27,2022-01-12 17:11:44-08:00,"['SparkSessionCatalog.java', 'SparkSessionCatalog.java', 'SparkSessionCatalog.java']"
Test: Make sure to delete temp folders (#3790),25,148,2022-01-13 07:00:12+01:00,"['FlinkTestBase.java', 'TestFlinkReaderDeletesBase.java', 'FlinkTestBase.java', 'TestFlinkReaderDeletesBase.java', 'FlinkTestBase.java', 'TestCatalogTableLoader.java', 'TestFlinkReaderDeletesBase.java', 'HiveMetastoreTest.java', 'TestHiveCatalog.java', 'TestHiveMetastore.java', 'TestHiveIcebergStorageHandlerLocalScan.java', 'TestHiveIcebergStorageHandlerNoScan.java', 'TestHiveIcebergStorageHandlerTimezone.java', 'TestHiveIcebergStorageHandlerWithEngine.java', 'TestHiveIcebergStorageHandlerWithMultipleCatalogs.java', 'TestHiveShell.java', 'SparkTestBase.java', 'TestSparkReaderDeletes.java', 'SparkTestBase.java', 'TestSparkReaderDeletes.java', 'SparkTestBase.java', 'TestSparkReaderDeletes.java', 'SparkTestBase.java', 'SparkTestBaseWithCatalog.java', 'TestSparkReaderDeletes.java']"
Bump Nessie from 0.17.0 to 0.18.0 (#3890),2,4,2022-01-13 13:28:08+01:00,"['mkdocs.yml', 'versions.props']"
"API: Register existing tables in Iceberg HiveCatalog (#3851)

Co-authored-by: Anton Okolnychyi <aokolnychyi@apple.com>",4,83,2022-01-13 11:46:10-06:00,"['Catalog.java', 'HiveCatalog.java', 'HiveTableOperations.java', 'HiveTableTest.java']"
"Parquet: Lazily initialize the underlying writer in ParquetWriter (#3780)

Co-authored-by: Tim Steinbach <tim.steinbach@shopify.com>",6,145,2022-01-13 12:17:55-08:00,"['BaseTaskWriter.java', 'RollingFileWriter.java', 'TestDeltaTaskWriter.java', 'TestDeltaTaskWriter.java', 'TestDeltaTaskWriter.java', 'ParquetWriter.java']"
"Spark : Support parallelism in RemoveOrphanFiles (#3872)


Co-authored-by: Steve Zhang <hongyue_zhang@apple.com>",15,656,2022-01-14 12:21:33-06:00,"['DeleteOrphanFiles.java', 'BaseDeleteOrphanFilesSparkAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesProcedure.java', 'BaseDeleteOrphanFilesSparkAction.java', 'RemoveOrphanFilesProcedure.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesProcedure.java', 'BaseDeleteOrphanFilesSparkAction.java', 'RemoveOrphanFilesProcedure.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesProcedure.java', 'BaseDeleteOrphanFilesSparkAction.java', 'RemoveOrphanFilesProcedure.java', 'TestRemoveOrphanFilesAction.java']"
Spark 3.2: Implement copy-on-write MERGE (#3804),19,1204,2022-01-14 11:21:13-08:00,"['IcebergSparkSessionExtensions.scala', 'AlignRowLevelCommandAssignments.scala', 'CheckMergeIntoTableConditions.scala', 'MergeIntoIcebergTableResolutionCheck.scala', 'ResolveMergeIntoTableReferences.scala', 'RewriteMergeIntoTable.scala', 'ExtendedReplaceNullWithFalseInPredicate.scala', 'ExtendedSimplifyConditionalsInPredicate.scala', 'IcebergSparkSqlExtensionsParser.scala', 'MergeIntoIcebergTable.scala', 'MergeRows.scala', 'UnresolvedMergeIntoIcebergTable.scala', 'ExtendedDataSourceV2Strategy.scala', 'MergeRowsExec.scala', 'RowLevelCommandDynamicPruning.scala', 'TestCopyOnWriteMerge.java', 'TestMerge.java', 'SparkWriteConf.java', 'SparkWriteBuilder.java']"
"Core: Split FileScanTasks on Offsets (#460) (#3292)

Previously FileScanTasks would only be split if the exceed the target split size of requested. This prevented the combination of tasks which were smaller than the split size, but could be combined to make a request closer to the requested split size. To fix this we split all files on their offsets when we are splitting, and then recombine them during the creation of scan tasks to try to hit the desired split sizes.",7,542,2022-01-14 23:42:26-06:00,"['BaseCombinedScanTask.java', 'BaseFileScanTask.java', 'BinPackStrategy.java', 'TestOffsetsBasedSplitScanTaskIterator.java', 'TestRewriteDataFilesAction.java', 'TestRewriteDataFilesAction.java', 'TestRewriteDataFilesAction.java']"
Spark 3.2: Implement merge-on-read DELETE (#3763),29,1890,2022-01-17 23:19:44-08:00,"['PartitionSpec.java', 'TypeUtil.java', 'StructProjection.java', 'TableProperties.java', 'ProjectingInternalRow.scala', 'RewriteDeleteFromTable.scala', 'RewriteRowLevelCommand.scala', 'RewrittenRowLevelCommand.scala', 'WriteDelta.scala', 'RowDeltaUtils.scala', 'WriteDeltaProjections.scala', 'ExtendedDataSourceV2Strategy.scala', 'ExtendedV2Writes.scala', 'WriteDeltaExec.scala', 'SparkRowLevelOperationsTestBase.java', 'TestDelete.java', 'TestMergeOnReadDelete.java', 'TestUpdate.java', 'Spark3Util.java', 'SparkDistributionAndOrderingUtil.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'SparkBatchQueryScan.java', 'SparkPositionDeltaOperation.java', 'SparkPositionDeltaWrite.java', 'SparkPositionDeltaWriteBuilder.java', 'SparkRowLevelOperationBuilder.java', 'SparkScanBuilder.java', 'TestDataSourceOptions.java']"
Docs: Link expire_snapshots to table expiration properties (#3878),1,2,2022-01-18 08:24:10-08:00,['spark-procedures.md']
"Docs: Add LOCALLY ORDERED BY and DISTRIBUTED BY clauses (#3820)

Co-authored-by: zhangxiaotian13 <zhangxiaotian13@jd.com>",1,29,2022-01-18 08:55:59-08:00,['spark-ddl.md']
Spark 3.2: Add tests for multiple NOT MATCHED clauses (#3917),1,51,2022-01-18 09:31:59-08:00,['TestMerge.java']
"Spark 3.2: Add tests for resolving star actions in MERGE by name (#3918)

Co-authored-by: Kyle Bendickson <kjbendickson@gmail.com>",1,53,2022-01-18 12:17:52-08:00,['TestMerge.java']
"Build: Fix source-release script in actions, add git remote validation (#3915)",1,7,2022-01-18 16:02:41-08:00,['source-release.sh']
"Python: Expand primitive types to individual classes (#3839)

Co-authored-by: Sam Redai <sam@tabular.io>",2,239,2022-01-18 16:03:34-08:00,"['types.py', 'test_types.py']"
Flink: Fix classloader in Avro ManifestReader (#3906),1,1,2022-01-18 16:07:21-08:00,['ManifestReader.java']
"[Spark][Core]: Support RewriteDataFiles when Files are Completely Eliminated by Deletes (#3724)

Previously, RewriteDataFiles would fail if the outcome of a rewrite was the complete removal of all DataFiles, this is actually now a possibility given Merge on Read so it is now allowed.

Co-authored-by: Jiebao Xiao <xiaojiebao@xiaomi.com>",4,61,2022-01-19 10:34:43-06:00,"['BaseRewriteFiles.java', 'TestRewriteFiles.java', 'FileRewriteCoordinator.java', 'TestRewriteDataFilesAction.java']"
Flink: Fix flaky tests that depend on row order (#3931),3,27,2022-01-19 11:05:21-08:00,"['TestIcebergConnector.java', 'TestIcebergConnector.java', 'TestIcebergConnector.java']"
Flink 1.14: Add Kryo tests for SerializableTable (#3925),2,131,2022-01-19 13:53:17-08:00,"['TestHelpers.java', 'TestTableSerialization.java']"
Python: Fix quote handling in expression parser (#3875),2,15,2022-01-19 15:21:44-08:00,"['expression_parser.py', 'test_str_to_expr.py']"
"Python: Fix incorrect single-value encoding for boolean (#3924) (#3927)

Signed-off-by: cccs-eric <eric.ladouceur@cyber.gc.ca>",2,12,2022-01-19 15:22:39-08:00,"['conversions.py', 'test_conversions.py']"
Docs: Add compression codec options (#3892),1,4,2022-01-19 15:23:59-08:00,['configuration.md']
"Spark: Add helper to register truncate UDF (#3708)

Co-authored-by: zhangxiaotian13 <zhangxiaotian13@jd.com>",3,157,2022-01-19 16:42:26-08:00,"['IcebergSpark.java', 'TestIcebergSpark.java', 'TestPartitionedWritesAsSelect.java']"
Flink 1.12: Fix SerializableTable with Kryo (#3926),2,131,2022-01-20 09:52:10+08:00,"['TestHelpers.java', 'TestTableSerialization.java']"
Flink 1.14: Add tests to check whether should remove meta columns in source reader (#3893),2,209,2022-01-20 10:34:43+08:00,"['TestHelpers.java', 'TestProjectMetaColumn.java']"
"[Spark] Backport rewrite data files are eliminated by deletes to Spark v3.0 and Spark v3.1 (#3935)

Backport of #3724 to Spark 3.0 and 3.1

Co-authored-by: Jiebao Xiao <xiaojiebao@xiaomi.com>",4,104,2022-01-19 23:47:02-06:00,"['FileRewriteCoordinator.java', 'TestRewriteDataFilesAction.java', 'FileRewriteCoordinator.java', 'TestRewriteDataFilesAction.java']"
Hive: Do not skip IO config serialization for metadata queries (#3911),2,11,2022-01-20 11:22:50+01:00,"['HiveIcebergStorageHandler.java', 'IcebergInputFormat.java']"
"JMH: Parameterize spark project version for JHM Benchmarks (#3946)

Given that we have multiple Spark project versions in the codebase and
that users might want to run a particular Benchmark from a specific
Spark version, we should make the Spark project version a parameter of
the JMH Benchmark Action.",1,7,2022-01-21 11:09:39-06:00,['jmh-bechmarks.yml']
Spark 3.2: Revise distribution and ordering in copy-on-write DELETE (#3930),3,252,2022-01-21 11:38:29-08:00,"['SparkDistributionAndOrderingUtil.java', 'SparkWriteConf.java', 'TestSparkDistributionAndOrderingUtil.java']"
"Spark: Backport Streaming Test Refactors (#3948)

Back-porting test refactor from #3775",2,734,2022-01-21 14:00:19-06:00,"['TestStructuredStreamingRead3.java', 'TestStructuredStreamingRead3.java']"
Spark 3.2: Revise distribution and ordering in copy-on-write UPDATE (#3949),5,545,2022-01-21 15:46:24-08:00,"['TestUpdate.java', 'SparkDistributionAndOrderingUtil.java', 'SparkWriteConf.java', 'SparkCopyOnWriteOperation.java', 'TestSparkDistributionAndOrderingUtil.java']"
Fix SparkCatalog time travel check. (#3942),3,6,2022-01-21 16:28:28-08:00,"['SparkCatalog.java', 'SparkCatalog.java', 'SparkCatalog.java']"
Core: Deprecate the MERGE cardinality check property (#3953),1,8,2022-01-21 17:05:48-08:00,['TableProperties.java']
Core: Fix an error message in BinPackStrategy (#3919),1,2,2022-01-23 16:31:57-08:00,['BinPackStrategy.java']
"Python: Add FileIO, InputFile, and OutputFile abstract base classes (#3691)",2,416,2022-01-23 16:37:31-08:00,"['base.py', 'test_base.py']"
Core: Added no-arg constructor in ResolvingFileIO (#3923),1,15,2022-01-23 16:39:55-08:00,['ResolvingFileIO.java']
"Data: Read metrics in parallel during TableMigration (#3876)

Adds a parameter for reading the metrics of files in parallel, rather than one at a time in TableMigrationUtils.

Co-authored-by: King <wangdongyang@deepexi.com>",1,182,2022-01-24 07:40:52-06:00,['TableMigrationUtil.java']
"Python: Fix type for partition_type struct fields (#3939) (#3940)

Signed-off-by: cccs-eric <eric.ladouceur@cyber.gc.ca>",1,2,2022-01-24 08:27:23-08:00,['truncate.py']
"Parquet: NPE in Parquet Writer Metrics when data value max bound will overflow (#3760)

Previously when writing metrics whose max bound would overflow when incremented. This would result in a null value for the metrics and cause an NPE when put in the Metrics array. Now instead the null values are ignored if returned from truncate.",2,144,2022-01-24 12:38:16-06:00,"['ParquetUtil.java', 'TestParquetDataWriter.java']"
"Hive: Make Iceberg table filter optional in HiveCatalog (#3908)

This adds an option to return all Hive tables, not just Iceberg tables to avoid loading metadata and slowing down the operation.",2,38,2022-01-24 11:01:37-08:00,"['HiveCatalog.java', 'HiveTableTest.java']"
Core: Allow removing and adding the same partition field as a noop (#3954),2,53,2022-01-24 11:05:46-08:00,"['BaseUpdatePartitionSpec.java', 'TestUpdatePartitionSpec.java']"
Core: Fix delete file index with manifests of only existing files (#3943),3,64,2022-01-24 11:07:53-08:00,"['DeleteFileIndex.java', 'TableTestBase.java', 'TestDeleteFileIndex.java']"
AWS: fix Iceberg to Glue schema conversion (#3887),3,148,2022-01-24 11:55:20-08:00,"['TestGlueCatalogTable.java', 'IcebergToGlueConverter.java', 'TestIcebergToGlueConverter.java']"
"Core: Add reserved UUID Table Property and Expose in HMS. (#3914)



Co-authored-by: Karuppayya Rajendran <karuppayya.rajendran@apple.com>
Co-authored-by: Yufei Gu <yufei_gu@apple.com>",8,73,2022-01-24 14:39:47-06:00,"['TableProperties.java', 'TestTableMetadata.java', 'TestFlinkCatalogTable.java', 'TestFlinkCatalogTable.java', 'TestFlinkCatalogTable.java', 'HiveTableOperations.java', 'TestHiveCatalog.java', 'TestHiveIcebergStorageHandlerNoScan.java']"
AWS: show old fields in Glue table (#3888),3,130,2022-01-24 13:29:48-08:00,"['TestGlueCatalogTable.java', 'IcebergToGlueConverter.java', 'TestIcebergToGlueConverter.java']"
Spark 3.2: Add tests for copy-on-write MERGE distribution and ordering (#3964),1,293,2022-01-24 14:48:45-08:00,['TestSparkDistributionAndOrderingUtil.java']
AWS: fix Glue catalog for unknown commit status (#3967),2,36,2022-01-24 17:14:43-08:00,"['TestGlueCatalogCommitFailure.java', 'GlueTableOperations.java']"
Docs: Add Amazon EMR announcement (#3976),1,4,2022-01-24 21:46:57-08:00,['aws.md']
Spark 3.2: Revise distribution and ordering for merge-on-read DELETE (#3970),2,186,2022-01-25 00:03:36-08:00,"['SparkWriteConf.java', 'TestSparkDistributionAndOrderingUtil.java']"
Docs: Add section to include instructions for Hive on Tez (#3944),1,8,2022-01-25 11:54:36+01:00,['hive.md']
"AWS: Support checksum validation with S3 eTags (#3813)

* [S3FileIO] Add capability to perform checksum validations using S3 eTags.

* fix checkstyle error

* Update to move checksum checks to s3 server side

* Enable s3 checksum checks in aws integration tests

* Catch protocol error and log helpful error message

* Use digest bytes instead of MessageDigest and update tests

* Fix checkstyle failure

* Use DigestOutputStream

* Remove redundant spaces

* rename etag to checksum in leftover places

* address

* Remove ununsed import

* Config name change

* minor updates",4,227,2022-01-25 12:50:19-08:00,"['TestS3MultipartUpload.java', 'AwsProperties.java', 'S3OutputStream.java', 'TestS3OutputStream.java']"
Docs: Update release instructions (#3982),3,85,2022-01-27 16:14:47-08:00,"['source-release.sh', 'stage-binaries.sh', 'how-to-release.md']"
Docs: Fix MapType example (#3993),1,5,2022-01-27 16:17:01-08:00,['api.md']
Docs: Add s3.checksum-enabled to AWS (#3996),1,4,2022-01-27 16:17:56-08:00,['aws.md']
Spark 3.2: Fix cardinality check for alternative join implementations (#3992),5,178,2022-01-27 17:30:04-08:00,"['RewriteMergeIntoTable.scala', 'NoStatsUnaryNode.scala', 'ExtendedDataSourceV2Strategy.scala', 'MergeRowsExec.scala', 'TestMerge.java']"
"Spark: Add option to skip overwrites in streaming (#3517)

Co-authored-by: Rajarshi Sarkar <srajars@amazon.com>",4,65,2022-01-28 11:40:52-08:00,"['SparkReadConf.java', 'SparkReadOptions.java', 'SparkMicroBatchStream.java', 'TestStructuredStreamingRead3.java']"
Build: Fix release script signing and checksum commands (#3999),1,4,2022-01-28 11:42:55-08:00,['source-release.sh']
"Spark: Handle CaseSenstivity in runtimeFiltering of Spark (#3979)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",2,36,2022-01-28 11:49:56-08:00,"['SparkBatchQueryScan.java', 'TestRuntimeFiltering.java']"
Spec: Add REST basics for TableOperations (#3955),1,752,2022-01-28 16:51:13-08:00,['rest-catalog-open-api.yaml']
Spec: Remove unnecessary quotes in REST examples (#4004),1,6,2022-01-30 09:40:38-08:00,['rest-catalog-open-api.yaml']
Spec: Add 403 responses to REST API (#4003),1,43,2022-01-30 09:41:17-08:00,['rest-catalog-open-api.yaml']
Python: Support visiting MapType (#3989),3,36,2022-01-31 08:21:44-08:00,"['type.py', 'type_util.py', 'types.py']"
Spark 3.1: Add option to skip overwrites in streaming (#4013),4,64,2022-01-31 08:22:14-08:00,"['SparkReadConf.java', 'SparkReadOptions.java', 'SparkMicroBatchStream.java', 'TestStructuredStreamingRead3.java']"
Spark 3.0: Add option to skip overwrites in streaming (#4014),4,64,2022-01-31 08:22:37-08:00,"['SparkReadConf.java', 'SparkReadOptions.java', 'SparkMicroBatchStream.java', 'TestStructuredStreamingRead3.java']"
Hive: Parquet vectorization support for Hive 3 (#3980),6,317,2022-01-31 20:03:07+01:00,"['HiveVectorizedReader.java', 'ParquetSchemaFieldNameVisitor.java', 'HiveIcebergInputFormat.java', 'HiveIcebergStorageHandler.java', 'IcebergInputFormat.java', 'TestHiveIcebergStorageHandlerWithEngine.java']"
Docs: Add max_concurrent_deletes param for procedures (#4008),1,2,2022-01-31 15:55:24-08:00,['spark-procedures.md']
Spark 3.2: Refactor SparkBatchScan (#3516),6,226,2022-01-31 16:59:48-08:00,"['SparkBatch.java', 'SparkBatchQueryScan.java', 'SparkCopyOnWriteScan.java', 'SparkFilesScan.java', 'SparkMicroBatchStream.java', 'SparkScan.java']"
Spec: Add missing error codes to REST API (#4010),1,11,2022-02-01 09:37:51-08:00,['rest-catalog-open-api.yaml']
Parquet: Support reading 2-level lists in imported data files (#3774),16,532,2022-02-01 12:13:20-08:00,"['TestGenericData.java', 'FlinkParquetReaders.java', 'TestFlinkParquetReader.java', 'BaseParquetReaders.java', 'ApplyNameMapping.java', 'MessageTypeToType.java', 'ParquetAvroValueReaders.java', 'ParquetSchemaUtil.java', 'ParquetTypeVisitor.java', 'PruneColumns.java', 'TypeWithSchemaVisitor.java', 'TestParquet.java', 'TestParquetSchemaUtil.java', 'PigParquetReader.java', 'SparkParquetReaders.java', 'TestCreateActions.java']"
Python: Add .python-version file for tox-pyenv support (#4022),2,4,2022-02-01 12:27:43-08:00,"['.rat-excludes', '.python-version']"
Spark 3.2: Fix predicate pushdown in row-level operations (#4023),2,81,2022-02-01 12:46:48-08:00,"['RowLevelCommandScanRelationPushDown.scala', 'TestMerge.java']"
"Spark 3.1: Reports bytesWritten and recordsWritten to metrics (#4029)

Co-authored-by: zhangchen351 <zhangchen351@jd.com>",1,29,2022-02-02 08:43:01-08:00,['SparkWrite.java']
"Spark 3.2: Reports bytesWritten and recordsWritten to metrics (#4030)

Co-authored-by: zhangchen351 <zhangchen351@jd.com>",1,29,2022-02-02 08:43:26-08:00,['SparkWrite.java']
Spec: Fix REST response objects (#4027),1,139,2022-02-02 08:49:45-08:00,['rest-catalog-open-api.yaml']
"Spark 3.0: Reports bytesWritten and recordsWritten to metrics (#4020)

Co-authored-by: zhangchen351 <zhangchen351@jd.com>",1,29,2022-02-02 08:53:55-08:00,['SparkWrite.java']
Docs: Add --check to verify checksum doc (#4028),1,2,2022-02-02 11:36:45-08:00,['how-to-verify-a-release.md']
Spark: Fix create table in Hadoop catalog root namespace (#4024),6,51,2022-02-02 14:06:16-08:00,"['SparkCatalog.java', 'TestCreateTable.java', 'SparkCatalog.java', 'TestCreateTable.java', 'SparkCatalog.java', 'TestCreateTable.java']"
Python: Implement __eq__ for iceberg type classes (#3965),2,153,2022-02-02 14:13:48-08:00,"['types.py', 'test_types.py']"
Python: Set black line-length to 130 in tox settings (#4025),5,60,2022-02-02 14:25:04-08:00,"['types.py', 'bin_packing.py', 'test_base.py', 'test_bin_packing.py', 'tox.ini']"
API: Upgrade Guava to pull in murmur3_32_fixed (#3815),3,17,2022-02-02 14:27:03-08:00,"['Bucket.java', 'TestBucketing.java', 'versions.props']"
"Core: Add SnapshotRef to API (#4019)

Co-authored-by: wangzeyu <1249369293@qq.com>
Co-authored-by: Jack Ye <yzhaoqin@amazon.com>",3,305,2022-02-02 15:31:41-08:00,"['SnapshotRef.java', 'SnapshotRefType.java', 'TestSnapshotRef.java']"
Python: Add --diff to show the line diff when black fails (#4034),1,2,2022-02-03 09:35:49-08:00,['tox.ini']
Python: Autoformat test_types.py with new line-length (#4032),1,8,2022-02-03 09:39:22-08:00,['test_types.py']
Flink: Ensure temp manifest names are unique across tasks (#3986),5,45,2022-02-04 09:38:39-08:00,"['FlinkManifestUtil.java', 'IcebergFilesCommitter.java', 'ManifestOutputFileFactory.java', 'TestFlinkManifest.java', 'TestIcebergFilesCommitter.java']"
Spark 3.2: Implement merge-on-read UPDATE (#3984),12,591,2022-02-04 15:33:17-08:00,"['BasePositionDeltaWriter.java', 'PositionDeltaWriter.java', 'TestPositionDeltaWriters.java', 'RewriteUpdateTable.scala', 'TestMergeOnReadUpdate.java', 'TestUpdate.java', 'SparkDistributionAndOrderingUtil.java', 'SparkWriteConf.java', 'SparkPositionDeltaWrite.java', 'SparkPositionDeltaWriteBuilder.java', 'SparkWriteBuilder.java', 'TestSparkDistributionAndOrderingUtil.java']"
Flink 1.14: Add ArrayBatchRecords and RecordAndPosition (#3865),3,309,2022-02-06 10:14:01-08:00,"['ArrayBatchRecords.java', 'RecordAndPosition.java', 'TestArrayBatchRecords.java']"
Docs: Remove the publish directive from .asf.yaml (#4045),1,3,2022-02-06 10:14:23-08:00,['.asf.yaml']
Spark 3.2: Rename variables referring to RowLevelOperationTable (#4044),3,52,2022-02-06 10:26:26-08:00,"['RewriteDeleteFromTable.scala', 'RewriteMergeIntoTable.scala', 'RewriteUpdateTable.scala']"
Spark 3.2: Remove unused methods in SparkScanBuilder (#4043),1,9,2022-02-06 10:26:53-08:00,['SparkScanBuilder.java']
Docs: Fix sample code in CONTRIBUTING.md (#4049),1,2,2022-02-06 10:37:11-08:00,['CONTRIBUTING.md']
Python (legacy): Support passing customized protocol for HMSClient (#4041),1,6,2022-02-06 10:38:29-08:00,['hive_tables.py']
"Core: Use DataWriter::write instead of DataWriter::add in BaseRollingWriter (#4048)

DataWriter::add is deprecated in 0.13 and will be removed in 0.14.
BaseRollingWriter should stop using the deprecated add() method.
Moreover, if a subclass of BaseRollingWriter only overrides the write()
method, add() should honor that.",2,4,2022-02-06 10:40:49-08:00,"['BaseTaskWriter.java', 'DataWriter.java']"
Flink: Add FLIP-27 RecordFactory to create and populate batches (#3866),2,102,2022-02-06 12:34:03-08:00,"['RecordFactory.java', 'RowDataRecordFactory.java']"
"Core: SnapshotRef parser and serialization logic (#4036)

Co-authored-by: wangzeyu <1249369293@qq.com>
Co-authored-by: Jack Ye <yzhaoqin@amazon.com>",4,320,2022-02-07 13:45:58-08:00,"['SnapshotRef.java', 'SnapshotRefParser.java', 'JsonUtil.java', 'TestSnapshotRefParser.java']"
Docs: Remove site to migrate to iceberg-docs repository (#4056),7005,2691911,2022-02-07 16:38:48-08:00,"['.gitignore', 'README.md', 'deploy.sh', 'Concurrency in Iceberg.pdf', 'api.md', 'aws.md', 'benchmarks.md', 'blogs.md', 'community.md', 'configuration.md', 'extra.css', 'custom-catalog.md', 'evolution.md', 'flink-connector.md', 'flink.md', 'getting-started.md', 'hive.md', 'how-to-release.md', 'how-to-verify-a-release.md', 'GitHub-Mark.png', 'Iceberg-logo-wordmark.png', 'Iceberg-logo.png', 'Slack_Mark_Web.png', 'asf.png', 'dremio-logo.png', 'favicon-16x16.png', 'favicon-32x32.png', 'favicon-96x96.png', 'favicon.ico', 'flink-logo.png', 'hive-logo.png', 'iceberg-logo-icon.png', 'iceberg-metadata.png', 'java.png', 'partition-spec-evolution.png', 'prestodb-logo.png', 'python.png', 'trino-logo.png', 'index.md', 'java-api-quickstart.md', 'allclasses-frame.html', 'allclasses-noframe.html', 'constant-values.html', 'deprecated-list.html', 'help-doc.html', 'index-all.html', 'index.html', 'Accessor.html', 'Accessors.html', 'AllDataFilesTable.AllDataFilesTableScan.html', 'AllDataFilesTable.html', 'AllEntriesTable.html', 'AllManifestsTable.AllManifestsTableScan.html', 'AllManifestsTable.html', 'AppendFiles.html', 'BaseCombinedScanTask.html', 'BaseMetastoreCatalog.BaseMetastoreCatalogTableBuilder.html', 'BaseMetastoreCatalog.html', 'BaseMetastoreTableOperations.html', 'BaseOverwriteFiles.html', 'BaseReplacePartitions.html', 'BaseRewriteManifests.html', 'BaseTable.html', 'CachingCatalog.html', 'CatalogUtil.html', 'CombinedScanTask.html', 'ContentFile.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DataFilesTable.FilesTableScan.html', 'DataFilesTable.html', 'DataOperations.html', 'DataTableScan.html', 'DataTask.html', 'DeleteFile.html', 'DeleteFiles.html', 'ExpireSnapshots.html', 'FileContent.html', 'FileFormat.html', 'FileMetadata.Builder.html', 'FileMetadata.html', 'FileScanTask.html', 'Files.html', 'FindFiles.Builder.html', 'FindFiles.html', 'GenericManifestFile.CopyBuilder.html', 'GenericManifestFile.html', 'GenericPartitionFieldSummary.html', 'GuavaClasses.html', 'HasTableOperations.html', 'HistoryEntry.html', 'HistoryTable.html', 'LocationProviders.html', 'ManageSnapshots.html', 'ManifestContent.html', 'ManifestEntriesTable.html', 'ManifestFile.PartitionFieldSummary.html', 'ManifestFile.html', 'ManifestFiles.html', 'ManifestReader.FileType.html', 'ManifestReader.html', 'ManifestWriter.html', 'ManifestsTable.html', 'MetadataColumns.html', 'MetadataTableType.html', 'MetadataTableUtils.html', 'Metrics.html', 'MetricsConfig.html', 'MetricsModes.Counts.html', 'MetricsModes.Full.html', 'MetricsModes.MetricsMode.html', 'MetricsModes.None.html', 'MetricsModes.Truncate.html', 'MetricsModes.html', 'MicroBatches.MicroBatch.html', 'MicroBatches.MicroBatchBuilder.html', 'MicroBatches.html', 'NullOrder.html', 'OverwriteFiles.html', 'PartitionField.html', 'PartitionKey.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'PartitionsTable.html', 'PendingUpdate.html', 'ReplacePartitions.html', 'RewriteFiles.html', 'RewriteManifests.html', 'Rollback.html', 'RowDelta.html', 'ScanSummary.Builder.html', 'ScanSummary.PartitionMetrics.html', 'ScanSummary.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'SetLocation.html', 'Snapshot.html', 'SnapshotManager.html', 'SnapshotParser.html', 'SnapshotSummary.Builder.html', 'SnapshotSummary.html', 'SnapshotUpdate.html', 'SnapshotsTable.html', 'SortDirection.html', 'SortField.html', 'SortOrder.Builder.html', 'SortOrder.html', 'SortOrderParser.html', 'StaticTableOperations.html', 'StructLike.html', 'SystemProperties.html', 'Table.html', 'TableMetadata.MetadataLogEntry.html', 'TableMetadata.SnapshotLogEntry.html', 'TableMetadata.html', 'TableMetadataParser.Codec.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableProperties.html', 'TableScan.html', 'Tables.html', 'Transaction.html', 'Transactions.html', 'UpdateLocation.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Action.html', 'Actions.html', 'BaseRewriteDataFilesAction.html', 'ExpireSnapshotsAction.html', 'ExpireSnapshotsActionResult.html', 'ManifestFileBean.html', 'RemoveOrphanFilesAction.html', 'RewriteDataFilesAction.html', 'RewriteDataFilesActionResult.html', 'RewriteManifestsAction.html', 'RewriteManifestsActionResult.html', 'SnapshotUpdateAction.html', 'SparkActions.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ArrowAllocation.html', 'ArrowSchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'NullabilityHolder.html', 'VectorHolder.ConstantVectorHolder.html', 'VectorHolder.html', 'VectorizedArrowReader.ConstantVectorReader.html', 'VectorizedArrowReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseVectorizedParquetValuesReader.html', 'VectorizedColumnIterator.html', 'VectorizedDictionaryEncodedParquetValuesReader.html', 'VectorizedPageIterator.html', 'VectorizedParquetDefinitionLevelReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Avro.DeleteWriteBuilder.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroEncoderUtil.html', 'AvroIterable.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'AvroSchemaWithTypeVisitor.html', 'AvroWithPartnerByStructureVisitor.html', 'LogicalMap.html', 'ProjectionDatumReader.html', 'RemoveIds.html', 'SupportsRowPosition.html', 'UUIDConversion.html', 'ValueReader.html', 'ValueReaders.StructReader.html', 'ValueReaders.html', 'ValueWriter.html', 'ValueWriters.StructWriter.html', 'ValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Catalog.TableBuilder.html', 'Catalog.html', 'Namespace.html', 'SupportsNamespaces.html', 'TableIdentifier.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DeleteFilter.html', 'GenericAppenderFactory.html', 'GenericDeleteFilter.html', 'GenericRecord.html', 'IcebergGenerics.ScanBuilder.html', 'IcebergGenerics.html', 'IdentityPartitionConverters.html', 'InternalRecordWrapper.html', 'Record.html', 'DataReader.html', 'DataWriter.html', 'DecoderResolver.html', 'IcebergDecoder.html', 'IcebergEncoder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericOrcReader.html', 'GenericOrcReaders.html', 'GenericOrcWriter.html', 'GenericOrcWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseParquetReaders.html', 'BaseParquetWriter.html', 'GenericParquetReaders.html', 'GenericParquetWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Deletes.html', 'EqualityDeleteWriter.html', 'PositionDelete.html', 'PositionDeleteWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'EncryptedFiles.html', 'EncryptedInputFile.html', 'EncryptedOutputFile.html', 'EncryptionKeyMetadata.html', 'EncryptionKeyMetadatas.html', 'EncryptionManager.html', 'PlaintextEncryptionManager.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CreateSnapshotEvent.html', 'Listener.html', 'Listeners.html', 'ScanEvent.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CherrypickAncestorCommitException.html', 'CommitFailedException.html', 'DuplicateWAPCommitException.html', 'NamespaceNotEmptyException.html', 'NoSuchIcebergTableException.html', 'NoSuchNamespaceException.html', 'NoSuchTableException.html', 'NotFoundException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'Bound.html', 'BoundLiteralPredicate.html', 'BoundPredicate.html', 'BoundReference.html', 'BoundSetPredicate.html', 'BoundTerm.html', 'BoundTransform.html', 'BoundUnaryPredicate.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.BoundVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'InclusiveMetricsEvaluator.html', 'Literal.html', 'ManifestEvaluator.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'StrictMetricsEvaluator.html', 'Term.html', 'True.html', 'Unbound.html', 'UnboundPredicate.html', 'UnboundTerm.html', 'UnboundTransform.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CatalogLoader.HadoopCatalogLoader.html', 'CatalogLoader.HiveCatalogLoader.html', 'CatalogLoader.html', 'FlinkCatalog.html', 'FlinkCatalogFactory.html', 'FlinkSchemaUtil.html', 'FlinkTableFactory.html', 'FlinkTypeVisitor.html', 'IcebergTableSink.html', 'IcebergTableSource.html', 'RowDataWrapper.html', 'TableLoader.CatalogTableLoader.html', 'TableLoader.HadoopTableLoader.html', 'TableLoader.html', 'AvroWithFlinkSchemaVisitor.html', 'FlinkAvroReader.html', 'FlinkAvroWriter.html', 'FlinkOrcReader.html', 'FlinkOrcWriter.html', 'FlinkParquetReaders.html', 'FlinkParquetWriters.html', 'FlinkValueReaders.html', 'FlinkValueWriters.html', 'ParquetWithFlinkSchemaVisitor.html', 'RowDataUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'FlinkSink.Builder.html', 'FlinkSink.html', 'RowDataTaskWriterFactory.FlinkFileAppenderFactory.html', 'RowDataTaskWriterFactory.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'FlinkInputFormat.html', 'FlinkInputSplit.html', 'FlinkSource.Builder.html', 'FlinkSource.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ConfigProperties.html', 'HadoopCatalog.html', 'HadoopFileIO.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTableOperations.html', 'HadoopTables.html', 'HiddenPathFilter.html', 'SerializableConfiguration.html', 'Util.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ClientPool.Action.html', 'ClientPool.html', 'HiveCatalog.html', 'HiveCatalogs.html', 'HiveClientPool.html', 'HiveTableOperations.html', 'HiveTypeConverter.html', 'MetastoreUtil.html', 'RuntimeMetaException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseTaskWriter.RollingFileWriter.html', 'BaseTaskWriter.html', 'CloseableGroup.html', 'CloseableIterable.ConcatCloseableIterable.html', 'CloseableIterable.html', 'CloseableIterator.html', 'ClosingIterator.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'FileAppender.html', 'FileAppenderFactory.html', 'FileIO.html', 'FilterIterator.html', 'InputFile.html', 'LocationProvider.html', 'OutputFile.html', 'OutputFileFactory.html', 'PartitionedWriter.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'TaskWriter.html', 'UnpartitionedWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'MappedField.html', 'MappedFields.html', 'MappingUtil.html', 'NameMapping.html', 'NameMappingParser.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CatalogLoader.html', 'Catalogs.html', 'InputFormatConfig.ConfigBuilder.html', 'InputFormatConfig.InMemoryDataModel.html', 'InputFormatConfig.html', 'SerializationUtil.html', 'HiveIcebergFilterFactory.html', 'HiveIcebergInputFormat.html', 'HiveIcebergMetaHook.html', 'HiveIcebergOutputFormat.html', 'HiveIcebergSerDe.html', 'HiveIcebergSplit.html', 'HiveIcebergStorageHandler.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergBinaryObjectInspector.html', 'IcebergDateObjectInspector.html', 'IcebergDateObjectInspectorHive3.html', 'IcebergDecimalObjectInspector.html', 'IcebergObjectInspector.html', 'IcebergRecordObjectInspector.html', 'IcebergTimestampObjectInspector.html', 'IcebergTimestampObjectInspectorHive3.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Container.html', 'MapredIcebergInputFormat.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergInputFormat.html', 'IcebergSplit.html', 'IcebergSplitContainer.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ORC.ReadBuilder.html', 'ORC.WriteBuilder.html', 'ORC.html', 'ORCSchemaUtil.BinaryType.html', 'ORCSchemaUtil.LongType.html', 'ORCSchemaUtil.html', 'OrcBatchReader.html', 'OrcMetrics.html', 'OrcRowReader.html', 'OrcRowWriter.html', 'OrcSchemaVisitor.html', 'OrcSchemaWithTypeVisitor.html', 'OrcValueReader.html', 'OrcValueReaders.StructReader.html', 'OrcValueReaders.html', 'OrcValueWriter.html', 'VectorizedRowBatchIterator.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseColumnIterator.html', 'BasePageIterator.IntIterator.html', 'BasePageIterator.html', 'ColumnIterator.html', 'ColumnWriter.html', 'Parquet.DeleteWriteBuilder.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetAvroReader.html', 'ParquetAvroValueReaders.TimeMillisReader.html', 'ParquetAvroValueReaders.TimestampMillisReader.html', 'ParquetAvroValueReaders.html', 'ParquetAvroWriter.html', 'ParquetDictionaryRowGroupFilter.html', 'ParquetIterable.html', 'ParquetMetricsRowGroupFilter.html', 'ParquetReader.html', 'ParquetSchemaUtil.HasIds.html', 'ParquetSchemaUtil.html', 'ParquetTypeVisitor.html', 'ParquetUtil.html', 'ParquetValueReader.html', 'ParquetValueReaders.BinaryAsDecimalReader.html', 'ParquetValueReaders.ByteArrayReader.html', 'ParquetValueReaders.BytesReader.html', 'ParquetValueReaders.FloatAsDoubleReader.html', 'ParquetValueReaders.IntAsLongReader.html', 'ParquetValueReaders.IntegerAsDecimalReader.html', 'ParquetValueReaders.ListReader.html', 'ParquetValueReaders.LongAsDecimalReader.html', 'ParquetValueReaders.MapReader.html', 'ParquetValueReaders.PrimitiveReader.html', 'ParquetValueReaders.RepeatedKeyValueReader.html', 'ParquetValueReaders.RepeatedReader.html', 'ParquetValueReaders.ReusableEntry.html', 'ParquetValueReaders.StringReader.html', 'ParquetValueReaders.StructReader.html', 'ParquetValueReaders.UnboxedReader.html', 'ParquetValueReaders.html', 'ParquetValueWriter.html', 'ParquetValueWriters.PositionDeleteStructWriter.html', 'ParquetValueWriters.PrimitiveWriter.html', 'ParquetValueWriters.RepeatedKeyValueWriter.html', 'ParquetValueWriters.RepeatedWriter.html', 'ParquetValueWriters.StructWriter.html', 'ParquetValueWriters.html', 'ParquetWriteAdapter.html', 'RemoveIds.html', 'TripleWriter.html', 'TypeToMessageType.html', 'TypeWithSchemaVisitor.html', 'ValuesAsBytesReader.html', 'VectorizedParquetReader.html', 'VectorizedReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergPigInputFormat.IcebergRecordReader.html', 'IcebergPigInputFormat.html', 'IcebergStorage.html', 'PigParquetReader.html', 'SchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'SchemaWithPartnerVisitor.PartnerAccessors.html', 'SchemaWithPartnerVisitor.html', 'UnionByNameVisitor.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSpark.html', 'PruneColumnsWithReordering.html', 'PruneColumnsWithoutReordering.html', 'RollbackStagedTable.html', 'Spark3Util.DescribeSchemaVisitor.html', 'Spark3Util.html', 'SparkCatalog.html', 'SparkDataFile.html', 'SparkExceptionUtil.html', 'SparkFilters.html', 'SparkSchemaUtil.html', 'SparkSessionCatalog.html', 'SparkStructLike.html', 'SparkTableUtil.SparkPartition.html', 'SparkTableUtil.html', 'SparkUtil.html', 'SparkValueConverter.html', 'AvroWithSparkSchemaVisitor.html', 'ParquetWithSparkSchemaVisitor.html', 'SparkAvroReader.html', 'SparkAvroWriter.html', 'SparkOrcReader.html', 'SparkOrcValueReaders.html', 'SparkOrcWriter.html', 'SparkParquetReaders.html', 'SparkParquetWriters.html', 'SparkValueReaders.html', 'SparkValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ArrowVectorAccessor.html', 'ArrowVectorAccessors.html', 'ColumnarBatchReader.html', 'IcebergArrowColumnVector.html', 'RowPostitionColumnVector.html', 'VectorizedSparkOrcReaders.html', 'VectorizedSparkParquetReaders.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSource.html', 'RowDataRewriter.html', 'SparkPartitionedWriter.html', 'SparkScanBuilder.html', 'SparkStreamingWrite.html', 'SparkTable.html', 'StagedSparkTable.html', 'Stats.html', 'StreamingWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PartitionSpecVisitor.html', 'Transform.html', 'Transforms.html', 'UnknownTransform.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CheckCompatibility.html', 'Comparators.html', 'Conversions.html', 'FixupTypes.html', 'IndexByName.html', 'IndexParents.html', 'JavaHash.html', 'JavaHashes.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ArrayUtil.html', 'BinPacking.ListPacker.html', 'BinPacking.PackingIterable.html', 'BinPacking.html', 'BinaryUtil.html', 'ByteBuffers.html', 'CharSequenceSet.html', 'CharSequenceWrapper.html', 'DateTimeUtil.html', 'DecimalUtil.html', 'ExceptionUtil.html', 'Exceptions.html', 'Filter.html', 'JsonUtil.html', 'ManifestFileUtil.html', 'Pair.html', 'ParallelIterable.html', 'PartitionSet.html', 'PartitionUtil.html', 'PropertyUtil.html', 'SerializableSupplier.html', 'SnapshotUtil.html', 'SortedMerge.html', 'StructLikeSet.html', 'StructLikeWrapper.html', 'StructProjection.html', 'TableScanUtil.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'ThreadPools.html', 'UUIDUtil.html', 'UnicodeUtil.html', 'WapUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'overview-frame.html', 'overview-summary.html', 'overview-tree.html', 'package-list', 'script.js', 'serialized-form.html', 'stylesheet.css', 'allclasses-frame.html', 'allclasses-noframe.html', 'constant-values.html', 'deprecated-list.html', 'help-doc.html', 'index-all.html', 'index.html', 'Accessor.html', 'Accessors.html', 'AllDataFilesTable.AllDataFilesTableScan.html', 'AllDataFilesTable.html', 'AllEntriesTable.html', 'AllManifestsTable.AllManifestsTableScan.html', 'AllManifestsTable.html', 'AppendFiles.html', 'BaseCombinedScanTask.html', 'BaseMetastoreCatalog.BaseMetastoreCatalogTableBuilder.html', 'BaseMetastoreCatalog.html', 'BaseMetastoreTableOperations.html', 'BaseOverwriteFiles.html', 'BaseReplacePartitions.html', 'BaseReplaceSortOrder.html', 'BaseRewriteManifests.html', 'BaseTable.html', 'CachingCatalog.html', 'CatalogProperties.html', 'CatalogUtil.html', 'CombinedScanTask.html', 'ContentFile.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DataFilesTable.FilesTableScan.html', 'DataFilesTable.html', 'DataOperations.html', 'DataTableScan.html', 'DataTask.html', 'DeleteFile.html', 'DeleteFiles.html', 'DistributionMode.html', 'ExpireSnapshots.html', 'FieldMetrics.html', 'FileContent.html', 'FileFormat.html', 'FileMetadata.Builder.html', 'FileMetadata.html', 'FileScanTask.html', 'Files.html', 'FindFiles.Builder.html', 'FindFiles.html', 'FloatFieldMetrics.html', 'GenericManifestFile.CopyBuilder.html', 'GenericManifestFile.html', 'GenericPartitionFieldSummary.html', 'GuavaClasses.html', 'HasTableOperations.html', 'HistoryEntry.html', 'HistoryTable.html', 'IsolationLevel.html', 'LocationProviders.html', 'ManageSnapshots.html', 'ManifestContent.html', 'ManifestEntriesTable.html', 'ManifestFile.PartitionFieldSummary.html', 'ManifestFile.html', 'ManifestFiles.html', 'ManifestReader.FileType.html', 'ManifestReader.html', 'ManifestWriter.html', 'ManifestsTable.html', 'MetadataColumns.html', 'MetadataTableType.html', 'MetadataTableUtils.html', 'Metrics.html', 'MetricsConfig.html', 'MetricsModes.Counts.html', 'MetricsModes.Full.html', 'MetricsModes.MetricsMode.html', 'MetricsModes.None.html', 'MetricsModes.Truncate.html', 'MetricsModes.html', 'MetricsUtil.html', 'MicroBatches.MicroBatch.html', 'MicroBatches.MicroBatchBuilder.html', 'MicroBatches.html', 'NullOrder.html', 'OverwriteFiles.html', 'PartitionField.html', 'PartitionKey.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'Partitioning.html', 'PartitionsTable.html', 'PendingUpdate.html', 'ReplacePartitions.html', 'ReplaceSortOrder.html', 'RewriteFiles.html', 'RewriteManifests.html', 'Rollback.html', 'RowDelta.html', 'ScanSummary.Builder.html', 'ScanSummary.PartitionMetrics.html', 'ScanSummary.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'SetLocation.html', 'Snapshot.html', 'SnapshotManager.html', 'SnapshotParser.html', 'SnapshotSummary.Builder.html', 'SnapshotSummary.html', 'SnapshotUpdate.html', 'SnapshotsTable.html', 'SortDirection.html', 'SortField.html', 'SortOrder.Builder.html', 'SortOrder.html', 'SortOrderBuilder.html', 'SortOrderParser.html', 'StaticTableOperations.html', 'StructLike.html', 'SystemProperties.html', 'Table.html', 'TableMetadata.MetadataLogEntry.html', 'TableMetadata.SnapshotLogEntry.html', 'TableMetadata.html', 'TableMetadataParser.Codec.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableProperties.html', 'TableScan.html', 'Tables.html', 'Transaction.html', 'Transactions.html', 'UpdateLocation.html', 'UpdatePartitionSpec.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Action.html', 'Actions.html', 'BaseRewriteDataFilesAction.html', 'CreateAction.html', 'ExpireSnapshotsAction.html', 'ExpireSnapshotsActionResult.html', 'ManifestFileBean.html', 'RemoveOrphanFilesAction.html', 'RewriteDataFilesAction.html', 'RewriteDataFilesActionResult.html', 'RewriteManifestsAction.html', 'RewriteManifestsActionResult.html', 'SnapshotAction.html', 'SnapshotUpdateAction.html', 'Spark3MigrateAction.html', 'Spark3SnapshotAction.html', 'SparkActions.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ArrowAllocation.html', 'ArrowSchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'NullabilityHolder.html', 'VectorHolder.ConstantVectorHolder.html', 'VectorHolder.PositionVectorHolder.html', 'VectorHolder.html', 'VectorizedArrowReader.ConstantVectorReader.html', 'VectorizedArrowReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseVectorizedParquetValuesReader.html', 'VectorizedColumnIterator.html', 'VectorizedDictionaryEncodedParquetValuesReader.html', 'VectorizedPageIterator.html', 'VectorizedParquetDefinitionLevelReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Avro.DeleteWriteBuilder.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroEncoderUtil.html', 'AvroIterable.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'AvroSchemaWithTypeVisitor.html', 'AvroWithPartnerByStructureVisitor.html', 'LogicalMap.html', 'ProjectionDatumReader.html', 'RemoveIds.html', 'SupportsRowPosition.html', 'UUIDConversion.html', 'ValueReader.html', 'ValueReaders.StructReader.html', 'ValueReaders.html', 'ValueWriter.html', 'ValueWriters.StructWriter.html', 'ValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AssumeRoleAwsClientFactory.html', 'AwsClientFactories.html', 'AwsClientFactory.html', 'AwsProperties.html', 'GlueCatalog.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'S3FileIO.html', 'S3InputFile.html', 'S3OutputFile.html', 'S3RequestUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Catalog.TableBuilder.html', 'Catalog.html', 'Namespace.html', 'SupportsNamespaces.html', 'TableIdentifier.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DeleteFilter.html', 'GenericAppenderFactory.html', 'GenericDeleteFilter.html', 'GenericRecord.html', 'IcebergGenerics.ScanBuilder.html', 'IcebergGenerics.html', 'IdentityPartitionConverters.html', 'InternalRecordWrapper.html', 'Record.html', 'DataReader.html', 'DataWriter.html', 'DecoderResolver.html', 'IcebergDecoder.html', 'IcebergEncoder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericOrcReader.html', 'GenericOrcReaders.html', 'GenericOrcWriter.html', 'GenericOrcWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseParquetReaders.html', 'BaseParquetWriter.html', 'GenericParquetReaders.html', 'GenericParquetWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Deletes.html', 'EqualityDeleteWriter.html', 'PositionDelete.html', 'PositionDeleteWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'EncryptedFiles.html', 'EncryptedInputFile.html', 'EncryptedOutputFile.html', 'EncryptionKeyMetadata.html', 'EncryptionKeyMetadatas.html', 'EncryptionManager.html', 'PlaintextEncryptionManager.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CreateSnapshotEvent.html', 'IncrementalScanEvent.html', 'Listener.html', 'Listeners.html', 'ScanEvent.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CherrypickAncestorCommitException.html', 'CommitFailedException.html', 'DuplicateWAPCommitException.html', 'NamespaceNotEmptyException.html', 'NoSuchIcebergTableException.html', 'NoSuchNamespaceException.html', 'NoSuchTableException.html', 'NotFoundException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'Bound.html', 'BoundLiteralPredicate.html', 'BoundPredicate.html', 'BoundReference.html', 'BoundSetPredicate.html', 'BoundTerm.html', 'BoundTransform.html', 'BoundUnaryPredicate.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.BoundVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'InclusiveMetricsEvaluator.html', 'Literal.html', 'ManifestEvaluator.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'StrictMetricsEvaluator.html', 'Term.html', 'True.html', 'Unbound.html', 'UnboundPredicate.html', 'UnboundTerm.html', 'UnboundTransform.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CatalogLoader.CustomCatalogLoader.html', 'CatalogLoader.HadoopCatalogLoader.html', 'CatalogLoader.HiveCatalogLoader.html', 'CatalogLoader.html', 'FlinkCatalog.html', 'FlinkCatalogFactory.html', 'FlinkFilters.html', 'FlinkSchemaUtil.html', 'FlinkTableFactory.html', 'FlinkTableOptions.html', 'FlinkTypeVisitor.html', 'IcebergTableSink.html', 'IcebergTableSource.html', 'RowDataWrapper.html', 'TableLoader.CatalogTableLoader.html', 'TableLoader.HadoopTableLoader.html', 'TableLoader.html', 'Actions.html', 'RewriteDataFilesAction.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AvroWithFlinkSchemaVisitor.html', 'FlinkAvroReader.html', 'FlinkAvroWriter.html', 'FlinkOrcReader.html', 'FlinkOrcWriter.html', 'FlinkParquetReaders.html', 'FlinkParquetWriters.html', 'FlinkValueReaders.html', 'FlinkValueWriters.html', 'ParquetWithFlinkSchemaVisitor.html', 'RowDataUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'FlinkAppenderFactory.html', 'FlinkSink.Builder.html', 'FlinkSink.html', 'RowDataTaskWriterFactory.html', 'TaskWriterFactory.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'FlinkInputFormat.html', 'FlinkInputSplit.html', 'FlinkSource.Builder.html', 'FlinkSource.html', 'RowDataRewriter.RewriteMap.html', 'RowDataRewriter.html', 'StreamingMonitorFunction.html', 'StreamingReaderOperator.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ConfigProperties.html', 'HadoopCatalog.html', 'HadoopFileIO.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTableOperations.html', 'HadoopTables.html', 'HiddenPathFilter.html', 'SerializableConfiguration.html', 'Util.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ClientPool.Action.html', 'ClientPool.html', 'HiveCatalog.html', 'HiveCatalogs.html', 'HiveClientPool.html', 'HiveSchemaUtil.html', 'HiveTableOperations.html', 'MetastoreUtil.html', 'RuntimeMetaException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseTaskWriter.BaseEqualityDeltaWriter.html', 'BaseTaskWriter.RollingEqDeleteWriter.html', 'BaseTaskWriter.RollingFileWriter.html', 'BaseTaskWriter.html', 'CloseableGroup.html', 'CloseableIterable.ConcatCloseableIterable.html', 'CloseableIterable.html', 'CloseableIterator.html', 'ClosingIterator.html', 'DataWriter.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'DeleteSchemaUtil.html', 'FileAppender.html', 'FileAppenderFactory.html', 'FileIO.html', 'FilterIterator.html', 'InputFile.html', 'LocationProvider.html', 'OutputFile.html', 'OutputFileFactory.html', 'PartitionedFanoutWriter.html', 'PartitionedWriter.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'TaskWriter.html', 'UnpartitionedWriter.html', 'WriteResult.Builder.html', 'WriteResult.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'MappedField.html', 'MappedFields.html', 'MappingUtil.html', 'NameMapping.html', 'NameMappingParser.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CatalogLoader.html', 'Catalogs.html', 'InputFormatConfig.ConfigBuilder.html', 'InputFormatConfig.InMemoryDataModel.html', 'InputFormatConfig.html', 'HiveIcebergFilterFactory.html', 'HiveIcebergInputFormat.html', 'HiveIcebergMetaHook.html', 'HiveIcebergOutputCommitter.html', 'HiveIcebergOutputFormat.html', 'HiveIcebergSerDe.html', 'HiveIcebergSplit.html', 'HiveIcebergStorageHandler.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergBinaryObjectInspector.html', 'IcebergDateObjectInspector.html', 'IcebergDateObjectInspectorHive3.html', 'IcebergDecimalObjectInspector.html', 'IcebergFixedObjectInspector.html', 'IcebergObjectInspector.html', 'IcebergRecordObjectInspector.html', 'IcebergTimeObjectInspector.html', 'IcebergTimestampObjectInspector.html', 'IcebergTimestampObjectInspectorHive3.html', 'IcebergTimestampWithZoneObjectInspector.html', 'IcebergTimestampWithZoneObjectInspectorHive3.html', 'IcebergUUIDObjectInspector.html', 'WriteObjectInspector.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Container.html', 'MapredIcebergInputFormat.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergInputFormat.html', 'IcebergSplit.html', 'IcebergSplitContainer.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'NessieCatalog.html', 'NessieTableOperations.html', 'NessieUtil.html', 'TableReference.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ORC.ReadBuilder.html', 'ORC.WriteBuilder.html', 'ORC.html', 'ORCSchemaUtil.BinaryType.html', 'ORCSchemaUtil.LongType.html', 'ORCSchemaUtil.html', 'OrcBatchReader.html', 'OrcMetrics.html', 'OrcRowReader.html', 'OrcRowWriter.html', 'OrcSchemaVisitor.html', 'OrcSchemaWithTypeVisitor.html', 'OrcValueReader.html', 'OrcValueReaders.StructReader.html', 'OrcValueReaders.html', 'OrcValueWriter.html', 'VectorizedRowBatchIterator.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseColumnIterator.html', 'BasePageIterator.IntIterator.html', 'BasePageIterator.html', 'ColumnIterator.html', 'ColumnWriter.html', 'Parquet.DeleteWriteBuilder.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetAvroReader.html', 'ParquetAvroValueReaders.TimeMillisReader.html', 'ParquetAvroValueReaders.TimestampMillisReader.html', 'ParquetAvroValueReaders.html', 'ParquetAvroWriter.html', 'ParquetDictionaryRowGroupFilter.html', 'ParquetIterable.html', 'ParquetMetricsRowGroupFilter.html', 'ParquetReader.html', 'ParquetSchemaUtil.HasIds.html', 'ParquetSchemaUtil.html', 'ParquetTypeVisitor.html', 'ParquetUtil.html', 'ParquetValueReader.html', 'ParquetValueReaders.BinaryAsDecimalReader.html', 'ParquetValueReaders.ByteArrayReader.html', 'ParquetValueReaders.BytesReader.html', 'ParquetValueReaders.FloatAsDoubleReader.html', 'ParquetValueReaders.IntAsLongReader.html', 'ParquetValueReaders.IntegerAsDecimalReader.html', 'ParquetValueReaders.ListReader.html', 'ParquetValueReaders.LongAsDecimalReader.html', 'ParquetValueReaders.MapReader.html', 'ParquetValueReaders.PrimitiveReader.html', 'ParquetValueReaders.RepeatedKeyValueReader.html', 'ParquetValueReaders.RepeatedReader.html', 'ParquetValueReaders.ReusableEntry.html', 'ParquetValueReaders.StringReader.html', 'ParquetValueReaders.StructReader.html', 'ParquetValueReaders.UnboxedReader.html', 'ParquetValueReaders.html', 'ParquetValueWriter.html', 'ParquetValueWriters.PositionDeleteStructWriter.html', 'ParquetValueWriters.PrimitiveWriter.html', 'ParquetValueWriters.RepeatedKeyValueWriter.html', 'ParquetValueWriters.RepeatedWriter.html', 'ParquetValueWriters.StructWriter.html', 'ParquetValueWriters.html', 'ParquetWriteAdapter.html', 'RemoveIds.html', 'TripleWriter.html', 'TypeToMessageType.html', 'TypeWithSchemaVisitor.html', 'ValuesAsBytesReader.html', 'VectorizedParquetReader.html', 'VectorizedReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergPigInputFormat.IcebergRecordReader.html', 'IcebergPigInputFormat.html', 'IcebergStorage.html', 'PigParquetReader.html', 'SchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'SchemaWithPartnerVisitor.PartnerAccessors.html', 'SchemaWithPartnerVisitor.html', 'UnionByNameVisitor.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSpark.html', 'PathIdentifier.html', 'PruneColumnsWithReordering.html', 'PruneColumnsWithoutReordering.html', 'RollbackStagedTable.html', 'Spark3Util.CatalogAndIdentifier.html', 'Spark3Util.DescribeSchemaVisitor.html', 'Spark3Util.html', 'SparkCatalog.html', 'SparkDataFile.html', 'SparkExceptionUtil.html', 'SparkFilters.html', 'SparkReadOptions.html', 'SparkSchemaUtil.html', 'SparkSessionCatalog.html', 'SparkStructLike.html', 'SparkTableUtil.SparkPartition.html', 'SparkTableUtil.html', 'SparkUtil.html', 'SparkValueConverter.html', 'SparkWriteOptions.html', 'AvroWithSparkSchemaVisitor.html', 'ParquetWithSparkSchemaVisitor.html', 'SparkAvroReader.html', 'SparkAvroWriter.html', 'SparkOrcReader.html', 'SparkOrcValueReaders.html', 'SparkOrcWriter.html', 'SparkParquetReaders.html', 'SparkParquetWriters.html', 'SparkValueReaders.html', 'SparkValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ArrowVectorAccessor.html', 'ArrowVectorAccessors.html', 'ColumnarBatchReader.html', 'IcebergArrowColumnVector.html', 'RowPostitionColumnVector.html', 'VectorizedSparkOrcReaders.html', 'VectorizedSparkParquetReaders.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ExpireSnapshotsProcedure.html', 'RemoveOrphanFilesProcedure.html', 'SparkProcedures.ProcedureBuilder.html', 'SparkProcedures.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CustomCatalogs.html', 'IcebergSource.html', 'RowDataRewriter.html', 'SparkPartitionedFanoutWriter.html', 'SparkPartitionedWriter.html', 'SparkScanBuilder.html', 'SparkTable.html', 'StagedSparkTable.html', 'Stats.html', 'StreamingWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PartitionSpecVisitor.html', 'SortOrderVisitor.html', 'Transform.html', 'Transforms.html', 'UnknownTransform.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CheckCompatibility.html', 'Comparators.html', 'Conversions.html', 'FixupTypes.html', 'IndexByName.html', 'IndexParents.html', 'JavaHash.html', 'JavaHashes.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ArrayUtil.html', 'BinPacking.ListPacker.html', 'BinPacking.PackingIterable.html', 'BinPacking.html', 'BinaryUtil.html', 'ByteBuffers.html', 'CharSequenceSet.html', 'CharSequenceWrapper.html', 'DateTimeUtil.html', 'DecimalUtil.html', 'ExceptionUtil.Block.html', 'ExceptionUtil.CatchBlock.html', 'ExceptionUtil.FinallyBlock.html', 'ExceptionUtil.html', 'Exceptions.html', 'Filter.html', 'JsonUtil.html', 'ManifestFileUtil.html', 'NaNUtil.html', 'Pair.html', 'ParallelIterable.html', 'PartitionSet.html', 'PartitionUtil.html', 'PropertyUtil.html', 'SerializableSupplier.html', 'SerializationUtil.html', 'SnapshotUtil.html', 'SortedMerge.html', 'StructLikeMap.html', 'StructLikeSet.html', 'StructLikeWrapper.html', 'StructProjection.html', 'TableScanUtil.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'ThreadPools.html', 'UUIDUtil.html', 'UnicodeUtil.html', 'WapUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'NoSuchProcedureException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSqlExtensionsBaseListener.html', 'IcebergSqlExtensionsBaseVisitor.html', 'IcebergSqlExtensionsLexer.html', 'IcebergSqlExtensionsListener.html', 'IcebergSqlExtensionsParser.AddPartitionFieldContext.html', 'IcebergSqlExtensionsParser.ApplyTransformContext.html', 'IcebergSqlExtensionsParser.BigDecimalLiteralContext.html', 'IcebergSqlExtensionsParser.BigIntLiteralContext.html', 'IcebergSqlExtensionsParser.BooleanLiteralContext.html', 'IcebergSqlExtensionsParser.BooleanValueContext.html', 'IcebergSqlExtensionsParser.CallArgumentContext.html', 'IcebergSqlExtensionsParser.CallContext.html', 'IcebergSqlExtensionsParser.ConstantContext.html', 'IcebergSqlExtensionsParser.DecimalLiteralContext.html', 'IcebergSqlExtensionsParser.DoubleLiteralContext.html', 'IcebergSqlExtensionsParser.DropPartitionFieldContext.html', 'IcebergSqlExtensionsParser.ExponentLiteralContext.html', 'IcebergSqlExtensionsParser.ExpressionContext.html', 'IcebergSqlExtensionsParser.FloatLiteralContext.html', 'IcebergSqlExtensionsParser.IdentifierContext.html', 'IcebergSqlExtensionsParser.IdentityTransformContext.html', 'IcebergSqlExtensionsParser.IntegerLiteralContext.html', 'IcebergSqlExtensionsParser.MultipartIdentifierContext.html', 'IcebergSqlExtensionsParser.NamedArgumentContext.html', 'IcebergSqlExtensionsParser.NonReservedContext.html', 'IcebergSqlExtensionsParser.NumberContext.html', 'IcebergSqlExtensionsParser.NumericLiteralContext.html', 'IcebergSqlExtensionsParser.OrderContext.html', 'IcebergSqlExtensionsParser.OrderFieldContext.html', 'IcebergSqlExtensionsParser.PositionalArgumentContext.html', 'IcebergSqlExtensionsParser.QuotedIdentifierAlternativeContext.html', 'IcebergSqlExtensionsParser.QuotedIdentifierContext.html', 'IcebergSqlExtensionsParser.SetTableOrderContext.html', 'IcebergSqlExtensionsParser.SingleStatementContext.html', 'IcebergSqlExtensionsParser.SmallIntLiteralContext.html', 'IcebergSqlExtensionsParser.StatementContext.html', 'IcebergSqlExtensionsParser.StringLiteralContext.html', 'IcebergSqlExtensionsParser.StringMapContext.html', 'IcebergSqlExtensionsParser.TinyIntLiteralContext.html', 'IcebergSqlExtensionsParser.TransformArgumentContext.html', 'IcebergSqlExtensionsParser.TransformContext.html', 'IcebergSqlExtensionsParser.TypeConstructorContext.html', 'IcebergSqlExtensionsParser.UnquotedIdentifierContext.html', 'IcebergSqlExtensionsParser.html', 'IcebergSqlExtensionsVisitor.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ExtendedSupportsDelete.html', 'Procedure.html', 'ProcedureCatalog.html', 'ProcedureParameter.html', 'SupportsMerge.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ClusteredDistribution.html', 'Distribution.html', 'Distributions.html', 'OrderedDistribution.html', 'UnspecifiedDistribution.html', 'ClusterDistributionImpl.html', 'OrderedDistributionImpl.html', 'UnspecifiedDistributionImpl.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'NullOrdering.html', 'SortDirection.html', 'SortOrder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'SupportsFileFilter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'MergeBuilder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'overview-frame.html', 'overview-summary.html', 'overview-tree.html', 'package-list', 'script.js', 'serialized-form.html', 'stylesheet.css', 'allclasses-frame.html', 'allclasses-noframe.html', 'constant-values.html', 'deprecated-list.html', 'help-doc.html', 'index-all.html', 'index.html', 'Accessor.html', 'Accessors.html', 'AllDataFilesTable.AllDataFilesTableScan.html', 'AllDataFilesTable.html', 'AllEntriesTable.html', 'AllManifestsTable.AllManifestsTableScan.html', 'AllManifestsTable.html', 'AppendFiles.html', 'BaseCombinedScanTask.html', 'BaseMetastoreCatalog.BaseMetastoreCatalogTableBuilder.html', 'BaseMetastoreCatalog.html', 'BaseMetastoreTableOperations.html', 'BaseOverwriteFiles.html', 'BaseReplacePartitions.html', 'BaseReplaceSortOrder.html', 'BaseRewriteManifests.html', 'BaseTable.html', 'CachingCatalog.html', 'CatalogProperties.html', 'CatalogUtil.html', 'CombinedScanTask.html', 'ContentFile.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DataFilesTable.FilesTableScan.html', 'DataFilesTable.html', 'DataOperations.html', 'DataTableScan.html', 'DataTask.html', 'DeleteFile.html', 'DeleteFiles.html', 'DistributionMode.html', 'ExpireSnapshots.html', 'FieldMetrics.html', 'FileContent.html', 'FileFormat.html', 'FileMetadata.Builder.html', 'FileMetadata.html', 'FileScanTask.html', 'Files.html', 'FindFiles.Builder.html', 'FindFiles.html', 'FloatFieldMetrics.html', 'GenericManifestFile.CopyBuilder.html', 'GenericManifestFile.html', 'GenericPartitionFieldSummary.html', 'GuavaClasses.html', 'HasTableOperations.html', 'HistoryEntry.html', 'HistoryTable.html', 'IsolationLevel.html', 'LocationProviders.html', 'ManageSnapshots.html', 'ManifestContent.html', 'ManifestEntriesTable.html', 'ManifestFile.PartitionFieldSummary.html', 'ManifestFile.html', 'ManifestFiles.html', 'ManifestReader.FileType.html', 'ManifestReader.html', 'ManifestWriter.html', 'ManifestsTable.html', 'MetadataColumns.html', 'MetadataTableType.html', 'MetadataTableUtils.html', 'Metrics.html', 'MetricsConfig.html', 'MetricsModes.Counts.html', 'MetricsModes.Full.html', 'MetricsModes.MetricsMode.html', 'MetricsModes.None.html', 'MetricsModes.Truncate.html', 'MetricsModes.html', 'MetricsUtil.html', 'MicroBatches.MicroBatch.html', 'MicroBatches.MicroBatchBuilder.html', 'MicroBatches.html', 'NullOrder.html', 'OverwriteFiles.html', 'PartitionField.html', 'PartitionKey.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'Partitioning.html', 'PartitionsTable.html', 'PendingUpdate.html', 'ReplacePartitions.html', 'ReplaceSortOrder.html', 'RewriteFiles.html', 'RewriteManifests.html', 'Rollback.html', 'RowDelta.html', 'ScanSummary.Builder.html', 'ScanSummary.PartitionMetrics.html', 'ScanSummary.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'SetLocation.html', 'Snapshot.html', 'SnapshotManager.html', 'SnapshotParser.html', 'SnapshotSummary.Builder.html', 'SnapshotSummary.html', 'SnapshotUpdate.html', 'SnapshotsTable.html', 'SortDirection.html', 'SortField.html', 'SortOrder.Builder.html', 'SortOrder.html', 'SortOrderBuilder.html', 'SortOrderParser.html', 'StaticTableOperations.html', 'StructLike.html', 'SystemProperties.html', 'Table.html', 'TableMetadata.MetadataLogEntry.html', 'TableMetadata.SnapshotLogEntry.html', 'TableMetadata.html', 'TableMetadataParser.Codec.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableProperties.html', 'TableScan.html', 'Tables.html', 'Transaction.html', 'Transactions.html', 'UpdateLocation.html', 'UpdatePartitionSpec.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Action.html', 'Actions.html', 'BaseRewriteDataFilesAction.html', 'CreateAction.html', 'ExpireSnapshotsAction.html', 'ExpireSnapshotsActionResult.html', 'ManifestFileBean.html', 'RemoveOrphanFilesAction.html', 'RewriteDataFilesAction.html', 'RewriteDataFilesActionResult.html', 'RewriteManifestsAction.html', 'RewriteManifestsActionResult.html', 'SnapshotAction.html', 'SnapshotUpdateAction.html', 'Spark3MigrateAction.html', 'Spark3SnapshotAction.html', 'SparkActions.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ArrowAllocation.html', 'ArrowSchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'NullabilityHolder.html', 'VectorHolder.ConstantVectorHolder.html', 'VectorHolder.PositionVectorHolder.html', 'VectorHolder.html', 'VectorizedArrowReader.ConstantVectorReader.html', 'VectorizedArrowReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseVectorizedParquetValuesReader.html', 'VectorizedColumnIterator.html', 'VectorizedDictionaryEncodedParquetValuesReader.html', 'VectorizedPageIterator.html', 'VectorizedParquetDefinitionLevelReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Avro.DeleteWriteBuilder.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroEncoderUtil.html', 'AvroIterable.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'AvroSchemaWithTypeVisitor.html', 'AvroWithPartnerByStructureVisitor.html', 'LogicalMap.html', 'ProjectionDatumReader.html', 'RemoveIds.html', 'SupportsRowPosition.html', 'UUIDConversion.html', 'ValueReader.html', 'ValueReaders.StructReader.html', 'ValueReaders.html', 'ValueWriter.html', 'ValueWriters.StructWriter.html', 'ValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AssumeRoleAwsClientFactory.html', 'AwsClientFactories.html', 'AwsClientFactory.html', 'AwsProperties.html', 'GlueCatalog.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'S3FileIO.html', 'S3InputFile.html', 'S3OutputFile.html', 'S3RequestUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Catalog.TableBuilder.html', 'Catalog.html', 'Namespace.html', 'SupportsNamespaces.html', 'TableIdentifier.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DeleteFilter.html', 'GenericAppenderFactory.html', 'GenericDeleteFilter.html', 'GenericRecord.html', 'IcebergGenerics.ScanBuilder.html', 'IcebergGenerics.html', 'IdentityPartitionConverters.html', 'InternalRecordWrapper.html', 'Record.html', 'DataReader.html', 'DataWriter.html', 'DecoderResolver.html', 'IcebergDecoder.html', 'IcebergEncoder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericOrcReader.html', 'GenericOrcReaders.html', 'GenericOrcWriter.html', 'GenericOrcWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseParquetReaders.html', 'BaseParquetWriter.html', 'GenericParquetReaders.html', 'GenericParquetWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Deletes.html', 'EqualityDeleteWriter.html', 'PositionDelete.html', 'PositionDeleteWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'EncryptedFiles.html', 'EncryptedInputFile.html', 'EncryptedOutputFile.html', 'EncryptionKeyMetadata.html', 'EncryptionKeyMetadatas.html', 'EncryptionManager.html', 'PlaintextEncryptionManager.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CreateSnapshotEvent.html', 'IncrementalScanEvent.html', 'Listener.html', 'Listeners.html', 'ScanEvent.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CherrypickAncestorCommitException.html', 'CommitFailedException.html', 'DuplicateWAPCommitException.html', 'NamespaceNotEmptyException.html', 'NoSuchIcebergTableException.html', 'NoSuchNamespaceException.html', 'NoSuchTableException.html', 'NotFoundException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'Bound.html', 'BoundLiteralPredicate.html', 'BoundPredicate.html', 'BoundReference.html', 'BoundSetPredicate.html', 'BoundTerm.html', 'BoundTransform.html', 'BoundUnaryPredicate.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.BoundVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'InclusiveMetricsEvaluator.html', 'Literal.html', 'ManifestEvaluator.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'StrictMetricsEvaluator.html', 'Term.html', 'True.html', 'Unbound.html', 'UnboundPredicate.html', 'UnboundTerm.html', 'UnboundTransform.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CatalogLoader.CustomCatalogLoader.html', 'CatalogLoader.HadoopCatalogLoader.html', 'CatalogLoader.HiveCatalogLoader.html', 'CatalogLoader.html', 'FlinkCatalog.html', 'FlinkCatalogFactory.html', 'FlinkFilters.html', 'FlinkSchemaUtil.html', 'FlinkTableFactory.html', 'FlinkTableOptions.html', 'FlinkTypeVisitor.html', 'IcebergTableSink.html', 'IcebergTableSource.html', 'RowDataWrapper.html', 'TableLoader.CatalogTableLoader.html', 'TableLoader.HadoopTableLoader.html', 'TableLoader.html', 'Actions.html', 'RewriteDataFilesAction.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AvroWithFlinkSchemaVisitor.html', 'FlinkAvroReader.html', 'FlinkAvroWriter.html', 'FlinkOrcReader.html', 'FlinkOrcWriter.html', 'FlinkParquetReaders.html', 'FlinkParquetWriters.html', 'FlinkValueReaders.html', 'FlinkValueWriters.html', 'ParquetWithFlinkSchemaVisitor.html', 'RowDataUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'FlinkAppenderFactory.html', 'FlinkSink.Builder.html', 'FlinkSink.html', 'RowDataTaskWriterFactory.html', 'TaskWriterFactory.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'FlinkInputFormat.html', 'FlinkInputSplit.html', 'FlinkSource.Builder.html', 'FlinkSource.html', 'RowDataRewriter.RewriteMap.html', 'RowDataRewriter.html', 'StreamingMonitorFunction.html', 'StreamingReaderOperator.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ConfigProperties.html', 'HadoopCatalog.html', 'HadoopFileIO.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTableOperations.html', 'HadoopTables.html', 'HiddenPathFilter.html', 'SerializableConfiguration.html', 'Util.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ClientPool.Action.html', 'ClientPool.html', 'HiveCatalog.html', 'HiveCatalogs.html', 'HiveClientPool.html', 'HiveSchemaUtil.html', 'HiveTableOperations.html', 'MetastoreUtil.html', 'RuntimeMetaException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseTaskWriter.BaseEqualityDeltaWriter.html', 'BaseTaskWriter.RollingEqDeleteWriter.html', 'BaseTaskWriter.RollingFileWriter.html', 'BaseTaskWriter.html', 'CloseableGroup.html', 'CloseableIterable.ConcatCloseableIterable.html', 'CloseableIterable.html', 'CloseableIterator.html', 'ClosingIterator.html', 'DataWriter.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'DeleteSchemaUtil.html', 'FileAppender.html', 'FileAppenderFactory.html', 'FileIO.html', 'FilterIterator.html', 'InputFile.html', 'LocationProvider.html', 'OutputFile.html', 'OutputFileFactory.html', 'PartitionedFanoutWriter.html', 'PartitionedWriter.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'TaskWriter.html', 'UnpartitionedWriter.html', 'WriteResult.Builder.html', 'WriteResult.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'MappedField.html', 'MappedFields.html', 'MappingUtil.html', 'NameMapping.html', 'NameMappingParser.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CatalogLoader.html', 'Catalogs.html', 'InputFormatConfig.ConfigBuilder.html', 'InputFormatConfig.InMemoryDataModel.html', 'InputFormatConfig.html', 'HiveIcebergFilterFactory.html', 'HiveIcebergInputFormat.html', 'HiveIcebergMetaHook.html', 'HiveIcebergOutputCommitter.html', 'HiveIcebergOutputFormat.html', 'HiveIcebergSerDe.html', 'HiveIcebergSplit.html', 'HiveIcebergStorageHandler.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergBinaryObjectInspector.html', 'IcebergDateObjectInspector.html', 'IcebergDateObjectInspectorHive3.html', 'IcebergDecimalObjectInspector.html', 'IcebergFixedObjectInspector.html', 'IcebergObjectInspector.html', 'IcebergRecordObjectInspector.html', 'IcebergTimeObjectInspector.html', 'IcebergTimestampObjectInspector.html', 'IcebergTimestampObjectInspectorHive3.html', 'IcebergTimestampWithZoneObjectInspector.html', 'IcebergTimestampWithZoneObjectInspectorHive3.html', 'IcebergUUIDObjectInspector.html', 'WriteObjectInspector.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Container.html', 'MapredIcebergInputFormat.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergInputFormat.html', 'IcebergSplit.html', 'IcebergSplitContainer.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'NessieCatalog.html', 'NessieTableOperations.html', 'NessieUtil.html', 'TableReference.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ORC.ReadBuilder.html', 'ORC.WriteBuilder.html', 'ORC.html', 'ORCSchemaUtil.BinaryType.html', 'ORCSchemaUtil.LongType.html', 'ORCSchemaUtil.html', 'OrcBatchReader.html', 'OrcMetrics.html', 'OrcRowReader.html', 'OrcRowWriter.html', 'OrcSchemaVisitor.html', 'OrcSchemaWithTypeVisitor.html', 'OrcValueReader.html', 'OrcValueReaders.StructReader.html', 'OrcValueReaders.html', 'OrcValueWriter.html', 'VectorizedRowBatchIterator.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseColumnIterator.html', 'BasePageIterator.IntIterator.html', 'BasePageIterator.html', 'ColumnIterator.html', 'ColumnWriter.html', 'Parquet.DeleteWriteBuilder.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetAvroReader.html', 'ParquetAvroValueReaders.TimeMillisReader.html', 'ParquetAvroValueReaders.TimestampMillisReader.html', 'ParquetAvroValueReaders.html', 'ParquetAvroWriter.html', 'ParquetDictionaryRowGroupFilter.html', 'ParquetIterable.html', 'ParquetMetricsRowGroupFilter.html', 'ParquetReader.html', 'ParquetSchemaUtil.HasIds.html', 'ParquetSchemaUtil.html', 'ParquetTypeVisitor.html', 'ParquetUtil.html', 'ParquetValueReader.html', 'ParquetValueReaders.BinaryAsDecimalReader.html', 'ParquetValueReaders.ByteArrayReader.html', 'ParquetValueReaders.BytesReader.html', 'ParquetValueReaders.FloatAsDoubleReader.html', 'ParquetValueReaders.IntAsLongReader.html', 'ParquetValueReaders.IntegerAsDecimalReader.html', 'ParquetValueReaders.ListReader.html', 'ParquetValueReaders.LongAsDecimalReader.html', 'ParquetValueReaders.MapReader.html', 'ParquetValueReaders.PrimitiveReader.html', 'ParquetValueReaders.RepeatedKeyValueReader.html', 'ParquetValueReaders.RepeatedReader.html', 'ParquetValueReaders.ReusableEntry.html', 'ParquetValueReaders.StringReader.html', 'ParquetValueReaders.StructReader.html', 'ParquetValueReaders.UnboxedReader.html', 'ParquetValueReaders.html', 'ParquetValueWriter.html', 'ParquetValueWriters.PositionDeleteStructWriter.html', 'ParquetValueWriters.PrimitiveWriter.html', 'ParquetValueWriters.RepeatedKeyValueWriter.html', 'ParquetValueWriters.RepeatedWriter.html', 'ParquetValueWriters.StructWriter.html', 'ParquetValueWriters.html', 'ParquetWriteAdapter.html', 'RemoveIds.html', 'TripleWriter.html', 'TypeToMessageType.html', 'TypeWithSchemaVisitor.html', 'ValuesAsBytesReader.html', 'VectorizedParquetReader.html', 'VectorizedReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergPigInputFormat.IcebergRecordReader.html', 'IcebergPigInputFormat.html', 'IcebergStorage.html', 'PigParquetReader.html', 'SchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'SchemaWithPartnerVisitor.PartnerAccessors.html', 'SchemaWithPartnerVisitor.html', 'UnionByNameVisitor.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSpark.html', 'PathIdentifier.html', 'PruneColumnsWithReordering.html', 'PruneColumnsWithoutReordering.html', 'RollbackStagedTable.html', 'Spark3Util.CatalogAndIdentifier.html', 'Spark3Util.DescribeSchemaVisitor.html', 'Spark3Util.html', 'SparkCatalog.html', 'SparkDataFile.html', 'SparkExceptionUtil.html', 'SparkFilters.html', 'SparkReadOptions.html', 'SparkSchemaUtil.html', 'SparkSessionCatalog.html', 'SparkStructLike.html', 'SparkTableUtil.SparkPartition.html', 'SparkTableUtil.html', 'SparkUtil.html', 'SparkValueConverter.html', 'SparkWriteOptions.html', 'AvroWithSparkSchemaVisitor.html', 'ParquetWithSparkSchemaVisitor.html', 'SparkAvroReader.html', 'SparkAvroWriter.html', 'SparkOrcReader.html', 'SparkOrcValueReaders.html', 'SparkOrcWriter.html', 'SparkParquetReaders.html', 'SparkParquetWriters.html', 'SparkValueReaders.html', 'SparkValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ArrowVectorAccessor.html', 'ArrowVectorAccessors.html', 'ColumnarBatchReader.html', 'IcebergArrowColumnVector.html', 'RowPostitionColumnVector.html', 'VectorizedSparkOrcReaders.html', 'VectorizedSparkParquetReaders.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ExpireSnapshotsProcedure.html', 'RemoveOrphanFilesProcedure.html', 'SparkProcedures.ProcedureBuilder.html', 'SparkProcedures.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CustomCatalogs.html', 'IcebergSource.html', 'RowDataRewriter.html', 'SparkPartitionedFanoutWriter.html', 'SparkPartitionedWriter.html', 'SparkScanBuilder.html', 'SparkTable.html', 'StagedSparkTable.html', 'Stats.html', 'StreamingWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PartitionSpecVisitor.html', 'SortOrderVisitor.html', 'Transform.html', 'Transforms.html', 'UnknownTransform.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CheckCompatibility.html', 'Comparators.html', 'Conversions.html', 'FixupTypes.html', 'IndexByName.html', 'IndexParents.html', 'JavaHash.html', 'JavaHashes.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ArrayUtil.html', 'BinPacking.ListPacker.html', 'BinPacking.PackingIterable.html', 'BinPacking.html', 'BinaryUtil.html', 'ByteBuffers.html', 'CharSequenceSet.html', 'CharSequenceWrapper.html', 'DateTimeUtil.html', 'DecimalUtil.html', 'ExceptionUtil.Block.html', 'ExceptionUtil.CatchBlock.html', 'ExceptionUtil.FinallyBlock.html', 'ExceptionUtil.html', 'Exceptions.html', 'Filter.html', 'JsonUtil.html', 'ManifestFileUtil.html', 'NaNUtil.html', 'Pair.html', 'ParallelIterable.html', 'PartitionSet.html', 'PartitionUtil.html', 'PropertyUtil.html', 'SerializableSupplier.html', 'SerializationUtil.html', 'SnapshotUtil.html', 'SortedMerge.html', 'StructLikeMap.html', 'StructLikeSet.html', 'StructLikeWrapper.html', 'StructProjection.html', 'TableScanUtil.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'ThreadPools.html', 'UUIDUtil.html', 'UnicodeUtil.html', 'WapUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'NoSuchProcedureException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSqlExtensionsBaseListener.html', 'IcebergSqlExtensionsBaseVisitor.html', 'IcebergSqlExtensionsLexer.html', 'IcebergSqlExtensionsListener.html', 'IcebergSqlExtensionsParser.AddPartitionFieldContext.html', 'IcebergSqlExtensionsParser.ApplyTransformContext.html', 'IcebergSqlExtensionsParser.BigDecimalLiteralContext.html', 'IcebergSqlExtensionsParser.BigIntLiteralContext.html', 'IcebergSqlExtensionsParser.BooleanLiteralContext.html', 'IcebergSqlExtensionsParser.BooleanValueContext.html', 'IcebergSqlExtensionsParser.CallArgumentContext.html', 'IcebergSqlExtensionsParser.CallContext.html', 'IcebergSqlExtensionsParser.ConstantContext.html', 'IcebergSqlExtensionsParser.DecimalLiteralContext.html', 'IcebergSqlExtensionsParser.DoubleLiteralContext.html', 'IcebergSqlExtensionsParser.DropPartitionFieldContext.html', 'IcebergSqlExtensionsParser.ExponentLiteralContext.html', 'IcebergSqlExtensionsParser.ExpressionContext.html', 'IcebergSqlExtensionsParser.FloatLiteralContext.html', 'IcebergSqlExtensionsParser.IdentifierContext.html', 'IcebergSqlExtensionsParser.IdentityTransformContext.html', 'IcebergSqlExtensionsParser.IntegerLiteralContext.html', 'IcebergSqlExtensionsParser.MultipartIdentifierContext.html', 'IcebergSqlExtensionsParser.NamedArgumentContext.html', 'IcebergSqlExtensionsParser.NonReservedContext.html', 'IcebergSqlExtensionsParser.NumberContext.html', 'IcebergSqlExtensionsParser.NumericLiteralContext.html', 'IcebergSqlExtensionsParser.OrderContext.html', 'IcebergSqlExtensionsParser.OrderFieldContext.html', 'IcebergSqlExtensionsParser.PositionalArgumentContext.html', 'IcebergSqlExtensionsParser.QuotedIdentifierAlternativeContext.html', 'IcebergSqlExtensionsParser.QuotedIdentifierContext.html', 'IcebergSqlExtensionsParser.SetTableOrderContext.html', 'IcebergSqlExtensionsParser.SingleStatementContext.html', 'IcebergSqlExtensionsParser.SmallIntLiteralContext.html', 'IcebergSqlExtensionsParser.StatementContext.html', 'IcebergSqlExtensionsParser.StringLiteralContext.html', 'IcebergSqlExtensionsParser.StringMapContext.html', 'IcebergSqlExtensionsParser.TinyIntLiteralContext.html', 'IcebergSqlExtensionsParser.TransformArgumentContext.html', 'IcebergSqlExtensionsParser.TransformContext.html', 'IcebergSqlExtensionsParser.TypeConstructorContext.html', 'IcebergSqlExtensionsParser.UnquotedIdentifierContext.html', 'IcebergSqlExtensionsParser.html', 'IcebergSqlExtensionsVisitor.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ExtendedSupportsDelete.html', 'Procedure.html', 'ProcedureCatalog.html', 'ProcedureParameter.html', 'SupportsMerge.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ClusteredDistribution.html', 'Distribution.html', 'Distributions.html', 'OrderedDistribution.html', 'UnspecifiedDistribution.html', 'ClusterDistributionImpl.html', 'OrderedDistributionImpl.html', 'UnspecifiedDistributionImpl.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'NullOrdering.html', 'SortDirection.html', 'SortOrder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'SupportsFileFilter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'MergeBuilder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'overview-frame.html', 'overview-summary.html', 'overview-tree.html', 'package-list', 'script.js', 'serialized-form.html', 'stylesheet.css', 'allclasses-index.html', 'allclasses.html', 'allpackages-index.html', 'constant-values.html', 'deprecated-list.html', 'help-doc.html', 'index-all.html', 'index.html', 'jquery.js', 'ui-bg_glass_55_fbf9ee_1x400.png', 'ui-bg_glass_65_dadada_1x400.png', 'ui-bg_glass_75_dadada_1x400.png', 'ui-bg_glass_75_e6e6e6_1x400.png', 'ui-bg_glass_95_fef1ec_1x400.png', 'ui-bg_highlight-soft_75_cccccc_1x100.png', 'ui-icons_222222_256x240.png', 'ui-icons_2e83ff_256x240.png', 'ui-icons_454545_256x240.png', 'ui-icons_888888_256x240.png', 'ui-icons_cd0a0a_256x240.png', 'jquery-3.5.1.js', 'jquery-ui.css', 'jquery-ui.js', 'jquery-ui.min.css', 'jquery-ui.min.js', 'jquery-ui.structure.css', 'jquery-ui.structure.min.css', 'member-search-index.js', 'member-search-index.zip', 'VectorizedSupport.Support.html', 'VectorizedSupport.html', 'package-summary.html', 'package-tree.html', 'Accessor.html', 'Accessors.html', 'AllDataFilesTable.AllDataFilesTableScan.html', 'AllDataFilesTable.html', 'AllEntriesTable.html', 'AllManifestsTable.AllManifestsTableScan.html', 'AllManifestsTable.html', 'AppendFiles.html', 'BaseCombinedScanTask.html', 'BaseMetastoreCatalog.BaseMetastoreCatalogTableBuilder.html', 'BaseMetastoreCatalog.html', 'BaseMetastoreTableOperations.CommitStatus.html', 'BaseMetastoreTableOperations.html', 'BaseOverwriteFiles.html', 'BaseReplacePartitions.html', 'BaseReplaceSortOrder.html', 'BaseRewriteManifests.html', 'BaseTable.html', 'CachingCatalog.html', 'CatalogProperties.html', 'CatalogUtil.html', 'ClientPool.Action.html', 'ClientPool.html', 'ClientPoolImpl.html', 'CombinedScanTask.html', 'ContentFile.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DataFilesTable.FilesTableScan.html', 'DataFilesTable.html', 'DataOperations.html', 'DataTableScan.html', 'DataTask.html', 'DeleteFile.html', 'DeleteFiles.html', 'DistributionMode.html', 'DoubleFieldMetrics.Builder.html', 'DoubleFieldMetrics.html', 'ExpireSnapshots.html', 'FieldMetrics.html', 'FileContent.html', 'FileFormat.html', 'FileMetadata.Builder.html', 'FileMetadata.html', 'FileScanTask.html', 'Files.html', 'FindFiles.Builder.html', 'FindFiles.html', 'FloatFieldMetrics.Builder.html', 'FloatFieldMetrics.html', 'GenericManifestFile.CopyBuilder.html', 'GenericManifestFile.html', 'GenericPartitionFieldSummary.html', 'GuavaClasses.html', 'HasTableOperations.html', 'HistoryEntry.html', 'HistoryTable.html', 'IsolationLevel.html', 'LocationProviders.html', 'ManageSnapshots.html', 'ManifestContent.html', 'ManifestEntriesTable.html', 'ManifestFile.PartitionFieldSummary.html', 'ManifestFile.html', 'ManifestFiles.html', 'ManifestReader.FileType.html', 'ManifestReader.html', 'ManifestWriter.html', 'ManifestsTable.html', 'MetadataColumns.html', 'MetadataTableType.html', 'MetadataTableUtils.html', 'Metrics.html', 'MetricsConfig.html', 'MetricsModes.Counts.html', 'MetricsModes.Full.html', 'MetricsModes.MetricsMode.html', 'MetricsModes.None.html', 'MetricsModes.Truncate.html', 'MetricsModes.html', 'MetricsUtil.html', 'MicroBatches.MicroBatch.html', 'MicroBatches.MicroBatchBuilder.html', 'MicroBatches.html', 'NullOrder.html', 'OverwriteFiles.html', 'PartitionField.html', 'PartitionKey.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'Partitioning.html', 'PartitionsTable.html', 'PendingUpdate.html', 'ReachableFileUtil.html', 'ReplacePartitions.html', 'ReplaceSortOrder.html', 'RewriteFiles.html', 'RewriteManifests.html', 'Rollback.html', 'RowDelta.html', 'ScanSummary.Builder.html', 'ScanSummary.PartitionMetrics.html', 'ScanSummary.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'SerializableTable.html', 'SetLocation.html', 'Snapshot.html', 'SnapshotManager.html', 'SnapshotParser.html', 'SnapshotSummary.Builder.html', 'SnapshotSummary.html', 'SnapshotUpdate.html', 'SnapshotsTable.html', 'SortDirection.html', 'SortField.html', 'SortOrder.Builder.html', 'SortOrder.html', 'SortOrderBuilder.html', 'SortOrderParser.html', 'StaticTableOperations.html', 'StructLike.html', 'SystemProperties.html', 'Table.html', 'TableMetadata.MetadataLogEntry.html', 'TableMetadata.SnapshotLogEntry.html', 'TableMetadata.html', 'TableMetadataParser.Codec.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableProperties.html', 'TableScan.html', 'Tables.html', 'Transaction.html', 'Transactions.html', 'UpdateLocation.html', 'UpdatePartitionSpec.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Action.html', 'Actions.html', 'ActionsProvider.html', 'BaseDeleteOrphanFilesActionResult.html', 'BaseDeleteReachableFilesActionResult.html', 'BaseExpireSnapshotsActionResult.html', 'BaseFileGroupRewriteResult.html', 'BaseMigrateTableActionResult.html', 'BaseRewriteDataFilesAction.html', 'BaseRewriteDataFilesFileGroupInfo.html', 'BaseRewriteDataFilesResult.html', 'BaseRewriteManifestsActionResult.html', 'BaseSnapshotTableActionResult.html', 'BinPackStrategy.html', 'CreateAction.html', 'DeleteOrphanFiles.Result.html', 'DeleteOrphanFiles.html', 'DeleteReachableFiles.Result.html', 'DeleteReachableFiles.html', 'ExpireSnapshots.Result.html', 'ExpireSnapshots.html', 'ExpireSnapshotsAction.html', 'ExpireSnapshotsActionResult.html', 'ManifestFileBean.html', 'MigrateTable.Result.html', 'MigrateTable.html', 'RemoveOrphanFilesAction.html', 'RewriteDataFiles.FileGroupInfo.html', 'RewriteDataFiles.FileGroupRewriteResult.html', 'RewriteDataFiles.Result.html', 'RewriteDataFiles.html', 'RewriteDataFilesAction.html', 'RewriteDataFilesActionResult.html', 'RewriteDataFilesCommitManager.CommitService.html', 'RewriteDataFilesCommitManager.html', 'RewriteFileGroup.html', 'RewriteManifests.Result.html', 'RewriteManifests.html', 'RewriteManifestsAction.html', 'RewriteManifestsActionResult.html', 'RewriteStrategy.html', 'SnapshotAction.html', 'SnapshotTable.Result.html', 'SnapshotTable.html', 'SnapshotUpdate.html', 'SnapshotUpdateAction.html', 'SortStrategy.html', 'Spark3MigrateAction.html', 'Spark3SnapshotAction.html', 'SparkActions.html', 'package-summary.html', 'package-tree.html', 'ArrowAllocation.html', 'ArrowSchemaUtil.html', 'package-summary.html', 'package-tree.html', 'ArrowReader.html', 'ArrowVectorAccessor.html', 'ColumnVector.html', 'ColumnarBatch.html', 'GenericArrowVectorAccessorFactory.ArrayFactory.html', 'GenericArrowVectorAccessorFactory.DecimalFactory.html', 'GenericArrowVectorAccessorFactory.StringFactory.html', 'GenericArrowVectorAccessorFactory.StructChildFactory.html', 'GenericArrowVectorAccessorFactory.html', 'NullabilityHolder.html', 'VectorHolder.ConstantVectorHolder.html', 'VectorHolder.PositionVectorHolder.html', 'VectorHolder.html', 'VectorizedArrowReader.ConstantVectorReader.html', 'VectorizedArrowReader.html', 'VectorizedReaderBuilder.html', 'VectorizedTableScanIterable.html', 'package-summary.html', 'package-tree.html', 'BaseVectorizedParquetValuesReader.html', 'VectorizedColumnIterator.BatchReader.html', 'VectorizedColumnIterator.BooleanBatchReader.html', 'VectorizedColumnIterator.DictionaryBatchReader.html', 'VectorizedColumnIterator.DoubleBatchReader.html', 'VectorizedColumnIterator.FixedLengthDecimalBatchReader.html', 'VectorizedColumnIterator.FixedSizeBinaryBatchReader.html', 'VectorizedColumnIterator.FixedWidthTypeBinaryBatchReader.html', 'VectorizedColumnIterator.FloatBatchReader.html', 'VectorizedColumnIterator.IntBackedDecimalBatchReader.html', 'VectorizedColumnIterator.IntegerBatchReader.html', 'VectorizedColumnIterator.LongBackedDecimalBatchReader.html', 'VectorizedColumnIterator.LongBatchReader.html', 'VectorizedColumnIterator.TimestampMillisBatchReader.html', 'VectorizedColumnIterator.VarWidthTypeBatchReader.html', 'VectorizedColumnIterator.html', 'VectorizedDictionaryEncodedParquetValuesReader.html', 'VectorizedPageIterator.html', 'VectorizedParquetDefinitionLevelReader.html', 'package-summary.html', 'package-tree.html', 'Avro.DataWriteBuilder.html', 'Avro.DeleteWriteBuilder.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroEncoderUtil.html', 'AvroIterable.html', 'AvroMetrics.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'AvroSchemaWithTypeVisitor.html', 'AvroWithPartnerByStructureVisitor.html', 'LogicalMap.html', 'MetricsAwareDatumWriter.html', 'ProjectionDatumReader.html', 'RemoveIds.html', 'SupportsRowPosition.html', 'UUIDConversion.html', 'ValueReader.html', 'ValueReaders.StructReader.html', 'ValueReaders.html', 'ValueWriter.html', 'ValueWriters.StructWriter.html', 'ValueWriters.html', 'package-summary.html', 'package-tree.html', 'AssumeRoleAwsClientFactory.html', 'AwsClientFactories.html', 'AwsClientFactory.html', 'AwsProperties.html', 'DynamoDbCatalog.html', 'package-summary.html', 'package-tree.html', 'GlueCatalog.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'S3FileIO.html', 'S3InputFile.html', 'S3OutputFile.html', 'S3RequestUtil.html', 'package-summary.html', 'package-tree.html', 'Catalog.TableBuilder.html', 'Catalog.html', 'Namespace.html', 'SupportsNamespaces.html', 'TableIdentifier.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-summary.html', 'package-tree.html', 'BaseWriterFactory.html', 'DeleteFilter.html', 'GenericAppenderFactory.html', 'GenericDeleteFilter.html', 'GenericRecord.html', 'IcebergGenerics.ScanBuilder.html', 'IcebergGenerics.html', 'IdentityPartitionConverters.html', 'InternalRecordWrapper.html', 'Record.html', 'TableMigrationUtil.html', 'DataReader.html', 'DataWriter.html', 'DecoderResolver.html', 'IcebergDecoder.html', 'IcebergEncoder.html', 'package-summary.html', 'package-tree.html', 'GenericOrcReader.html', 'GenericOrcReaders.html', 'GenericOrcWriter.html', 'GenericOrcWriters.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'BaseParquetReaders.html', 'BaseParquetWriter.html', 'GenericParquetReaders.html', 'GenericParquetWriter.html', 'package-summary.html', 'package-tree.html', 'Deletes.html', 'EqualityDeleteWriter.html', 'PositionDelete.html', 'PositionDeleteWriter.html', 'package-summary.html', 'package-tree.html', 'EncryptedFiles.html', 'EncryptedInputFile.html', 'EncryptedOutputFile.html', 'EncryptionKeyMetadata.html', 'EncryptionKeyMetadatas.html', 'EncryptionManager.html', 'PlaintextEncryptionManager.html', 'package-summary.html', 'package-tree.html', 'CreateSnapshotEvent.html', 'IncrementalScanEvent.html', 'Listener.html', 'Listeners.html', 'ScanEvent.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CherrypickAncestorCommitException.html', 'CommitFailedException.html', 'CommitStateUnknownException.html', 'DuplicateWAPCommitException.html', 'NamespaceNotEmptyException.html', 'NoSuchIcebergTableException.html', 'NoSuchNamespaceException.html', 'NoSuchTableException.html', 'NotFoundException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'Bound.html', 'BoundLiteralPredicate.html', 'BoundPredicate.html', 'BoundReference.html', 'BoundSetPredicate.html', 'BoundTerm.html', 'BoundTransform.html', 'BoundUnaryPredicate.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.BoundVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'InclusiveMetricsEvaluator.html', 'Literal.html', 'ManifestEvaluator.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'StrictMetricsEvaluator.html', 'Term.html', 'True.html', 'Unbound.html', 'UnboundPredicate.html', 'UnboundTerm.html', 'UnboundTransform.html', 'package-summary.html', 'package-tree.html', 'CatalogLoader.CustomCatalogLoader.html', 'CatalogLoader.HadoopCatalogLoader.html', 'CatalogLoader.HiveCatalogLoader.html', 'CatalogLoader.html', 'FlinkCatalog.html', 'FlinkCatalogFactory.html', 'FlinkConfigOptions.html', 'FlinkDynamicTableFactory.html', 'FlinkFilters.html', 'FlinkSchemaUtil.html', 'FlinkTypeVisitor.html', 'IcebergTableSink.html', 'IcebergTableSource.html', 'RowDataWrapper.html', 'TableLoader.CatalogTableLoader.html', 'TableLoader.HadoopTableLoader.html', 'TableLoader.html', 'Actions.html', 'RewriteDataFilesAction.html', 'package-summary.html', 'package-tree.html', 'AvroWithFlinkSchemaVisitor.html', 'FlinkAvroReader.html', 'FlinkAvroWriter.html', 'FlinkOrcReader.html', 'FlinkOrcWriter.html', 'FlinkParquetReaders.html', 'FlinkParquetWriters.html', 'FlinkValueReaders.html', 'FlinkValueWriters.html', 'ParquetWithFlinkSchemaVisitor.html', 'RowDataUtil.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'FlinkAppenderFactory.html', 'FlinkSink.Builder.html', 'FlinkSink.html', 'RowDataTaskWriterFactory.html', 'TaskWriterFactory.html', 'package-summary.html', 'package-tree.html', 'FlinkInputFormat.html', 'FlinkInputSplit.html', 'FlinkSource.Builder.html', 'FlinkSource.html', 'RowDataRewriter.RewriteMap.html', 'RowDataRewriter.html', 'StreamingMonitorFunction.html', 'StreamingReaderOperator.html', 'package-summary.html', 'package-tree.html', 'FlinkCompatibilityUtil.html', 'package-summary.html', 'package-tree.html', 'ConfigProperties.html', 'HadoopCatalog.html', 'HadoopConfigurable.html', 'HadoopFileIO.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTableOperations.html', 'HadoopTables.html', 'HiddenPathFilter.html', 'SerializableConfiguration.html', 'Util.html', 'package-summary.html', 'package-tree.html', 'CachedClientPool.html', 'HiveCatalog.html', 'HiveCatalogs.html', 'HiveClientPool.html', 'HiveSchemaUtil.html', 'HiveTableOperations.html', 'MetastoreUtil.html', 'RuntimeMetaException.html', 'package-summary.html', 'package-tree.html', 'BaseTaskWriter.BaseEqualityDeltaWriter.html', 'BaseTaskWriter.RollingEqDeleteWriter.html', 'BaseTaskWriter.RollingFileWriter.html', 'BaseTaskWriter.html', 'CloseableGroup.html', 'CloseableIterable.ConcatCloseableIterable.html', 'CloseableIterable.html', 'CloseableIterator.html', 'ClosingIterator.html', 'DataWriter.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'DeleteSchemaUtil.html', 'FileAppender.html', 'FileAppenderFactory.html', 'FileIO.html', 'FilterIterator.html', 'InputFile.html', 'LocationProvider.html', 'OutputFile.html', 'OutputFileFactory.Builder.html', 'OutputFileFactory.html', 'PartitionedFanoutWriter.html', 'PartitionedWriter.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'TaskWriter.html', 'UnpartitionedWriter.html', 'WriteResult.Builder.html', 'WriteResult.html', 'WriterFactory.html', 'package-summary.html', 'package-tree.html', 'JdbcCatalog.html', 'UncheckedInterruptedException.html', 'UncheckedSQLException.html', 'package-summary.html', 'package-tree.html', 'MappedField.html', 'MappedFields.html', 'MappingUtil.html', 'NameMapping.html', 'NameMappingParser.html', 'package-summary.html', 'package-tree.html', 'Catalogs.html', 'InputFormatConfig.ConfigBuilder.html', 'InputFormatConfig.InMemoryDataModel.html', 'InputFormatConfig.html', 'HiveIcebergFilterFactory.html', 'HiveIcebergInputFormat.html', 'HiveIcebergMetaHook.html', 'HiveIcebergOutputCommitter.html', 'HiveIcebergOutputFormat.html', 'HiveIcebergSerDe.html', 'HiveIcebergSplit.html', 'HiveIcebergStorageHandler.html', 'TezUtil.html', 'package-summary.html', 'package-tree.html', 'IcebergBinaryObjectInspector.html', 'IcebergDateObjectInspector.html', 'IcebergDecimalObjectInspector.html', 'IcebergFixedObjectInspector.html', 'IcebergObjectInspector.html', 'IcebergRecordObjectInspector.html', 'IcebergTimeObjectInspector.html', 'IcebergTimestampObjectInspector.html', 'IcebergTimestampWithZoneObjectInspector.html', 'IcebergUUIDObjectInspector.html', 'WriteObjectInspector.html', 'package-summary.html', 'package-tree.html', 'AbstractMapredIcebergRecordReader.html', 'Container.html', 'MapredIcebergInputFormat.CompatibilityTaskAttemptContextImpl.html', 'MapredIcebergInputFormat.html', 'package-summary.html', 'package-tree.html', 'IcebergInputFormat.html', 'IcebergSplit.html', 'IcebergSplitContainer.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'NessieCatalog.html', 'NessieTableOperations.html', 'NessieUtil.html', 'TableReference.html', 'package-summary.html', 'package-tree.html', 'ORC.DataWriteBuilder.html', 'ORC.ReadBuilder.html', 'ORC.WriteBuilder.html', 'ORC.html', 'ORCSchemaUtil.BinaryType.html', 'ORCSchemaUtil.LongType.html', 'ORCSchemaUtil.html', 'OrcBatchReader.html', 'OrcMetrics.html', 'OrcRowReader.html', 'OrcRowWriter.html', 'OrcSchemaVisitor.html', 'OrcSchemaWithTypeVisitor.html', 'OrcValueReader.html', 'OrcValueReaders.StructReader.html', 'OrcValueReaders.html', 'OrcValueWriter.html', 'VectorizedRowBatchIterator.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'BaseColumnIterator.html', 'BasePageIterator.IntIterator.html', 'BasePageIterator.html', 'ColumnIterator.html', 'ColumnWriter.html', 'Parquet.DataWriteBuilder.html', 'Parquet.DeleteWriteBuilder.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetAvroReader.html', 'ParquetAvroValueReaders.TimeMillisReader.html', 'ParquetAvroValueReaders.TimestampMillisReader.html', 'ParquetAvroValueReaders.html', 'ParquetAvroWriter.html', 'ParquetDictionaryRowGroupFilter.html', 'ParquetIterable.html', 'ParquetMetricsRowGroupFilter.html', 'ParquetReader.html', 'ParquetSchemaUtil.HasIds.html', 'ParquetSchemaUtil.html', 'ParquetTypeVisitor.html', 'ParquetUtil.html', 'ParquetValueReader.html', 'ParquetValueReaders.BinaryAsDecimalReader.html', 'ParquetValueReaders.ByteArrayReader.html', 'ParquetValueReaders.BytesReader.html', 'ParquetValueReaders.FloatAsDoubleReader.html', 'ParquetValueReaders.IntAsLongReader.html', 'ParquetValueReaders.IntegerAsDecimalReader.html', 'ParquetValueReaders.ListReader.html', 'ParquetValueReaders.LongAsDecimalReader.html', 'ParquetValueReaders.MapReader.html', 'ParquetValueReaders.PrimitiveReader.html', 'ParquetValueReaders.RepeatedKeyValueReader.html', 'ParquetValueReaders.RepeatedReader.html', 'ParquetValueReaders.ReusableEntry.html', 'ParquetValueReaders.StringReader.html', 'ParquetValueReaders.StructReader.html', 'ParquetValueReaders.UnboxedReader.html', 'ParquetValueReaders.html', 'ParquetValueWriter.html', 'ParquetValueWriters.PositionDeleteStructWriter.html', 'ParquetValueWriters.PrimitiveWriter.html', 'ParquetValueWriters.RepeatedKeyValueWriter.html', 'ParquetValueWriters.RepeatedWriter.html', 'ParquetValueWriters.StructWriter.html', 'ParquetValueWriters.html', 'ParquetWriteAdapter.html', 'RemoveIds.html', 'TripleWriter.html', 'TypeToMessageType.html', 'TypeWithSchemaVisitor.html', 'ValuesAsBytesReader.html', 'VectorizedParquetReader.html', 'VectorizedReader.html', 'package-summary.html', 'package-tree.html', 'IcebergPigInputFormat.IcebergRecordReader.html', 'IcebergPigInputFormat.html', 'IcebergStorage.html', 'PigParquetReader.html', 'SchemaUtil.html', 'package-summary.html', 'package-tree.html', 'SchemaWithPartnerVisitor.PartnerAccessors.html', 'SchemaWithPartnerVisitor.html', 'UnionByNameVisitor.html', 'package-summary.html', 'package-tree.html', 'FileRewriteCoordinator.html', 'FileScanTaskSetManager.html', 'IcebergSpark.html', 'JobGroupInfo.html', 'JobGroupUtils.html', 'PathIdentifier.html', 'PruneColumnsWithReordering.html', 'PruneColumnsWithoutReordering.html', 'RollbackStagedTable.html', 'Spark3Util.CatalogAndIdentifier.html', 'Spark3Util.DescribeSchemaVisitor.html', 'Spark3Util.html', 'Spark3VersionUtil.html', 'SparkCatalog.html', 'SparkDataFile.html', 'SparkExceptionUtil.html', 'SparkFilters.html', 'SparkReadOptions.html', 'SparkSchemaUtil.html', 'SparkSessionCatalog.html', 'SparkStructLike.html', 'SparkTableUtil.SparkPartition.html', 'SparkTableUtil.html', 'SparkUtil.html', 'SparkValueConverter.html', 'SparkWriteOptions.html', 'BaseDeleteOrphanFilesSparkAction.html', 'BaseDeleteReachableFilesSparkAction.html', 'BaseExpireSnapshotsSparkAction.html', 'BaseMigrateTableSparkAction.html', 'BaseRewriteDataFilesSpark3Action.html', 'BaseRewriteManifestsSparkAction.html', 'BaseSnapshotTableSparkAction.html', 'Spark3BinPackStrategy.html', 'SparkActions.html', 'package-summary.html', 'package-tree.html', 'AvroWithSparkSchemaVisitor.html', 'ParquetWithSparkSchemaVisitor.html', 'SparkAvroReader.html', 'SparkAvroWriter.html', 'SparkOrcReader.html', 'SparkOrcValueReaders.html', 'SparkOrcWriter.html', 'SparkParquetReaders.html', 'SparkParquetWriters.html', 'SparkValueReaders.html', 'SparkValueWriters.html', 'package-summary.html', 'package-tree.html', 'ArrowVectorAccessors.html', 'ColumnarBatchReader.html', 'IcebergArrowColumnVector.html', 'RowPositionColumnVector.html', 'VectorizedSparkOrcReaders.html', 'VectorizedSparkParquetReaders.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'ExpireSnapshotsProcedure.html', 'RemoveOrphanFilesProcedure.html', 'SparkProcedures.ProcedureBuilder.html', 'SparkProcedures.html', 'package-summary.html', 'package-tree.html', 'EqualityDeleteRowReader.html', 'IcebergSource.html', 'RowDataRewriter.html', 'SparkMicroBatchStream.html', 'SparkPartitionedFanoutWriter.html', 'SparkPartitionedWriter.html', 'SparkRewriteBuilder.html', 'SparkScanBuilder.html', 'SparkTable.html', 'StagedSparkTable.html', 'package-summary.html', 'package-tree.html', 'PartitionSpecVisitor.html', 'SortOrderVisitor.html', 'Transform.html', 'Transforms.html', 'UnknownTransform.html', 'package-summary.html', 'package-tree.html', 'CheckCompatibility.html', 'Comparators.html', 'Conversions.html', 'FixupTypes.html', 'IndexByName.html', 'IndexParents.html', 'JavaHash.html', 'JavaHashes.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-summary.html', 'package-tree.html', 'ArrayUtil.html', 'BinPacking.ListPacker.html', 'BinPacking.PackingIterable.html', 'BinPacking.html', 'BinaryUtil.html', 'ByteBuffers.html', 'CharSequenceSet.html', 'CharSequenceWrapper.html', 'DateTimeUtil.html', 'DecimalUtil.html', 'ExceptionUtil.Block.html', 'ExceptionUtil.CatchBlock.html', 'ExceptionUtil.FinallyBlock.html', 'ExceptionUtil.html', 'Exceptions.html', 'Filter.html', 'JsonUtil.html', 'ManifestFileUtil.html', 'NaNUtil.html', 'Pair.html', 'ParallelIterable.html', 'PartitionSet.html', 'PartitionUtil.html', 'PropertyUtil.html', 'SerializableMap.html', 'SerializableSupplier.html', 'SerializationUtil.html', 'SnapshotUtil.html', 'SortOrderUtil.html', 'SortedMerge.html', 'StructLikeMap.html', 'StructLikeSet.html', 'StructLikeWrapper.html', 'StructProjection.html', 'TableScanUtil.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'ThreadPools.html', 'UUIDUtil.html', 'UnicodeUtil.html', 'WapUtil.html', 'package-summary.html', 'package-tree.html', 'NoSuchProcedureException.html', 'package-summary.html', 'package-tree.html', 'IcebergSqlExtensionsBaseListener.html', 'IcebergSqlExtensionsBaseVisitor.html', 'IcebergSqlExtensionsLexer.html', 'IcebergSqlExtensionsListener.html', 'IcebergSqlExtensionsParser.AddPartitionFieldContext.html', 'IcebergSqlExtensionsParser.ApplyTransformContext.html', 'IcebergSqlExtensionsParser.BigDecimalLiteralContext.html', 'IcebergSqlExtensionsParser.BigIntLiteralContext.html', 'IcebergSqlExtensionsParser.BooleanLiteralContext.html', 'IcebergSqlExtensionsParser.BooleanValueContext.html', 'IcebergSqlExtensionsParser.CallArgumentContext.html', 'IcebergSqlExtensionsParser.CallContext.html', 'IcebergSqlExtensionsParser.ConstantContext.html', 'IcebergSqlExtensionsParser.DecimalLiteralContext.html', 'IcebergSqlExtensionsParser.DoubleLiteralContext.html', 'IcebergSqlExtensionsParser.DropIdentifierFieldsContext.html', 'IcebergSqlExtensionsParser.DropPartitionFieldContext.html', 'IcebergSqlExtensionsParser.ExponentLiteralContext.html', 'IcebergSqlExtensionsParser.ExpressionContext.html', 'IcebergSqlExtensionsParser.FieldListContext.html', 'IcebergSqlExtensionsParser.FloatLiteralContext.html', 'IcebergSqlExtensionsParser.IdentifierContext.html', 'IcebergSqlExtensionsParser.IdentityTransformContext.html', 'IcebergSqlExtensionsParser.IntegerLiteralContext.html', 'IcebergSqlExtensionsParser.MultipartIdentifierContext.html', 'IcebergSqlExtensionsParser.NamedArgumentContext.html', 'IcebergSqlExtensionsParser.NonReservedContext.html', 'IcebergSqlExtensionsParser.NumberContext.html', 'IcebergSqlExtensionsParser.NumericLiteralContext.html', 'IcebergSqlExtensionsParser.OrderContext.html', 'IcebergSqlExtensionsParser.OrderFieldContext.html', 'IcebergSqlExtensionsParser.PositionalArgumentContext.html', 'IcebergSqlExtensionsParser.QuotedIdentifierAlternativeContext.html', 'IcebergSqlExtensionsParser.QuotedIdentifierContext.html', 'IcebergSqlExtensionsParser.ReplacePartitionFieldContext.html', 'IcebergSqlExtensionsParser.SetIdentifierFieldsContext.html', 'IcebergSqlExtensionsParser.SetWriteDistributionAndOrderingContext.html', 'IcebergSqlExtensionsParser.SingleStatementContext.html', 'IcebergSqlExtensionsParser.SmallIntLiteralContext.html', 'IcebergSqlExtensionsParser.StatementContext.html', 'IcebergSqlExtensionsParser.StringLiteralContext.html', 'IcebergSqlExtensionsParser.StringMapContext.html', 'IcebergSqlExtensionsParser.TinyIntLiteralContext.html', 'IcebergSqlExtensionsParser.TransformArgumentContext.html', 'IcebergSqlExtensionsParser.TransformContext.html', 'IcebergSqlExtensionsParser.TypeConstructorContext.html', 'IcebergSqlExtensionsParser.UnquotedIdentifierContext.html', 'IcebergSqlExtensionsParser.WriteDistributionSpecContext.html', 'IcebergSqlExtensionsParser.WriteOrderingSpecContext.html', 'IcebergSqlExtensionsParser.WriteSpecContext.html', 'IcebergSqlExtensionsParser.html', 'IcebergSqlExtensionsVisitor.html', 'package-summary.html', 'package-tree.html', 'ExtendedSupportsDelete.html', 'Procedure.html', 'ProcedureCatalog.html', 'ProcedureParameter.html', 'SupportsMerge.html', 'package-summary.html', 'package-tree.html', 'ClusteredDistribution.html', 'Distribution.html', 'Distributions.html', 'OrderedDistribution.html', 'UnspecifiedDistribution.html', 'ClusterDistributionImpl.html', 'OrderedDistributionImpl.html', 'UnspecifiedDistributionImpl.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'NullOrdering.html', 'SortDirection.html', 'SortOrder.html', 'package-summary.html', 'package-tree.html', 'SupportsFileFilter.html', 'package-summary.html', 'package-tree.html', 'MergeBuilder.html', 'package-summary.html', 'package-tree.html', 'overview-summary.html', 'overview-tree.html', 'package-search-index.js', 'package-search-index.zip', 'glass.png', 'x.png', 'script.js', 'search.js', 'serialized-form.html', 'stylesheet.css', 'type-search-index.js', 'type-search-index.zip', 'allclasses-index.html', 'allclasses.html', 'allpackages-index.html', 'constant-values.html', 'deprecated-list.html', 'help-doc.html', 'index-all.html', 'index.html', 'jquery.js', 'ui-bg_glass_55_fbf9ee_1x400.png', 'ui-bg_glass_65_dadada_1x400.png', 'ui-bg_glass_75_dadada_1x400.png', 'ui-bg_glass_75_e6e6e6_1x400.png', 'ui-bg_glass_95_fef1ec_1x400.png', 'ui-bg_highlight-soft_75_cccccc_1x100.png', 'ui-icons_222222_256x240.png', 'ui-icons_2e83ff_256x240.png', 'ui-icons_454545_256x240.png', 'ui-icons_888888_256x240.png', 'ui-icons_cd0a0a_256x240.png', 'jquery-3.5.1.js', 'jquery-ui.css', 'jquery-ui.js', 'jquery-ui.min.css', 'jquery-ui.min.js', 'jquery-ui.structure.css', 'jquery-ui.structure.min.css', 'member-search-index.js', 'member-search-index.zip', 'VectorizedSupport.Support.html', 'VectorizedSupport.html', 'package-summary.html', 'package-tree.html', 'Accessor.html', 'Accessors.html', 'AllDataFilesTable.AllDataFilesTableScan.html', 'AllDataFilesTable.html', 'AllEntriesTable.html', 'AllManifestsTable.AllManifestsTableScan.html', 'AllManifestsTable.html', 'AppendFiles.html', 'BaseCombinedScanTask.html', 'BaseMetastoreCatalog.BaseMetastoreCatalogTableBuilder.html', 'BaseMetastoreCatalog.html', 'BaseMetastoreTableOperations.CommitStatus.html', 'BaseMetastoreTableOperations.html', 'BaseOverwriteFiles.html', 'BaseReplacePartitions.html', 'BaseReplaceSortOrder.html', 'BaseRewriteManifests.html', 'BaseTable.html', 'CachingCatalog.html', 'CatalogProperties.html', 'CatalogUtil.html', 'ClientPool.Action.html', 'ClientPool.html', 'ClientPoolImpl.html', 'CombinedScanTask.html', 'ContentFile.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DataFilesTable.FilesTableScan.html', 'DataFilesTable.html', 'DataOperations.html', 'DataTableScan.html', 'DataTask.html', 'DeleteFile.html', 'DeleteFiles.html', 'DistributionMode.html', 'DoubleFieldMetrics.Builder.html', 'DoubleFieldMetrics.html', 'ExpireSnapshots.html', 'FieldMetrics.html', 'FileContent.html', 'FileFormat.html', 'FileMetadata.Builder.html', 'FileMetadata.html', 'FileScanTask.html', 'Files.html', 'FindFiles.Builder.html', 'FindFiles.html', 'FloatFieldMetrics.Builder.html', 'FloatFieldMetrics.html', 'GenericManifestFile.CopyBuilder.html', 'GenericManifestFile.html', 'GenericPartitionFieldSummary.html', 'GuavaClasses.html', 'HasTableOperations.html', 'HistoryEntry.html', 'HistoryTable.html', 'IsolationLevel.html', 'LocationProviders.html', 'ManageSnapshots.html', 'ManifestContent.html', 'ManifestEntriesTable.html', 'ManifestFile.PartitionFieldSummary.html', 'ManifestFile.html', 'ManifestFiles.html', 'ManifestReader.FileType.html', 'ManifestReader.html', 'ManifestWriter.html', 'ManifestsTable.html', 'MetadataColumns.html', 'MetadataTableType.html', 'MetadataTableUtils.html', 'Metrics.html', 'MetricsConfig.html', 'MetricsModes.Counts.html', 'MetricsModes.Full.html', 'MetricsModes.MetricsMode.html', 'MetricsModes.None.html', 'MetricsModes.Truncate.html', 'MetricsModes.html', 'MetricsUtil.html', 'MicroBatches.MicroBatch.html', 'MicroBatches.MicroBatchBuilder.html', 'MicroBatches.html', 'NullOrder.html', 'OverwriteFiles.html', 'PartitionField.html', 'PartitionKey.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'Partitioning.html', 'PartitionsTable.html', 'PendingUpdate.html', 'ReachableFileUtil.html', 'ReplacePartitions.html', 'ReplaceSortOrder.html', 'RewriteFiles.html', 'RewriteManifests.html', 'Rollback.html', 'RowDelta.html', 'ScanSummary.Builder.html', 'ScanSummary.PartitionMetrics.html', 'ScanSummary.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'SerializableTable.html', 'SetLocation.html', 'Snapshot.html', 'SnapshotManager.html', 'SnapshotParser.html', 'SnapshotSummary.Builder.html', 'SnapshotSummary.html', 'SnapshotUpdate.html', 'SnapshotsTable.html', 'SortDirection.html', 'SortField.html', 'SortOrder.Builder.html', 'SortOrder.html', 'SortOrderBuilder.html', 'SortOrderParser.html', 'StaticTableOperations.html', 'StructLike.html', 'SystemProperties.html', 'Table.html', 'TableMetadata.MetadataLogEntry.html', 'TableMetadata.SnapshotLogEntry.html', 'TableMetadata.html', 'TableMetadataParser.Codec.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableProperties.html', 'TableScan.html', 'Tables.html', 'Transaction.html', 'Transactions.html', 'UpdateLocation.html', 'UpdatePartitionSpec.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Action.html', 'Actions.html', 'ActionsProvider.html', 'BaseDeleteOrphanFilesActionResult.html', 'BaseDeleteReachableFilesActionResult.html', 'BaseExpireSnapshotsActionResult.html', 'BaseFileGroupRewriteResult.html', 'BaseMigrateTableActionResult.html', 'BaseRewriteDataFilesAction.html', 'BaseRewriteDataFilesFileGroupInfo.html', 'BaseRewriteDataFilesResult.html', 'BaseRewriteManifestsActionResult.html', 'BaseSnapshotTableActionResult.html', 'BinPackStrategy.html', 'CreateAction.html', 'DeleteOrphanFiles.Result.html', 'DeleteOrphanFiles.html', 'DeleteReachableFiles.Result.html', 'DeleteReachableFiles.html', 'ExpireSnapshots.Result.html', 'ExpireSnapshots.html', 'ExpireSnapshotsAction.html', 'ExpireSnapshotsActionResult.html', 'ManifestFileBean.html', 'MigrateTable.Result.html', 'MigrateTable.html', 'RemoveOrphanFilesAction.html', 'RewriteDataFiles.FileGroupInfo.html', 'RewriteDataFiles.FileGroupRewriteResult.html', 'RewriteDataFiles.Result.html', 'RewriteDataFiles.html', 'RewriteDataFilesAction.html', 'RewriteDataFilesActionResult.html', 'RewriteDataFilesCommitManager.CommitService.html', 'RewriteDataFilesCommitManager.html', 'RewriteFileGroup.html', 'RewriteManifests.Result.html', 'RewriteManifests.html', 'RewriteManifestsAction.html', 'RewriteManifestsActionResult.html', 'RewriteStrategy.html', 'SnapshotAction.html', 'SnapshotTable.Result.html', 'SnapshotTable.html', 'SnapshotUpdate.html', 'SnapshotUpdateAction.html', 'SortStrategy.html', 'Spark3MigrateAction.html', 'Spark3SnapshotAction.html', 'SparkActions.html', 'package-summary.html', 'package-tree.html', 'ArrowAllocation.html', 'ArrowSchemaUtil.html', 'package-summary.html', 'package-tree.html', 'ArrowReader.html', 'ArrowVectorAccessor.html', 'ColumnVector.html', 'ColumnarBatch.html', 'GenericArrowVectorAccessorFactory.ArrayFactory.html', 'GenericArrowVectorAccessorFactory.DecimalFactory.html', 'GenericArrowVectorAccessorFactory.StringFactory.html', 'GenericArrowVectorAccessorFactory.StructChildFactory.html', 'GenericArrowVectorAccessorFactory.html', 'NullabilityHolder.html', 'VectorHolder.ConstantVectorHolder.html', 'VectorHolder.PositionVectorHolder.html', 'VectorHolder.html', 'VectorizedArrowReader.ConstantVectorReader.html', 'VectorizedArrowReader.html', 'VectorizedReaderBuilder.html', 'VectorizedTableScanIterable.html', 'package-summary.html', 'package-tree.html', 'BaseVectorizedParquetValuesReader.html', 'VectorizedColumnIterator.BatchReader.html', 'VectorizedColumnIterator.BooleanBatchReader.html', 'VectorizedColumnIterator.DictionaryBatchReader.html', 'VectorizedColumnIterator.DoubleBatchReader.html', 'VectorizedColumnIterator.FixedLengthDecimalBatchReader.html', 'VectorizedColumnIterator.FixedSizeBinaryBatchReader.html', 'VectorizedColumnIterator.FixedWidthTypeBinaryBatchReader.html', 'VectorizedColumnIterator.FloatBatchReader.html', 'VectorizedColumnIterator.IntBackedDecimalBatchReader.html', 'VectorizedColumnIterator.IntegerBatchReader.html', 'VectorizedColumnIterator.LongBackedDecimalBatchReader.html', 'VectorizedColumnIterator.LongBatchReader.html', 'VectorizedColumnIterator.TimestampMillisBatchReader.html', 'VectorizedColumnIterator.VarWidthTypeBatchReader.html', 'VectorizedColumnIterator.html', 'VectorizedDictionaryEncodedParquetValuesReader.html', 'VectorizedPageIterator.html', 'VectorizedParquetDefinitionLevelReader.html', 'package-summary.html', 'package-tree.html', 'Avro.DataWriteBuilder.html', 'Avro.DeleteWriteBuilder.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroEncoderUtil.html', 'AvroIterable.html', 'AvroMetrics.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'AvroSchemaWithTypeVisitor.html', 'AvroWithPartnerByStructureVisitor.html', 'LogicalMap.html', 'MetricsAwareDatumWriter.html', 'ProjectionDatumReader.html', 'RemoveIds.html', 'SupportsRowPosition.html', 'UUIDConversion.html', 'ValueReader.html', 'ValueReaders.StructReader.html', 'ValueReaders.html', 'ValueWriter.html', 'ValueWriters.StructWriter.html', 'ValueWriters.html', 'package-summary.html', 'package-tree.html', 'AssumeRoleAwsClientFactory.html', 'AwsClientFactories.html', 'AwsClientFactory.html', 'AwsProperties.html', 'DynamoDbCatalog.html', 'package-summary.html', 'package-tree.html', 'GlueCatalog.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'S3FileIO.html', 'S3InputFile.html', 'S3OutputFile.html', 'S3RequestUtil.html', 'package-summary.html', 'package-tree.html', 'Catalog.TableBuilder.html', 'Catalog.html', 'Namespace.html', 'SupportsNamespaces.html', 'TableIdentifier.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-summary.html', 'package-tree.html', 'BaseWriterFactory.html', 'DeleteFilter.html', 'GenericAppenderFactory.html', 'GenericDeleteFilter.html', 'GenericRecord.html', 'IcebergGenerics.ScanBuilder.html', 'IcebergGenerics.html', 'IdentityPartitionConverters.html', 'InternalRecordWrapper.html', 'Record.html', 'TableMigrationUtil.html', 'DataReader.html', 'DataWriter.html', 'DecoderResolver.html', 'IcebergDecoder.html', 'IcebergEncoder.html', 'package-summary.html', 'package-tree.html', 'GenericOrcReader.html', 'GenericOrcReaders.html', 'GenericOrcWriter.html', 'GenericOrcWriters.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'BaseParquetReaders.html', 'BaseParquetWriter.html', 'GenericParquetReaders.html', 'GenericParquetWriter.html', 'package-summary.html', 'package-tree.html', 'Deletes.html', 'EqualityDeleteWriter.html', 'PositionDelete.html', 'PositionDeleteWriter.html', 'package-summary.html', 'package-tree.html', 'EncryptedFiles.html', 'EncryptedInputFile.html', 'EncryptedOutputFile.html', 'EncryptionKeyMetadata.html', 'EncryptionKeyMetadatas.html', 'EncryptionManager.html', 'PlaintextEncryptionManager.html', 'package-summary.html', 'package-tree.html', 'CreateSnapshotEvent.html', 'IncrementalScanEvent.html', 'Listener.html', 'Listeners.html', 'ScanEvent.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CherrypickAncestorCommitException.html', 'CommitFailedException.html', 'CommitStateUnknownException.html', 'DuplicateWAPCommitException.html', 'NamespaceNotEmptyException.html', 'NoSuchIcebergTableException.html', 'NoSuchNamespaceException.html', 'NoSuchTableException.html', 'NotFoundException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'Bound.html', 'BoundLiteralPredicate.html', 'BoundPredicate.html', 'BoundReference.html', 'BoundSetPredicate.html', 'BoundTerm.html', 'BoundTransform.html', 'BoundUnaryPredicate.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.BoundVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'InclusiveMetricsEvaluator.html', 'Literal.html', 'ManifestEvaluator.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'StrictMetricsEvaluator.html', 'Term.html', 'True.html', 'Unbound.html', 'UnboundPredicate.html', 'UnboundTerm.html', 'UnboundTransform.html', 'package-summary.html', 'package-tree.html', 'CatalogLoader.CustomCatalogLoader.html', 'CatalogLoader.HadoopCatalogLoader.html', 'CatalogLoader.HiveCatalogLoader.html', 'CatalogLoader.html', 'FlinkCatalog.html', 'FlinkCatalogFactory.html', 'FlinkConfigOptions.html', 'FlinkDynamicTableFactory.html', 'FlinkFilters.html', 'FlinkSchemaUtil.html', 'FlinkTypeVisitor.html', 'IcebergTableSink.html', 'IcebergTableSource.html', 'RowDataWrapper.html', 'TableLoader.CatalogTableLoader.html', 'TableLoader.HadoopTableLoader.html', 'TableLoader.html', 'Actions.html', 'RewriteDataFilesAction.html', 'package-summary.html', 'package-tree.html', 'AvroWithFlinkSchemaVisitor.html', 'FlinkAvroReader.html', 'FlinkAvroWriter.html', 'FlinkOrcReader.html', 'FlinkOrcWriter.html', 'FlinkParquetReaders.html', 'FlinkParquetWriters.html', 'FlinkValueReaders.html', 'FlinkValueWriters.html', 'ParquetWithFlinkSchemaVisitor.html', 'RowDataUtil.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'FlinkAppenderFactory.html', 'FlinkSink.Builder.html', 'FlinkSink.html', 'RowDataTaskWriterFactory.html', 'TaskWriterFactory.html', 'package-summary.html', 'package-tree.html', 'FlinkInputFormat.html', 'FlinkInputSplit.html', 'FlinkSource.Builder.html', 'FlinkSource.html', 'RowDataRewriter.RewriteMap.html', 'RowDataRewriter.html', 'StreamingMonitorFunction.html', 'StreamingReaderOperator.html', 'package-summary.html', 'package-tree.html', 'FlinkCompatibilityUtil.html', 'package-summary.html', 'package-tree.html', 'ConfigProperties.html', 'HadoopCatalog.html', 'HadoopConfigurable.html', 'HadoopFileIO.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTableOperations.html', 'HadoopTables.html', 'HiddenPathFilter.html', 'SerializableConfiguration.html', 'Util.html', 'package-summary.html', 'package-tree.html', 'CachedClientPool.html', 'HiveCatalog.html', 'HiveCatalogs.html', 'HiveClientPool.html', 'HiveSchemaUtil.html', 'HiveTableOperations.html', 'MetastoreUtil.html', 'RuntimeMetaException.html', 'package-summary.html', 'package-tree.html', 'BaseTaskWriter.BaseEqualityDeltaWriter.html', 'BaseTaskWriter.RollingEqDeleteWriter.html', 'BaseTaskWriter.RollingFileWriter.html', 'BaseTaskWriter.html', 'CloseableGroup.html', 'CloseableIterable.ConcatCloseableIterable.html', 'CloseableIterable.html', 'CloseableIterator.html', 'ClosingIterator.html', 'DataWriter.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'DeleteSchemaUtil.html', 'FileAppender.html', 'FileAppenderFactory.html', 'FileIO.html', 'FilterIterator.html', 'InputFile.html', 'LocationProvider.html', 'OutputFile.html', 'OutputFileFactory.Builder.html', 'OutputFileFactory.html', 'PartitionedFanoutWriter.html', 'PartitionedWriter.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'TaskWriter.html', 'UnpartitionedWriter.html', 'WriteResult.Builder.html', 'WriteResult.html', 'WriterFactory.html', 'package-summary.html', 'package-tree.html', 'JdbcCatalog.html', 'UncheckedInterruptedException.html', 'UncheckedSQLException.html', 'package-summary.html', 'package-tree.html', 'MappedField.html', 'MappedFields.html', 'MappingUtil.html', 'NameMapping.html', 'NameMappingParser.html', 'package-summary.html', 'package-tree.html', 'Catalogs.html', 'InputFormatConfig.ConfigBuilder.html', 'InputFormatConfig.InMemoryDataModel.html', 'InputFormatConfig.html', 'HiveIcebergFilterFactory.html', 'HiveIcebergInputFormat.html', 'HiveIcebergMetaHook.html', 'HiveIcebergOutputCommitter.html', 'HiveIcebergOutputFormat.html', 'HiveIcebergSerDe.html', 'HiveIcebergSplit.html', 'HiveIcebergStorageHandler.html', 'TezUtil.html', 'package-summary.html', 'package-tree.html', 'IcebergBinaryObjectInspector.html', 'IcebergDateObjectInspector.html', 'IcebergDecimalObjectInspector.html', 'IcebergFixedObjectInspector.html', 'IcebergObjectInspector.html', 'IcebergRecordObjectInspector.html', 'IcebergTimeObjectInspector.html', 'IcebergTimestampObjectInspector.html', 'IcebergTimestampWithZoneObjectInspector.html', 'IcebergUUIDObjectInspector.html', 'WriteObjectInspector.html', 'package-summary.html', 'package-tree.html', 'AbstractMapredIcebergRecordReader.html', 'Container.html', 'MapredIcebergInputFormat.CompatibilityTaskAttemptContextImpl.html', 'MapredIcebergInputFormat.html', 'package-summary.html', 'package-tree.html', 'IcebergInputFormat.html', 'IcebergSplit.html', 'IcebergSplitContainer.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'NessieCatalog.html', 'NessieTableOperations.html', 'NessieUtil.html', 'TableReference.html', 'package-summary.html', 'package-tree.html', 'ORC.DataWriteBuilder.html', 'ORC.ReadBuilder.html', 'ORC.WriteBuilder.html', 'ORC.html', 'ORCSchemaUtil.BinaryType.html', 'ORCSchemaUtil.LongType.html', 'ORCSchemaUtil.html', 'OrcBatchReader.html', 'OrcMetrics.html', 'OrcRowReader.html', 'OrcRowWriter.html', 'OrcSchemaVisitor.html', 'OrcSchemaWithTypeVisitor.html', 'OrcValueReader.html', 'OrcValueReaders.StructReader.html', 'OrcValueReaders.html', 'OrcValueWriter.html', 'VectorizedRowBatchIterator.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'BaseColumnIterator.html', 'BasePageIterator.IntIterator.html', 'BasePageIterator.html', 'ColumnIterator.html', 'ColumnWriter.html', 'Parquet.DataWriteBuilder.html', 'Parquet.DeleteWriteBuilder.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetAvroReader.html', 'ParquetAvroValueReaders.TimeMillisReader.html', 'ParquetAvroValueReaders.TimestampMillisReader.html', 'ParquetAvroValueReaders.html', 'ParquetAvroWriter.html', 'ParquetDictionaryRowGroupFilter.html', 'ParquetIterable.html', 'ParquetMetricsRowGroupFilter.html', 'ParquetReader.html', 'ParquetSchemaUtil.HasIds.html', 'ParquetSchemaUtil.html', 'ParquetTypeVisitor.html', 'ParquetUtil.html', 'ParquetValueReader.html', 'ParquetValueReaders.BinaryAsDecimalReader.html', 'ParquetValueReaders.ByteArrayReader.html', 'ParquetValueReaders.BytesReader.html', 'ParquetValueReaders.FloatAsDoubleReader.html', 'ParquetValueReaders.IntAsLongReader.html', 'ParquetValueReaders.IntegerAsDecimalReader.html', 'ParquetValueReaders.ListReader.html', 'ParquetValueReaders.LongAsDecimalReader.html', 'ParquetValueReaders.MapReader.html', 'ParquetValueReaders.PrimitiveReader.html', 'ParquetValueReaders.RepeatedKeyValueReader.html', 'ParquetValueReaders.RepeatedReader.html', 'ParquetValueReaders.ReusableEntry.html', 'ParquetValueReaders.StringReader.html', 'ParquetValueReaders.StructReader.html', 'ParquetValueReaders.UnboxedReader.html', 'ParquetValueReaders.html', 'ParquetValueWriter.html', 'ParquetValueWriters.PositionDeleteStructWriter.html', 'ParquetValueWriters.PrimitiveWriter.html', 'ParquetValueWriters.RepeatedKeyValueWriter.html', 'ParquetValueWriters.RepeatedWriter.html', 'ParquetValueWriters.StructWriter.html', 'ParquetValueWriters.html', 'ParquetWriteAdapter.html', 'RemoveIds.html', 'TripleWriter.html', 'TypeToMessageType.html', 'TypeWithSchemaVisitor.html', 'ValuesAsBytesReader.html', 'VectorizedParquetReader.html', 'VectorizedReader.html', 'package-summary.html', 'package-tree.html', 'IcebergPigInputFormat.IcebergRecordReader.html', 'IcebergPigInputFormat.html', 'IcebergStorage.html', 'PigParquetReader.html', 'SchemaUtil.html', 'package-summary.html', 'package-tree.html', 'SchemaWithPartnerVisitor.PartnerAccessors.html', 'SchemaWithPartnerVisitor.html', 'UnionByNameVisitor.html', 'package-summary.html', 'package-tree.html', 'FileRewriteCoordinator.html', 'FileScanTaskSetManager.html', 'IcebergSpark.html', 'JobGroupInfo.html', 'JobGroupUtils.html', 'PathIdentifier.html', 'PruneColumnsWithReordering.html', 'PruneColumnsWithoutReordering.html', 'RollbackStagedTable.html', 'Spark3Util.CatalogAndIdentifier.html', 'Spark3Util.DescribeSchemaVisitor.html', 'Spark3Util.html', 'Spark3VersionUtil.html', 'SparkCatalog.html', 'SparkDataFile.html', 'SparkExceptionUtil.html', 'SparkFilters.html', 'SparkReadOptions.html', 'SparkSchemaUtil.html', 'SparkSessionCatalog.html', 'SparkStructLike.html', 'SparkTableUtil.SparkPartition.html', 'SparkTableUtil.html', 'SparkUtil.html', 'SparkValueConverter.html', 'SparkWriteOptions.html', 'BaseDeleteOrphanFilesSparkAction.html', 'BaseDeleteReachableFilesSparkAction.html', 'BaseExpireSnapshotsSparkAction.html', 'BaseMigrateTableSparkAction.html', 'BaseRewriteDataFilesSpark3Action.html', 'BaseRewriteManifestsSparkAction.html', 'BaseSnapshotTableSparkAction.html', 'Spark3BinPackStrategy.html', 'SparkActions.html', 'package-summary.html', 'package-tree.html', 'AvroWithSparkSchemaVisitor.html', 'ParquetWithSparkSchemaVisitor.html', 'SparkAvroReader.html', 'SparkAvroWriter.html', 'SparkOrcReader.html', 'SparkOrcValueReaders.html', 'SparkOrcWriter.html', 'SparkParquetReaders.html', 'SparkParquetWriters.html', 'SparkValueReaders.html', 'SparkValueWriters.html', 'package-summary.html', 'package-tree.html', 'ArrowVectorAccessors.html', 'ColumnarBatchReader.html', 'IcebergArrowColumnVector.html', 'RowPositionColumnVector.html', 'VectorizedSparkOrcReaders.html', 'VectorizedSparkParquetReaders.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'ExpireSnapshotsProcedure.html', 'RemoveOrphanFilesProcedure.html', 'SparkProcedures.ProcedureBuilder.html', 'SparkProcedures.html', 'package-summary.html', 'package-tree.html', 'EqualityDeleteRowReader.html', 'IcebergSource.html', 'RowDataRewriter.html', 'SparkMicroBatchStream.html', 'SparkPartitionedFanoutWriter.html', 'SparkPartitionedWriter.html', 'SparkRewriteBuilder.html', 'SparkScanBuilder.html', 'SparkTable.html', 'StagedSparkTable.html', 'package-summary.html', 'package-tree.html', 'PartitionSpecVisitor.html', 'SortOrderVisitor.html', 'Transform.html', 'Transforms.html', 'UnknownTransform.html', 'package-summary.html', 'package-tree.html', 'CheckCompatibility.html', 'Comparators.html', 'Conversions.html', 'FixupTypes.html', 'IndexByName.html', 'IndexParents.html', 'JavaHash.html', 'JavaHashes.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-summary.html', 'package-tree.html', 'ArrayUtil.html', 'BinPacking.ListPacker.html', 'BinPacking.PackingIterable.html', 'BinPacking.html', 'BinaryUtil.html', 'ByteBuffers.html', 'CharSequenceSet.html', 'CharSequenceWrapper.html', 'DateTimeUtil.html', 'DecimalUtil.html', 'ExceptionUtil.Block.html', 'ExceptionUtil.CatchBlock.html', 'ExceptionUtil.FinallyBlock.html', 'ExceptionUtil.html', 'Exceptions.html', 'Filter.html', 'JsonUtil.html', 'ManifestFileUtil.html', 'NaNUtil.html', 'Pair.html', 'ParallelIterable.html', 'PartitionSet.html', 'PartitionUtil.html', 'PropertyUtil.html', 'SerializableMap.html', 'SerializableSupplier.html', 'SerializationUtil.html', 'SnapshotUtil.html', 'SortOrderUtil.html', 'SortedMerge.html', 'StructLikeMap.html', 'StructLikeSet.html', 'StructLikeWrapper.html', 'StructProjection.html', 'TableScanUtil.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'ThreadPools.html', 'UUIDUtil.html', 'UnicodeUtil.html', 'WapUtil.html', 'package-summary.html', 'package-tree.html', 'NoSuchProcedureException.html', 'package-summary.html', 'package-tree.html', 'IcebergSqlExtensionsBaseListener.html', 'IcebergSqlExtensionsBaseVisitor.html', 'IcebergSqlExtensionsLexer.html', 'IcebergSqlExtensionsListener.html', 'IcebergSqlExtensionsParser.AddPartitionFieldContext.html', 'IcebergSqlExtensionsParser.ApplyTransformContext.html', 'IcebergSqlExtensionsParser.BigDecimalLiteralContext.html', 'IcebergSqlExtensionsParser.BigIntLiteralContext.html', 'IcebergSqlExtensionsParser.BooleanLiteralContext.html', 'IcebergSqlExtensionsParser.BooleanValueContext.html', 'IcebergSqlExtensionsParser.CallArgumentContext.html', 'IcebergSqlExtensionsParser.CallContext.html', 'IcebergSqlExtensionsParser.ConstantContext.html', 'IcebergSqlExtensionsParser.DecimalLiteralContext.html', 'IcebergSqlExtensionsParser.DoubleLiteralContext.html', 'IcebergSqlExtensionsParser.DropIdentifierFieldsContext.html', 'IcebergSqlExtensionsParser.DropPartitionFieldContext.html', 'IcebergSqlExtensionsParser.ExponentLiteralContext.html', 'IcebergSqlExtensionsParser.ExpressionContext.html', 'IcebergSqlExtensionsParser.FieldListContext.html', 'IcebergSqlExtensionsParser.FloatLiteralContext.html', 'IcebergSqlExtensionsParser.IdentifierContext.html', 'IcebergSqlExtensionsParser.IdentityTransformContext.html', 'IcebergSqlExtensionsParser.IntegerLiteralContext.html', 'IcebergSqlExtensionsParser.MultipartIdentifierContext.html', 'IcebergSqlExtensionsParser.NamedArgumentContext.html', 'IcebergSqlExtensionsParser.NonReservedContext.html', 'IcebergSqlExtensionsParser.NumberContext.html', 'IcebergSqlExtensionsParser.NumericLiteralContext.html', 'IcebergSqlExtensionsParser.OrderContext.html', 'IcebergSqlExtensionsParser.OrderFieldContext.html', 'IcebergSqlExtensionsParser.PositionalArgumentContext.html', 'IcebergSqlExtensionsParser.QuotedIdentifierAlternativeContext.html', 'IcebergSqlExtensionsParser.QuotedIdentifierContext.html', 'IcebergSqlExtensionsParser.ReplacePartitionFieldContext.html', 'IcebergSqlExtensionsParser.SetIdentifierFieldsContext.html', 'IcebergSqlExtensionsParser.SetWriteDistributionAndOrderingContext.html', 'IcebergSqlExtensionsParser.SingleStatementContext.html', 'IcebergSqlExtensionsParser.SmallIntLiteralContext.html', 'IcebergSqlExtensionsParser.StatementContext.html', 'IcebergSqlExtensionsParser.StringLiteralContext.html', 'IcebergSqlExtensionsParser.StringMapContext.html', 'IcebergSqlExtensionsParser.TinyIntLiteralContext.html', 'IcebergSqlExtensionsParser.TransformArgumentContext.html', 'IcebergSqlExtensionsParser.TransformContext.html', 'IcebergSqlExtensionsParser.TypeConstructorContext.html', 'IcebergSqlExtensionsParser.UnquotedIdentifierContext.html', 'IcebergSqlExtensionsParser.WriteDistributionSpecContext.html', 'IcebergSqlExtensionsParser.WriteOrderingSpecContext.html', 'IcebergSqlExtensionsParser.WriteSpecContext.html', 'IcebergSqlExtensionsParser.html', 'IcebergSqlExtensionsVisitor.html', 'package-summary.html', 'package-tree.html', 'ExtendedSupportsDelete.html', 'Procedure.html', 'ProcedureCatalog.html', 'ProcedureParameter.html', 'SupportsMerge.html', 'package-summary.html', 'package-tree.html', 'ClusteredDistribution.html', 'Distribution.html', 'Distributions.html', 'OrderedDistribution.html', 'UnspecifiedDistribution.html', 'ClusterDistributionImpl.html', 'OrderedDistributionImpl.html', 'UnspecifiedDistributionImpl.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'NullOrdering.html', 'SortDirection.html', 'SortOrder.html', 'package-summary.html', 'package-tree.html', 'SupportsFileFilter.html', 'package-summary.html', 'package-tree.html', 'MergeBuilder.html', 'package-summary.html', 'package-tree.html', 'overview-summary.html', 'overview-tree.html', 'package-search-index.js', 'package-search-index.zip', 'glass.png', 'x.png', 'script.js', 'search.js', 'serialized-form.html', 'stylesheet.css', 'type-search-index.js', 'type-search-index.zip', 'allclasses-frame.html', 'allclasses-noframe.html', 'constant-values.html', 'deprecated-list.html', 'help-doc.html', 'index-all.html', 'index.html', 'Accessor.html', 'Accessors.html', 'AppendFiles.html', 'BaseCombinedScanTask.html', 'BaseMetastoreCatalog.html', 'BaseMetastoreTableOperations.html', 'BaseOverwriteFiles.html', 'BaseReplacePartitions.html', 'BaseRewriteManifests.html', 'BaseTable.html', 'CombinedScanTask.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DataFilesTable.FilesTableScan.html', 'DataFilesTable.html', 'DataOperations.html', 'DataTableScan.html', 'DataTask.html', 'DeleteFiles.html', 'ExpireSnapshots.html', 'FileFormat.html', 'FileHistory.Builder.html', 'FileHistory.html', 'FileScanTask.html', 'Files.html', 'Filterable.html', 'FilteredManifest.html', 'FindFiles.Builder.html', 'FindFiles.html', 'GenericManifestFile.html', 'GenericPartitionFieldSummary.html', 'HasTableOperations.html', 'HistoryEntry.html', 'HistoryTable.html', 'LocationProviders.html', 'ManifestEntriesTable.html', 'ManifestFile.PartitionFieldSummary.html', 'ManifestFile.html', 'ManifestReader.html', 'ManifestWriter.html', 'ManifestsTable.html', 'MetadataTableType.html', 'Metrics.html', 'MetricsConfig.html', 'MetricsModes.Counts.html', 'MetricsModes.Full.html', 'MetricsModes.MetricsMode.html', 'MetricsModes.None.html', 'MetricsModes.Truncate.html', 'MetricsModes.html', 'OverwriteFiles.html', 'PartitionField.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'PendingUpdate.html', 'ReplacePartitions.html', 'RewriteFiles.html', 'RewriteManifests.html', 'Rollback.html', 'ScanSummary.Builder.html', 'ScanSummary.PartitionMetrics.html', 'ScanSummary.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'SetLocation.html', 'Snapshot.html', 'SnapshotParser.html', 'SnapshotSummary.Builder.html', 'SnapshotSummary.html', 'SnapshotUpdate.html', 'SnapshotsTable.html', 'StructLike.html', 'SystemProperties.html', 'Table.html', 'TableMetadata.SnapshotLogEntry.html', 'TableMetadata.html', 'TableMetadataParser.Codec.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableProperties.html', 'TableScan.html', 'Tables.html', 'Transaction.html', 'Transactions.html', 'UpdateLocation.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroIterable.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'LogicalMap.html', 'ProjectionDatumReader.html', 'UUIDConversion.html', 'ValueReader.html', 'ValueReaders.StructReader.html', 'ValueReaders.html', 'ValueWriter.html', 'ValueWriters.StructWriter.html', 'ValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Catalog.html', 'Namespace.html', 'TableIdentifier.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericRecord.html', 'IcebergGenerics.ScanBuilder.html', 'IcebergGenerics.html', 'Record.html', 'DataReader.html', 'DataWriter.html', 'IcebergDecoder.html', 'IcebergEncoder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericParquetReaders.html', 'GenericParquetWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'EncryptedFiles.html', 'EncryptedInputFile.html', 'EncryptedOutputFile.html', 'EncryptionKeyMetadata.html', 'EncryptionKeyMetadatas.html', 'EncryptionManager.html', 'PlaintextEncryptionManager.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Listener.html', 'Listeners.html', 'ScanEvent.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CommitFailedException.html', 'NoSuchTableException.html', 'NotFoundException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'BoundPredicate.html', 'BoundReference.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'InclusiveMetricsEvaluator.html', 'Literal.html', 'ManifestEvaluator.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'StrictMetricsEvaluator.html', 'True.html', 'UnboundPredicate.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'HadoopFileIO.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTableOperations.html', 'HadoopTables.html', 'SerializableConfiguration.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ClientPool.Action.html', 'ClientPool.html', 'HiveCatalog.html', 'HiveCatalogs.html', 'HiveClientPool.html', 'HiveTableOperations.html', 'HiveTypeConverter.html', 'RuntimeMetaException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CloseableGroup.html', 'CloseableIterable.ConcatCloseableIterable.html', 'CloseableIterable.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'FileAppender.html', 'FileIO.html', 'InputFile.html', 'LocationProvider.html', 'OutputFile.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'MappedField.html', 'MappedFields.html', 'MappingUtil.html', 'NameMapping.html', 'NameMappingParser.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ColumnIdMap.html', 'ORC.ReadBuilder.html', 'ORC.WriteBuilder.html', 'ORC.html', 'OrcMetrics.html', 'OrcValueReader.html', 'OrcValueWriter.html', 'TypeConversion.html', 'VectorizedRowBatchIterator.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ColumnIterator.html', 'ColumnWriter.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetAvroReader.html', 'ParquetAvroValueReaders.TimeMillisReader.html', 'ParquetAvroValueReaders.TimestampMillisReader.html', 'ParquetAvroValueReaders.html', 'ParquetAvroWriter.html', 'ParquetDictionaryRowGroupFilter.html', 'ParquetIterable.html', 'ParquetMetricsRowGroupFilter.html', 'ParquetReader.html', 'ParquetSchemaUtil.html', 'ParquetTypeVisitor.html', 'ParquetUtil.html', 'ParquetValueReader.html', 'ParquetValueReaders.BinaryAsDecimalReader.html', 'ParquetValueReaders.BytesReader.html', 'ParquetValueReaders.FloatAsDoubleReader.html', 'ParquetValueReaders.IntAsLongReader.html', 'ParquetValueReaders.IntegerAsDecimalReader.html', 'ParquetValueReaders.ListReader.html', 'ParquetValueReaders.LongAsDecimalReader.html', 'ParquetValueReaders.MapReader.html', 'ParquetValueReaders.PrimitiveReader.html', 'ParquetValueReaders.RepeatedKeyValueReader.html', 'ParquetValueReaders.RepeatedReader.html', 'ParquetValueReaders.ReusableEntry.html', 'ParquetValueReaders.StringReader.html', 'ParquetValueReaders.StructReader.html', 'ParquetValueReaders.UnboxedReader.html', 'ParquetValueReaders.html', 'ParquetValueWriter.html', 'ParquetValueWriters.PrimitiveWriter.html', 'ParquetValueWriters.RepeatedKeyValueWriter.html', 'ParquetValueWriters.RepeatedWriter.html', 'ParquetValueWriters.StructWriter.html', 'ParquetValueWriters.html', 'ParquetWriteAdapter.html', 'TripleWriter.html', 'TypeToMessageType.html', 'TypeWithSchemaVisitor.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergPigInputFormat.IcebergRecordReader.html', 'IcebergPigInputFormat.html', 'IcebergStorage.html', 'PigParquetReader.html', 'SchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PruneColumnsWithReordering.html', 'PruneColumnsWithoutReordering.html', 'SparkFilters.html', 'SparkSchemaUtil.html', 'SparkAvroReader.html', 'SparkAvroWriter.html', 'SparkOrcReader.html', 'SparkOrcWriter.html', 'SparkParquetReaders.html', 'SparkParquetWriters.html', 'SparkValueReaders.html', 'SparkValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Hive.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSource.html', 'StreamingWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PartitionSpecVisitor.html', 'Transform.html', 'Transforms.html', 'UnknownTransform.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CheckCompatibility.html', 'Comparators.html', 'Conversions.html', 'IndexByName.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BinPacking.ListPacker.html', 'BinPacking.PackingIterable.html', 'BinPacking.html', 'BinaryUtil.html', 'ByteBuffers.html', 'CharSequenceWrapper.html', 'ExceptionUtil.html', 'Exceptions.html', 'JsonUtil.html', 'ManifestFileUtil.html', 'Pair.html', 'ParallelIterable.html', 'PropertyUtil.html', 'SnapshotUtil.html', 'StructLikeWrapper.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'ThreadPools.html', 'UnicodeUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'overview-frame.html', 'overview-summary.html', 'overview-tree.html', 'package-list', 'script.js', 'serialized-form.html', 'stylesheet.css', 'allclasses-frame.html', 'allclasses-noframe.html', 'constant-values.html', 'deprecated-list.html', 'help-doc.html', 'index-all.html', 'index.html', 'Accessor.html', 'Accessors.html', 'AllDataFilesTable.AllDataFilesTableScan.html', 'AllDataFilesTable.html', 'AllEntriesTable.html', 'AllManifestsTable.AllManifestsTableScan.html', 'AllManifestsTable.html', 'AppendFiles.html', 'BaseCombinedScanTask.html', 'BaseMetastoreCatalog.html', 'BaseMetastoreTableOperations.html', 'BaseOverwriteFiles.html', 'BaseReplacePartitions.html', 'BaseRewriteManifests.html', 'BaseTable.html', 'CachingCatalog.html', 'CombinedScanTask.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DataFilesTable.FilesTableScan.html', 'DataFilesTable.html', 'DataOperations.html', 'DataTableScan.html', 'DataTask.html', 'DeleteFiles.html', 'ExpireSnapshots.html', 'FileFormat.html', 'FileHistory.Builder.html', 'FileHistory.html', 'FileScanTask.html', 'Files.html', 'Filterable.html', 'FilteredManifest.html', 'FindFiles.Builder.html', 'FindFiles.html', 'GenericManifestFile.CopyBuilder.html', 'GenericManifestFile.html', 'GenericPartitionFieldSummary.html', 'HasTableOperations.html', 'HistoryEntry.html', 'HistoryTable.html', 'LocationProviders.html', 'ManageSnapshots.html', 'ManifestEntriesTable.html', 'ManifestFile.PartitionFieldSummary.html', 'ManifestFile.html', 'ManifestFiles.html', 'ManifestReader.html', 'ManifestWriter.html', 'ManifestsTable.html', 'MetadataTableType.html', 'Metrics.html', 'MetricsConfig.html', 'MetricsModes.Counts.html', 'MetricsModes.Full.html', 'MetricsModes.MetricsMode.html', 'MetricsModes.None.html', 'MetricsModes.Truncate.html', 'MetricsModes.html', 'OverwriteFiles.html', 'PartitionField.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'PartitionsTable.html', 'PendingUpdate.html', 'ReplacePartitions.html', 'RewriteFiles.html', 'RewriteManifests.html', 'Rollback.html', 'ScanSummary.Builder.html', 'ScanSummary.PartitionMetrics.html', 'ScanSummary.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'SetLocation.html', 'Snapshot.html', 'SnapshotManager.html', 'SnapshotParser.html', 'SnapshotSummary.Builder.html', 'SnapshotSummary.html', 'SnapshotUpdate.html', 'SnapshotsTable.html', 'StructLike.html', 'SystemProperties.html', 'Table.html', 'TableMetadata.MetadataLogEntry.html', 'TableMetadata.SnapshotLogEntry.html', 'TableMetadata.html', 'TableMetadataParser.Codec.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableProperties.html', 'TableScan.html', 'Tables.html', 'Transaction.html', 'Transactions.html', 'UpdateLocation.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Action.html', 'Actions.html', 'RemoveOrphanFilesAction.html', 'RewriteManifestsAction.html', 'RewriteManifestsActionResult.html', 'SnapshotUpdateAction.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ArrowSchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergArrowVectors.DecimalArrowVector.html', 'IcebergArrowVectors.VarBinaryArrowVector.html', 'IcebergArrowVectors.VarcharArrowVector.html', 'IcebergArrowVectors.html', 'NullabilityHolder.html', 'VectorHolder.html', 'VectorizedArrowReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseVectorizedParquetValuesReader.html', 'VectorizedColumnIterator.html', 'VectorizedDictionaryEncodedParquetValuesReader.html', 'VectorizedPageIterator.html', 'VectorizedParquetDefinitionLevelReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroIterable.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'AvroSchemaWithTypeVisitor.html', 'LogicalMap.html', 'ProjectionDatumReader.html', 'UUIDConversion.html', 'ValueReader.html', 'ValueReaders.StructReader.html', 'ValueReaders.html', 'ValueWriter.html', 'ValueWriters.StructWriter.html', 'ValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Catalog.html', 'Namespace.html', 'SupportsNamespaces.html', 'TableIdentifier.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DateTimeUtil.html', 'GenericRecord.html', 'IcebergGenerics.ScanBuilder.html', 'IcebergGenerics.html', 'Record.html', 'DataReader.html', 'DataWriter.html', 'IcebergDecoder.html', 'IcebergEncoder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericOrcReader.html', 'GenericOrcWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericParquetReaders.html', 'GenericParquetWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'EncryptedFiles.html', 'EncryptedInputFile.html', 'EncryptedOutputFile.html', 'EncryptionKeyMetadata.html', 'EncryptionKeyMetadatas.html', 'EncryptionManager.html', 'PlaintextEncryptionManager.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Listener.html', 'Listeners.html', 'ScanEvent.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CherrypickAncestorCommitException.html', 'CommitFailedException.html', 'DuplicateWAPCommitException.html', 'NamespaceNotEmptyException.html', 'NoSuchNamespaceException.html', 'NoSuchTableException.html', 'NotFoundException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'Bound.html', 'BoundLiteralPredicate.html', 'BoundPredicate.html', 'BoundReference.html', 'BoundSetPredicate.html', 'BoundTerm.html', 'BoundTransform.html', 'BoundUnaryPredicate.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.BoundVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'InclusiveMetricsEvaluator.html', 'Literal.html', 'ManifestEvaluator.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'StrictMetricsEvaluator.html', 'Term.html', 'True.html', 'Unbound.html', 'UnboundPredicate.html', 'UnboundTerm.html', 'UnboundTransform.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'HadoopCatalog.html', 'HadoopFileIO.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTableOperations.html', 'HadoopTables.html', 'HiddenPathFilter.html', 'SerializableConfiguration.html', 'Util.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ClientPool.Action.html', 'ClientPool.html', 'HiveCatalog.html', 'HiveCatalogs.html', 'HiveClientPool.html', 'HiveTableOperations.html', 'HiveTypeConverter.html', 'RuntimeMetaException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CloseableGroup.html', 'CloseableIterable.ConcatCloseableIterable.html', 'CloseableIterable.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'FileAppender.html', 'FileIO.html', 'InputFile.html', 'LocationProvider.html', 'OutputFile.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'MappedField.html', 'MappedFields.html', 'MappingUtil.html', 'NameMapping.html', 'NameMappingParser.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'SerializationUtil.html', 'IcebergInputFormat.ConfigBuilder.html', 'IcebergInputFormat.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ORC.ReadBuilder.html', 'ORC.WriteBuilder.html', 'ORC.html', 'ORCSchemaUtil.BinaryType.html', 'ORCSchemaUtil.LongType.html', 'ORCSchemaUtil.html', 'OrcMetrics.html', 'OrcValueReader.html', 'OrcValueWriter.html', 'VectorizedRowBatchIterator.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseColumnIterator.html', 'BasePageIterator.IntIterator.html', 'BasePageIterator.html', 'ColumnIterator.html', 'ColumnWriter.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetAvroReader.html', 'ParquetAvroValueReaders.TimeMillisReader.html', 'ParquetAvroValueReaders.TimestampMillisReader.html', 'ParquetAvroValueReaders.html', 'ParquetAvroWriter.html', 'ParquetDictionaryRowGroupFilter.html', 'ParquetIterable.html', 'ParquetMetricsRowGroupFilter.html', 'ParquetReader.html', 'ParquetSchemaUtil.html', 'ParquetTypeVisitor.html', 'ParquetUtil.html', 'ParquetValueReader.html', 'ParquetValueReaders.BinaryAsDecimalReader.html', 'ParquetValueReaders.BytesReader.html', 'ParquetValueReaders.FloatAsDoubleReader.html', 'ParquetValueReaders.IntAsLongReader.html', 'ParquetValueReaders.IntegerAsDecimalReader.html', 'ParquetValueReaders.ListReader.html', 'ParquetValueReaders.LongAsDecimalReader.html', 'ParquetValueReaders.MapReader.html', 'ParquetValueReaders.PrimitiveReader.html', 'ParquetValueReaders.RepeatedKeyValueReader.html', 'ParquetValueReaders.RepeatedReader.html', 'ParquetValueReaders.ReusableEntry.html', 'ParquetValueReaders.StringReader.html', 'ParquetValueReaders.StructReader.html', 'ParquetValueReaders.UnboxedReader.html', 'ParquetValueReaders.html', 'ParquetValueWriter.html', 'ParquetValueWriters.PrimitiveWriter.html', 'ParquetValueWriters.RepeatedKeyValueWriter.html', 'ParquetValueWriters.RepeatedWriter.html', 'ParquetValueWriters.StructWriter.html', 'ParquetValueWriters.html', 'ParquetWriteAdapter.html', 'TripleWriter.html', 'TypeToMessageType.html', 'TypeWithSchemaVisitor.html', 'ValuesAsBytesReader.html', 'VectorizedParquetReader.html', 'VectorizedReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergPigInputFormat.IcebergRecordReader.html', 'IcebergPigInputFormat.html', 'IcebergStorage.html', 'PigParquetReader.html', 'SchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PruneColumnsWithReordering.html', 'PruneColumnsWithoutReordering.html', 'SparkDataFile.html', 'SparkFilters.html', 'SparkSchemaUtil.html', 'SparkStructLike.html', 'SparkValueConverter.html', 'SparkAvroReader.html', 'SparkAvroWriter.html', 'SparkOrcReader.html', 'SparkOrcWriter.html', 'SparkParquetReaders.html', 'SparkParquetWriters.html', 'SparkValueReaders.html', 'SparkValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSource.html', 'StreamingWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PartitionSpecVisitor.html', 'Transform.html', 'Transforms.html', 'UnknownTransform.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CheckCompatibility.html', 'Comparators.html', 'Conversions.html', 'IndexByName.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BinPacking.ListPacker.html', 'BinPacking.PackingIterable.html', 'BinPacking.html', 'BinaryUtil.html', 'ByteBuffers.html', 'CharSequenceSet.html', 'CharSequenceWrapper.html', 'ExceptionUtil.html', 'Exceptions.html', 'JsonUtil.html', 'ManifestFileUtil.html', 'Pair.html', 'ParallelIterable.html', 'PartitionUtil.html', 'PropertyUtil.html', 'SerializableSupplier.html', 'SnapshotUtil.html', 'StructLikeWrapper.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'ThreadPools.html', 'UnicodeUtil.html', 'WapUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'overview-frame.html', 'overview-summary.html', 'overview-tree.html', 'package-list', 'script.js', 'serialized-form.html', 'stylesheet.css', 'allclasses-index.html', 'allclasses.html', 'allpackages-index.html', 'constant-values.html', 'deprecated-list.html', 'help-doc.html', 'index-all.html', 'index.html', 'jquery.js', 'ui-bg_glass_55_fbf9ee_1x400.png', 'ui-bg_glass_65_dadada_1x400.png', 'ui-bg_glass_75_dadada_1x400.png', 'ui-bg_glass_75_e6e6e6_1x400.png', 'ui-bg_glass_95_fef1ec_1x400.png', 'ui-bg_highlight-soft_75_cccccc_1x100.png', 'ui-icons_222222_256x240.png', 'ui-icons_2e83ff_256x240.png', 'ui-icons_454545_256x240.png', 'ui-icons_888888_256x240.png', 'ui-icons_cd0a0a_256x240.png', 'jquery-3.3.1.js', 'jquery-migrate-3.0.1.js', 'jquery-ui.css', 'jquery-ui.js', 'jquery-ui.min.css', 'jquery-ui.min.js', 'jquery-ui.structure.css', 'jquery-ui.structure.min.css', 'member-search-index.js', 'member-search-index.zip', 'Accessor.html', 'Accessors.html', 'AllDataFilesTable.AllDataFilesTableScan.html', 'AllDataFilesTable.html', 'AllEntriesTable.html', 'AllManifestsTable.AllManifestsTableScan.html', 'AllManifestsTable.html', 'AppendFiles.html', 'BaseCombinedScanTask.html', 'BaseMetastoreCatalog.html', 'BaseMetastoreTableOperations.html', 'BaseOverwriteFiles.html', 'BaseReplacePartitions.html', 'BaseRewriteManifests.html', 'BaseRowDelta.html', 'BaseTable.html', 'CachingCatalog.html', 'CombinedScanTask.html', 'ContentFile.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DataFilesTable.FilesTableScan.html', 'DataFilesTable.html', 'DataOperations.html', 'DataTableScan.html', 'DataTask.html', 'DeleteFile.html', 'DeleteFiles.html', 'ExpireSnapshots.html', 'FileContent.html', 'FileFormat.html', 'FileScanTask.html', 'Files.html', 'FindFiles.Builder.html', 'FindFiles.html', 'GenericManifestFile.CopyBuilder.html', 'GenericManifestFile.html', 'GenericPartitionFieldSummary.html', 'GuavaClasses.html', 'HasTableOperations.html', 'HistoryEntry.html', 'HistoryTable.html', 'LocationProviders.html', 'ManageSnapshots.html', 'ManifestContent.html', 'ManifestEntriesTable.html', 'ManifestFile.PartitionFieldSummary.html', 'ManifestFile.html', 'ManifestFiles.html', 'ManifestReader.FileType.html', 'ManifestReader.html', 'ManifestWriter.html', 'ManifestsTable.html', 'MetadataTableType.html', 'Metrics.html', 'MetricsConfig.html', 'MetricsModes.Counts.html', 'MetricsModes.Full.html', 'MetricsModes.MetricsMode.html', 'MetricsModes.None.html', 'MetricsModes.Truncate.html', 'MetricsModes.html', 'OverwriteFiles.html', 'PartitionField.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'PartitionsTable.html', 'PendingUpdate.html', 'ReplacePartitions.html', 'RewriteFiles.html', 'RewriteManifests.html', 'Rollback.html', 'RowDelta.html', 'ScanSummary.Builder.html', 'ScanSummary.PartitionMetrics.html', 'ScanSummary.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'SetLocation.html', 'Snapshot.html', 'SnapshotManager.html', 'SnapshotParser.html', 'SnapshotSummary.Builder.html', 'SnapshotSummary.html', 'SnapshotUpdate.html', 'SnapshotsTable.html', 'StructLike.html', 'SystemProperties.html', 'Table.html', 'TableMetadata.MetadataLogEntry.html', 'TableMetadata.SnapshotLogEntry.html', 'TableMetadata.html', 'TableMetadataParser.Codec.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableProperties.html', 'TableScan.html', 'Tables.html', 'Transaction.html', 'Transactions.html', 'UpdateLocation.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Action.html', 'Actions.html', 'RemoveOrphanFilesAction.html', 'RewriteDataFilesAction.html', 'RewriteDataFilesActionResult.html', 'RewriteManifestsAction.html', 'RewriteManifestsActionResult.html', 'SnapshotUpdateAction.html', 'package-summary.html', 'package-tree.html', 'ArrowAllocation.html', 'ArrowSchemaUtil.html', 'package-summary.html', 'package-tree.html', 'IcebergArrowVectors.DecimalArrowVector.html', 'IcebergArrowVectors.VarcharArrowVector.html', 'IcebergArrowVectors.html', 'NullabilityHolder.html', 'VectorHolder.html', 'VectorizedArrowReader.html', 'package-summary.html', 'package-tree.html', 'BaseVectorizedParquetValuesReader.html', 'VectorizedColumnIterator.html', 'VectorizedDictionaryEncodedParquetValuesReader.html', 'VectorizedPageIterator.html', 'VectorizedParquetDefinitionLevelReader.html', 'package-summary.html', 'package-tree.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroIterable.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'AvroSchemaWithTypeVisitor.html', 'LogicalMap.html', 'ProjectionDatumReader.html', 'RemoveIds.html', 'UUIDConversion.html', 'ValueReader.html', 'ValueReaders.StructReader.html', 'ValueReaders.html', 'ValueWriter.html', 'ValueWriters.StructWriter.html', 'ValueWriters.html', 'package-summary.html', 'package-tree.html', 'Catalog.html', 'Namespace.html', 'SupportsNamespaces.html', 'TableIdentifier.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-summary.html', 'package-tree.html', 'GenericRecord.html', 'IcebergGenerics.ScanBuilder.html', 'IcebergGenerics.html', 'IdentityPartitionConverters.html', 'Record.html', 'DataReader.html', 'DataWriter.html', 'IcebergDecoder.html', 'IcebergEncoder.html', 'package-summary.html', 'package-tree.html', 'GenericOrcReader.html', 'GenericOrcReaders.html', 'GenericOrcWriter.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'BaseParquetReaders.html', 'BaseParquetWriter.html', 'GenericParquetReaders.html', 'GenericParquetWriter.html', 'package-summary.html', 'package-tree.html', 'EncryptedFiles.html', 'EncryptedInputFile.html', 'EncryptedOutputFile.html', 'EncryptionKeyMetadata.html', 'EncryptionKeyMetadatas.html', 'EncryptionManager.html', 'PlaintextEncryptionManager.html', 'package-summary.html', 'package-tree.html', 'CreateSnapshotEvent.html', 'Listener.html', 'Listeners.html', 'ScanEvent.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CherrypickAncestorCommitException.html', 'CommitFailedException.html', 'DuplicateWAPCommitException.html', 'NamespaceNotEmptyException.html', 'NoSuchIcebergTableException.html', 'NoSuchNamespaceException.html', 'NoSuchTableException.html', 'NotFoundException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'Bound.html', 'BoundLiteralPredicate.html', 'BoundPredicate.html', 'BoundReference.html', 'BoundSetPredicate.html', 'BoundTerm.html', 'BoundTransform.html', 'BoundUnaryPredicate.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.BoundVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'InclusiveMetricsEvaluator.html', 'Literal.html', 'ManifestEvaluator.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'StrictMetricsEvaluator.html', 'Term.html', 'True.html', 'Unbound.html', 'UnboundPredicate.html', 'UnboundTerm.html', 'UnboundTransform.html', 'package-summary.html', 'package-tree.html', 'FlinkSchemaUtil.html', 'FlinkTypeToType.html', 'FlinkTypeVisitor.html', 'FlinkAvroReader.html', 'FlinkAvroWriter.html', 'FlinkParquetReaders.html', 'FlinkParquetWriters.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'HadoopCatalog.html', 'HadoopFileIO.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTableOperations.html', 'HadoopTables.html', 'HiddenPathFilter.html', 'SerializableConfiguration.html', 'Util.html', 'package-summary.html', 'package-tree.html', 'ClientPool.Action.html', 'ClientPool.html', 'HiveCatalog.html', 'HiveCatalogs.html', 'HiveClientPool.html', 'HiveTableOperations.html', 'HiveTypeConverter.html', 'RuntimeMetaException.html', 'package-summary.html', 'package-tree.html', 'CloseableGroup.html', 'CloseableIterable.ConcatCloseableIterable.html', 'CloseableIterable.html', 'CloseableIterator.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'FileAppender.html', 'FileIO.html', 'InputFile.html', 'LocationProvider.html', 'OutputFile.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'package-summary.html', 'package-tree.html', 'MappedField.html', 'MappedFields.html', 'MappingUtil.html', 'NameMapping.html', 'NameMappingParser.html', 'package-summary.html', 'package-tree.html', 'InputFormatConfig.ConfigBuilder.html', 'InputFormatConfig.InMemoryDataModel.html', 'InputFormatConfig.html', 'SerializationUtil.html', 'IcebergSerDe.html', 'IcebergWritable.html', 'package-summary.html', 'package-tree.html', 'IcebergBinaryObjectInspector.html', 'IcebergDateObjectInspector.html', 'IcebergDecimalObjectInspector.html', 'IcebergObjectInspector.html', 'IcebergRecordObjectInspector.html', 'IcebergTimestampObjectInspector.html', 'package-summary.html', 'package-tree.html', 'IcebergInputFormat.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'ORC.ReadBuilder.html', 'ORC.WriteBuilder.html', 'ORC.html', 'ORCSchemaUtil.BinaryType.html', 'ORCSchemaUtil.LongType.html', 'ORCSchemaUtil.html', 'OrcMetrics.html', 'OrcRowReader.html', 'OrcSchemaVisitor.html', 'OrcSchemaWithTypeVisitor.html', 'OrcValueReader.html', 'OrcValueReaders.StructReader.html', 'OrcValueReaders.html', 'OrcValueWriter.html', 'VectorizedRowBatchIterator.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'BaseColumnIterator.html', 'BasePageIterator.IntIterator.html', 'BasePageIterator.html', 'ColumnIterator.html', 'ColumnWriter.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetAvroReader.html', 'ParquetAvroValueReaders.TimeMillisReader.html', 'ParquetAvroValueReaders.TimestampMillisReader.html', 'ParquetAvroValueReaders.html', 'ParquetAvroWriter.html', 'ParquetDictionaryRowGroupFilter.html', 'ParquetIterable.html', 'ParquetMetricsRowGroupFilter.html', 'ParquetReader.html', 'ParquetSchemaUtil.HasIds.html', 'ParquetSchemaUtil.html', 'ParquetTypeVisitor.html', 'ParquetUtil.html', 'ParquetValueReader.html', 'ParquetValueReaders.BinaryAsDecimalReader.html', 'ParquetValueReaders.BytesReader.html', 'ParquetValueReaders.FloatAsDoubleReader.html', 'ParquetValueReaders.IntAsLongReader.html', 'ParquetValueReaders.IntegerAsDecimalReader.html', 'ParquetValueReaders.ListReader.html', 'ParquetValueReaders.LongAsDecimalReader.html', 'ParquetValueReaders.MapReader.html', 'ParquetValueReaders.PrimitiveReader.html', 'ParquetValueReaders.RepeatedKeyValueReader.html', 'ParquetValueReaders.RepeatedReader.html', 'ParquetValueReaders.ReusableEntry.html', 'ParquetValueReaders.StringReader.html', 'ParquetValueReaders.StructReader.html', 'ParquetValueReaders.UnboxedReader.html', 'ParquetValueReaders.html', 'ParquetValueWriter.html', 'ParquetValueWriters.PrimitiveWriter.html', 'ParquetValueWriters.RepeatedKeyValueWriter.html', 'ParquetValueWriters.RepeatedWriter.html', 'ParquetValueWriters.StructWriter.html', 'ParquetValueWriters.html', 'ParquetWriteAdapter.html', 'RemoveIds.html', 'TripleWriter.html', 'TypeToMessageType.html', 'TypeWithSchemaVisitor.html', 'ValuesAsBytesReader.html', 'VectorizedParquetReader.html', 'VectorizedReader.html', 'package-summary.html', 'package-tree.html', 'IcebergPigInputFormat.IcebergRecordReader.html', 'IcebergPigInputFormat.html', 'IcebergStorage.html', 'PigParquetReader.html', 'SchemaUtil.html', 'package-summary.html', 'package-tree.html', 'PruneColumnsWithReordering.html', 'PruneColumnsWithoutReordering.html', 'RollbackStagedTable.html', 'Spark3Util.DescribeSchemaVisitor.html', 'Spark3Util.html', 'SparkCatalog.html', 'SparkDataFile.html', 'SparkExceptionUtil.html', 'SparkFilters.html', 'SparkSchemaUtil.html', 'SparkSessionCatalog.html', 'SparkStructLike.html', 'SparkTableUtil.SparkPartition.html', 'SparkTableUtil.html', 'SparkUtil.html', 'SparkValueConverter.html', 'AvroWithSparkSchemaVisitor.html', 'ParquetWithSparkSchemaVisitor.html', 'SparkAvroReader.html', 'SparkAvroWriter.html', 'SparkOrcReader.html', 'SparkOrcWriter.html', 'SparkParquetReaders.html', 'SparkParquetWriters.html', 'SparkValueReaders.html', 'SparkValueWriters.html', 'package-summary.html', 'package-tree.html', 'ArrowVectorAccessor.html', 'ArrowVectorAccessors.html', 'ColumnarBatchReader.html', 'IcebergArrowColumnVector.html', 'NullValuesColumnVector.html', 'VectorizedSparkParquetReaders.html', 'package-summary.html', 'package-tree.html', 'package-summary.html', 'package-tree.html', 'IcebergSource.html', 'RowDataRewriter.html', 'SparkScanBuilder.html', 'SparkStreamingWrite.html', 'SparkTable.html', 'StagedSparkTable.html', 'package-summary.html', 'package-tree.html', 'PartitionSpecVisitor.html', 'Transform.html', 'Transforms.html', 'UnknownTransform.html', 'package-summary.html', 'package-tree.html', 'CheckCompatibility.html', 'Comparators.html', 'Conversions.html', 'IndexByName.html', 'IndexParents.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-summary.html', 'package-tree.html', 'BinPacking.ListPacker.html', 'BinPacking.PackingIterable.html', 'BinPacking.html', 'BinaryUtil.html', 'ByteBuffers.html', 'CharSequenceSet.html', 'CharSequenceWrapper.html', 'DateTimeUtil.html', 'ExceptionUtil.html', 'Exceptions.html', 'JsonUtil.html', 'ManifestFileUtil.html', 'Pair.html', 'ParallelIterable.html', 'PartitionUtil.html', 'PropertyUtil.html', 'SerializableSupplier.html', 'SnapshotUtil.html', 'StructLikeWrapper.html', 'TableScanUtil.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'ThreadPools.html', 'UnicodeUtil.html', 'WapUtil.html', 'package-summary.html', 'package-tree.html', 'overview-summary.html', 'overview-tree.html', 'package-search-index.js', 'package-search-index.zip', 'glass.png', 'x.png', 'script.js', 'search.js', 'serialized-form.html', 'stylesheet.css', 'type-search-index.js', 'type-search-index.zip', 'allclasses-frame.html', 'allclasses-noframe.html', 'constant-values.html', 'deprecated-list.html', 'help-doc.html', 'index-all.html', 'index.html', 'Accessor.html', 'Accessors.html', 'AllDataFilesTable.AllDataFilesTableScan.html', 'AllDataFilesTable.html', 'AllEntriesTable.html', 'AllManifestsTable.AllManifestsTableScan.html', 'AllManifestsTable.html', 'AppendFiles.html', 'BaseCombinedScanTask.html', 'BaseMetastoreCatalog.html', 'BaseMetastoreTableOperations.html', 'BaseOverwriteFiles.html', 'BaseReplacePartitions.html', 'BaseRewriteManifests.html', 'BaseRowDelta.html', 'BaseTable.html', 'CachingCatalog.html', 'CombinedScanTask.html', 'ContentFile.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DataFilesTable.FilesTableScan.html', 'DataFilesTable.html', 'DataOperations.html', 'DataTableScan.html', 'DataTask.html', 'DeleteFile.html', 'DeleteFiles.html', 'ExpireSnapshots.html', 'FileContent.html', 'FileFormat.html', 'FileScanTask.html', 'Files.html', 'FindFiles.Builder.html', 'FindFiles.html', 'GenericManifestFile.CopyBuilder.html', 'GenericManifestFile.html', 'GenericPartitionFieldSummary.html', 'GuavaClasses.html', 'HasTableOperations.html', 'HistoryEntry.html', 'HistoryTable.html', 'LocationProviders.html', 'ManageSnapshots.html', 'ManifestContent.html', 'ManifestEntriesTable.html', 'ManifestFile.PartitionFieldSummary.html', 'ManifestFile.html', 'ManifestFiles.html', 'ManifestReader.FileType.html', 'ManifestReader.html', 'ManifestWriter.html', 'ManifestsTable.html', 'MetadataTableType.html', 'Metrics.html', 'MetricsConfig.html', 'MetricsModes.Counts.html', 'MetricsModes.Full.html', 'MetricsModes.MetricsMode.html', 'MetricsModes.None.html', 'MetricsModes.Truncate.html', 'MetricsModes.html', 'OverwriteFiles.html', 'PartitionField.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'PartitionsTable.html', 'PendingUpdate.html', 'ReplacePartitions.html', 'RewriteFiles.html', 'RewriteManifests.html', 'Rollback.html', 'RowDelta.html', 'ScanSummary.Builder.html', 'ScanSummary.PartitionMetrics.html', 'ScanSummary.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'SetLocation.html', 'Snapshot.html', 'SnapshotManager.html', 'SnapshotParser.html', 'SnapshotSummary.Builder.html', 'SnapshotSummary.html', 'SnapshotUpdate.html', 'SnapshotsTable.html', 'StructLike.html', 'SystemProperties.html', 'Table.html', 'TableMetadata.MetadataLogEntry.html', 'TableMetadata.SnapshotLogEntry.html', 'TableMetadata.html', 'TableMetadataParser.Codec.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableProperties.html', 'TableScan.html', 'Tables.html', 'Transaction.html', 'Transactions.html', 'UpdateLocation.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Action.html', 'Actions.html', 'RemoveOrphanFilesAction.html', 'RewriteDataFilesAction.html', 'RewriteDataFilesActionResult.html', 'RewriteManifestsAction.html', 'RewriteManifestsActionResult.html', 'SnapshotUpdateAction.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ArrowAllocation.html', 'ArrowSchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergArrowVectors.DecimalArrowVector.html', 'IcebergArrowVectors.VarcharArrowVector.html', 'IcebergArrowVectors.html', 'NullabilityHolder.html', 'VectorHolder.html', 'VectorizedArrowReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseVectorizedParquetValuesReader.html', 'VectorizedColumnIterator.html', 'VectorizedDictionaryEncodedParquetValuesReader.html', 'VectorizedPageIterator.html', 'VectorizedParquetDefinitionLevelReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroIterable.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'AvroSchemaWithTypeVisitor.html', 'LogicalMap.html', 'ProjectionDatumReader.html', 'RemoveIds.html', 'UUIDConversion.html', 'ValueReader.html', 'ValueReaders.StructReader.html', 'ValueReaders.html', 'ValueWriter.html', 'ValueWriters.StructWriter.html', 'ValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Catalog.html', 'Namespace.html', 'SupportsNamespaces.html', 'TableIdentifier.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericRecord.html', 'IcebergGenerics.ScanBuilder.html', 'IcebergGenerics.html', 'IdentityPartitionConverters.html', 'Record.html', 'DataReader.html', 'DataWriter.html', 'IcebergDecoder.html', 'IcebergEncoder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericOrcReader.html', 'GenericOrcReaders.html', 'GenericOrcWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseParquetReaders.html', 'BaseParquetWriter.html', 'GenericParquetReaders.html', 'GenericParquetWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'EncryptedFiles.html', 'EncryptedInputFile.html', 'EncryptedOutputFile.html', 'EncryptionKeyMetadata.html', 'EncryptionKeyMetadatas.html', 'EncryptionManager.html', 'PlaintextEncryptionManager.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CreateSnapshotEvent.html', 'Listener.html', 'Listeners.html', 'ScanEvent.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CherrypickAncestorCommitException.html', 'CommitFailedException.html', 'DuplicateWAPCommitException.html', 'NamespaceNotEmptyException.html', 'NoSuchIcebergTableException.html', 'NoSuchNamespaceException.html', 'NoSuchTableException.html', 'NotFoundException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'Bound.html', 'BoundLiteralPredicate.html', 'BoundPredicate.html', 'BoundReference.html', 'BoundSetPredicate.html', 'BoundTerm.html', 'BoundTransform.html', 'BoundUnaryPredicate.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.BoundVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'InclusiveMetricsEvaluator.html', 'Literal.html', 'ManifestEvaluator.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'StrictMetricsEvaluator.html', 'Term.html', 'True.html', 'Unbound.html', 'UnboundPredicate.html', 'UnboundTerm.html', 'UnboundTransform.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'FlinkSchemaUtil.html', 'FlinkTypeToType.html', 'FlinkTypeVisitor.html', 'FlinkAvroReader.html', 'FlinkAvroWriter.html', 'FlinkParquetReaders.html', 'FlinkParquetWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'HadoopCatalog.html', 'HadoopFileIO.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTableOperations.html', 'HadoopTables.html', 'HiddenPathFilter.html', 'SerializableConfiguration.html', 'Util.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ClientPool.Action.html', 'ClientPool.html', 'HiveCatalog.html', 'HiveCatalogs.html', 'HiveClientPool.html', 'HiveTableOperations.html', 'HiveTypeConverter.html', 'RuntimeMetaException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CloseableGroup.html', 'CloseableIterable.ConcatCloseableIterable.html', 'CloseableIterable.html', 'CloseableIterator.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'FileAppender.html', 'FileIO.html', 'InputFile.html', 'LocationProvider.html', 'OutputFile.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'MappedField.html', 'MappedFields.html', 'MappingUtil.html', 'NameMapping.html', 'NameMappingParser.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'InputFormatConfig.ConfigBuilder.html', 'InputFormatConfig.InMemoryDataModel.html', 'InputFormatConfig.html', 'SerializationUtil.html', 'IcebergSerDe.html', 'IcebergWritable.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergBinaryObjectInspector.html', 'IcebergDateObjectInspector.html', 'IcebergDecimalObjectInspector.html', 'IcebergObjectInspector.html', 'IcebergRecordObjectInspector.html', 'IcebergTimestampObjectInspector.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergInputFormat.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ORC.ReadBuilder.html', 'ORC.WriteBuilder.html', 'ORC.html', 'ORCSchemaUtil.BinaryType.html', 'ORCSchemaUtil.LongType.html', 'ORCSchemaUtil.html', 'OrcMetrics.html', 'OrcRowReader.html', 'OrcSchemaVisitor.html', 'OrcSchemaWithTypeVisitor.html', 'OrcValueReader.html', 'OrcValueReaders.StructReader.html', 'OrcValueReaders.html', 'OrcValueWriter.html', 'VectorizedRowBatchIterator.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BaseColumnIterator.html', 'BasePageIterator.IntIterator.html', 'BasePageIterator.html', 'ColumnIterator.html', 'ColumnWriter.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetAvroReader.html', 'ParquetAvroValueReaders.TimeMillisReader.html', 'ParquetAvroValueReaders.TimestampMillisReader.html', 'ParquetAvroValueReaders.html', 'ParquetAvroWriter.html', 'ParquetDictionaryRowGroupFilter.html', 'ParquetIterable.html', 'ParquetMetricsRowGroupFilter.html', 'ParquetReader.html', 'ParquetSchemaUtil.HasIds.html', 'ParquetSchemaUtil.html', 'ParquetTypeVisitor.html', 'ParquetUtil.html', 'ParquetValueReader.html', 'ParquetValueReaders.BinaryAsDecimalReader.html', 'ParquetValueReaders.BytesReader.html', 'ParquetValueReaders.FloatAsDoubleReader.html', 'ParquetValueReaders.IntAsLongReader.html', 'ParquetValueReaders.IntegerAsDecimalReader.html', 'ParquetValueReaders.ListReader.html', 'ParquetValueReaders.LongAsDecimalReader.html', 'ParquetValueReaders.MapReader.html', 'ParquetValueReaders.PrimitiveReader.html', 'ParquetValueReaders.RepeatedKeyValueReader.html', 'ParquetValueReaders.RepeatedReader.html', 'ParquetValueReaders.ReusableEntry.html', 'ParquetValueReaders.StringReader.html', 'ParquetValueReaders.StructReader.html', 'ParquetValueReaders.UnboxedReader.html', 'ParquetValueReaders.html', 'ParquetValueWriter.html', 'ParquetValueWriters.PrimitiveWriter.html', 'ParquetValueWriters.RepeatedKeyValueWriter.html', 'ParquetValueWriters.RepeatedWriter.html', 'ParquetValueWriters.StructWriter.html', 'ParquetValueWriters.html', 'ParquetWriteAdapter.html', 'RemoveIds.html', 'TripleWriter.html', 'TypeToMessageType.html', 'TypeWithSchemaVisitor.html', 'ValuesAsBytesReader.html', 'VectorizedParquetReader.html', 'VectorizedReader.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergPigInputFormat.IcebergRecordReader.html', 'IcebergPigInputFormat.html', 'IcebergStorage.html', 'PigParquetReader.html', 'SchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PruneColumnsWithReordering.html', 'PruneColumnsWithoutReordering.html', 'RollbackStagedTable.html', 'Spark3Util.DescribeSchemaVisitor.html', 'Spark3Util.html', 'SparkCatalog.html', 'SparkDataFile.html', 'SparkExceptionUtil.html', 'SparkFilters.html', 'SparkSchemaUtil.html', 'SparkSessionCatalog.html', 'SparkStructLike.html', 'SparkTableUtil.SparkPartition.html', 'SparkTableUtil.html', 'SparkUtil.html', 'SparkValueConverter.html', 'AvroWithSparkSchemaVisitor.html', 'ParquetWithSparkSchemaVisitor.html', 'SparkAvroReader.html', 'SparkAvroWriter.html', 'SparkOrcReader.html', 'SparkOrcWriter.html', 'SparkParquetReaders.html', 'SparkParquetWriters.html', 'SparkValueReaders.html', 'SparkValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ArrowVectorAccessor.html', 'ArrowVectorAccessors.html', 'ColumnarBatchReader.html', 'IcebergArrowColumnVector.html', 'NullValuesColumnVector.html', 'VectorizedSparkParquetReaders.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSource.html', 'RowDataRewriter.html', 'SparkScanBuilder.html', 'SparkStreamingWrite.html', 'SparkTable.html', 'StagedSparkTable.html', 'Stats.html', 'StreamingWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PartitionSpecVisitor.html', 'Transform.html', 'Transforms.html', 'UnknownTransform.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CheckCompatibility.html', 'Comparators.html', 'Conversions.html', 'IndexByName.html', 'IndexParents.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BinPacking.ListPacker.html', 'BinPacking.PackingIterable.html', 'BinPacking.html', 'BinaryUtil.html', 'ByteBuffers.html', 'CharSequenceSet.html', 'CharSequenceWrapper.html', 'DateTimeUtil.html', 'ExceptionUtil.html', 'Exceptions.html', 'JsonUtil.html', 'ManifestFileUtil.html', 'Pair.html', 'ParallelIterable.html', 'PartitionUtil.html', 'PropertyUtil.html', 'SerializableSupplier.html', 'SnapshotUtil.html', 'StructLikeWrapper.html', 'TableScanUtil.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'ThreadPools.html', 'UnicodeUtil.html', 'WapUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'overview-frame.html', 'overview-summary.html', 'overview-tree.html', 'package-list', 'script.js', 'serialized-form.html', 'stylesheet.css', 'index.html', 'allclasses-frame.html', 'allclasses-noframe.html', 'constant-values.html', 'deprecated-list.html', 'help-doc.html', 'index-all.html', 'index.html', 'Accessor.html', 'Accessors.html', 'AppendFiles.html', 'BaseCombinedScanTask.html', 'BaseMetastoreCatalog.html', 'BaseMetastoreTableOperations.html', 'BaseMetastoreTables.html', 'BaseTable.html', 'CombinedScanTask.html', 'ConfigProperties.html', 'DataFile.html', 'DataFiles.Builder.html', 'DataFiles.html', 'DataOperations.html', 'DeleteFiles.html', 'ExpireSnapshots.html', 'FileFormat.html', 'FileHistory.Builder.html', 'FileHistory.html', 'FileScanTask.html', 'Files.html', 'Filterable.html', 'FilteredManifest.html', 'GenericManifestFile.html', 'GenericPartitionFieldSummary.html', 'HasTableOperations.html', 'LocationProviders.html', 'ManifestFile.PartitionFieldSummary.html', 'ManifestFile.html', 'ManifestReader.html', 'ManifestWriter.html', 'Metrics.html', 'OverwriteData.html', 'OverwriteFiles.html', 'PartitionField.html', 'PartitionSpec.Builder.html', 'PartitionSpec.html', 'PartitionSpecParser.html', 'PendingUpdate.html', 'ReplaceManifests.html', 'ReplacePartitions.html', 'ReplacePartitionsOperation.html', 'RewriteFiles.html', 'RewriteManifests.html', 'Rollback.html', 'ScanSummary.Builder.html', 'ScanSummary.PartitionMetrics.html', 'ScanSummary.html', 'ScanTask.html', 'Schema.html', 'SchemaParser.html', 'SetLocation.html', 'Snapshot.html', 'SnapshotParser.html', 'SnapshotSummary.Builder.html', 'SnapshotSummary.html', 'SnapshotUpdate.html', 'StructLike.html', 'SystemProperties.html', 'Table.html', 'TableMetadata.SnapshotLogEntry.html', 'TableMetadata.html', 'TableMetadataParser.html', 'TableOperations.html', 'TableProperties.html', 'TableScan.html', 'Tables.html', 'Transaction.html', 'Transactions.html', 'UpdateLocation.html', 'UpdateProperties.html', 'UpdateSchema.html', 'Avro.ReadBuilder.html', 'Avro.WriteBuilder.html', 'Avro.html', 'AvroIterable.html', 'AvroSchemaUtil.html', 'AvroSchemaVisitor.html', 'LogicalMap.html', 'ProjectionDatumReader.html', 'UUIDConversion.html', 'ValueReader.html', 'ValueReaders.StructReader.html', 'ValueReaders.html', 'ValueWriter.html', 'ValueWriters.StructWriter.html', 'ValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Catalog.html', 'Namespace.html', 'TableIdentifier.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'DynClasses.Builder.html', 'DynClasses.html', 'DynConstructors.Builder.html', 'DynConstructors.Ctor.html', 'DynConstructors.html', 'DynFields.BoundField.html', 'DynFields.Builder.html', 'DynFields.StaticField.html', 'DynFields.UnboundField.html', 'DynFields.html', 'DynMethods.BoundMethod.html', 'DynMethods.Builder.html', 'DynMethods.StaticMethod.html', 'DynMethods.UnboundMethod.html', 'DynMethods.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericRecord.html', 'IcebergGenerics.ScanBuilder.html', 'IcebergGenerics.html', 'Record.html', 'DataReader.html', 'DataWriter.html', 'IcebergDecoder.html', 'IcebergEncoder.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'GenericParquetReaders.html', 'GenericParquetWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'EncryptedFiles.html', 'EncryptedInputFile.html', 'EncryptedOutputFile.html', 'EncryptionKeyMetadata.html', 'EncryptionKeyMetadatas.html', 'EncryptionManager.html', 'PlaintextEncryptionManager.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Listener.html', 'Listeners.html', 'ScanEvent.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'AlreadyExistsException.html', 'CommitFailedException.html', 'NoSuchTableException.html', 'RuntimeIOException.html', 'ValidationException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'And.html', 'Binder.html', 'BoundPredicate.html', 'BoundReference.html', 'Evaluator.html', 'Expression.Operation.html', 'Expression.html', 'ExpressionVisitors.BoundExpressionVisitor.html', 'ExpressionVisitors.ExpressionVisitor.html', 'ExpressionVisitors.html', 'Expressions.html', 'False.html', 'InclusiveManifestEvaluator.html', 'InclusiveMetricsEvaluator.html', 'Literal.html', 'NamedReference.html', 'Not.html', 'Or.html', 'Predicate.html', 'Projections.ProjectionEvaluator.html', 'Projections.html', 'Reference.html', 'ResidualEvaluator.html', 'StrictMetricsEvaluator.html', 'True.html', 'UnboundPredicate.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'HadoopFileIO.html', 'HadoopInputFile.html', 'HadoopOutputFile.html', 'HadoopTableOperations.html', 'HadoopTables.html', 'SerializableConfiguration.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'HiveCatalog.html', 'HiveCatalogs.html', 'HiveTableOperations.html', 'HiveTables.html', 'HiveTypeConverter.html', 'RuntimeMetaException.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CloseableGroup.html', 'CloseableIterable.ConcatCloseableIterable.html', 'CloseableIterable.html', 'DelegatingInputStream.html', 'DelegatingOutputStream.html', 'FileAppender.html', 'FileIO.html', 'InputFile.html', 'LocationProvider.html', 'OutputFile.html', 'PositionOutputStream.html', 'SeekableInputStream.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ColumnIdMap.html', 'ORC.ReadBuilder.html', 'ORC.WriteBuilder.html', 'ORC.html', 'OrcMetrics.html', 'OrcValueReader.html', 'OrcValueWriter.html', 'TypeConversion.html', 'VectorizedRowBatchIterator.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'ColumnIterator.html', 'ColumnWriter.html', 'Parquet.ReadBuilder.html', 'Parquet.WriteBuilder.html', 'Parquet.html', 'ParquetAvroReader.html', 'ParquetAvroValueReaders.TimeMillisReader.html', 'ParquetAvroValueReaders.TimestampMillisReader.html', 'ParquetAvroValueReaders.html', 'ParquetAvroWriter.html', 'ParquetDictionaryRowGroupFilter.html', 'ParquetIterable.html', 'ParquetMetricsRowGroupFilter.html', 'ParquetReader.html', 'ParquetSchemaUtil.html', 'ParquetTypeVisitor.html', 'ParquetUtil.html', 'ParquetValueReader.html', 'ParquetValueReaders.BinaryAsDecimalReader.html', 'ParquetValueReaders.BytesReader.html', 'ParquetValueReaders.FloatAsDoubleReader.html', 'ParquetValueReaders.IntAsLongReader.html', 'ParquetValueReaders.IntegerAsDecimalReader.html', 'ParquetValueReaders.ListReader.html', 'ParquetValueReaders.LongAsDecimalReader.html', 'ParquetValueReaders.MapReader.html', 'ParquetValueReaders.PrimitiveReader.html', 'ParquetValueReaders.RepeatedKeyValueReader.html', 'ParquetValueReaders.RepeatedReader.html', 'ParquetValueReaders.ReusableEntry.html', 'ParquetValueReaders.StringReader.html', 'ParquetValueReaders.StructReader.html', 'ParquetValueReaders.UnboxedReader.html', 'ParquetValueReaders.html', 'ParquetValueWriter.html', 'ParquetValueWriters.PrimitiveWriter.html', 'ParquetValueWriters.RepeatedKeyValueWriter.html', 'ParquetValueWriters.RepeatedWriter.html', 'ParquetValueWriters.StructWriter.html', 'ParquetValueWriters.html', 'ParquetWriteAdapter.html', 'TripleWriter.html', 'TypeToMessageType.html', 'TypeWithSchemaVisitor.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergPigInputFormat.IcebergRecordReader.html', 'IcebergPigInputFormat.html', 'IcebergStorage.html', 'PigParquetReader.html', 'SchemaUtil.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PruneColumnsWithReordering.html', 'PruneColumnsWithoutReordering.html', 'SparkFilters.html', 'SparkSchemaUtil.html', 'SparkAvroReader.html', 'SparkAvroWriter.html', 'SparkOrcReader.html', 'SparkOrcWriter.html', 'SparkParquetReaders.html', 'SparkParquetWriters.html', 'SparkValueReaders.html', 'SparkValueWriters.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'Hive.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'IcebergSource.html', 'StreamingWriter.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'PartitionSpecVisitor.html', 'Transform.html', 'Transforms.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'CheckCompatibility.html', 'Comparators.html', 'Conversions.html', 'IndexByName.html', 'Type.NestedType.html', 'Type.PrimitiveType.html', 'Type.TypeID.html', 'Type.html', 'TypeUtil.CustomOrderSchemaVisitor.html', 'TypeUtil.NextID.html', 'TypeUtil.SchemaVisitor.html', 'TypeUtil.html', 'Types.BinaryType.html', 'Types.BooleanType.html', 'Types.DateType.html', 'Types.DecimalType.html', 'Types.DoubleType.html', 'Types.FixedType.html', 'Types.FloatType.html', 'Types.IntegerType.html', 'Types.ListType.html', 'Types.LongType.html', 'Types.MapType.html', 'Types.NestedField.html', 'Types.StringType.html', 'Types.StructType.html', 'Types.TimeType.html', 'Types.TimestampType.html', 'Types.UUIDType.html', 'Types.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'BinPacking.ListPacker.html', 'BinPacking.PackingIterable.html', 'BinPacking.html', 'ByteBuffers.html', 'CharSequenceWrapper.html', 'ExceptionUtil.html', 'Exceptions.html', 'JsonUtil.html', 'Pair.html', 'ParallelIterable.html', 'PropertyUtil.html', 'StructLikeWrapper.html', 'Tasks.Builder.html', 'Tasks.FailureTask.html', 'Tasks.Task.html', 'Tasks.UnrecoverableException.html', 'Tasks.html', 'ThreadPools.html', 'package-frame.html', 'package-summary.html', 'package-tree.html', 'overview-frame.html', 'overview-summary.html', 'overview-tree.html', 'package-list', 'script.js', 'serialized-form.html', 'stylesheet.css', 'jdbc.md', 'maintenance.md', 'nessie.md', 'partitioning.md', 'performance.md', 'python-api-intro.md', 'python-feature-support.md', 'python-quickstart.md', 'releases.md', 'reliability.md', 'roadmap.md', 'schemas.md', 'security.md', 'snapshots.md', 'spark-configuration.md', 'spark-ddl.md', 'spark-procedures.md', 'spark-queries.md', 'spark-structured-streaming.md', 'spark-writes.md', 'spec.md', 'terms.md', '404.html', 'nav-item.html', 'topbar.html', 'trademarks.md', 'trino-prestodb.md', 'mkdocs.yml', 'requirements.txt']"
Spec: Update REST CreateNamespaceResponse with properties (#4039),1,25,2022-02-08 08:09:58-08:00,['rest-catalog-open-api.yaml']
Build: Upgrade to Gradle 7.4 (#4066),2,4,2022-02-08 08:10:29-08:00,"['gradle-wrapper.properties', 'gradlew']"
Hive: Fix Javadoc argument (#4064),1,4,2022-02-08 08:11:25-08:00,['TestHiveMetastore.java']
Spark 3.2: Add Scala 2.13 build and CI (#4009),27,260,2022-02-08 11:57:05-08:00,"['publish-snapshot.yml', 'spark-ci.yml', 'gradle.properties', 'jmh.gradle', 'settings.gradle', 'build.gradle', 'AssignmentAlignmentSupport.scala', 'ResolveProcedures.scala', 'RewriteRowLevelCommand.scala', 'ExtendedV2ExpressionUtils.scala', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'Call.scala', 'WriteDelta.scala', 'CallExec.scala', 'ExtendedDataSourceV2Strategy.scala', 'ExtendedDistributionAndOrderingUtils.scala', 'SetIdentifierFieldsExec.scala', 'WriteDeltaExec.scala', 'RowLevelCommandDynamicPruning.scala', 'Spark3Util.java', 'SparkTableUtil.java', 'DistributionAndOrderingUtils.scala', 'TestCreateActions.java', 'TestForwardCompatibility.java', 'TestStructuredStreaming.java', 'versions.props']"
"Tests: Replace DataWriter::add with DataWriter::write in tests (#4053)

This is a follow-up change of #4048",7,18,2022-02-08 11:58:21-08:00,"['TestAvroDataWriter.java', 'TestOrcDataWriter.java', 'TestAppenderFactory.java', 'TestFileWriterFactory.java', 'TestGenericSortedPosDeleteWriter.java', 'TestWriterMetrics.java', 'TestParquetDataWriter.java']"
Docs: add new site markdown files (#4062),80,8811,2022-02-08 13:42:14-08:00,"['labeler.yml', 'flink-ci.yml', 'hive-ci.yml', 'java-ci.yml', 'spark-ci.yml', '.rat-excludes', 'blogs.md', 'join.md', 'talks.md', 'spec.md', 'terms.md', 'benchmarks.md', 'how-to-release.md', 'multi-engine-support.md', 'roadmap.md', 'security.md', 'trademarks.md', 'how-to-verify-a-release.md', 'release-notes.md', '_index.md', 'java-api-quickstart.md', 'java-api.md', 'java-custom-catalog.md', '_index.md', 'python-api-intro.md', 'python-feature-support.md', 'python-quickstart.md', '_index.md', '_index.md', '_index.md', '_index.md', '_index.md', '_index.md', '_index.md', '_index.md', 'blogs.md', 'join.md', 'talks.md', '_index.md', '_index.md', '_index.md', 'flink-connector.md', 'flink-getting-started.md', '_index.md', 'spec.md', 'terms.md', '_index.md', '_index.md', 'aws.md', 'jdbc.md', 'nessie.md', '_index.md', '_index.md', 'benchmarks.md', 'how-to-release.md', 'roadmap.md', 'security.md', 'trademarks.md', '_index.md', '_index.md', '_index.md', '_index.md', 'release-notes.md', '_index.md', 'spark-configuration.md', 'spark-ddl.md', 'spark-getting-started.md', 'spark-procedures.md', 'spark-queries.md', 'spark-structured-streaming.md', 'spark-writes.md', '_index.md', 'configuration.md', 'evolution.md', 'maintenance.md', 'partitioning.md', 'performance.md', 'reliability.md', 'schemas.md', '_index.md']"
Spark 3.2: Fix testUpdateWithoutCondition for copy-on-write (#4033),2,45,2022-02-08 20:49:13-08:00,"['SparkRowLevelOperationsTestBase.java', 'TestUpdate.java']"
Docs: update documentation contribution instructions (#4069),1,5,2022-02-08 22:43:37-08:00,['CONTRIBUTING.md']
Spec: Move REST catalog OpenAPI spec to new docs/rest folder (#4057),1,0,2022-02-09 10:55:03-08:00,['rest-catalog-open-api.yaml']
Python (legacy): Add Decimal type conversion (#3988),4,251,2022-02-09 16:51:01-08:00,"['TestConversions.java', 'conversions.py', 'type_util.py', 'test_conversions.py']"
Python: Add InputStream and OutputStream protocols for FileIO streams (#4021),2,77,2022-02-09 16:54:45-08:00,"['base.py', 'test_base.py']"
"Core: Add reference structures to TableMetadata to unblock TableMetadata API changes (#4082)

Co-authored-by: @hameizi 1249369293@qq.com
Co-authored-by: @jackye1995 yzhaoqin@amazon.com",3,41,2022-02-10 07:58:52-08:00,"['TableMetadata.java', 'TableMetadataParser.java', 'TestTableMetadata.java']"
Flink: Support custom snapshot metadata in sink builder (#4061),4,38,2022-02-10 08:10:14-08:00,"['FlinkSink.java', 'IcebergFilesCommitter.java', 'TestFlinkIcebergSink.java', 'TestIcebergFilesCommitter.java']"
ORC: Upgrade ORC to 1.7.3 (#4084),1,2,2022-02-10 08:10:49-08:00,['versions.props']
Nessie: Use consistent naming for LOG (#4076),2,16,2022-02-10 10:10:53-08:00,"['NessieCatalog.java', 'BaseTestIceberg.java']"
Core: Add support for writing and reading ZSTD Avro Files (#4083),2,66,2022-02-10 21:18:02-08:00,"['TableProperties.java', 'Avro.java']"
"Docs: Update Release Artifacts in Quickstart Commands for Spark (#4078)

* Update Release Artifacts in Quickstart Commands for Spark to Spark3.2 Artifacts",6,19,2022-02-11 11:22:00-06:00,"['how-to-verify-a-release.md', 'java-api.md', 'aws.md', 'jdbc.md', 'nessie.md', 'spark-getting-started.md']"
AWS: fix inconsistency of S3 checksum feature names (#4103),1,17,2022-02-12 12:21:36-08:00,['AwsProperties.java']
Docs: refer to multi-engine-support page for engine compatibility (#4067),1,23,2022-02-12 14:17:29-08:00,['README.md']
"Build: Exclude readme, contributing and gitattributes from CI (#4107)",5,25,2022-02-13 11:16:13-08:00,"['labeler.yml', 'flink-ci.yml', 'hive-ci.yml', 'java-ci.yml', 'spark-ci.yml']"
Build: Add GCP label (#4108),1,2,2022-02-13 11:16:42-08:00,['labeler.yml']
Flink: Support HDFS locality with LocatableInputSplit (#3817),7,149,2022-02-13 19:02:42-08:00,"['FlinkConfigOptions.java', 'FlinkInputFormat.java', 'FlinkInputSplit.java', 'FlinkSource.java', 'FlinkSplitPlanner.java', 'ScanContext.java', 'TestFlinkScanSql.java']"
Docs: Add separate contributing page for Iceberg website. (#4096),8,252,2022-02-14 08:30:58-08:00,"['blogs.md', 'contribute.md', 'join.md', 'talks.md', 'blogs.md', 'contributing.md', 'join.md', 'talks.md']"
Docs: add multi-engine support redirect page in versioned doc project section (#4104),1,20,2022-02-14 08:32:47-08:00,['multi-engine-support.md']
Core: Disable metrics for wide tables to reduce metadata size (#3959),9,273,2022-02-14 08:50:41-08:00,"['MetricsConfig.java', 'TestWriterMetrics.java', 'TestFlinkWriterMetrics.java', 'TestFlinkWriterMetrics.java', 'TestFlinkWriterMetrics.java', 'TestSparkWriterMetrics.java', 'TestSparkWriterMetrics.java', 'TestSparkWriterMetrics.java', 'TestSparkWriterMetrics.java']"
Docs: add engine support start version and Flink 1.11 information (#4109),1,38,2022-02-14 10:16:16-08:00,['multi-engine-support.md']
Infra: ignore docs folder for release (#4106),1,4,2022-02-14 10:16:56-08:00,['.gitattributes']
Flink: Avoid writing duplicate equality deletes (#3834),5,57,2022-02-14 10:57:55-08:00,"['BaseTaskWriter.java', 'TestTaskEqualityDeltaWriter.java', 'TestDeltaTaskWriter.java', 'TestDeltaTaskWriter.java', 'TestDeltaTaskWriter.java']"
Docs: Fix spark runtime jar link (#4124),1,2,2022-02-14 14:02:22-08:00,['spark-getting-started.md']
API: Fail Namespace with null level or null character (#3938),2,36,2022-02-14 15:10:10-08:00,"['Namespace.java', 'TestNamespace.java']"
Docs: add website release instruction (#4105),1,71,2022-02-14 15:59:42-08:00,['how-to-release.md']
"Data: Close Migration ExecutorService if Started (#4125)

Previously, the executor service created for parallel reading of partitions in
TableMigrationUtil would only be claused when the finalizer was called. Instead in this
patch we close the service as soon as the method has completed.",1,8,2022-02-14 16:02:43-08:00,['TableMigrationUtil.java']
Docs: Add 0.13.1 release notes (#4122),2,38,2022-02-15 09:26:51-08:00,"['release-notes.md', '_index.md']"
Core: Replace setCurrentSnapshot with setBranchSnapshot in metadata builder (#4089),6,156,2022-02-15 14:21:19-08:00,"['SnapshotRef.java', 'MetadataUpdate.java', 'SnapshotProducer.java', 'TableMetadata.java', 'NessieTableOperations.java', 'TestIcebergSourceTablesBase.java']"
Spark 3.2: Implement merge-on-read MERGE (#4047),9,697,2022-02-15 14:27:44-08:00,"['RewriteMergeIntoTable.scala', 'MergeRows.scala', 'TestMerge.java', 'TestMergeOnReadMerge.java', 'SparkDistributionAndOrderingUtil.java', 'SparkWriteConf.java', 'SparkPositionDeltaWriteBuilder.java', 'SparkTestBase.java', 'TestSparkDistributionAndOrderingUtil.java']"
Core: Update SnapshotManager to use a Transaction (#4128),9,684,2022-02-15 16:28:42-08:00,"['BaseTransaction.java', 'CherryPickOperation.java', 'SetSnapshotOperation.java', 'SnapshotManager.java', 'TestSnapshotManager.java', 'TestWapWorkflow.java', 'TestCherrypickSnapshotProcedure.java', 'TestCherrypickSnapshotProcedure.java', 'TestCherrypickSnapshotProcedure.java']"
Arrow: Bump Apache Arrow 7.0.0 (#4112),1,4,2022-02-15 16:34:04-08:00,['versions.props']
Core: use setBranchSnapshot to commit SetSnapshotOperation (#4138),1,2,2022-02-15 22:37:59-08:00,['SetSnapshotOperation.java']
Bump Nessie from 0.18.0 to 0.19.0 (#4055),3,16,2022-02-16 10:06:29+01:00,"['BaseTestIceberg.java', 'TestNessieTable.java', 'versions.props']"
Docs: Broken JavaDoc Links on Spark Procedures Page (#4136),1,6,2022-02-16 10:39:26-08:00,['spark-procedures.md']
"Spark: Close executor services after action completes in Procedures (#4126)

* Spark: Close executor services after action completes in Procedures

Previously executor services were left to be GC'd, instead now they are
shutdown immediately after the action completes.",3,83,2022-02-16 14:42:01-06:00,"['BaseProcedure.java', 'ExpireSnapshotsProcedure.java', 'RemoveOrphanFilesProcedure.java']"
"Avro: Fix BuildAvroProjection list and map handling to preserve field IDs (#4120)

Co-authored-by: Haizhou Zhao <haizhou_zhao@apple.com>",6,483,2022-02-16 14:31:21-08:00,"['AvroSchemaUtil.java', 'BuildAvroProjection.java', 'HasIds.java', 'MissingIds.java', 'TestAvroSchemaProjection.java', 'TestBuildAvroProjection.java']"
Nessie: Bump dependency from 0.19.0 to 0.20.0 (#4143),1,2,2022-02-16 14:33:28-08:00,['versions.props']
"Core: Add MetricsContext to enable metrics tracking, initial IO metrics (#4050)",10,409,2022-02-16 16:56:28-08:00,"['FileIOMetricsContext.java', 'MetricsContext.java', 'BaseS3File.java', 'S3FileIO.java', 'S3InputFile.java', 'S3InputStream.java', 'S3OutputFile.java', 'S3OutputStream.java', 'TestS3OutputStream.java', 'HadoopMetricsContext.java']"
AWS: Upgrade AWS SDK to 2.17.131 (#4153),1,2,2022-02-17 09:07:38-08:00,['versions.props']
Core: Support parallel planning for snapshots expiration (#4148),3,28,2022-02-17 12:09:09-08:00,"['ExpireSnapshots.java', 'RemoveSnapshots.java', 'TestRemoveSnapshots.java']"
"Parquet: Fix parquet zstd compression level conf (#4075)

Co-authored-by: zhongyujiang <zhongyujiang@xiaomi.com>",1,2,2022-02-17 13:31:06-08:00,['Parquet.java']
Dell: Add Dell EMC EcsFileIO.  (#3376),23,2173,2022-02-18 14:17:35+08:00,"['build.gradle', 'DellClientFactories.java', 'DellClientFactory.java', 'DellProperties.java', 'BaseEcsFile.java', 'EcsAppendOutputStream.java', 'EcsFileIO.java', 'EcsInputFile.java', 'EcsOutputFile.java', 'EcsSeekableInputStream.java', 'EcsURI.java', 'TestEcsAppendOutputStream.java', 'TestEcsInputFile.java', 'TestEcsOutputFile.java', 'TestEcsSeekableInputStream.java', 'TestEcsURI.java', 'MockDellClientFactory.java', 'EcsS3MockRule.java', 'MockS3Client.java', 'ObjectData.java', 'TestExceptionCode.java', 'settings.gradle', 'versions.props']"
Spark: Fix flaky testDeleteWithSerializableIsolation (#4123),3,57,2022-02-17 22:27:21-08:00,"['TestDelete.java', 'TestDelete.java', 'TestDelete.java']"
Flink 1.13: Support HDFS locality with LocatableInputSplit (#4111),7,144,2022-02-18 08:48:35-08:00,"['FlinkConfigOptions.java', 'FlinkInputFormat.java', 'FlinkInputSplit.java', 'FlinkSource.java', 'FlinkSplitGenerator.java', 'ScanContext.java', 'TestFlinkScanSql.java']"
Parquet: Make row group record checks configurable (#3181),8,154,2022-02-18 09:20:47-08:00,"['TableProperties.java', 'Parquet.java', 'ParquetWriter.java', 'TestParquet.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryEncodedVectorizedReads.java']"
Spark 3.2: Bump Spark version to 3.2.1 (#4163),1,2,2022-02-18 15:29:32-08:00,['build.gradle']
Spark: Enable test blocked by SPARK-33267 (#4172),4,8,2022-02-20 08:25:16-08:00,"['TestDelete.java', 'TestUpdate.java', 'TestDelete.java', 'TestUpdate.java']"
API: Use murmur3_32_fixed in bucket unit tests (#4171),1,2,2022-02-20 08:25:55-08:00,['TestBucketing.java']
Spark: Add unit test for ExpireSnapshot with DeleteFile (#4141),1,77,2022-02-20 08:33:28-08:00,['TestExpireSnapshotsProcedure.java']
Core: Support parallel scan planning with a custom thread pool (#4146),11,207,2022-02-20 08:36:43-08:00,"['TableScan.java', 'AllDataFilesTable.java', 'AllEntriesTable.java', 'BaseTableScan.java', 'DataTableScan.java', 'IncrementalDataTableScan.java', 'PartitionsTable.java', 'TableScanContext.java', 'TestDataTableScan.java', 'TestIncrementalDataTableScan.java', 'TestMetadataTableScans.java']"
Docs: Add Snowflake and Dremio blogs and link recent talks (#4170),2,16,2022-02-20 08:37:43-08:00,"['blogs.md', 'talks.md']"
Nessie: Bump dependency to 0.20.1 (#4160),1,2,2022-02-20 08:46:02-08:00,['versions.props']
Flink: Support configurable Scala version (#4157),4,135,2022-02-20 08:56:53-08:00,"['build.gradle', 'build.gradle', 'build.gradle', 'settings.gradle']"
Doc: Delete duplicate contents in spec (#4156),1,2,2022-02-20 09:04:50-08:00,['spec.md']
Docs: Add Spark streaming option skip-overwrites (#4121),1,2,2022-02-20 09:06:40-08:00,['spark-structured-streaming.md']
Spark: Use Spark's ANTLR version and exclude it from runtime jars (#4118),6,209,2022-02-20 09:08:54-08:00,"['build.gradle', 'LICENSE', 'build.gradle', 'LICENSE', 'build.gradle', 'LICENSE']"
"Docs: Add missing configuration properties (#4119)

Co-authored-by: Ryan Blue <blue@apache.org>",1,21,2022-02-20 09:43:53-08:00,['configuration.md']
Python (legacy): Skipping HMS host and port check when using iprot (#4070),2,25,2022-02-20 11:17:46-08:00,"['hive_tables.py', 'test_hive_tables.py']"
Docs: Update AWS SDK version in site doc (#4180),1,12,2022-02-21 10:38:31-08:00,['aws.md']
Spark: Log when converting delete to metadata-only-delete (#4169),1,4,2022-02-21 10:39:48-08:00,['OptimizeMetadataOnlyDeleteFromTable.scala']
Core: Support write manifest changes with a custom worker pool (#4147),8,115,2022-02-21 10:50:21-08:00,"['SnapshotUpdate.java', 'BaseRewriteManifests.java', 'ManifestFilterManager.java', 'ManifestMergeManager.java', 'MergingSnapshotProducer.java', 'SnapshotProducer.java', 'TestMergeAppend.java', 'TestRewriteManifests.java']"
"Docs: Minor updates to Python API intro (#4151)

Co-authored-by: jeehong.lee@navercorp.com <jeehong.lee@navercorp.com>",1,5,2022-02-21 14:22:25-08:00,['python-api-intro.md']
Spark: Delete dataFile on iteration level in SparkParquetWritersFlatDataBenchmark (#4149),4,12,2022-02-21 14:24:07-08:00,"['SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java']"
"Core: Add REST requests, responses, and serialization (#4037)",22,2703,2022-02-21 16:27:13-08:00,"['Namespace.java', 'TableIdentifierParser.java', 'RESTSerializers.java', 'CreateNamespaceRequest.java', 'UpdateNamespacePropertiesRequest.java', 'CreateNamespaceResponse.java', 'DropNamespaceResponse.java', 'GetNamespaceResponse.java', 'ListNamespacesResponse.java', 'ListTablesResponse.java', 'UpdateNamespacePropertiesResponse.java', 'JsonUtil.java', 'TestTableIdentifierParser.java', 'RequestResponseTestBase.java', 'TestCreateNamespaceRequest.java', 'TestUpdateNamespacePropertiesRequest.java', 'TestCreateNamespaceResponse.java', 'TestDropNamespaceResponse.java', 'TestGetNamespaceResponse.java', 'TestListNamespacesResponse.java', 'TestListTablesResponse.java', 'TestUpdateNamespacePropertiesResponse.java']"
Add test for remove orphan files with delete files (#4182),3,106,2022-02-22 00:02:16-06:00,"['TestExpireSnapshotsProcedure.java', 'TestRemoveOrphanFilesProcedure.java', 'TestHelpers.java']"
Flink: Fix the testing utility SimpleDataUtil#snapshotToDataFiles (#4187),3,12,2022-02-22 19:19:18+08:00,"['SimpleDataUtil.java', 'SimpleDataUtil.java', 'SimpleDataUtil.java']"
"Spark 3.2: Fix JMH Spark parquet benchmark (#3910)

Co-authored-by: zhongyujiang <zhongyujiang@xiaomi.com>",5,15,2022-02-22 09:33:00-08:00,"['jmh-bechmarks.yml', 'SparkParquetWritersNestedDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java']"
Python: Reuse types with __new__ (#4016),2,481,2022-02-22 09:43:07-08:00,"['types.py', 'test_types.py']"
Core: Use consistent constant definition for Parquet page sizes (#4199),1,6,2022-02-22 11:25:48-08:00,['TableProperties.java']
Spark 3.2: Fix method names for reading content files in actions (#4198),6,45,2022-02-22 12:43:50-08:00,"['DeleteOrphanFiles.java', 'ExpireSnapshots.java', 'BaseDeleteOrphanFilesSparkAction.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseExpireSnapshotsSparkAction.java', 'BaseSparkAction.java']"
Core: Remove deprecated table properties staged for removal in 0.14 (#4197),1,11,2022-02-22 12:45:13-08:00,['TableProperties.java']
Core : Fix assert message in TestDeleteFileIndex (#4178),1,2,2022-02-22 16:55:50-06:00,['TestDeleteFileIndex.java']
Core: Support Namespace properties in JDBC Catalog (#3275),3,374,2022-02-22 16:23:59-08:00,"['JdbcCatalog.java', 'JdbcUtil.java', 'TestJdbcCatalog.java']"
Parquet: Enable vectorized reads by default (#4196),2,5,2022-02-22 16:25:32-08:00,"['TableProperties.java', 'TestSparkTableUtilWithInMemoryCatalog.java']"
Docs: Fix numeration in Metastore Tables section (#4195),1,8,2022-02-22 19:17:47-08:00,['spec.md']
Spark 3.2: Support mergeSchema option on write (#4154),13,344,2022-02-22 20:43:15-08:00,"['Schema.java', 'ReassignIds.java', 'TypeUtil.java', 'TableProperties.java', 'FixupTypes.java', 'SparkConfParser.java', 'SparkSchemaUtil.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'SparkTable.java', 'SparkWriteBuilder.java', 'SparkTestBase.java', 'TestDataFrameWriterV2.java']"
AWS: Use Glue optimistic locking while updating table (#4166),2,42,2022-02-22 22:07:21-08:00,"['GlueCatalog.java', 'GlueTableOperations.java']"
Core: Add simple REST request interface and error response (#4201),4,291,2022-02-23 07:47:20-08:00,"['RESTClient.java', 'ErrorResponse.java', 'ErrorResponseParser.java', 'TestErrorResponseParser.java']"
AWS: make DynamoDbLockManager public (#4102),4,742,2022-02-23 09:49:42-08:00,"['TestDynamoDbLockManager.java', 'TestGlueCatalogLock.java', 'DynamoDbLockManager.java', 'DynamoLockManager.java']"
Core: Update GenericManifestFile toString (#4185),1,3,2022-02-23 12:55:56-06:00,['GenericManifestFile.java']
Core: Add error handlers and exceptions for the REST catalog (#4202),6,298,2022-02-23 11:07:02-08:00,"['BadRequestException.java', 'ForbiddenException.java', 'NotAuthorizedException.java', 'RESTException.java', 'ServiceFailureException.java', 'ErrorHandlers.java']"
AWS: Use independent http client for AWS clients (#4175),4,21,2022-02-23 12:25:58-08:00,"['TestAssumeRoleAwsClientFactory.java', 'AssumeRoleAwsClientFactory.java', 'AwsClientFactories.java', 'TestS3FileIO.java']"
Python: Add PyArrowFileIO Implementation (#4081),5,705,2022-02-23 12:27:23-08:00,"['base.py', 'pyarrow.py', 'test_base.py', 'test_pyarrow.py', 'tox.ini']"
Flink 1.14: Fix flaky testHashDistributeMode by ingesting all rows in one checkpoint cycle (#4189),3,93,2022-02-23 12:33:25-08:00,"['TestFlinkTableSink.java', 'BoundedTableFactory.java', 'BoundedTestSource.java']"
Flink 1.12: Fix flaky testHashDistributeMode by ingesting all rows in one checkpoint cycle (#4214),3,93,2022-02-25 09:29:31+08:00,"['TestFlinkTableSink.java', 'BoundedTableFactory.java', 'BoundedTestSource.java']"
Flink 1.13: Fix flaky testHashDistributeMode by ingesting all rows in one checkpoint cycle (#4213),3,93,2022-02-25 09:31:18+08:00,"['TestFlinkTableSink.java', 'BoundedTableFactory.java', 'BoundedTestSource.java']"
Docs: fix doc for flink streaming reading (#4205),1,2,2022-02-25 11:14:05+08:00,['flink-getting-started.md']
Flink: Add DataIteratorBatcher that is an iterator of batches (#4060),6,645,2022-02-25 10:13:48-08:00,"['BaseFileScanTask.java', 'FlinkConfigOptions.java', 'DataIterator.java', 'ArrayPoolDataIteratorBatcher.java', 'DataIteratorBatcher.java', 'TestArrayPoolDataIteratorBatcherRowData.java']"
Build: Verify integrity of gradle distribution (#4206),1,2,2022-02-25 10:56:07-08:00,['gradle-wrapper.properties']
Core: Update JDBC catalog implementation (#4220),3,395,2022-02-25 12:16:21-08:00,"['JdbcCatalog.java', 'JdbcUtil.java', 'TestJdbcCatalog.java']"
Core: Add config response class for REST catalog (#4184),2,427,2022-02-25 12:21:41-08:00,"['RESTCatalogConfigResponse.java', 'TestRESTCatalogConfigResponse.java']"
Core: Make REST response builders public (#4232),4,8,2022-02-25 13:56:10-08:00,"['CreateNamespaceResponse.java', 'GetNamespaceResponse.java', 'ListNamespacesResponse.java', 'ListTablesResponse.java']"
Core: Avoid possible NPE in RESTCatalogConfigResponse#merge (#4233),1,8,2022-02-25 13:56:55-08:00,['RESTCatalogConfigResponse.java']
"Core: Clean up JDBC implementation, add catalog namespace tests (#4231)",4,806,2022-02-25 13:57:13-08:00,"['JdbcCatalog.java', 'JdbcUtil.java', 'CatalogTests.java', 'TestJdbcCatalog.java']"
Flink: Remove the scala version suffix from artifact names. (#4193),4,54,2022-02-26 09:31:52+08:00,"['build.gradle', 'build.gradle', 'build.gradle', 'settings.gradle']"
Flink 1.14:  Add EqualityFieldKeySelector. (#2898),3,287,2022-02-28 14:46:25+08:00,"['EqualityFieldKeySelector.java', 'FlinkSink.java', 'TestFlinkIcebergSinkV2.java']"
Spark 3.2: Add stream-results param to expire_snapshots procedure (#4152),4,60,2022-03-01 02:13:31-08:00,"['TestExpireSnapshotsProcedure.java', 'BaseExpireSnapshotsSparkAction.java', 'ExpireSnapshotsProcedure.java', 'TestExpireSnapshotsAction.java']"
Docs: fix typo in spark-writes sample code (#4247),1,2,2022-03-01 19:29:44-08:00,['spark-writes.md']
Docs: Add Glue optimistic locking (#4216),1,57,2022-03-01 19:37:39-08:00,['aws.md']
Core: Add test for Table::expireSnapshot API removing delete files (#4211),1,61,2022-03-02 16:57:41-06:00,['TestRemoveSnapshots.java']
Core: Support serializable and snapshot isolation for ReplacePartitions (#2925),11,1092,2022-03-02 21:42:54-08:00,"['ReplacePartitions.java', 'BaseReplacePartitions.java', 'DeleteFileIndex.java', 'ManifestReader.java', 'MergingSnapshotProducer.java', 'PartitionSet.java', 'TestReplacePartitions.java', 'TestConflictValidation.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'SparkWrite.java']"
Spark 3.2: Support PURGE flag in DROP TABLE (#3056),4,198,2022-03-02 21:45:15-08:00,"['TestRemoveOrphanFilesProcedure.java', 'SparkCatalog.java', 'SparkSessionCatalog.java', 'TestDropTable.java']"
ORC: Add configurable write properties (#3810),5,212,2022-03-03 14:09:47+08:00,"['build.gradle', 'TableProperties.java', 'configuration.md', 'ORC.java', 'TestTableProperties.java']"
Spark: Backport #4152 - stream-results option for expire snapshot procedure (#4252),10,125,2022-03-03 15:29:39-06:00,"['spark-procedures.md', 'BaseExpireSnapshotsSparkAction.java', 'TestExpireSnapshotsProcedure.java', 'BaseExpireSnapshotsSparkAction.java', 'ExpireSnapshotsProcedure.java', 'TestExpireSnapshotsAction.java', 'TestExpireSnapshotsProcedure.java', 'BaseExpireSnapshotsSparkAction.java', 'ExpireSnapshotsProcedure.java', 'TestExpireSnapshotsAction.java']"
Core: Improve GenericReader performance (#4218),12,296,2022-03-04 14:45:25+08:00,"['.gitignore', 'GenericOrcReaderBenchmark.java', 'GenericParquetReaderBenchmark.java', 'ReaderBenchmark.java', 'jmh.gradle', 'Deserializer.java', 'GenericOrcReaders.java', 'GenericParquetReaders.java', '.gitkeep', '.gitkeep', '.gitkeep', '.gitkeep']"
Docs: Fix typo in Java API Quickstart (#4256),1,4,2022-03-04 14:50:57+08:00,['java-api-quickstart.md']
Flink: Add FLIP-27 reader function that reads IcebergSourceSplit (#4234),7,568,2022-03-04 11:14:00-08:00,"['DataIteratorReaderFunction.java', 'ReaderFunction.java', 'RowDataReaderFunction.java', 'ReaderFunctionTestBase.java', 'ReaderUtil.java', 'TestArrayPoolDataIteratorBatcherRowData.java', 'TestRowDataReaderFunction.java']"
Common: Add dynamic loading exceptions as suppressed exceptions. (#4276),1,20,2022-03-07 10:37:26+08:00,['DynConstructors.java']
Flink 1.12: Add EqualityFieldKeySelector. (#4275),3,286,2022-03-07 10:44:15+08:00,"['EqualityFieldKeySelector.java', 'FlinkSink.java', 'TestFlinkIcebergSinkV2.java']"
Flink 1.13: Add EqualityFieldKeySelector. (#4274),3,287,2022-03-07 10:47:56+08:00,"['EqualityFieldKeySelector.java', 'FlinkSink.java', 'TestFlinkIcebergSinkV2.java']"
Hive: Known exception should not become CommitStateUnknownException (#4261),2,50,2022-03-07 12:54:11-06:00,"['HiveTableOperations.java', 'TestHiveCommits.java']"
Docs: Restructure docs files for new contributing guideline (#4208),79,1767,2022-03-07 16:50:34-08:00,"['_index.md', 'java-api-quickstart.md', 'java-api.md', 'java-custom-catalog.md', '_index.md', 'python-api-intro.md', 'python-feature-support.md', 'python-quickstart.md', '_index.md', '_index.md', '_index.md', '_index.md', '_index.md', '_index.md', '_index.md', 'blogs.md', 'contribute.md', 'join.md', 'talks.md', 'terms.md', 'benchmarks.md', 'how-to-release.md', 'multi-engine-support.md', 'roadmap.md', 'security.md', 'trademarks.md', 'how-to-verify-a-release.md', 'release-notes.md', '_index.md', 'blogs.md', 'contributing.md', 'join.md', 'talks.md', '_index.md', '_index.md', '_index.md', 'flink-connector.md', 'flink-getting-started.md', '_index.md', 'spec.md', 'terms.md', '_index.md', '_index.md', 'aws.md', 'jdbc.md', 'nessie.md', '_index.md', '_index.md', 'benchmarks.md', 'how-to-release.md', 'multi-engine-support.md', 'roadmap.md', 'security.md', 'trademarks.md', '_index.md', '_index.md', '_index.md', '_index.md', '_index.md', 'release-notes.md', '_index.md', 'spark-configuration.md', 'spark-ddl.md', 'spark-getting-started.md', 'spark-procedures.md', 'spark-queries.md', 'spark-structured-streaming.md', 'spark-writes.md', '_index.md', 'configuration.md', 'evolution.md', 'maintenance.md', 'partitioning.md', 'performance.md', 'reliability.md', 'schemas.md', '_index.md', 'spec.md', 'rest-catalog-open-api.yaml']"
Core: Add in RESTUtil for URL encoding (#4244),2,233,2022-03-07 16:53:51-08:00,"['RESTUtil.java', 'TestRESTUtil.java']"
Build: Cancel duplicate workflow runs (#4207),7,69,2022-03-07 16:55:38-08:00,"['cancel-duplicate-workflow-runs.yml', 'flink-ci.yml', 'hive-ci.yml', 'java-ci.yml', 'python-ci.yml', 'python-legacy-ci.yml', 'spark-ci.yml']"
"Build: Trigger CI using on pull_request, push to master branch or tags only (#4210)",6,99,2022-03-07 16:57:53-08:00,"['flink-ci.yml', 'hive-ci.yml', 'java-ci.yml', 'python-ci.yml', 'python-legacy-ci.yml', 'spark-ci.yml']"
Build: Disable CI for anything in open-api or format doc directories (#4286),4,8,2022-03-07 18:48:57-08:00,"['flink-ci.yml', 'hive-ci.yml', 'java-ci.yml', 'spark-ci.yml']"
"Build: Align the module name among spark2.4, spark3.0, spark3.1 and spark3.2 (#4158)",5,103,2022-03-08 16:22:52+08:00,"['spark-ci.yml', 'jmh.gradle', 'settings.gradle', 'build.gradle', 'build.gradle']"
Build: Trigger CI when pushing to a release branch or tag (#4287),6,18,2022-03-08 09:18:17-08:00,"['flink-ci.yml', 'hive-ci.yml', 'java-ci.yml', 'python-ci.yml', 'python-legacy-ci.yml', 'spark-ci.yml']"
Nessie: Bump Nessie to 0.21.2 (#4290),1,2,2022-03-08 09:19:32-08:00,['versions.props']
Core: Implement table refs in TableMetadataParser (#4260),3,190,2022-03-08 09:23:58-08:00,"['TableMetadata.java', 'TableMetadataParser.java', 'TestTableMetadata.java']"
"Spark: Allow Bin-Pack optimization to work across different partition specs (#4279)

Previously, Bin-Pack would always use a NONE distribution for rewriting datafiles. This assumed
that incoming datafiles were from the same partition as the new output files would
be written to. When the spec is changed, the data must be resorted to place the data in the
new correct partitions.",2,38,2022-03-09 15:16:46-06:00,"['Spark3BinPackStrategy.java', 'TestRewriteDataFilesAction.java']"
Core: Fix deleted data files validation in OverwriteFiles (#4303),2,61,2022-03-09 14:07:08-08:00,"['BaseOverwriteFiles.java', 'TestOverwriteWithValidation.java']"
AWS : use additionalLocations in glue table to store location info (#4248),4,70,2022-03-09 15:44:43-08:00,"['GlueTestBase.java', 'TestGlueCatalogTable.java', 'IcebergToGlueConverter.java', 'TestIcebergToGlueConverter.java']"
Flink: Use a worker pool per job in operators (#4177),14,158,2022-03-11 08:21:48-08:00,"['ThreadPools.java', 'FlinkConfigOptions.java', 'FlinkDynamicTableFactory.java', 'IcebergTableSink.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'FlinkInputFormat.java', 'FlinkSource.java', 'FlinkSplitPlanner.java', 'ScanContext.java', 'StreamingMonitorFunction.java', 'TestIcebergFilesCommitter.java', 'SplitHelpers.java', 'TestStreamingReaderOperator.java']"
ORC: Fix typo in orcColumnType (#4297),1,4,2022-03-11 14:10:00-08:00,['ORCSchemaUtil.java']
Nessie: Bump version from 0.21.2 to 0.22.0 (#4314),1,2,2022-03-11 14:13:18-08:00,['versions.props']
Core: Add delete_files metadata table (#4243),11,791,2022-03-11 15:21:40-08:00,"['AllDataFilesTable.java', 'BaseFilesTable.java', 'DataFilesTable.java', 'DeleteFilesTable.java', 'MetadataTableType.java', 'MetadataTableUtils.java', 'TableTestBase.java', 'TestMetadataTableScans.java', 'HadoopTableTestBase.java', 'TestTableSerialization.java', 'TestMetadataTables.java']"
Flink: Remove deprecated calls to enable blink planner (#4315),6,16,2022-03-13 09:25:59-07:00,"['FlinkTestBase.java', 'TestFlinkTableSink.java', 'TestIcebergConnector.java', 'ChangeLogTableTestBase.java', 'TestFlinkScanSql.java', 'TestStreamScanSql.java']"
Core: Fix NPE after HadoopMetricsContext deserialization (#4309),2,84,2022-03-13 09:35:47-07:00,"['HadoopMetricsContext.java', 'TestHadoopMetricsContextSerialization.java']"
Build: Upgrade to Gradle 7.4.1 (#4306),2,6,2022-03-13 09:49:48-07:00,"['gradle-wrapper.properties', 'gradlew']"
"Spark: Use withNullability instead of a new AttributeRef (#4133)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",1,2,2022-03-13 10:19:07-07:00,['RewriteMergeIntoTable.scala']
Flink: Add FLIP-27 split assigner (#4270),8,553,2022-03-13 10:47:42-07:00,"['GetSplitResult.java', 'SimpleSplitAssigner.java', 'SimpleSplitAssignerFactory.java', 'SplitAssigner.java', 'SplitAssignerFactory.java', 'IcebergSourceSplitState.java', 'IcebergSourceSplitStatus.java', 'TestSimpleSplitAssigner.java']"
Spark: Exclude Netty from Spark runtime modules (#4110),12,1052,2022-03-13 16:40:34-07:00,"['build.gradle', 'LICENSE', 'NOTICE', 'build.gradle', 'LICENSE', 'NOTICE', 'build.gradle', 'LICENSE', 'NOTICE', 'build.gradle', 'LICENSE', 'NOTICE']"
"Spark 3.1: Support PURGE flag in DROP TABLE (#4277)

Co-authored-by: xianyangliu <xianyangliu@tencent.com>",3,205,2022-03-13 16:44:22-07:00,"['SparkCatalog.java', 'SparkSessionCatalog.java', 'TestDropTable.java']"
Spark: Simplify validation in BaseRewriteDataFilesSparkAction (#4324),1,2,2022-03-14 08:48:52-05:00,['BaseRewriteDataFilesSparkAction.java']
AWS: support object tagging for S3FileIO during write (#4259),9,175,2022-03-14 09:36:26-07:00,"['AwsProperties.java', 'BaseS3File.java', 'S3FileIO.java', 'S3OutputFile.java', 'S3OutputStream.java', 'TestGlueCatalog.java', 'TestS3FileIO.java', 'TestS3OutputStream.java', 'PropertyUtil.java']"
Docs: Add S3 Tagging docs (#4323),1,16,2022-03-14 10:08:15-07:00,['aws.md']
Core: Clarify ValidationException Javadoc (#4258),1,6,2022-03-14 11:29:02-07:00,['ValidationException.java']
Spark 3.2: Cleanup DataFrame.overwritePartitions isolation level handling (#4310),2,31,2022-03-14 16:18:02-07:00,"['TestConflictValidation.java', 'SparkWrite.java']"
Core: Add table error handler (#4321),1,18,2022-03-14 16:40:36-07:00,['ErrorHandlers.java']
Core: Add MetadataUpdate.applyTo to re-apply changes (#4320),2,175,2022-03-14 19:55:13-07:00,"['MetadataUpdate.java', 'TableMetadata.java']"
Core: Add transaction catalog tests (#4319),6,1483,2022-03-14 20:19:23-07:00,"['CharSequenceSet.java', 'BaseMetastoreCatalog.java', 'BaseMetastoreTableOperations.java', 'JdbcTableOperations.java', 'CatalogTests.java', 'HiveCreateReplaceTableTest.java']"
Build: Test flink modules for both scala 2.11 and 2.12 (#4179),1,32,2022-03-15 12:08:24+08:00,['flink-ci.yml']
"Spark: Fix Rewrite Overlap Test Function (#4278)

Previously the overlap function would not correctly find overlaps when the bounds for
overlapping files were equivelent, or if a single file was returned. The new function
correctly only ignores files that are exactly the same (path and bounds) and throws an
error if overlaps are being checked for on a single file.",1,44,2022-03-15 11:00:21-05:00,['TestRewriteDataFilesAction.java']
Spark 3.1: Simplify validation in BaseRewriteDataFilesSparkAction - Backport #4324 (#4331),1,2,2022-03-15 11:06:26-05:00,['BaseRewriteDataFilesSparkAction.java']
Spark 3.0: Simplify validation in BaseRewriteDataFilesSparkAction  - Backport #4324 (#4332),1,2,2022-03-15 11:06:59-05:00,['BaseRewriteDataFilesSparkAction.java']
Spec: Update REST spec with changes needed for transactions (#4335),1,68,2022-03-15 09:56:25-07:00,['rest-catalog-open-api.yaml']
Spark: Backport of #4278 - Fix Overlap Function (#4327),2,86,2022-03-15 14:39:30-05:00,"['TestRewriteDataFilesAction.java', 'TestRewriteDataFilesAction.java']"
Core: Fix ValidationException on metadata-only delete of certain delete files (#4304),3,54,2022-03-15 14:02:57-07:00,"['ManifestFilterManager.java', 'TestDelete.java', 'TestHelpers.java']"
"AWS: Add SupportBulkOperation interface. S3FileIO implementation will perform a batch deletion using RemoveObjects API (#4052)

Thanks @amogh-jahagirdar!",7,343,2022-03-15 14:38:06-07:00,"['BulkDeletionFailureException.java', 'SupportsBulkOperations.java', 'TestS3FileIOIntegration.java', 'AwsProperties.java', 'S3FileIO.java', 'TestAwsProperties.java', 'TestS3FileIO.java']"
"Core : Don't consider groups for compaction if they have a single file (#3676)

Avoid rewrite datafile operations that are essentially NOOPs. Previously single file compactions were possible when minInputFiles was = 1, these compactions would read and write the same file which had no benefit. Now only rewrite cases where the output would differ from the input are considered.",2,60,2022-03-15 16:42:52-05:00,"['BinPackStrategy.java', 'TestBinPackStrategy.java']"
"Style: Add checkstyle rule to prevent using raw ConcurrentHashMap, LinkedHashSet (#4296)

Adds Style rules for new ConcurrentHashMap and alike to be rejected in favor of Guava collection apis.",9,48,2022-03-16 09:07:28-05:00,"['checkstyle.xml', 'DynClasses.java', 'MockS3Client.java', 'TestFlinkParquetReader.java', 'TestParquet.java', 'TestPartitionPruning.java', 'TestPartitionPruning.java', 'TestPartitionPruning.java', 'TestPartitionPruning.java']"
Core: Use existing SnapshotRefParser in TableMetadataParser (#4294),1,31,2022-03-16 08:31:06-07:00,['TableMetadataParser.java']
Core: Add REST catalog table requests and responses. (#4322),4,743,2022-03-16 08:41:52-07:00,"['CreateTableRequest.java', 'UpdateTableRequest.java', 'DropTableResponse.java', 'LoadTableResponse.java']"
Spark: Update gradle commands for running individual Spark 3.2 JMH tests (#4328),20,102,2022-03-16 08:43:24-07:00,"['AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'IcebergSourceParquetEqDeleteBenchmark.java', 'IcebergSourceParquetMultiDeleteFileBenchmark.java', 'IcebergSourceParquetPosDeleteBenchmark.java', 'IcebergSourceParquetWithUnrelatedDeleteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java']"
Avro: Fix Javadoc links (#4339),1,8,2022-03-16 08:45:20-07:00,['AvroSchemaUtil.java']
Flink: Fix dropped parallelism in ScanContext (#4341),1,4,2022-03-16 08:47:53-07:00,['ScanContext.java']
AWS: Fix S3FileIOIntegrationTest failure (#4347),1,2,2022-03-16 11:35:45-07:00,['S3FileIO.java']
Parquet: Close ColumnWriteStore during flush (#4338),1,1,2022-03-16 12:36:31-07:00,['ParquetWriter.java']
Core: Skip context for object storage in table prefixes (#4349),2,32,2022-03-16 16:18:06-07:00,"['LocationProviders.java', 'TestLocationProvider.java']"
Docs: Update section on inspecting tables (#4255),1,4,2022-03-16 16:55:43-07:00,['spark-queries.md']
Spark 3.2: Support isolation levels in overwrite by filter (#4293),2,212,2022-03-16 23:37:46-07:00,"['TestConflictValidation.java', 'SparkWrite.java']"
AWS: Move S3 writeTags to AwsProperties (#4350),7,128,2022-03-17 13:24:07-07:00,"['AwsProperties.java', 'BaseS3File.java', 'S3FileIO.java', 'S3OutputFile.java', 'S3OutputStream.java', 'TestS3FileIO.java', 'TestS3OutputStream.java']"
AWS: Fix TestGlueCatalogTable failure (#4355),1,6,2022-03-17 16:59:59-07:00,['TestGlueCatalogTable.java']
AWS: Remove get from getter method (#4357),3,6,2022-03-17 20:29:24-07:00,"['AwsProperties.java', 'S3OutputStream.java', 'TestS3OutputStream.java']"
AWS: Add TagSession support in AssumeRoleAwsClientFactory (#4358),3,32,2022-03-17 20:35:20-07:00,"['TestAssumeRoleAwsClientFactory.java', 'AssumeRoleAwsClientFactory.java', 'AwsProperties.java']"
"Revert ""Spark: Exclude Netty from Spark runtime modules (#4110)"" (#4344)

This reverts commit eace97307cecf1e6a8cdd96cf78a5d0847ea1cb7.",12,1052,2022-03-18 12:13:06-07:00,"['build.gradle', 'LICENSE', 'NOTICE', 'build.gradle', 'LICENSE', 'NOTICE', 'build.gradle', 'LICENSE', 'NOTICE', 'build.gradle', 'LICENSE', 'NOTICE']"
API: Add UnboundSortOrder that has no schema (#4360),6,264,2022-03-18 14:04:36-07:00,"['SortOrder.java', 'UnboundSortOrder.java', 'MetadataUpdate.java', 'SortOrderParser.java', 'TableMetadata.java', 'RESTSerializers.java']"
API: Add UnboundPartitionSpec for serialization (#4361),7,240,2022-03-20 09:13:43-07:00,"['PartitionSpec.java', 'SortOrder.java', 'UnboundPartitionSpec.java', 'MetadataUpdate.java', 'PartitionSpecParser.java', 'TableMetadata.java', 'RESTSerializers.java']"
AWS : make passing s3WriteTags javaDoc example engine agnostic (#4351),1,2,2022-03-20 10:50:44-07:00,['AwsProperties.java']
"Docs: Clarify ""read-optimized"" (#4352)

Co-authored-by:  <wuwenchi@deepexi.com>",1,2,2022-03-20 14:08:22-07:00,['spec.md']
Core: Update DELETE routes to use 204 for success (#4366),1,40,2022-03-20 15:20:05-07:00,['rest-catalog-open-api.yaml']
ORC: Read configured key-value from table properties. (#4291),2,103,2022-03-21 18:01:10+08:00,"['TableProperties.java', 'ORC.java']"
Dell: Add Dell EMC EcsCatalog.  (#4221),15,1332,2022-03-21 19:39:23+08:00,"['build.gradle', 'EcsCatalog.java', 'EcsTableOperations.java', 'EcsURI.java', 'PropertiesSerDesUtil.java', 'TestEcsCatalog.java', 'TestEcsTableOperations.java', 'TestEcsURI.java', 'TestPropertiesSerDesUtil.java', 'MockDellClientFactory.java', 'EcsS3MockRule.java', 'MockS3Client.java', 'ObjectData.java', 'ObjectId.java', 'TestExceptionCode.java']"
Flink: Remove redundant reuseContainers (#4375),3,3,2022-03-22 20:43:08+08:00,"['RowDataFileScanTaskReader.java', 'RowDataFileScanTaskReader.java', 'RowDataFileScanTaskReader.java']"
Core: Remove unnecessary fully qualified name (#4374),1,4,2022-03-22 08:57:16-07:00,['AvroSchemaUtil.java']
Docs: Update Spark Write Conf docs for isolation-level (#4369),1,3,2022-03-22 14:28:26-05:00,['spark-configuration.md']
Core: Add ErrorResponse to RESTSerializers (#4236),1,20,2022-03-22 12:36:03-07:00,['RESTSerializers.java']
Core: Include delete files in 'files' and add 'data_files' table (#4336),8,758,2022-03-22 14:20:44-07:00,"['DataFilesTable.java', 'FilesTable.java', 'MetadataTableType.java', 'MetadataTableUtils.java', 'TestMetadataTableFilters.java', 'TestMetadataTableScans.java', 'TestMetadataTables.java', 'TestHelpers.java']"
Python: Add doctest to tox (#4285),6,99,2022-03-22 15:11:50-07:00,"['setup.cfg', 'setup.py', 'expressions.py', 'pyarrow.py', 'types.py', 'tox.ini']"
Core: Add RESTCatalog and RESTTableOperations (#4348),9,1416,2022-03-22 15:53:54-07:00,"['UnprocessableEntityException.java', 'BaseTransaction.java', 'CatalogHandlers.java', 'RESTCatalog.java', 'RESTTableOperations.java', 'UpdateNamespacePropertiesRequest.java', 'CatalogTests.java', 'RESTCatalogAdapter.java', 'TestRESTCatalog.java']"
GCP: Add metrics tracking for GCSFileIO (#4267),8,110,2022-03-22 17:13:44-07:00,"['BaseGCSFile.java', 'GCSFileIO.java', 'GCSInputFile.java', 'GCSInputStream.java', 'GCSOutputFile.java', 'GCSOutputStream.java', 'GCSInputStreamTest.java', 'GCSOutputStreamTest.java']"
Core: Make removal of delete files optional in manifest filtering (#4370),2,86,2022-03-22 20:33:14-07:00,"['ManifestFilterManager.java', 'TestOverwriteWithValidation.java']"
API: Fix NPE when validating identifier fields (#4372),2,12,2022-03-23 10:25:34-07:00,"['Schema.java', 'TestSchemaUpdate.java']"
Docs: Fix wrong ordering of arguments in nessie catalog example (#4378),1,2,2022-03-23 13:09:11-07:00,['nessie.md']
AWS: support choosing Apache HTTP client as default (#4371),5,67,2022-03-23 16:48:08-07:00,"['TestAssumeRoleAwsClientFactory.java', 'AssumeRoleAwsClientFactory.java', 'AwsClientFactories.java', 'AwsProperties.java', 'build.gradle']"
Clarify timestamp in stored procedures (#4379),4,16,2022-03-24 11:13:13+08:00,"['spark-procedures.md', 'RollbackToTimestampProcedure.java', 'RollbackToTimestampProcedure.java', 'RollbackToTimestampProcedure.java']"
AWS: Add LakeFormation credential support for GlueCatalog (#4280),7,411,2022-03-23 20:22:26-07:00,"['TestLakeFormationAwsClientFactory.java', 'AssumeRoleAwsClientFactory.java', 'AwsClientFactories.java', 'AwsProperties.java', 'GlueCatalog.java', 'LakeFormationAwsClientFactory.java', 'build.gradle']"
AWS: Add support for s3 access points (#4334),12,262,2022-03-23 22:06:49-07:00,"['AwsIntegTestUtil.java', 'TestS3FileIOIntegration.java', 'AssumeRoleAwsClientFactory.java', 'AwsClientFactories.java', 'AwsProperties.java', 'LakeFormationAwsClientFactory.java', 'S3FileIO.java', 'S3InputFile.java', 'S3OutputFile.java', 'S3URI.java', 'TestS3URI.java', 'build.gradle']"
ORC : Avoid modifying existing conf of HadoopOutputFile rather create new one (#4384),1,15,2022-03-24 18:30:47+08:00,['ORC.java']
Core: Make DeleteFilter's constructor parameters more specific (#4381),5,28,2022-03-24 09:50:41-07:00,"['DeleteFilter.java', 'GenericDeleteFilter.java', 'RowDataFileScanTaskReader.java', 'BatchDataReader.java', 'RowDataReader.java']"
Spark: Update older DeleteFile constructor parameters (#4394),5,10,2022-03-24 14:43:20-07:00,"['RowDataFileScanTaskReader.java', 'RowDataFileScanTaskReader.java', 'RowDataReader.java', 'RowDataReader.java', 'RowDataReader.java']"
Data: fix typo in TableMigrationUtil (#4400),1,12,2022-03-25 13:09:25+01:00,['TableMigrationUtil.java']
Docs: Fix javadoc link for RewriteManifests (#4390),1,2,2022-03-25 10:12:35-07:00,['spark-procedures.md']
Core: Add HTTPClient implementation of RESTClient (#4245),7,592,2022-03-27 14:03:20-07:00,"['build.gradle', 'HTTPClient.java', 'RESTClient.java', 'HttpMethod.java', 'RESTCatalogAdapter.java', 'TestHTTPClient.java', 'versions.props']"
Spec: Clean up error responses in REST protocol (#4367),1,134,2022-03-27 14:35:58-07:00,['rest-catalog-open-api.yaml']
Core: Fix test helper visibility in HTTPClient.Builder (#4414),1,10,2022-03-27 16:36:27-07:00,['HTTPClient.java']
Spark: Update Spark 3.2 JMH Benchmark javadocs (#4409),24,56,2022-03-27 16:37:29-07:00,"['SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'IcebergSourceParquetEqDeleteBenchmark.java', 'IcebergSourceParquetMultiDeleteFileBenchmark.java', 'IcebergSourceParquetPosDeleteBenchmark.java', 'IcebergSourceParquetWithUnrelatedDeleteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java']"
Spark: Update Spark 3.1 JMH benchmark javadoc (#4408),20,80,2022-03-27 16:38:11-07:00,"['SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java']"
Spec: Clarify that floating point bounds cannot contain NaNs (#4404),1,2,2022-03-27 16:42:33-07:00,['spec.md']
Spec: Clarify manifest entry file uniqueness (#4272),1,11,2022-03-27 16:44:42-07:00,['spec.md']
Core: CachingCatalog.invalidateTable should also invalidate in the wrapped catalog (#4388),2,26,2022-03-27 17:00:30-07:00,"['CachingCatalog.java', 'TestCachingCatalog.java']"
"Flink: Fix UPSERT delete file metadata (#4364)

Co-authored-by: liliwei <hililiwei@gmail.com>",8,334,2022-03-27 19:12:55-07:00,"['build.gradle', 'BaseTaskWriter.java', 'TestTaskEqualityDeltaWriter.java', 'BaseDeltaTaskWriter.java', 'BaseDeltaTaskWriter.java', 'BaseDeltaTaskWriter.java', 'RowDataTaskWriterFactory.java', 'TestFlinkUpsert.java']"
ORC: Support estimated length for unclosed file. (#3784),16,418,2022-03-28 11:55:15+08:00,"['build.gradle', 'BaseTaskWriter.java', 'ClusteredDataWriter.java', 'ClusteredEqualityDeleteWriter.java', 'ClusteredPositionDeleteWriter.java', 'FanoutDataWriter.java', 'TestBaseTaskWriter.java', 'TestRollingFileWriters.java', 'TestRewriteDataFilesAction.java', 'TestIcebergStreamWriter.java', 'TestTaskWriters.java', 'EstimateOrcAvgWidthVisitor.java', 'OrcFileAppender.java', 'TestEstimateOrcAvgWidthVisitor.java', 'SparkWrite.java', 'TestSparkDataWrite.java']"
"Core: Fixes read metadata failed after dropped partition transform for V1 format (#3411)

V1 Tables replace dropped partition transforms with a Void Transform which always returns null. The type of this Void transform always matches the column's original type. This has issues when the column's type differed from the transform used to previously partition the column. Here the issue is patched by retaining the correct type for the transform values when those values are being read after the transform has been dropped.",4,249,2022-03-28 10:33:55-05:00,"['AllManifestsTable.java', 'ManifestsTable.java', 'Partitioning.java', 'TestMetadataTableScans.java']"
"Core: Make CatalogTests run with JUnit5 (#4333)

This is needed for Nessie to reuse the tests.",4,54,2022-03-28 08:41:46-07:00,"['build.gradle', 'CatalogTests.java', 'TestJdbcCatalog.java', 'TestRESTCatalog.java']"
"Hive: Avoid recursive listing in HiveCatalog#renameTable (#4407)

Previously stats were disabled when HiveTableOperations commits table changes to avoid the unused and unnecessary stats checks. This change was not applied to HiveCatalog ""renameTable"" operations. In this patch the same stat collection is disabled for ""renameTable"" as well.

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",3,44,2022-03-28 14:36:53-05:00,"['HiveCatalog.java', 'HiveTableOperations.java', 'MetastoreUtil.java']"
Core: Update REST catalog to use 204/404 for DELETE (#4412),7,333,2022-03-28 16:59:28-07:00,"['CatalogHandlers.java', 'HTTPClient.java', 'RESTCatalog.java', 'DropNamespaceResponse.java', 'DropTableResponse.java', 'RESTCatalogAdapter.java', 'TestDropNamespaceResponse.java']"
Core: Add stack trace to REST ErrorResponse (#4413),4,109,2022-03-28 17:00:11-07:00,"['ErrorResponse.java', 'ErrorResponseParser.java', 'RESTCatalogAdapter.java', 'TestErrorResponseParser.java']"
ORC: Enabled all file rolling related unit tests. (#4419),24,297,2022-03-29 16:56:06+08:00,"['ClusteredDataWriter.java', 'ClusteredEqualityDeleteWriter.java', 'ClusteredPositionDeleteWriter.java', 'FanoutDataWriter.java', 'TestPartitioningWriters.java', 'TestPositionDeltaWriters.java', 'TestRewriteDataFilesAction.java', 'TestIcebergStreamWriter.java', 'TestTaskWriters.java', 'TestRewriteDataFilesAction.java', 'TestIcebergStreamWriter.java', 'TestTaskWriters.java', 'WritersBenchmark.java', 'TestSparkDataWrite.java', 'WritersBenchmark.java', 'SparkWrite.java', 'TestSparkDataWrite.java', 'WritersBenchmark.java', 'SparkWrite.java', 'TestSparkDataWrite.java', 'IcebergSourceDeleteBenchmark.java', 'WritersBenchmark.java', 'SparkPositionDeltaWrite.java', 'SparkWrite.java']"
Core: Remove redundant word in Javadoc (#4425),1,2,2022-03-29 08:45:00-07:00,['DeleteFileIndex.java']
ORC: Add compression properties (#4273),4,151,2022-03-30 14:47:25+08:00,"['TableProperties.java', 'configuration.md', 'ORC.java', 'TestTableProperties.java']"
AWS: Add S3 delete tagging (#4342),3,133,2022-03-30 11:17:15-07:00,"['AwsProperties.java', 'S3FileIO.java', 'TestS3OutputStream.java']"
Aliyun: Add metrics tracking for OSSFileIO (#4393),9,109,2022-03-30 12:38:49-07:00,"['BaseOSSFile.java', 'OSSFileIO.java', 'OSSInputFile.java', 'OSSInputStream.java', 'OSSOutputFile.java', 'OSSOutputStream.java', 'TestOSSInputFile.java', 'TestOSSOutputFile.java', 'TestOSSOutputStream.java']"
"Python: Add literals (#4262)

Co-authored-by: Steve Zhang <hongyue_zhang@apple.com>
Co-authored-by: samredai <43911210+samredai@users.noreply.github.com>",7,1204,2022-03-30 13:32:39-07:00,"['setup.cfg', '__init__.py', 'literals.py', 'types.py', '__init__.py', 'test_literals.py', 'tox.ini']"
CoreRemoving an initialization that sets a variable to null (#4429),2,4,2022-03-30 16:09:15-05:00,"['Avro.java', 'BuildAvroProjection.java']"
CoreRemoving a fully defined type that is already imported (#4430),1,2,2022-03-30 16:10:20-05:00,['BuildAvroProjection.java']
Python: Implement single-value serialization (#4263),2,823,2022-03-30 19:05:51-07:00,"['conversions.py', 'test_conversions.py']"
Core: Add RESTRequest and RESTResponse interfaces (#4405),28,251,2022-03-31 08:13:06-07:00,"['HTTPClient.java', 'RESTClient.java', 'RESTMessage.java', 'RESTRequest.java', 'RESTResponse.java', 'CreateNamespaceRequest.java', 'CreateTableRequest.java', 'UpdateNamespacePropertiesRequest.java', 'UpdateTableRequest.java', 'CreateNamespaceResponse.java', 'ErrorResponse.java', 'GetNamespaceResponse.java', 'ListNamespacesResponse.java', 'ListTablesResponse.java', 'LoadTableResponse.java', 'RESTCatalogConfigResponse.java', 'UpdateNamespacePropertiesResponse.java', 'RESTCatalogAdapter.java', 'RequestResponseTestBase.java', 'TestHTTPClient.java', 'TestCreateNamespaceRequest.java', 'TestUpdateNamespacePropertiesRequest.java', 'TestCreateNamespaceResponse.java', 'TestGetNamespaceResponse.java', 'TestListNamespacesResponse.java', 'TestListTablesResponse.java', 'TestRESTCatalogConfigResponse.java', 'TestUpdateNamespacePropertiesResponse.java']"
Python: Updates to literals (#4436),2,273,2022-03-31 08:43:36-07:00,"['literals.py', 'test_literals.py']"
AWS: Make S3 client initialization thread safe (#4454),1,8,2022-03-31 11:52:57-07:00,['S3FileIO.java']
Flink: Add test case for ReusableMapData (#4441),2,17,2022-03-31 12:01:48-07:00,"['TestHelpers.java', 'TestFlinkScan.java']"
"Flink 1.13: Fix UPSERT delete file metadata (#4417)

Co-authored-by: liliwei <hililiwei@gmail.com>",3,306,2022-03-31 12:08:21-07:00,"['BaseDeltaTaskWriter.java', 'RowDataTaskWriterFactory.java', 'TestFlinkUpsert.java']"
Flink: Fix parquet readers for array data (#4432),2,11,2022-04-01 10:10:04+08:00,"['FlinkParquetReaders.java', 'TestFlinkScan.java']"
Aliyun: Deprecate the public OSSInputStream (#4450),1,8,2022-04-01 14:25:01+08:00,['OSSInputStream.java']
"Build: Add DELL label (#4462)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",1,4,2022-04-01 18:11:02+08:00,['labeler.yml']
"Build: Update spotless version and add spotless tasks (#4077)

This adds the three spotless tasks to the build:

```
spotlessApply - Applies code formatting steps to sourcecode in-place.
spotlessCheck - Checks that sourcecode satisfies formatting steps.
spotlessDiagnose
```",2,5,2022-04-01 15:34:23+02:00,"['baseline.gradle', 'build.gradle']"
Nessie: Use config constants from public Nessie API (#4387),3,11,2022-04-01 15:36:15+02:00,"['NessieCatalog.java', 'NessieUtil.java', 'TestCustomNessieClient.java']"
Nessie: Bump Nessie and add Namespace support (#4385),4,127,2022-04-01 15:41:02+02:00,"['NessieCatalog.java', 'BaseTestIceberg.java', 'TestNamespace.java', 'versions.props']"
Nessie: Add Catalog tests for NessieCatalog (#4392),4,169,2022-04-01 17:49:21+02:00,"['build.gradle', 'NessieTableOperations.java', 'TestNessieCatalog.java', 'TestNessieTable.java']"
Flink: FLIP-27 source reader (#4269),6,417,2022-04-01 09:08:04-07:00,"['IcebergSourceReader.java', 'IcebergSourceRecordEmitter.java', 'IcebergSourceSplitReader.java', 'ReaderMetricsContext.java', 'RecordAndPosition.java', 'SplitRequestEvent.java']"
Parquet: Avoid modifying existing conf of HadoopOutputFile rather create new one (#4411),2,21,2022-04-02 10:42:04+08:00,"['Parquet.java', 'SparkRowLevelOperationsTestBase.java']"
Docs: fix format-version doc returns 404 not found (#4458),1,2,2022-04-02 14:13:39+08:00,['configuration.md']
Core: Convert lambda to reference for error prone (#4442),1,3,2022-04-03 09:25:51-07:00,['FlinkSplitPlanner.java']
"Integrations: Fix FileIO client initialization thread safety (#4461)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",3,24,2022-04-03 09:38:06-07:00,"['OSSFileIO.java', 'EcsFileIO.java', 'GCSFileIO.java']"
Python: Add bucket transform (#4416),3,374,2022-04-03 10:42:56-07:00,"['setup.cfg', 'transforms.py', 'test_transforms.py']"
JDBC: Make SQL strings package-private (#4440),1,60,2022-04-03 13:29:18-07:00,['JdbcUtil.java']
Spark: Add identifier fields to Spark table properties (#4475),2,11,2022-04-03 13:31:45-07:00,"['SparkTable.java', 'TestCreateActions.java']"
Docs: Fix typo in configuration.md (#4477),1,2,2022-04-03 13:33:48-07:00,['configuration.md']
"Spark 3.2: Update task stats for split files (#4446)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",1,4,2022-04-03 14:33:49-07:00,['SparkScan.java']
Build: Upgrade to Gradle 7.4.2 (#4455),2,6,2022-04-03 14:39:08-07:00,"['gradle-wrapper.properties', 'gradlew']"
Core: Minor review fixes for ResolvingFileIO (#3603),1,25,2022-04-03 14:44:56-07:00,['ResolvingFileIO.java']
"Spec: Add common view format spec (#3188)

Co-authored-by: John Zhuge <jzhuge@apache.org>",2,284,2022-04-03 16:56:29-07:00,"['view-spec.md', 'view-spec.md']"
Core: Avoid Date for timestamp to string conversion (#4444),2,9,2022-04-04 08:32:14-07:00,"['RemoveSnapshots.java', 'ScanSummary.java']"
"Spark 3.x: Improve stats estimation for spark scan (port #4446) (#4487)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",2,8,2022-04-04 10:36:56-05:00,"['SparkBatchScan.java', 'SparkBatchScan.java']"
"Spark 2.x: Improve stats estimation for spark scan (backport #4446) (#4488)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",1,4,2022-04-04 10:37:23-05:00,['Reader.java']
Static Analysis: Missing Private Constructor for Utility Classes (#4481),3,9,2022-04-04 10:40:53-05:00,"['DynClasses.java', 'DynFields.java', 'SnapshotSummary.java']"
Static Analysis: Mixed Mutability Return Type (#4482),4,24,2022-04-04 10:45:44-05:00,"['BaseFileScanTask.java', 'FlinkCatalog.java', 'FlinkCatalog.java', 'FlinkCatalog.java']"
Static Analysis: Remove Unnecessary Integer wrapping of int,1,16,2022-04-04 10:48:22-05:00,['ParquetMetricsRowGroupFilter.java']
Core: Support rewrite-all flag in BinPackStrategy (#4433),3,122,2022-04-04 10:52:07-05:00,"['BinPackStrategy.java', 'SortStrategy.java', 'TestBinPackStrategy.java']"
Core: Add ResourcePaths helper for REST (#4467),7,407,2022-04-04 10:53:50-07:00,"['RESTCatalog.java', 'RESTUtil.java', 'ResourcePaths.java', 'CatalogTests.java', 'RESTCatalogAdapter.java', 'TestRESTUtil.java', 'TestResourcePaths.java']"
Spark 3.2: Refactor certain actions (#4469),7,180,2022-04-04 11:29:17-07:00,"['TestRemoveOrphanFilesProcedure.java', 'BaseDeleteOrphanFilesSparkAction.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseExpireSnapshotsSparkAction.java', 'BaseSparkAction.java', 'TestDeleteReachableFilesAction.java', 'TestRemoveOrphanFilesAction.java']"
Docs: Update Spark Write Conf for isolation-level followup (#4380),1,4,2022-04-04 12:06:51-07:00,['spark-configuration.md']
Python: Refactor to use common decimal and datetime util (#4480),7,312,2022-04-04 13:39:20-07:00,"['conversions.py', 'literals.py', 'transforms.py', 'datetime.py', 'decimal.py', 'test_conversions.py', 'test_transforms.py']"
Spark: Ignore SQL comments checking for Iceberg commands (#4396),3,73,2022-04-04 13:55:27-07:00,"['IcebergSparkSqlExtensionsParser.scala', 'TestCallStatementParser.java', 'TestExpireSnapshotsProcedure.java']"
Nessie: Bump from 0.23.1 to 0.24.0 (#4493),1,2,2022-04-04 13:56:06-07:00,['versions.props']
"Core: Fix errorprone warnings for unnecessary parens, variable (#4483)

* metadataTableSchena->metadataTableSchema

* fix Removing unnecessary grouping parentheses and variable",1,9,2022-04-04 13:57:30-07:00,['BaseFileScanTask.java']
Core: Add stage-create flag to REST create route (#4492),6,85,2022-04-04 14:14:11-07:00,"['RESTCatalog.java', 'ResourcePaths.java', 'CreateTableRequest.java', 'RESTCatalogAdapter.java', 'TestResourcePaths.java', 'rest-catalog-open-api.yaml']"
Python: Add Schema class (#4318),3,862,2022-04-04 14:27:42-07:00,"['schema.py', 'conftest.py', 'test_schema.py']"
Spark 3.2: Simplify action class hierarchy (#4494),7,194,2022-04-04 15:51:07-07:00,"['BaseRewriteDataFilesSpark3Action.java', 'BaseRewriteDataFilesSparkAction.java', 'BaseSnapshotTableSparkAction.java', 'BaseSparkActions.java', 'SparkActions.java', 'SparkBinPackStrategy.java', 'SparkSortStrategy.java']"
Spark: Remove useless table refresh in TestStructuredStreamingRead3 (#4502),1,15,2022-04-05 08:38:00-07:00,['TestStructuredStreamingRead3.java']
Core: Fix JsonUtil with explicit null values (#4499),2,23,2022-04-05 08:39:33-07:00,"['JsonUtil.java', 'TestErrorResponseParser.java']"
Hive: Use explicit UTF-8 charset (#4484),1,3,2022-04-05 08:41:46-07:00,['CompatibilityHiveVectorUtils.java']
Python: Implement Schema.find_column_name (#4504),3,125,2022-04-05 16:11:39-07:00,"['pyarrow.py', 'schema.py', 'test_schema.py']"
"Python (legacy): Fix typos (#4203)

Co-authored-by: jeehong.lee@navercorp.com <jeehong.lee@navercorp.com>",3,11,2022-04-05 16:15:23-07:00,"['base_transaction.py', 'test_predicate_binding.py', 'test_conversions.py']"
Core: Predicate pushdown for all_data_files table (#4382),9,237,2022-04-05 17:16:37-07:00,"['AllDataFilesTable.java', 'BaseAllMetadataTableScan.java', 'BaseFilesTable.java', 'BaseMetadataTableScan.java', 'DataFilesTable.java', 'DeleteFilesTable.java', 'FilesTable.java', 'TestMetadataTableFilters.java', 'TestMetadataTables.java']"
Dell: Add metrics tracking for EcsFileIO (#4489),8,129,2022-04-06 15:54:05+08:00,"['BaseEcsFile.java', 'EcsAppendOutputStream.java', 'EcsFileIO.java', 'EcsInputFile.java', 'EcsOutputFile.java', 'EcsSeekableInputStream.java', 'TestEcsAppendOutputStream.java', 'TestEcsSeekableInputStream.java']"
Core: Encryption basics (#2638),9,403,2022-04-06 12:09:58-05:00,"['S3InputFile.java', 'S3OutputFile.java', 'Ciphers.java', 'EncryptionAlgorithm.java', 'NativeFileCryptoParameters.java', 'NativelyEncryptedFile.java', 'HadoopInputFile.java', 'HadoopOutputFile.java', 'TestCiphers.java']"
Flink 1.13: Fix parquet readers for array data (#4521),3,26,2022-04-07 15:17:59+08:00,"['FlinkParquetReaders.java', 'TestHelpers.java', 'TestFlinkScan.java']"
Nessie: Fix NPE while accessing refreshed table in nessie catalog (#4509),2,30,2022-04-07 15:31:45+08:00,"['NessieTableOperations.java', 'TestBranchVisibility.java']"
Flink: Clear the deprecated FlinkSink#build. (#4524),3,36,2022-04-08 10:28:56+08:00,"['FlinkSink.java', 'FlinkSink.java', 'FlinkSink.java']"
Core: Fix FileAppenderFactory API javadoc (#4526),1,2,2022-04-08 10:37:21+08:00,['FileAppenderFactory.java']
Spark 3.x: Remove redundant table refresh calls in TestStructuredStreamingRead3 (#4511),2,28,2022-04-08 15:24:00+08:00,"['TestStructuredStreamingRead3.java', 'TestStructuredStreamingRead3.java']"
Hive: Expose Snapshot Stats in HMS (#4456),4,170,2022-04-08 09:49:44-07:00,"['TableProperties.java', 'HiveTableOperations.java', 'TestHiveCatalog.java', 'TestHiveIcebergStorageHandlerNoScan.java']"
Docs: Supplement spark-queries.md (#3482),1,131,2022-04-08 09:55:27-07:00,['spark-queries.md']
"Python: Reorganize expressions module structure (#4468)

Co-authored-by: Steve Zhang <hongyue_zhang@apple.com>",7,130,2022-04-10 13:02:59-07:00,"['__init__.py', 'base.py', 'literals.py', '__init__.py', 'test_expressions_base.py', 'test_literals.py', 'test_io_base.py']"
Flink: Inferred parallelism should respect global settings (#4531),2,29,2022-04-10 18:03:57-07:00,"['FlinkSource.java', 'TestFlinkScanSql.java']"
Flink: Fix out of order appends in upsert UT (#4532),2,80,2022-04-11 18:15:30+08:00,"['TestFlinkUpsert.java', 'TestFlinkUpsert.java']"
Core: Handle server-provided config in RESTCatalog (#4495),8,319,2022-04-11 18:51:56-07:00,"['HTTPClient.java', 'HTTPClientFactory.java', 'RESTCatalog.java', 'RESTCatalogProperties.java', 'RESTObjectMapper.java', 'RESTCatalogAdapter.java', 'TestHTTPClient.java', 'TestRESTCatalog.java']"
Core: Fix transaction retry logic (#4464),2,110,2022-04-11 19:51:38-07:00,"['BaseTransaction.java', 'TestTransaction.java']"
Core: Add specId for partitions metadata table (#4516),5,18,2022-04-12 11:59:32-07:00,"['PartitionsTable.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java']"
Core: Fix missing operation in OpenAPI Snapshot (#4544),1,5,2022-04-12 16:21:13-07:00,['rest-catalog-open-api.yaml']
Build: Remove exclusion to allow static imports for unrelocated Preconditions (#4543),1,1,2022-04-12 16:22:14-07:00,['checkstyle.xml']
FileIO: Handle null metrics fallback for MetricsContext (#4500),4,31,2022-04-13 08:13:00-07:00,"['OSSFileIO.java', 'S3FileIO.java', 'EcsFileIO.java', 'GCSFileIO.java']"
Spark: Add format-version to table properties (#4540),2,20,2022-04-13 09:43:20-07:00,"['SparkTable.java', 'TestCreateActions.java']"
Core: Fix filter pushdown for metadata tables with evolved specs (#4520),5,474,2022-04-13 13:14:49-07:00,"['BaseFilesTable.java', 'BaseMetadataTable.java', 'PartitionsTable.java', 'TestMetadataTableFilters.java', 'TestMetadataTablesWithPartitionEvolution.java']"
"API: KMS client interface (#3470)

Adds KMS Client interface for encryption",3,278,2022-04-13 17:02:57-05:00,"['KmsClient.java', 'KeyStoreKmsClient.java', 'MemoryMockKMS.java']"
API: Add branch and tag operations to ManageSnapshots (#4071),8,996,2022-04-13 15:58:40-07:00,"['ManageSnapshots.java', 'BaseTransaction.java', 'MetadataUpdate.java', 'SnapshotManager.java', 'TableMetadata.java', 'UpdateSnapshotReferencesOperation.java', 'SnapshotUtil.java', 'TestSnapshotManager.java']"
Flink: Remove support for Flink 1.12 (#4551),134,24591,2022-04-14 16:26:52+08:00,"['flink-ci.yml', 'java-ci.yml', 'stage-binaries.sh', 'build.gradle', 'build.gradle', 'LICENSE', 'NOTICE', 'CatalogLoader.java', 'FlinkCatalog.java', 'FlinkCatalogFactory.java', 'FlinkConfigOptions.java', 'FlinkDynamicTableFactory.java', 'FlinkFilters.java', 'FlinkFixupTypes.java', 'FlinkSchemaUtil.java', 'FlinkTypeToType.java', 'FlinkTypeVisitor.java', 'IcebergTableSink.java', 'IcebergTableSource.java', 'RowDataWrapper.java', 'TableLoader.java', 'TypeToFlinkType.java', 'Actions.java', 'RewriteDataFilesAction.java', 'AvroWithFlinkSchemaVisitor.java', 'FlinkAvroReader.java', 'FlinkAvroWriter.java', 'FlinkOrcReader.java', 'FlinkOrcReaders.java', 'FlinkOrcWriter.java', 'FlinkOrcWriters.java', 'FlinkParquetReaders.java', 'FlinkParquetWriters.java', 'FlinkSchemaVisitor.java', 'FlinkValueReaders.java', 'FlinkValueWriters.java', 'ParquetWithFlinkSchemaVisitor.java', 'RowDataProjection.java', 'RowDataUtil.java', 'BaseDeltaTaskWriter.java', 'DeltaManifests.java', 'DeltaManifestsSerializer.java', 'EqualityFieldKeySelector.java', 'FlinkAppenderFactory.java', 'FlinkFileWriterFactory.java', 'FlinkManifestUtil.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'IcebergStreamWriter.java', 'ManifestOutputFileFactory.java', 'PartitionKeySelector.java', 'PartitionedDeltaWriter.java', 'RowDataTaskWriterFactory.java', 'TaskWriterFactory.java', 'UnpartitionedDeltaWriter.java', 'DataIterator.java', 'FileScanTaskReader.java', 'FlinkInputFormat.java', 'FlinkInputSplit.java', 'FlinkSource.java', 'FlinkSplitGenerator.java', 'RowDataFileScanTaskReader.java', 'RowDataRewriter.java', 'ScanContext.java', 'StreamingMonitorFunction.java', 'StreamingReaderOperator.java', 'FlinkCompatibilityUtil.java', 'org.apache.flink.table.factories.Factory', 'org.apache.flink.table.factories.TableFactory', 'FlinkCatalogTestBase.java', 'FlinkTestBase.java', 'MiniClusterResource.java', 'RowDataConverter.java', 'SimpleDataUtil.java', 'TestCatalogTableLoader.java', 'TestChangeLogTable.java', 'TestDataFileSerialization.java', 'TestFixtures.java', 'TestFlinkCatalogDatabase.java', 'TestFlinkCatalogFactory.java', 'TestFlinkCatalogTable.java', 'TestFlinkCatalogTablePartitions.java', 'TestFlinkFilters.java', 'TestFlinkHiveCatalog.java', 'TestFlinkSchemaUtil.java', 'TestFlinkTableSink.java', 'TestFlinkTableSource.java', 'TestHelpers.java', 'TestIcebergConnector.java', 'TestManifestFileSerialization.java', 'TestRowDataWrapper.java', 'TestTableLoader.java', 'TestTableSerialization.java', 'TestRewriteDataFilesAction.java', 'RandomRowData.java', 'TestFlinkAvroReaderWriter.java', 'TestFlinkOrcReaderWriter.java', 'TestFlinkParquetReader.java', 'TestFlinkParquetWriter.java', 'TestRowDataProjection.java', 'TestRowProjection.java', 'TestDeltaTaskWriter.java', 'TestFlinkAppenderFactory.java', 'TestFlinkFileWriterFactory.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkV2.java', 'TestFlinkManifest.java', 'TestFlinkPartitioningWriters.java', 'TestFlinkPositionDeltaWriters.java', 'TestFlinkRollingFileWriters.java', 'TestFlinkWriterMetrics.java', 'TestIcebergFilesCommitter.java', 'TestIcebergStreamWriter.java', 'TestRowDataPartitionKey.java', 'TestTaskWriters.java', 'BoundedTableFactory.java', 'BoundedTestSource.java', 'ChangeLogTableTestBase.java', 'TestBoundedTableFactory.java', 'TestFlinkInputFormat.java', 'TestFlinkInputFormatReaderDeletes.java', 'TestFlinkMergingMetrics.java', 'TestFlinkReaderDeletesBase.java', 'TestFlinkScan.java', 'TestFlinkScanSql.java', 'TestFlinkSource.java', 'TestProjectMetaColumn.java', 'TestStreamScanSql.java', 'TestStreamingMonitorFunction.java', 'TestStreamingReaderOperator.java', 'org.apache.flink.table.factories.Factory', 'gradle.properties', 'settings.gradle', 'versions.props']"
"Core: Fix `Preconditions.checkArgument` error message format (#4558)

Replaces usages of %d which is not supported in Preconditions format messages with %s",10,38,2022-04-14 12:44:21-05:00,"['UUIDUtil.java', 'BaseRewriteDataFilesAction.java', 'BinPackStrategy.java', 'RewriteDataFilesAction.java', 'RewriteDataFilesAction.java', 'DataIterator.java', 'BaseRewriteManifestsSparkAction.java', 'BaseRewriteManifestsSparkAction.java', 'BaseRewriteManifestsSparkAction.java', 'BaseRewriteManifestsSparkAction.java']"
Spark: Fix SparkFixupTimestampType javadoc link (#4556),4,8,2022-04-14 15:36:32-07:00,"['SparkFixupTimestampType.java', 'SparkFixupTimestampType.java', 'SparkFixupTimestampType.java', 'SparkFixupTimestampType.java']"
Docs: Fix typo in tables/evolution.md (#4559),1,2,2022-04-14 15:38:57-07:00,['evolution.md']
Core: Avoid constants for last assigned partition id (#4386),3,13,2022-04-15 08:36:29-07:00,"['PartitionSpec.java', 'BaseUpdatePartitionSpec.java', 'TableMetadataParser.java']"
Flink 1.13: Inferred parallelism should respect global settings (#4533),2,29,2022-04-15 08:36:54-07:00,"['FlinkSource.java', 'TestFlinkScanSql.java']"
Hive: Remove unnecessary newline (#4570),1,1,2022-04-15 09:01:13-07:00,['HiveIcebergFilterFactory.java']
Core: Rename REST config response to ConfigResponse (#4554),6,104,2022-04-15 09:02:40-07:00,"['RESTCatalog.java', 'ConfigResponse.java', 'RESTCatalogAdapter.java', 'TestRESTCatalog.java', 'TestRESTCatalogConfigResponse.java', 'rest-catalog-open-api.yaml']"
"Spark: Add option to introduce ordering of RewriteFileGroup (#4377)

Allows users to specify the order in which Rewrite JobGroups should be executed.",5,267,2022-04-15 12:32:35-05:00,"['RewriteJobOrder.java', 'RewriteDataFiles.java', 'RewriteFileGroup.java', 'BaseRewriteDataFilesSparkAction.java', 'TestRewriteDataFilesAction.java']"
"Spark 3.x: Add option to introduce ordering of RewriteFileGroup (#4579)

Changes rewrite.job-order to rewrite-job-order and backports option to 3.0 and 3.1",6,387,2022-04-18 08:07:34-05:00,"['RewriteDataFiles.java', 'BaseRewriteDataFilesSparkAction.java', 'TestRewriteDataFilesAction.java', 'BaseRewriteDataFilesSparkAction.java', 'TestRewriteDataFilesAction.java', 'TestRewriteDataFilesAction.java']"
Static Analysis: Convert Lambda to Method Reference (#4574),1,5,2022-04-18 09:30:39-05:00,['IcebergSourceSplitReader.java']
"Docs: Update EMR links (#4568)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",2,4,2022-04-18 10:07:53-07:00,"['_index.md', 'aws.md']"
Parquet: Remove unused function converterFor from class ParquetMetricsRowGroupFilter (#4548),1,15,2022-04-18 13:37:23-07:00,['ParquetMetricsRowGroupFilter.java']
Flink: Support modifying table properties for table with primary key. (#4561),2,56,2022-04-19 20:22:57+08:00,"['FlinkCatalog.java', 'TestFlinkCatalogTable.java']"
"Nessie: Extract Catalog client code to NessieClient for Trino Consumption (#4491)

* Nessie: simplify code in Nessie catalog

This adds a new `NessieIcebergClient` class that encapsulates some of
the features that have been used across the `NessieCatalog`.
It also slightly improves the error messages to include the reference or
the table name when something fails.",6,683,2022-04-19 12:56:03-05:00,"['NessieCatalog.java', 'NessieIcebergClient.java', 'NessieTableOperations.java', 'NessieUtil.java', 'TestBranchVisibility.java', 'TestNessieTable.java']"
Nessie: Use memoized Supplier to avoid unnecessary API calls (#4593),3,31,2022-04-20 09:50:08-05:00,"['GuavaClasses.java', 'NessieIcebergClient.java', 'TestNessieTable.java']"
"Core: Strip trailing slashes in location consistently (#4585)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",13,203,2022-04-20 08:35:58-07:00,"['DynamoDbCatalog.java', 'GlueCatalog.java', 'TestGlueCatalog.java', 'LocationProviders.java', 'HadoopCatalog.java', 'JdbcCatalog.java', 'LocationUtil.java', 'TestTables.java', 'TestLocationUtil.java', 'EcsCatalog.java', 'HiveCatalog.java', 'TestHiveCatalog.java', 'TestTables.java']"
Python: Add StructProtocol and file type enums (#4598),1,53,2022-04-20 10:23:40-07:00,['files.py']
Core: Fix delete file handling in upgraded tables with rewritten manifests (#4514),2,248,2022-04-20 12:51:49-07:00,"['MergingSnapshotProducer.java', 'TestV1ToV2RowDeltaDelete.java']"
Spark 3.1: Ignore SQL comments checking for Iceberg commands (#4496),3,73,2022-04-20 16:53:59-07:00,"['IcebergSparkSqlExtensionsParser.scala', 'TestCallStatementParser.java', 'TestExpireSnapshotsProcedure.java']"
Spark 3.0: Ignore SQL comments checking for Iceberg commands (#4497),3,73,2022-04-20 16:57:01-07:00,"['IcebergSparkSqlExtensionsParser.scala', 'TestCallStatementParser.java', 'TestExpireSnapshotsProcedure.java']"
"Spark: Spark3 ZOrder Rewrite Strategy (#3983)

Adds initial implementation of a ZOrder File Rewrite Strategy. Allows uses to use a multidimensional sort algorithm for organizing data.",13,1758,2022-04-21 09:50:23-05:00,"['RewriteDataFiles.java', 'ByteBuffers.java', 'ZOrderByteUtilsBenchmark.java', 'ZOrderByteUtils.java', 'TestZOrderByteUtil.java', 'jmh.gradle', 'IcebergSortCompactionBenchmark.java', 'RandomGeneratingUDF.java', 'BaseRewriteDataFilesSparkAction.java', 'SparkSortStrategy.java', 'SparkZOrderStrategy.java', 'SparkZOrderUDF.java', 'TestRewriteDataFilesAction.java']"
Nessie: Allow catalog initialization using pre-configured client/file io instances (#4591),2,68,2022-04-21 11:27:11-05:00,"['NessieCatalog.java', 'TestCustomNessieClient.java']"
"Static Analysis: Removing System.out and System.err (#4584)

Removes usages of StdOut and StdErr in test cases.
Fixes Checkstyle message for StdErr usage",12,61,2022-04-21 11:29:26-05:00,"['checkstyle.xml', 'TestReadabilityChecks.java', 'TestSchemaUnionByFieldName.java', 'TestJdbcCatalog.java', 'TestParquetAvroReader.java', 'TestSparkDateTimes.java', 'TestParquetAvroReader.java', 'TestSparkDateTimes.java', 'TestParquetAvroReader.java', 'TestSparkDateTimes.java', 'TestParquetAvroReader.java', 'TestSparkDateTimes.java']"
"Core: Use memory-backed streams in tests (#4534)

Sometimes an actual file is needed, but sometimes it's not. In the case
where it isn't, we can use an in-memory `InputFile`, `OutputFile`
implementation.",7,286,2022-04-21 14:51:39-05:00,"['TestManifestListVersions.java', 'TestManifestWriterVersions.java', 'TestScansAndSchemaEvolution.java', 'TestAvroDeleteWriters.java', 'TestGenericAvro.java', 'InMemoryInputFile.java', 'InMemoryOutputFile.java']"
Core: Add MetadataUpdateParser with support for UpgradeFormatVersion (#4601),3,257,2022-04-21 15:48:15-07:00,"['MetadataUpdateParser.java', 'RESTSerializers.java', 'TestMetadataUpdateParser.java']"
Core: Refactor metadata tables and scans (#4566),19,556,2022-04-21 18:23:42-07:00,"['AllDataFilesTable.java', 'AllEntriesTable.java', 'AllManifestsTable.java', 'BaseAllMetadataTableScan.java', 'BaseFilesTable.java', 'BaseMetadataTableScan.java', 'BaseTableScan.java', 'DataFilesTable.java', 'DataTableScan.java', 'DeleteFilesTable.java', 'FilesTable.java', 'HistoryTable.java', 'IncrementalDataTableScan.java', 'ManifestEntriesTable.java', 'ManifestsTable.java', 'PartitionsTable.java', 'SnapshotsTable.java', 'StaticDataTask.java', 'StaticTableScan.java']"
Python: Add a generic Accessor class (#4609),3,82,2022-04-22 12:17:35-07:00,"['base.py', 'conftest.py', 'test_expressions_base.py']"
"Static Analysis: Fix Objects.requireNonNull usages (#4611)

Per project code style, Preconditions.checkNotNull should be used instead.",3,14,2022-04-22 15:29:25-05:00,"['NessieCatalog.java', 'UpdateableReference.java', 'TestCreateActions.java']"
"Python: Add And, Or, Not, AlwaysTrue, AlwaysFalse expressions (#4466)",2,266,2022-04-24 10:55:51-07:00,"['base.py', 'test_expressions_base.py']"
Spark 3.2: Add compareWithFileList to DeleteOrphanFiles action (#4503),6,292,2022-04-24 13:49:29-07:00,"['TestRemoveOrphanFilesProcedure.java', 'BaseDeleteOrphanFilesSparkAction.java', 'BaseSparkAction.java', 'RemoveOrphanFilesProcedure.java', 'TestRemoveOrphanFilesAction.java', 'FilePathLastModifiedRecord.java']"
"Style: Add rule to prevent using Objects.requireNonNull, Objects.nonNull (#4617)",1,4,2022-04-24 15:03:24-07:00,['checkstyle.xml']
Python: Add BoundReference class (#4619),2,85,2022-04-24 15:07:12-07:00,"['base.py', 'test_expressions_base.py']"
"Python: Add PartitionField (#4590)

Co-authored-by: Steve Zhang <hongyue_zhang@apple.com>",3,118,2022-04-25 08:14:36-07:00,"['partitioning.py', '__init__.py', 'test_partitioning.py']"
Core: Add RangeReadable interface for limiting FileIO reads (#4608),7,418,2022-04-25 09:55:49-07:00,"['LICENSE', 'RangeReadable.java', 'S3InputStream.java', 'TestS3InputStream.java', 'IOUtil.java', 'MockInputStream.java', 'TestIOUtil.java']"
Core: Disallow setting fields nested in optional structs as identifier fields,3,97,2022-04-25 11:21:48-07:00,"['Schema.java', 'SchemaUpdate.java', 'TestSchemaUpdate.java']"
Core: Fix Partitions table for evolved partition specs (#4560),2,234,2022-04-25 14:48:17-07:00,"['PartitionsTable.java', 'TestMetadataTablesWithPartitionEvolution.java']"
Hive: Expose default partition spec and sort order in HMS (#4546),4,228,2022-04-26 12:04:03-07:00,"['TableProperties.java', 'HiveTableOperations.java', 'TestHiveCatalog.java', 'TestHiveIcebergStorageHandlerNoScan.java']"
"Core - Use singleton RESTObjectMapper in REST RequestResponseTestBase class (#4636)

* Core - Use the dedicated RESTObjectMapper in REST request response test base class

* Update tests that previously threw on unrecognized fields as the object mapper is currently permissive - all but one of these cases fail validation anyways

* Fix last failing check",7,39,2022-04-27 11:09:04-07:00,"['RequestResponseTestBase.java', 'TestCreateNamespaceRequest.java', 'TestCreateNamespaceResponse.java', 'TestGetNamespaceResponse.java', 'TestListNamespacesResponse.java', 'TestListTablesResponse.java', 'TestRESTCatalogConfigResponse.java']"
Core - Fix field names in LoadTableResponse object to match REST spec (#4642),1,23,2022-04-27 11:10:21-07:00,['LoadTableResponse.java']
Core: Add TableMetadata to REST serializers (#4641),2,28,2022-04-27 11:37:10-07:00,"['TableMetadataParser.java', 'RESTSerializers.java']"
"Core: Add AddSchema, SetCurrentSchema, and SetDefaultPartitionSpec serialization (#4632)",2,228,2022-04-27 11:49:56-07:00,"['MetadataUpdateParser.java', 'TestMetadataUpdateParser.java']"
Python: Update docs to avoid InterpreterNotFound errors from tox (#4650),1,15,2022-04-27 14:21:09-07:00,['README.md']
Core: Add ByteBufferInputStream and implementations (#4623),7,1445,2022-04-28 09:14:10-07:00,"['LICENSE', 'ByteBufferInputStream.java', 'MultiBufferInputStream.java', 'SingleBufferInputStream.java', 'TestByteBufferInputStreams.java', 'TestMultiBufferInputStream.java', 'TestSingleBufferInputStream.java']"
"Spark 3.2: Add property to allow disabling HiddenPathFilter in RemoveOrphansFiles (#4655)

Co-authored-by: Ulrich Konrad <u.konrad@kasasi.de>",3,210,2022-04-28 10:06:34-07:00,"['HiddenPathFilter.java', 'BaseDeleteOrphanFilesSparkAction.java', 'TestRemoveOrphanFilesAction.java']"
Core: Rename test class to match ConfigResponse (#4653),1,2,2022-04-28 18:46:59-07:00,['TestConfigResponse.java']
Infra: Remove Szehon from collaborators (now a committer) (#4643),1,1,2022-04-28 18:48:16-07:00,['.asf.yaml']
Spec: Add/update required dialect field in View metadata example (#4648),1,10,2022-04-28 18:49:10-07:00,['view-spec.md']
Spark: Depend on Parquet directly for Spark modules (#4667),3,15,2022-04-29 09:22:38-07:00,"['build.gradle', 'build.gradle', 'build.gradle']"
Flink 1.14: Fix order-dependent FlinkTableSource tests that break in 1.15 (#4635),2,40,2022-04-29 09:25:32-07:00,"['FlinkTestBase.java', 'TestFlinkTableSource.java']"
Docs: Default value support feature specification (#4301),1,60,2022-04-29 13:28:15-07:00,['spec.md']
Spark: Fix NPEs in Spark value converter (#4663),8,411,2022-04-29 13:31:41-07:00,"['SparkValueConverter.java', 'TestSparkValueConverter.java', 'SparkValueConverter.java', 'TestSparkValueConverter.java', 'SparkValueConverter.java', 'TestSparkValueConverter.java', 'SparkValueConverter.java', 'TestSparkValueConverter.java']"
Spark: Metadata-only delete should throw ValidationException instead of IllegalArgumentException (#4630),4,42,2022-04-29 15:49:35-07:00,"['SparkTable.java', 'TestDeleteFrom.java', 'SparkTable.java', 'SparkTable.java']"
Python: Specify pip>=21.1 in tox dependencies (#4676),1,1,2022-05-02 11:57:59-07:00,['tox.ini']
Core: Add eq and pos delete file counts to snapshot summary (#4677),2,41,2022-05-02 12:06:53-07:00,"['SnapshotSummary.java', 'TestSnapshotSummary.java']"
Core: Fix table corruption from OOM during commit cleanup (#4673),1,14,2022-05-02 12:26:48-07:00,['SnapshotProducer.java']
Core: Fix ConvertEqualityDeleteStrategy::options return type (#4669),1,2,2022-05-02 13:58:52-07:00,['ConvertEqualityDeleteStrategy.java']
"Python: Add a skeleton for the BuildPositionAccessors visitor (#4678)

Co-authored-by: Fokko Driesprong <fokko@apache.org>",1,65,2022-05-02 16:17:49-07:00,['schema.py']
Flink 1.13: Backport fix for order dependent flink table source tests (#4682),2,40,2022-05-02 16:38:00-07:00,"['FlinkTestBase.java', 'TestFlinkTableSource.java']"
Flink: Support malformed Parquet lists added by addFiles API (#4555),4,31,2022-05-02 16:49:02-07:00,"['ParquetWithFlinkSchemaVisitor.java', 'ParquetTypeVisitor.java', 'TypeWithSchemaVisitor.java', 'TestParquetSchemaUtil.java']"
"Core: Add serialization for AddPartitionSpec, AddSortOrder (#4668)",2,333,2022-05-02 20:02:58-07:00,"['MetadataUpdateParser.java', 'TestMetadataUpdateParser.java']"
Flink: Add support for Flink 1.15 (#4553),165,28260,2022-05-03 08:53:01-07:00,"['flink-ci.yml', 'java-ci.yml', 'stage-binaries.sh', 'build.gradle', 'build.gradle', 'LICENSE', 'NOTICE', 'CatalogLoader.java', 'FlinkCatalog.java', 'FlinkCatalogFactory.java', 'FlinkConfigOptions.java', 'FlinkDynamicTableFactory.java', 'FlinkFilters.java', 'FlinkFixupTypes.java', 'FlinkSchemaUtil.java', 'FlinkTypeToType.java', 'FlinkTypeVisitor.java', 'IcebergTableSink.java', 'IcebergTableSource.java', 'RowDataWrapper.java', 'TableLoader.java', 'TypeToFlinkType.java', 'Actions.java', 'RewriteDataFilesAction.java', 'AvroWithFlinkSchemaVisitor.java', 'FlinkAvroReader.java', 'FlinkAvroWriter.java', 'FlinkOrcReader.java', 'FlinkOrcReaders.java', 'FlinkOrcWriter.java', 'FlinkOrcWriters.java', 'FlinkParquetReaders.java', 'FlinkParquetWriters.java', 'FlinkSchemaVisitor.java', 'FlinkValueReaders.java', 'FlinkValueWriters.java', 'ParquetWithFlinkSchemaVisitor.java', 'RowDataProjection.java', 'RowDataUtil.java', 'BaseDeltaTaskWriter.java', 'DeltaManifests.java', 'DeltaManifestsSerializer.java', 'EqualityFieldKeySelector.java', 'FlinkAppenderFactory.java', 'FlinkFileWriterFactory.java', 'FlinkManifestUtil.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'IcebergStreamWriter.java', 'ManifestOutputFileFactory.java', 'PartitionKeySelector.java', 'PartitionedDeltaWriter.java', 'RowDataTaskWriterFactory.java', 'TaskWriterFactory.java', 'UnpartitionedDeltaWriter.java', 'DataIterator.java', 'FileScanTaskReader.java', 'FlinkInputFormat.java', 'FlinkInputSplit.java', 'FlinkSource.java', 'FlinkSplitPlanner.java', 'RowDataFileScanTaskReader.java', 'RowDataRewriter.java', 'ScanContext.java', 'StreamingMonitorFunction.java', 'StreamingReaderOperator.java', 'GetSplitResult.java', 'SimpleSplitAssigner.java', 'SimpleSplitAssignerFactory.java', 'SplitAssigner.java', 'SplitAssignerFactory.java', 'ArrayBatchRecords.java', 'ArrayPoolDataIteratorBatcher.java', 'DataIteratorBatcher.java', 'DataIteratorReaderFunction.java', 'IcebergSourceReader.java', 'IcebergSourceRecordEmitter.java', 'IcebergSourceSplitReader.java', 'ReaderFunction.java', 'ReaderMetricsContext.java', 'RecordAndPosition.java', 'RecordFactory.java', 'RowDataReaderFunction.java', 'RowDataRecordFactory.java', 'IcebergSourceSplit.java', 'IcebergSourceSplitSerializer.java', 'IcebergSourceSplitState.java', 'IcebergSourceSplitStatus.java', 'SplitRequestEvent.java', 'FlinkCompatibilityUtil.java', 'org.apache.flink.table.factories.Factory', 'org.apache.flink.table.factories.TableFactory', 'FlinkCatalogTestBase.java', 'FlinkTestBase.java', 'MiniClusterResource.java', 'RowDataConverter.java', 'SimpleDataUtil.java', 'TestCatalogTableLoader.java', 'TestChangeLogTable.java', 'TestDataFileSerialization.java', 'TestFixtures.java', 'TestFlinkCatalogDatabase.java', 'TestFlinkCatalogFactory.java', 'TestFlinkCatalogTable.java', 'TestFlinkCatalogTablePartitions.java', 'TestFlinkFilters.java', 'TestFlinkHiveCatalog.java', 'TestFlinkSchemaUtil.java', 'TestFlinkTableSink.java', 'TestFlinkTableSource.java', 'TestFlinkUpsert.java', 'TestHelpers.java', 'TestIcebergConnector.java', 'TestManifestFileSerialization.java', 'TestRowDataWrapper.java', 'TestTableLoader.java', 'TestTableSerialization.java', 'TestRewriteDataFilesAction.java', 'RandomRowData.java', 'TestFlinkAvroReaderWriter.java', 'TestFlinkOrcReaderWriter.java', 'TestFlinkParquetReader.java', 'TestFlinkParquetWriter.java', 'TestRowDataProjection.java', 'TestRowProjection.java', 'TestDeltaTaskWriter.java', 'TestFlinkAppenderFactory.java', 'TestFlinkFileWriterFactory.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkV2.java', 'TestFlinkManifest.java', 'TestFlinkPartitioningWriters.java', 'TestFlinkPositionDeltaWriters.java', 'TestFlinkRollingFileWriters.java', 'TestFlinkWriterMetrics.java', 'TestIcebergFilesCommitter.java', 'TestIcebergStreamWriter.java', 'TestRowDataPartitionKey.java', 'TestTaskWriters.java', 'BoundedTableFactory.java', 'BoundedTestSource.java', 'ChangeLogTableTestBase.java', 'SplitHelpers.java', 'TestBoundedTableFactory.java', 'TestFlinkInputFormat.java', 'TestFlinkInputFormatReaderDeletes.java', 'TestFlinkMergingMetrics.java', 'TestFlinkReaderDeletesBase.java', 'TestFlinkScan.java', 'TestFlinkScanSql.java', 'TestFlinkSource.java', 'TestProjectMetaColumn.java', 'TestStreamScanSql.java', 'TestStreamingMonitorFunction.java', 'TestStreamingReaderOperator.java', 'TestSimpleSplitAssigner.java', 'ReaderFunctionTestBase.java', 'ReaderUtil.java', 'TestArrayBatchRecords.java', 'TestArrayPoolDataIteratorBatcherRowData.java', 'TestRowDataReaderFunction.java', 'TestIcebergSourceSplitSerializer.java', 'org.apache.flink.table.factories.Factory', 'gradle.properties', 'settings.gradle']"
Core: Add missing override annotations (#4690),1,2,2022-05-04 08:12:57-07:00,['MultiBufferInputStream.java']
Core: Prefer ImmutableList.of to Collections.emptyList (#4691),1,3,2022-05-04 08:13:59-07:00,['MultiBufferInputStream.java']
Python: Add UnknownTransform (#4684),2,38,2022-05-04 08:43:27-07:00,"['transforms.py', 'test_transforms.py']"
Hive: Log new metadata location in commit (#4681),2,4,2022-05-04 08:45:34-07:00,"['HadoopTableOperations.java', 'HiveTableOperations.java']"
"Bump Nessie to 0.28.0 and adopt test code (#4594)

Enhances Iceberg commit conflict detection by maintaining the commit-id from which a
table metadata has been loaded, to use it as the ""expected hash"" in a Nessie commit.

Makes Nessie specific properties available in `TableMetadata` properties:
* `nessie.content.id` - the Nessie `Content.getId()`
* `nessie.commit.id` - the commit ID used to retrieve the table metadata
* `nessie.reference.name` - the reference name from which the table metadata has been loaded

Also fixes an issue via `org.apache.iceberg.nessie.NessieTableOperations#loadTableMetadata`
that caused too many ""previous files"", because the `TableMetadata.buildFrom()` assumed that
it's only called for ongoing modifications.",10,503,2022-05-04 11:17:06-05:00,"['build.gradle', 'TableMetadata.java', 'NessieTableOperations.java', 'NessieUtil.java', 'NessieUtilTest.java', 'TestBranchVisibility.java', 'TestNessieCatalog.java', 'TestNessieTable.java', 'TestNessieUtil.java', 'versions.props']"
Python: Add UnboundReference class (#4679),1,47,2022-05-04 11:37:13-07:00,['base.py']
License: Add Apache HTTPComponents to runtime licenses (#4688),8,64,2022-05-04 11:43:59-07:00,"['LICENSE', 'LICENSE', 'LICENSE', 'LICENSE', 'LICENSE', 'LICENSE', 'LICENSE', 'LICENSE']"
Nessie: Support Namespace properties (#4610),4,99,2022-05-04 14:53:23-05:00,"['NessieCatalog.java', 'NessieIcebergClient.java', 'TestNamespace.java', 'TestNessieCatalog.java']"
Core: Fix filter pushdown for Partitions table with evolved specs (#4637),3,290,2022-05-04 16:06:02-07:00,"['PartitionsTable.java', 'TestMetadataTableScans.java', 'TestMetadataTablesWithPartitionEvolution.java']"
Core: Fix incorrect null check in JsonUtils::getIntOrNull and JsonUtils::getLongOrNull (#4696),1,4,2022-05-04 19:57:56-07:00,['JsonUtil.java']
"Spark 3.x: Support rewrite data files with starting sequence number (#4701) Backports (#3480)

Backport of #3480",4,142,2022-05-05 10:28:32-05:00,"['BaseRewriteDataFilesSparkAction.java', 'TestRewriteDataFilesAction.java', 'BaseRewriteDataFilesSparkAction.java', 'TestRewriteDataFilesAction.java']"
Core: Add all_delete_files and all_files tables (#4694),7,252,2022-05-06 14:18:41-07:00,"['AllDeleteFilesTable.java', 'AllFilesTable.java', 'MetadataTableType.java', 'MetadataTableUtils.java', 'TestMetadataTableFilters.java', 'TestMetadataTables.java', 'TestHelpers.java']"
Flink 1.15 - Fix flaky test that has implicit order dependency in TestFlinkTableSource (#4697),1,17,2022-05-06 18:43:51-05:00,['TestFlinkTableSource.java']
"Spark: Fix Commit State Unknown Handling (#4687)

Previously the snapshotUpdate operation could potentially throw a
CommitStateUnknownException which would cause Spark's Datasource to call
it's abort method. In this case we cannot remove the underlying data files
since those data files may actually have been successfully committed. We
previously added this code to prevent the removal of metadata files but
this issue is also possible in data file cleanup.",4,183,2022-05-06 20:39:02-05:00,"['PendingUpdate.java', 'SparkWrite.java', 'ManualSource.java', 'TestSparkDataWrite.java']"
"Nessie: Use ref.hash parameter to read data at given hash (#4700)

This makes sure that the `NessieCatalog` reads data at the given
`ref.hash` (`NessieConfigConstants.CONF_NESSIE_REF_HASH`) when it's provided. If `ref.hash` is `null`, then this means
that data should be read from whatever the latest `HEAD` is.",6,177,2022-05-09 10:54:07-05:00,"['NessieCatalog.java', 'NessieIcebergClient.java', 'BaseTestIceberg.java', 'TestBranchVisibility.java', 'TestNessieIcebergClient.java', 'versions.props']"
"Core: Fix query failure when using projection on top of partitions metadata table (#4720)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",3,29,2022-05-09 12:12:00-05:00,"['PartitionsTable.java', 'TestMetadataTableScans.java', 'TestMetadataTables.java']"
Core: Add JSON parser for UpdateRequirement (#4693),5,647,2022-05-09 10:40:35-07:00,"['RESTSerializers.java', 'UpdateRequirementParser.java', 'UpdateTableRequest.java', 'TestUpdateRequirementParser.java', 'rest-catalog-open-api.yaml']"
Spark 2.4 - 3.X: Backport Fix CommitStateUnknown Handling (#4687) (#4719),9,564,2022-05-09 17:09:34-05:00,"['Writer.java', 'ManualSource.java', 'TestSparkDataWrite.java', 'SparkWrite.java', 'ManualSource.java', 'TestSparkDataWrite.java', 'SparkWrite.java', 'ManualSource.java', 'TestSparkDataWrite.java']"
Core: Support table rename in RESTCatalog (#4448),8,346,2022-05-09 18:59:49-07:00,"['JdbcCatalog.java', 'CatalogHandlers.java', 'RESTCatalog.java', 'RenameTableRequest.java', 'CatalogTests.java', 'TestJdbcCatalog.java', 'RESTCatalogAdapter.java', 'TestRenameTableRequest.java']"
Python: Skip missing tox interpreters (#4731),1,1,2022-05-09 19:06:08-07:00,['tox.ini']
Python: Remove mypy error in Transform (#4728),2,25,2022-05-09 19:09:06-07:00,"['transforms.py', 'tox.ini']"
Flink: Backport flaky test fix for limit 1 query in TestFlinkTableSource (#4724),2,34,2022-05-09 19:13:41-07:00,"['TestFlinkTableSource.java', 'TestFlinkTableSource.java']"
Flink 1.15: Migrate back to use ReusableArrayData (#4712),1,8,2022-05-09 19:16:43-07:00,['FlinkParquetReaders.java']
Spark 3.2: Remove Thread.sleep in TestRemoveOrphanFilesAction (#4711),1,36,2022-05-09 19:17:42-07:00,['TestRemoveOrphanFilesAction.java']
Python: test_schema_find_column_name was defined twice (#4729),1,2,2022-05-09 19:34:09-07:00,['test_schema.py']
"Spark: Support parallel clean up for abort (#4704)

Co-authored-by: xianyangliu <xianyangliu@tencent.com>",1,2,2022-05-10 13:16:22-07:00,['SparkWrite.java']
Spark: Allow use-caching to be disabled in RewriteManifestsProcedure (#4722),3,6,2022-05-10 16:34:03-07:00,"['RewriteManifestsProcedure.java', 'RewriteManifestsProcedure.java', 'RewriteManifestsProcedure.java']"
"API: Add expression sanitizer, sanitize scan log messages (#4672)",5,527,2022-05-12 12:09:24-07:00,"['ExpressionUtil.java', 'Expressions.java', 'TestExpressionUtil.java', 'BaseAllMetadataTableScan.java', 'BaseTableScan.java']"
[SPEC] Fix typ in REST Catalog OpenAPI Spec (#4761),1,2,2022-05-12 16:19:35-07:00,['rest-catalog-open-api.yaml']
Flink 1.15: Improve unit tests for sink (#4699),6,60,2022-05-13 09:03:19-07:00,"['SimpleDataUtil.java', 'TestFlinkIcebergSink.java', 'TestFlinkManifest.java', 'TestIcebergFilesCommitter.java', 'TestIcebergStreamWriter.java', 'TestTaskWriters.java']"
Flink 1.15: Call getCatalogTable directly (#4752),1,17,2022-05-13 09:07:43-07:00,['FlinkDynamicTableFactory.java']
ORC: Upgrade to 1.7.4 (#4573),2,13,2022-05-13 12:35:23-05:00,"['TestMetricsRowGroupFilter.java', 'versions.props']"
Core: Optimize when not deleting oldest metadata files after commit (#4651),2,10,2022-05-13 10:51:16-07:00,"['BaseMetastoreTableOperations.java', 'HadoopTableOperations.java']"
API: Introduce a new IncrementalAppendScan interface (#4580),4,291,2022-05-13 12:55:57-07:00,"['IncrementalAppendScan.java', 'Scan.java', 'Table.java', 'TableScan.java']"
Spark 3.2: Avoid reflection to load metadata tables in SparkTableUtil (#4758),2,77,2022-05-13 13:09:58-07:00,"['Spark3Util.java', 'SparkTableUtil.java']"
Python: Add VoidTransform (#4727),2,46,2022-05-13 15:59:36-07:00,"['transforms.py', 'test_transforms.py']"
Python: Add spellcheck to the CI (#4730),9,66,2022-05-13 16:09:03-07:00,"['.rat-excludes', 'spellcheck-dictionary.txt', 'conversions.py', 'pyarrow.py', 'schema.py', 'partitioning.py', 'types.py', 'test_schema.py', 'tox.ini']"
Python: Add visitor to build Accessor for a Schema (#4685),5,288,2022-05-13 16:23:53-07:00,"['base.py', 'files.py', 'schema.py', 'conftest.py', 'test_schema.py']"
Spark 3.2: Clean static vars in SparkTableUtil (#4765),1,16,2022-05-13 17:00:09-07:00,['SparkTableUtil.java']
Core: Align snapshot summary property names for delete files (#4766),1,8,2022-05-13 19:09:40-07:00,['SnapshotSummary.java']
Build: Add binary compatibility checks via revapi gradle plugin  (#4638),3,6,2022-05-14 11:33:50-07:00,"['revapi.yml', 'build.gradle', '.rat-excludes']"
Core: Accept all API changes in master (#4770),1,85,2022-05-15 12:21:59-07:00,['revapi.yml']
Docs: Updated version support description for Flink (#4756),1,3,2022-05-16 20:07:46+08:00,['flink-getting-started.md']
"Remove redundant assignment (#4755)

`refresh()` updates `this.base`.",1,2,2022-05-16 11:09:08-07:00,['SnapshotProducer.java']
Core: Add content and delete file counts to manifest tables (#4764),6,205,2022-05-16 11:10:02-07:00,"['AllManifestsTable.java', 'ManifestsTable.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java']"
API: Add SessionCatalog interface and base class (#4773),2,486,2022-05-16 18:52:05-07:00,"['SessionCatalog.java', 'BaseSessionCatalog.java']"
Fix typo in revapi.yml (#4778),1,44,2022-05-17 14:18:07+02:00,['revapi.yml']
"Spec: Clarify manifest length is size in bytes, fix a typo (#4793)",1,4,2022-05-17 09:34:51-07:00,['spec.md']
Flink: Port #4752 to Flink 1.14 & 1.13 (#4789),2,34,2022-05-17 09:41:35-07:00,"['FlinkDynamicTableFactory.java', 'FlinkDynamicTableFactory.java']"
Docs: Add zstd for Avro to configuration page (#4790),1,2,2022-05-17 09:42:30-07:00,['configuration.md']
Flink: Fix comment in BaseDeltaTaskWriter.java (#4788),3,6,2022-05-17 09:43:16-07:00,"['BaseDeltaTaskWriter.java', 'BaseDeltaTaskWriter.java', 'BaseDeltaTaskWriter.java']"
"Core: Add OAuth2 to REST catalog spec (#4771)

* Core: Add OAuth2 to REST catalog spec.

* Fix OAuth2 requests and responses.

* Add descriptions for token params.

* Core: Add support for form encoding to RESTClient.

* Clarify OAuth2 getToken response fields.

* Rename route to use a plural.

* Ensure headers are always added in HTTPClient.

* Add JWT token type.

* Refactor OAuth in OpenAPI doc.",7,275,2022-05-17 10:42:12-07:00,"['HTTPClient.java', 'RESTClient.java', 'RESTUtil.java', 'RESTCatalogAdapter.java', 'TestRESTCatalog.java', 'TestRESTUtil.java', 'rest-catalog-open-api.yaml']"
"Python: Test for warning of PyLint (#4791)

* Python: Test for warning of PyLint

* Add ignore rule for overriding constructor",15,763,2022-05-17 12:45:56-07:00,"['pylintrc', 'conversions.py', 'base.py', 'literals.py', 'pyarrow.py', 'schema.py', 'transforms.py', 'types.py', 'test_expressions_base.py', 'test_literals.py', 'test_conversions.py', 'test_schema.py', 'test_transforms.py', 'test_types.py', 'tox.ini']"
Spec: Add note about reserved field id 141 in manifests (#4750),1,1,2022-05-17 13:04:49-07:00,['spec.md']
"Change types into dataclasses (#4767)

* Change types into dataclasses

Proposal to change the types into dataclasses.

This has several improvments:

- We can use the dataclasss field(repr=True) to include the fields in the representation, instead of building our own strings
- We can assign the types in the post_init when they are dynamic (List, Maps, Structs etc) , or just override them when they are static (Primitives)
- We don't have to implement any eq methods because they come for free
- The types are frozen, which is kind of nice since we re-use them
- The code is much more consise
- We can assign the min/max of the int/long/float as Final as of 3.8: https://peps.python.org/pep-0591/

My inspiration was the comment by Kyle:
https://github.com/apache/iceberg/pull/4742#discussion_r869494393

This would entail implementing eq, but why not use the generated one since we're comparing all the attributes :)

Would love to get you input

* Remove explicit repr and eq

* Use @cached_property to cache the string

Add missing words to spelling

* Add additional guard for initializing StructType using kwargs

* Replace type with field_type",6,427,2022-05-17 13:18:37-07:00,"['setup.cfg', 'spellcheck-dictionary.txt', 'schema.py', 'types.py', 'test_schema.py', 'test_types.py']"
"Core: Allow controlling table properties through catalog config (#4011)

Co-authored-by: Rajarshi Sarkar <srajars@amazon.com>",11,264,2022-05-17 15:51:25-07:00,"['TestGlueCatalogTable.java', 'GlueCatalog.java', 'TestGlueCatalog.java', 'BaseMetastoreCatalog.java', 'CatalogProperties.java', 'HadoopCatalog.java', 'PropertyUtil.java', 'HadoopTableTestBase.java', 'TestHadoopCatalog.java', 'HiveCatalog.java', 'TestHiveCatalog.java']"
Core: Add request headers to REST client. (#4772),8,206,2022-05-17 17:18:28-07:00,"['HTTPClient.java', 'RESTCatalog.java', 'RESTClient.java', 'RESTTableOperations.java', 'ResourcePaths.java', 'RESTCatalogAdapter.java', 'TestHTTPClient.java', 'TestRESTCatalog.java']"
Python - Add pyline disable super-init-not-called for one line (#4797),1,2,2022-05-17 17:53:14-07:00,['types.py']
Core: Use ImmutableMap for catalog properties (#4803),4,46,2022-05-18 08:28:02-07:00,"['GlueCatalog.java', 'BaseMetastoreCatalog.java', 'HadoopCatalog.java', 'HiveCatalog.java']"
Flink: Support hadoop-conf-dir for hdfs-site.xml and core-site.xml (#4622),1,15,2022-05-18 09:03:44-07:00,['FlinkCatalogFactory.java']
Python: Set Python 3.8 as minimum version (#4784),7,54,2022-05-18 10:10:15-07:00,"['python-ci.yml', '.python-version', 'setup.cfg', 'literals.py', 'schema.py', 'types.py', 'tox.ini']"
Python legacy: Use process pool for planning (#4745),1,2,2022-05-18 10:16:39-07:00,['data_table_scan.py']
Build: Update release scripts publish Spark 3.2 with Scala 2.13 (#4167),1,7,2022-05-18 14:50:33-07:00,['stage-binaries.sh']
Spark 3.2: Add positiol and equality delete file count to ExpireSnapshot results (#4629),10,336,2022-05-18 16:52:56-07:00,"['revapi.yml', 'ManifestContent.java', 'ExpireSnapshots.java', 'BaseExpireSnapshotsActionResult.java', 'TestExpireSnapshotsProcedure.java', 'BaseExpireSnapshotsSparkAction.java', 'BaseSparkAction.java', 'ManifestFileBean.java', 'ExpireSnapshotsProcedure.java', 'TestExpireSnapshotsAction.java']"
"Python: Fix the type_string of the NestedField (#4814)

If there is a doc, the rest gets ignored, which is kind of awkward.

Before:
```python
  python git:(master)  python3
Python 3.9.12 (main, Mar 26 2022, 15:44:31)
[Clang 13.1.6 (clang-1316.0.21.2)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> from iceberg.types import NestedField, LongType
>>> str(NestedField(
...     field_id=2,
...     name='bar',
...     field_type=LongType(),
...     is_optional=False,
...     doc=""Just a long""
... ))
'2: bar: required long'
>>> str(NestedField(
...     field_id=2,
...     name='bar',
...     field_type=LongType(),
...     is_optional=False,
...     doc=""Just a long""
... ))
' (Just a long)'
```

Now:
```python
  python git:(master)  python3
Python 3.9.12 (main, Mar 26 2022, 15:44:31)
[Clang 13.1.6 (clang-1316.0.21.2)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> str(NestedField(
...     field_id=2,
...     name='bar',
...     field_type=LongType(),
...     is_optional=False,
...     doc=""Just a long""
... ))
'2: bar: required long (Just a long)'
```",1,16,2022-05-20 08:53:18-07:00,['types.py']
AWS: handle Glue exceptions as iceberg errors instead of commit state unknown (#4821),2,88,2022-05-20 14:44:16-07:00,"['TestGlueCatalogCommitFailure.java', 'GlueTableOperations.java']"
AWS: support Path-Style Access (#4823),2,39,2022-05-21 12:19:42-07:00,"['AwsClientFactories.java', 'AwsProperties.java']"
Add project method to IcebergGenerics to enable projections by Schema (#4819),3,61,2022-05-23 11:50:13+02:00,"['IcebergGenerics.java', 'TestLocalScan.java', 'OrcValueReaders.java']"
"Spark: Handle CommitStateUnknown exception in RewriteManifestSparkAction (#4836)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",2,73,2022-05-23 10:39:42-07:00,"['BaseRewriteManifestsSparkAction.java', 'TestRewriteManifestsAction.java']"
Spec: Add more context about OAuth2 to the REST spec (#4843),1,41,2022-05-23 14:14:33-07:00,['rest-catalog-open-api.yaml']
Core: Add OAuth2 helpers for REST catalog (#4833),9,655,2022-05-23 14:50:12-07:00,"['RESTSerializers.java', 'ResourcePaths.java', 'OAuth2Properties.java', 'OAuth2Util.java', 'OAuthTokenResponse.java', 'RESTCatalogAdapter.java', 'RequestResponseTestBase.java', 'TestOAuth2Util.java', 'TestOAuthTokenResponse.java']"
Core: Add serialization for MetadataUpdate (#4716),6,714,2022-05-23 14:58:05-07:00,"['MetadataUpdate.java', 'MetadataUpdateParser.java', 'SnapshotParser.java', 'JsonUtil.java', 'TestMetadataUpdateParser.java', 'rest-catalog-open-api.yaml']"
Core: Remove Authorization header handling from HTTPClient (#4832),4,81,2022-05-23 14:59:36-07:00,"['HTTPClient.java', 'HTTPClientFactory.java', 'TestHTTPClient.java', 'TestRESTCatalog.java']"
API: Update SessionCatalog context to use a credentials map (#4845),1,13,2022-05-23 16:35:27-07:00,['SessionCatalog.java']
Core: Refactor REST catalog to RESTSessionCatalog (#4846),5,238,2022-05-23 16:36:15-07:00,"['HTTPClientFactory.java', 'RESTClient.java', 'RESTSessionCatalog.java', 'RESTTableOperations.java', 'TestRESTCatalog.java']"
"Spark: Backport CommitStateUnknownException handling for RewriteManifestSparkAction (#4850)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",6,219,2022-05-24 07:56:55-07:00,"['BaseRewriteManifestsSparkAction.java', 'TestRewriteManifestsAction.java', 'BaseRewriteManifestsSparkAction.java', 'TestRewriteManifestsAction.java', 'BaseRewriteManifestsSparkAction.java', 'TestRewriteManifestsAction.java']"
Docs : add AWS S3 access-point documentation (#4391),1,24,2022-05-24 08:09:37-07:00,['aws.md']
Docs: Add S3 delete tagging docs (#4443),1,24,2022-05-24 08:11:22-07:00,['aws.md']
Fix snapshot release publishing (#4838),1,2,2022-05-24 13:02:55-07:00,['publish-snapshot.yml']
ORC: Suppress JavaLocalDateTimeGetNano warning (#4861),1,2,2022-05-24 21:45:03-07:00,['GenericOrcWriters.java']
AWS: Fix tests failure in TestGlueCatalogCommitFailure (#4857),1,6,2022-05-24 21:45:56-07:00,['TestGlueCatalogCommitFailure.java']
AWS: Use strongly consistent read in DDBLockManager (#4763),1,1,2022-05-24 22:19:14-07:00,['DynamoDbLockManager.java']
Core: Use shared worker thread pool for abort and clean-up (#4799),8,16,2022-05-24 23:06:27-07:00,"['CatalogUtil.java', 'HadoopTableOperations.java', 'BaseTaskWriter.java', 'HiveIcebergRecordWriter.java', 'SparkTableUtil.java', 'BaseRewriteManifestsSparkAction.java', 'SparkPositionDeltaWrite.java', 'SparkWrite.java']"
Core: Add session catalog implementation for REST (#4830),10,1378,2022-05-25 09:02:13-07:00,"['baseline.gradle', 'RESTCatalog.java', 'RESTCatalogProperties.java', 'RESTSessionCatalog.java', 'RESTUtil.java', 'OAuth2Properties.java', 'OAuth2Util.java', 'ThreadPools.java', 'RESTCatalogAdapter.java', 'TestRESTCatalog.java']"
"Spark: Fix Alignment of Merge Commands with Mixed Case (#4848)

* Spark: Fix Alignment of Merge Commands with Mixed Case

Prior to this a mixed-case insert statement would fail to be marked
as aligned after our alignment rule was applied. This would then fail the
entire MERGE INTO command. The commands were correctly aligned but
our alignment check was always case sensitive.",4,75,2022-05-25 15:36:47-07:00,"['IcebergSparkSessionExtensions.scala', 'AlignedRowLevelIcebergCommandCheck.scala', 'AssignmentUtils.scala', 'TestMerge.java']"
Docs: Use 'execution.runtime-mode' in flink SQL client. (#4644),1,8,2022-05-26 10:29:41+08:00,['flink-getting-started.md']
API: Pass FileIO into Snapshot methods that read metadata (#4873),79,1503,2022-05-26 07:56:50-07:00,"['revapi.yml', 'Snapshot.java', 'TestGlueCatalogLock.java', 'AllDataFilesTable.java', 'AllDeleteFilesTable.java', 'AllEntriesTable.java', 'AllFilesTable.java', 'AllManifestsTable.java', 'BaseRewriteManifests.java', 'BaseSnapshot.java', 'BaseTransaction.java', 'CatalogUtil.java', 'CherryPickOperation.java', 'DataFilesTable.java', 'DataTableScan.java', 'DeleteFilesTable.java', 'FastAppend.java', 'FilesTable.java', 'FindFiles.java', 'IncrementalDataTableScan.java', 'ManifestEntriesTable.java', 'ManifestsTable.java', 'MergingSnapshotProducer.java', 'MicroBatches.java', 'PartitionsTable.java', 'RemoveSnapshots.java', 'ScanSummary.java', 'SnapshotProducer.java', 'SnapshotUtil.java', 'TableTestBase.java', 'TestDeleteFileIndex.java', 'TestDeleteFiles.java', 'TestEntriesMetadataTable.java', 'TestFastAppend.java', 'TestManifestCleanup.java', 'TestMergeAppend.java', 'TestMetadataTableFilters.java', 'TestOverwrite.java', 'TestRemoveSnapshots.java', 'TestReplacePartitions.java', 'TestRewriteFiles.java', 'TestRewriteManifests.java', 'TestRowDelta.java', 'TestSequenceNumberForV2Table.java', 'TestSnapshot.java', 'TestSnapshotJson.java', 'TestSnapshotSelection.java', 'TestTableMetadata.java', 'TestTimestampPartitions.java', 'TestTransaction.java', 'TestV1ToV2RowDeltaDelete.java', 'TestWapWorkflow.java', 'TestCatalogUtilDropTable.java', 'TestHadoopCommits.java', 'TestJdbcTableConcurrency.java', 'TestChangeLogTable.java', 'TestFlinkIcebergSinkV2.java', 'HiveCreateReplaceTableTest.java', 'HiveTableTest.java', 'TestHiveTableConcurrency.java', 'TestNessieTable.java', 'TestMerge.java', 'TestRewriteManifestsProcedure.java', 'TestUpdate.java', 'IcebergSourceParquetMultiDeleteFileBenchmark.java', 'IcebergSourceParquetPosDeleteBenchmark.java', 'IcebergSourceParquetWithUnrelatedDeleteBenchmark.java', 'BaseRewriteManifestsSparkAction.java', 'SparkMicroBatchStream.java', 'TestExpireSnapshotsAction.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'TestHelpers.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestIcebergSourceTablesBase.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestRefreshTable.java']"
Docs: Set table comment using `SET TBLPROPERTIES` (#4645),1,8,2022-05-26 15:18:46-07:00,['spark-ddl.md']
"Core: Use UnboundSortOrder, UnboundPartitionSpec in CreateTableRequest (#4880)",2,16,2022-05-26 19:29:12-07:00,"['SortOrder.java', 'CreateTableRequest.java']"
"Core: Add RemoveSnapshotRef to MetadataUpdateParser and REST spec (#4866)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",4,70,2022-05-26 19:34:14-07:00,"['MetadataUpdate.java', 'MetadataUpdateParser.java', 'TestMetadataUpdateParser.java', 'rest-catalog-open-api.yaml']"
"Spark, Flink: Pass FileIO into Snapshot methods that read metadata, backports (#4877)",28,296,2022-05-26 19:51:49-07:00,"['TestChangeLogTable.java', 'TestFlinkIcebergSinkV2.java', 'TestChangeLogTable.java', 'TestFlinkIcebergSinkV2.java', 'TestRewriteManifestsProcedure.java', 'BaseRewriteManifestsSparkAction.java', 'SparkMicroBatchStream.java', 'TestExpireSnapshotsAction.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestIcebergSourceTablesBase.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestRefreshTable.java', 'TestRewriteManifestsProcedure.java', 'BaseRewriteManifestsSparkAction.java', 'SparkMicroBatchStream.java', 'TestExpireSnapshotsAction.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestIcebergSourceTablesBase.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestRefreshTable.java']"
Docs: Add StarRocks to Documentation (#4774),1,23,2022-05-27 11:54:04+08:00,['_index.md']
API: Avoid unnecessary boxing in equality check in SnapshotRef (#4878),1,2,2022-05-26 23:26:35-07:00,['SnapshotRef.java']
Fix typo in spec page (#4882),1,2,2022-05-27 10:42:02+02:00,['spec.md']
Spark: Fix flaky time dependent test for remove orphan files (#4859),1,2,2022-05-27 08:01:46-07:00,['TestRemoveOrphanFilesAction.java']
"Flink: Use local FS paths in tests (#4853)

Co-authored-by:  <wuwenchi@deepexi.com>",3,24,2022-05-27 09:23:43-07:00,"['TestFlinkCatalogTable.java', 'TestFlinkCatalogTable.java', 'TestFlinkCatalogTable.java']"
Core: Add round-trip serialization to RESTCatalog tests (#4881),3,50,2022-05-27 10:04:51-07:00,"['TableMetadata.java', 'CatalogHandlers.java', 'TestRESTCatalog.java']"
"Core: Update caffeine 2.9.3, the latest 2.x release (#3803)",1,2,2022-05-27 10:13:32-07:00,['versions.props']
Python: Add BooleanExpressionVisitor and visit method (#4815),3,214,2022-05-27 11:17:55-07:00,"['spellcheck-dictionary.txt', 'base.py', 'test_expressions_base.py']"
Python: Add Catalog abstract base class (#3245) (#4706),7,738,2022-05-27 12:23:07-07:00,"['spellcheck-dictionary.txt', 'base.py', 'exceptions.py', 'base.py', '__init__.py', 'test_base.py', 'conftest.py']"
Core: Implement IncrementalAppendScan (#4744),15,1092,2022-05-27 12:56:11-07:00,"['revapi.yml', 'Scan.java', 'TableScan.java', 'IncrementalScanEvent.java', 'TestHelpers.java', 'BaseIncrementalAppendScan.java', 'BaseScan.java', 'BaseTable.java', 'BaseTableScan.java', 'IncrementalDataTableScan.java', 'TableScanContext.java', 'SnapshotUtil.java', 'ScanTestBase.java', 'TestBaseIncrementalAppendScan.java', 'TestDataTableScan.java']"
Core: Support _deleted metadata column in non-vectorized reads (#4683),8,506,2022-05-27 14:03:01-07:00,"['TestHelpers.java', 'Deletes.java', 'TestPositionFilter.java', 'DeleteFilter.java', 'IcebergSourceDeleteBenchmark.java', 'RowDataReader.java', 'SparkTable.java', 'TestSparkReaderDeletes.java']"
Build: Add a workflow for API binary compatibility checks (#4798),1,55,2022-05-29 10:01:27-07:00,['api-binary-compatibility.yml']
Core: Add REST catalog session timeout (#4894),4,51,2022-05-29 13:35:06-07:00,"['CatalogProperties.java', 'RESTSessionCatalog.java', 'OAuth2Properties.java', 'OAuth2Util.java']"
"OpenAPI: Reorder nested types, put type before required (#4891)",1,18,2022-05-29 13:37:24-07:00,['rest-catalog-open-api.yaml']
"Spark: Add commit state unknown handling to SparkPositionDeltaWrite (#4800)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",3,103,2022-05-29 13:42:18-07:00,"['TestMergeOnReadDelete.java', 'SparkPositionDeltaWrite.java', 'TestSparkCatalog.java']"
Spec: Make the type of a StructType required (#4892),1,1,2022-05-29 13:43:26-07:00,['rest-catalog-open-api.yaml']
Build: Upgrade github actions (#4851),10,146,2022-05-29 14:13:35-07:00,"['flink-ci.yml', 'hive-ci.yml', 'java-ci.yml', 'jmh-bechmarks.yml', 'labeler.yml', 'license_check.yml', 'publish-snapshot.yml', 'python-ci.yml', 'python-legacy-ci.yml', 'spark-ci.yml']"
Parquet: Support reading binary as string for old Parquet writers (#4841),1,6,2022-05-29 14:16:05-07:00,['BaseParquetReaders.java']
Python: Convert Avro to Iceberg schema (#4742),6,903,2022-05-29 14:39:05-07:00,"['spellcheck-dictionary.txt', 'schema.py', 'types.py', 'schema_conversion.py', 'conftest.py', 'test_schema_conversion.py']"
"Docs: Fix a typo, add using for writeTo when creating a table (#4885)",2,9,2022-05-29 15:25:49-07:00,"['spark-ddl.md', 'spark-writes.md']"
OpenAPI: Move to oneOf for types (#4899),1,2,2022-05-30 07:46:24-07:00,['rest-catalog-open-api.yaml']
Core: Update catalog tests for flexibility and consistency (#4897),2,30,2022-05-30 07:50:13-07:00,"['CatalogHandlers.java', 'CatalogTests.java']"
Flink: Add option to set monitorInterval (#4887),3,18,2022-05-30 08:44:22-07:00,"['FlinkSource.java', 'FlinkSource.java', 'FlinkSource.java']"
Core: Implement namespace listing with a parent in REST catalog (#4907),7,339,2022-05-30 15:01:55-07:00,"['HTTPClient.java', 'RESTClient.java', 'RESTSessionCatalog.java', 'CatalogTests.java', 'TestJdbcCatalog.java', 'RESTCatalogAdapter.java', 'TestRESTCatalog.java']"
Core: Add more options in CatalogTests (#4906),1,28,2022-05-30 15:02:48-07:00,['CatalogTests.java']
ORC: Use the built-in estimate memory method (#4734),1,16,2022-05-31 23:04:34+08:00,['OrcFileAppender.java']
API: Add CredentialSupplier to get credentials from FileIO. (#4895),2,50,2022-05-31 11:14:43-07:00,"['CredentialSupplier.java', 'S3FileIO.java']"
Python: Replace tox with pre-commit (#4811),22,399,2022-05-31 15:03:02-07:00,"['python-ci.yml', '.gitignore', 'CONTRIBUTING.md', '.pre-commit-config.yaml', 'CONTRIBUTING.md', 'Makefile', 'README.md', 'pyproject.toml', 'setup.cfg', 'spellcheck-dictionary.txt', '__init__.py', 'base.py', 'pyarrow.py', 'schema.py', 'base.py', 'types.py', 'schema_conversion.py', 'test_base.py', '__init__.py', 'test_io_base.py', 'test_pyarrow.py', 'tox.ini']"
"Dev: Release Script Fix Key Arg (#4919)

Default release repo is apache
Use keyId when passed in release script",1,4,2022-05-31 17:06:49-05:00,['source-release.sh']
Core: Follow-up to IncrementalAppendScan implementation (#4886),8,102,2022-05-31 18:06:31-07:00,"['BaseIncrementalAppendScan.java', 'BaseScan.java', 'BaseTableScan.java', 'DataTableScan.java', 'IncrementalDataTableScan.java', 'TableScanContext.java', 'SnapshotUtil.java', 'TestIncrementalDataTableScan.java']"
"Python: Remove typing extension imports (#4917)

This is a Python 3.7 relic",2,16,2022-06-02 08:57:10-07:00,"['files.py', 'base.py']"
"Spark: Provide Procedure for Catalog Register Procedure (#4810)

* Spark: Provide Procedure for Catalog Register Procedure

Adds the ability to invoke a Catalog's register method via a Spark
procedure. This allows a user to create a catalog entry for a metadata.json
file which already exists but does not have a corresponding catalog identifier.",11,278,2022-06-03 08:09:44-05:00,"['CachingCatalog.java', 'TestRegisterTableProcedure.java', 'BaseCatalog.java', 'Spark3Util.java', 'SparkCatalog.java', 'SparkSessionCatalog.java', 'RegisterTableProcedure.java', 'SparkProcedures.java', 'HasIcebergCatalog.java', 'TestSpark3Util.java', 'version.txt']"
"Remove version.txt from master (#4955)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",1,1,2022-06-03 09:23:39-05:00,['version.txt']
Core: Support metadata table loading in the REST catalog. (#4950),4,55,2022-06-03 08:36:55-07:00,"['BaseMetadataTable.java', 'CatalogHandlers.java', 'RESTSessionCatalog.java', 'CatalogTests.java']"
"Python: Bump pre-commit hooks (#4934)

More as an example, since nothing really changed in the lint tools.

Using pre-commit you can easily bump the integrations to the latest
version using `pre-commit autoupdate`.

```bash
  python git:(master) pre-commit autoupdate
Updating https://github.com/pre-commit/pre-commit-hooks ... already up to date.
Updating https://github.com/ambv/black ... already up to date.
Updating https://github.com/pre-commit/mirrors-isort ... already up to date.
Updating https://github.com/pre-commit/mirrors-mypy ... updating v0.950 -> v0.960.
Updating https://github.com/hadialqattan/pycln ... updating v1.3.2 -> v1.3.3.
```",2,6,2022-06-03 15:21:33-07:00,"['.pre-commit-config.yaml', 'CONTRIBUTING.md']"
"Use CatalogUtil classloader instead of context classloader for FileIO (#4957)

* Use CatalogUtil classloader instead of context classloader for FileIO

* Use AwsClientFactories classloader for loading custom client factory

* Set classloader for S3FileIO metrics dynamic loading",3,17,2022-06-03 15:48:47-07:00,"['AwsClientFactories.java', 'S3FileIO.java', 'CatalogUtil.java']"
API: Add expression equivalence testing (#4947),14,386,2022-06-03 16:13:12-07:00,"['And.java', 'BoundLiteralPredicate.java', 'BoundReference.java', 'BoundSetPredicate.java', 'BoundTerm.java', 'BoundTransform.java', 'BoundUnaryPredicate.java', 'Expression.java', 'ExpressionUtil.java', 'False.java', 'Or.java', 'True.java', 'UnboundPredicate.java', 'TestExpressionUtil.java']"
Core: Fix token refresh thread shutdown (#4958),1,1,2022-06-05 10:52:51-07:00,['RESTSessionCatalog.java']
Docs: Fix broken link to expiration properties (#4939),1,2,2022-06-05 11:13:02-07:00,['spark-procedures.md']
Python: Use struct constant to improve pack/unpack performance (#4929),1,35,2022-06-05 11:15:15-07:00,['conversions.py']
Python: Add pyupgrade as a pre-commit hook (#4935),7,190,2022-06-05 11:17:16-07:00,"['.pre-commit-config.yaml', 'base.py', 'schema.py', 'base.py', 'transforms.py', 'types.py', 'schema_conversion.py']"
Spec: Clarify truncate transform for strings is based on code points (#4937),1,3,2022-06-05 11:21:34-07:00,['spec.md']
Spark: Use original option keys in SparkCatalog (#4903),1,3,2022-06-05 16:14:48-07:00,['SparkCatalog.java']
Python: Add Poetry build and release instructions (#4844),9,934,2022-06-06 10:22:49-07:00,"['python-ci.yml', '.pre-commit-config.yaml', 'CONTRIBUTING.md', 'Makefile', 'README.md', 'RELEASE.md', 'poetry.lock', 'pyproject.toml', 'setup.cfg']"
Python: Add more tests for schema_conversion (#4972),2,140,2022-06-06 10:26:24-07:00,"['schema_conversion.py', 'test_schema_conversion.py']"
Python: Decimal is actually DecimalType (#4967),1,6,2022-06-06 10:26:47-07:00,['conversions.py']
"API: Fix revapi failure, allow BoudnTerm.isEquivalentTo (#4965)",1,3,2022-06-06 10:31:09-07:00,['revapi.yml']
Python: Disable autouse of fixtures (#4964),1,6,2022-06-06 10:32:03-07:00,['conftest.py']
"Spark: Add CommitMetadata class to pass additional snapshot properties (#4956)

This is needed because Spark cannot pass additional metadata for some operations.",10,326,2022-06-06 15:48:15-07:00,"['CommitMetadata.java', 'SparkWrite.java', 'TestDataSourceOptions.java', 'CommitMetadata.java', 'SparkWrite.java', 'TestDataSourceOptions.java', 'CommitMetadata.java', 'SparkPositionDeltaWrite.java', 'SparkWrite.java', 'TestDataSourceOptions.java']"
Flink: FLIP-27 source enumerator help classes (#4329),12,1456,2022-06-06 15:53:42-07:00,"['FlinkSplitPlanner.java', 'ScanContext.java', 'StreamingStartingStrategy.java', 'ContinuousEnumerationResult.java', 'ContinuousSplitPlanner.java', 'ContinuousSplitPlannerImpl.java', 'IcebergEnumeratorPosition.java', 'HadoopTableResource.java', 'TestFlinkScan.java', 'ManualContinuousSplitPlanner.java', 'TestContinuousSplitPlannerImpl.java', 'TestContinuousSplitPlannerImplStartStrategy.java']"
"Spec: Add Puffin, a file format for stats and indexes (#4944)",1,144,2022-06-06 15:58:31-07:00,['puffin-spec.md']
Flink 1.15: Port PR #4329 to add FLIP-27 enumerator classes (#4979),12,1456,2022-06-06 17:20:01-07:00,"['FlinkSplitPlanner.java', 'ScanContext.java', 'StreamingStartingStrategy.java', 'ContinuousEnumerationResult.java', 'ContinuousSplitPlanner.java', 'ContinuousSplitPlannerImpl.java', 'IcebergEnumeratorPosition.java', 'HadoopTableResource.java', 'TestFlinkScan.java', 'ManualContinuousSplitPlanner.java', 'TestContinuousSplitPlannerImpl.java', 'TestContinuousSplitPlannerImplStartStrategy.java']"
Spark 3.2: Use SnapshotSummary to deduce latestOffset (#4517),1,10,2022-06-07 08:47:24-07:00,['SparkMicroBatchStream.java']
Doc: Fix UnescapedEntity HTML javadoc warning (#4987),1,4,2022-06-07 13:13:37-07:00,['IdToOrcName.java']
Checkstyle: fix reference of non canonical subclass (#4990),1,2,2022-06-07 15:13:15-07:00,['BasePageIterator.java']
"Core, Spec: Update REST namespace separator to unit separator, 0x1F (#4975)",11,60,2022-06-08 12:33:58-07:00,"['TableIdentifierParser.java', 'RESTSessionCatalog.java', 'RESTUtil.java', 'RESTCatalogAdapter.java', 'TestRESTUtil.java', 'TestResourcePaths.java', 'TestCreateNamespaceRequest.java', 'TestCreateNamespaceResponse.java', 'TestGetNamespaceResponse.java', 'TestListTablesResponse.java', 'rest-catalog-open-api.yaml']"
Core: Replace unnecessary hash uses with hashCode (#4953),3,6,2022-06-08 13:04:57-07:00,"['CharSequenceSet.java', 'MappedFields.java', 'StructLikeSet.java']"
Build: Fix API compatibility Github Action (#4989),1,20,2022-06-08 16:49:14-07:00,['api-binary-compatibility.yml']
Python: Add Poetry IDEA instructions (#4980),1,16,2022-06-09 08:52:57-07:00,['CONTRIBUTING.md']
"Python: Change Python API naming to the spec (#4992)

See https://github.com/apache/iceberg/issues/4985",8,354,2022-06-09 09:02:21-07:00,"['schema.py', 'types.py', 'schema_conversion.py', 'conftest.py', 'test_expressions_base.py', 'test_schema.py', 'test_types.py', 'test_schema_conversion.py']"
Flink: Reduce the scope and duration of holding checkpoint lock in the read path (#4911),3,54,2022-06-10 16:44:02-07:00,"['StreamingMonitorFunction.java', 'StreamingMonitorFunction.java', 'StreamingMonitorFunction.java']"
Core: Resolve environment variables in REST catalog config (#5018),3,119,2022-06-12 08:43:40-07:00,"['RESTSessionCatalog.java', 'EnvironmentUtil.java', 'TestEnvironmentUtil.java']"
Spark: Fix flaky testOlderThanTimestamp in TestRemoveOrphanFilesAction3 (#4825),1,2,2022-06-12 12:49:41-07:00,['TestRemoveOrphanFilesAction.java']
Python: Extend the use of the Singleton (#5008),6,167,2022-06-12 12:58:40-07:00,"['base.py', 'literals.py', 'types.py', 'singleton.py', 'test_expressions_base.py', 'test_types.py']"
"Python: Add PartitionSpec (#4717)

Co-authored-by: Fokko Driesprong <fokko@apache.org>
Co-authored-by: Steve Zhang <hongyue_zhang@apple.com>",3,148,2022-06-12 13:55:57-07:00,"['spellcheck-dictionary.txt', 'partitioning.py', 'test_partitioning.py']"
Core: Rename JDBC namespace property column to non-keyword (#5017),1,6,2022-06-12 15:55:39-07:00,['JdbcUtil.java']
Docs: Restore Iceberg logo in README (#5016),1,2,2022-06-12 16:21:11-07:00,['README.md']
"Parquet: Fix NPE in logical type handling (#4999)

Co-authored-by: xianyangliu <xianyangliu@tencent.com>",2,46,2022-06-12 16:25:24-07:00,"['PruneColumns.java', 'TestPruneColumns.java']"
Core: Improve refresh executor shutdown in REST catalog close (#4991),2,17,2022-06-12 16:28:25-07:00,"['RESTSessionCatalog.java', 'OAuth2Util.java']"
"Parquet: Support row group bloom filters (#4938)

Co-authored-by: Xi Chen <jshmchenxi@163.com>
Co-authored-by: Hao Lin <linhao1990@gmail.com>",7,1416,2022-06-12 19:12:14-07:00,"['Binder.java', 'TableProperties.java', 'Parquet.java', 'ParquetBloomRowGroupFilter.java', 'ParquetUtil.java', 'ReadConf.java', 'TestBloomRowGroupFilter.java']"
"Docs: Fix copy paste: s/parquet/avro/ (#5020)

I think we forgot to update the home page from the Parquet block.",1,2,2022-06-13 12:12:17-07:00,['LICENSE']
Python: Add identity transform (#4908),3,163,2022-06-13 13:15:29-07:00,"['transforms.py', 'datetime.py', 'test_transforms.py']"
"Core: Enforce close for in-memory files (#5019)

The in-memory `InputFile` and `OutputFile` implementations has an
undesirable property that returned streams allowed use after close.
Since most streams don't have such property, it should be disallowed
here too.",4,106,2022-06-13 20:22:36-07:00,"['InMemoryInputFile.java', 'InMemoryOutputFile.java', 'TestInMemoryInputFile.java', 'TestInMemoryOutputFile.java']"
"Build: Avoid running engine tests on LICENSE and NOTICE update (#5022)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",4,8,2022-06-13 20:23:08-07:00,"['flink-ci.yml', 'hive-ci.yml', 'java-ci.yml', 'spark-ci.yml']"
Core: Update ExpireSnapshots impl for branching and tagging (#4578),4,416,2022-06-14 07:42:12-07:00,"['RemoveSnapshots.java', 'TableMetadataParser.java', 'TableProperties.java', 'TestRemoveSnapshots.java']"
Nessie: Properly close all resources in NessieCatalog (#5047),2,15,2022-06-15 12:59:14-05:00,"['NessieCatalog.java', 'TestNessieCatalog.java']"
Core: Add reader and writer for Puffin index and stats format (#4537),26,1787,2022-06-15 11:01:12-07:00,"['build.gradle', 'GuavaClasses.java', 'IOUtil.java', 'Blob.java', 'BlobMetadata.java', 'FileMetadata.java', 'FileMetadataParser.java', 'Puffin.java', 'PuffinCompressionCodec.java', 'PuffinFormat.java', 'PuffinReader.java', 'PuffinWriter.java', 'StandardBlobTypes.java', 'StandardPuffinProperties.java', 'JsonUtil.java', 'TestIOUtil.java', 'PuffinFormatTestUtil.java', 'TestFileMetadataParser.java', 'TestPuffinFormat.java', 'TestPuffinReader.java', 'TestPuffinWriter.java', 'empty-puffin-uncompressed.bin', 'sample-metric-data-compressed-zstd.bin', 'sample-metric-data-uncompressed.bin', '.rat-excludes', 'versions.props']"
AWS: add skip name validation config for glue namespace and table (#5041),6,157,2022-06-15 13:41:08-07:00,"['AwsProperties.java', 'GlueCatalog.java', 'GlueTableOperations.java', 'IcebergToGlueConverter.java', 'TestIcebergToGlueConverter.java', 'aws.md']"
"Python: Don't use a metaclass for the Singleton (#5055)

Metaclasses in Python don't mix very well, and when they cause
conflicts then it breaks at initialization.
Example of metaclasses is the ABC, but also the Pydantic BaseModel.
I tried to circumvent this by extending the Singleton from ABC
but it is likely that we use different metaclasses in the future,
and then it will bring us sadness and misery.",5,31,2022-06-15 14:07:43-07:00,"['base.py', 'literals.py', 'types.py', 'singleton.py', 'test_expressions_base.py']"
"Core: In HadoopTableOperations, replace Util.getFs call with getFileSystem (#5062)",1,2,2022-06-16 14:13:35+02:00,['HadoopTableOperations.java']
Python: Add Flake8 for simple checks (#5073),5,23,2022-06-17 08:33:56-07:00,"['.pre-commit-config.yaml', 'test_expressions_base.py', 'test_io_base.py', 'test_conversions.py', 'test_schema.py']"
Flink: FLIP-27 source enumerator (#4986),9,901,2022-06-17 09:34:47-07:00,"['build.gradle', 'AbstractIcebergEnumerator.java', 'ContinuousIcebergEnumerator.java', 'IcebergEnumeratorPositionSerializer.java', 'IcebergEnumeratorState.java', 'IcebergEnumeratorStateSerializer.java', 'StaticIcebergEnumerator.java', 'TestContinuousIcebergEnumerator.java', 'TestIcebergEnumeratorStateSerializer.java']"
Puffin: Inline PuffinWriter.writeFully (#5088),1,8,2022-06-20 07:59:36-07:00,['PuffinWriter.java']
"Open-api: RenameTableRequest props are required (#5093)

Currently, the properties are optional, which doesn't really make sense.

Also, in the Java code it throws an exception:
https://github.com/apache/iceberg/blob/master/core/src/test/java/org/apache/iceberg/rest/requests/TestRenameTableRequest.java#L106-L121

Therefore I would suggest making those required in the spec as well",1,3,2022-06-20 08:33:05-07:00,['rest-catalog-open-api.yaml']
"Python: Add py.typed file for annotations (#5091)

https://blog.whtsky.me/tech/2021/dont-forget-py.typed-for-your-typed-python-package/",1,18,2022-06-20 08:35:32-07:00,['py.typed']
"Include actual class name in class mismatch exception (#5089)

* Remove redundant call to String.valueOf in format argument

* Remove redundant warning suppression

The unchecked code was removed in
9384bd6f91996986ff680c0bf5de17179ebd0a1f.

* Include actual class name in class mismatch exception

Include requested and actual class name in the exception message thrown
when `PartitionData` detects type mismatch.",1,5,2022-06-20 08:39:07-07:00,['PartitionData.java']
Fix type of fields list in Puffin (#5087),1,2,2022-06-20 08:44:28-07:00,['puffin-spec.md']
Python: Add Avro read path (#4920),31,3135,2022-06-20 08:47:41-07:00,"['.pre-commit-config.yaml', 'LICENSE', 'poetry.lock', 'pyproject.toml', 'spellcheck-dictionary.txt', '__init__.py', '__init__.py', 'bzip2.py', 'codec.py', 'deflate.py', 'snappy_codec.py', 'zstandard_codec.py', 'decoder.py', 'file.py', 'reader.py', 'files.py', 'base.py', 'memory.py', 'types.py', 'datetime.py', 'schema_conversion.py', 'singleton.py', '__init__.py', 'test_decoder.py', 'test_file.py', 'test_reader.py', 'conftest.py', '__init__.py', 'test_io_base.py', 'test_schema_conversion.py', 'test_singleton.py']"
"Flink: Port #4986, FLIP-27 source enumerator to 1.14 module (#5078)",11,905,2022-06-20 08:55:51-07:00,"['build.gradle', 'AbstractIcebergEnumerator.java', 'ContinuousIcebergEnumerator.java', 'IcebergEnumeratorPositionSerializer.java', 'IcebergEnumeratorState.java', 'IcebergEnumeratorStateSerializer.java', 'StaticIcebergEnumerator.java', 'TestContinuousIcebergEnumerator.java', 'TestIcebergEnumeratorStateSerializer.java', 'AbstractIcebergEnumerator.java', 'StaticIcebergEnumerator.java']"
"Core: Add Javadoc for LoadTableResponse, fix error prone warnings (#5053)",3,11,2022-06-20 11:54:45-07:00,"['RenameTableRequest.java', 'LoadTableResponse.java', 'OAuthTokenResponse.java']"
"Core: Add serialization tests for CreateTableRequest (#5052)

Co-authored-by: Prashant Singh <35593236+singhpk234@users.noreply.github.com>",2,296,2022-06-20 12:22:51-07:00,"['CreateTableRequest.java', 'TestCreateTableRequest.java']"
"Python: Bump pre-commit versions (#5074)

```
  python git:(fd-bump-pre-commit) pre-commit autoupdate
Updating https://github.com/pre-commit/pre-commit-hooks ... updating v4.2.0 -> v4.3.0.
Updating https://github.com/ambv/black ... already up to date.
Updating https://github.com/pre-commit/mirrors-isort ... already up to date.
Updating https://github.com/pre-commit/mirrors-mypy ... updating v0.960 -> v0.961.
Updating https://github.com/hadialqattan/pycln ... already up to date.
Updating https://github.com/asottile/pyupgrade ... updating v2.32.1 -> v2.34.0.
  python git:(fd-bump-pre-commit)  pre-commit run --all-files
trim trailing whitespace.................................................Passed
fix end of files.........................................................Passed
check docstring is first.................................................Passed
debug statements (python)................................................Passed
check yaml...............................................................Passed
check python ast.........................................................Passed
black....................................................................Passed
isort....................................................................Passed
mypy.....................................................................Passed
pycln....................................................................Passed
pyupgrade................................................................Passed
```",1,6,2022-06-20 15:39:26-07:00,['.pre-commit-config.yaml']
AWS: add skip name validation to isValidIdentifier (#5081),4,34,2022-06-20 16:47:57-07:00,"['GlueTestBase.java', 'TestGlueCatalogTable.java', 'GlueCatalog.java', 'TestGlueCatalog.java']"
Python: Replace vars with cached_property decorator (#5068),2,52,2022-06-21 08:18:40-07:00,"['base.py', 'schema.py']"
Core: Send format version for create table in REST catalog (#5084),2,49,2022-06-21 08:27:48-07:00,"['RESTSessionCatalog.java', 'CatalogTests.java']"
"Python: Renable pylint (#5066)

* Python: Renable pylint

For some reason pylint fell through the cracks when migrating from tox
to pre-commit

* Be more explicit in disabled checks",13,156,2022-06-21 10:55:07-07:00,"['.pre-commit-config.yaml', 'poetry.lock', 'pylintrc', 'pyproject.toml', 'spellcheck-dictionary.txt', 'decoder.py', 'reader.py', 'transforms.py', 'test_reader.py', 'conftest.py', 'test_io_base.py', 'test_pyarrow.py', 'test_schema_conversion.py']"
"Core: Check for valid identifiers in REST catalog (#5107)

* Shutdown refresh token thread during REST catalog client close

* Improved shutdown of token refresh executor during REST catalog close

* REST: Set table format version for create table transactions

* add test for creating v2 table via transaction

* Core: Check for valid identifiers in REST catalog",1,29,2022-06-21 15:51:38-07:00,['RESTSessionCatalog.java']
Hive: Print db and table name while acquiring hive meta-store lock (#5039),1,5,2022-06-22 06:34:46+02:00,['HiveTableOperations.java']
Core: Metadata table queries fail if a partition column was reused in V2 (#4662),4,141,2022-06-22 09:37:12+02:00,"['BaseUpdatePartitionSpec.java', 'ScanTestBase.java', 'TestMetadataTableScans.java', 'TestMetadataTablesWithPartitionEvolution.java']"
Core: Support FileIO prefix operations (#5096),7,353,2022-06-22 13:40:33-07:00,"['FileInfo.java', 'SupportsPrefixOperations.java', 'S3FileIO.java', 'S3URI.java', 'TestS3FileIO.java', 'HadoopFileIO.java', 'HadoopFileIOTest.java']"
"Core: Remove Usage of Sets.Union in Loop (#5114)

Previously the repeated calls to union could create a very large stack depth since each call ends up creating a set view. This can lead to StackOverflow issues with very large compaction jobs.",1,4,2022-06-22 16:44:06-05:00,['RewriteDataFilesCommitManager.java']
Parquet: Fix VectorizedParquetDefinitionLevelReader with direct ByteBuffer (#5079),2,13,2022-06-22 18:56:48-07:00,"['VectorizedDictionaryEncodedParquetValuesReader.java', 'VectorizedParquetDefinitionLevelReader.java']"
Nessie: Fix drop/rename table with TableReference in identifier (#5033),2,112,2022-06-23 14:08:43+02:00,"['NessieCatalog.java', 'TestNessieTable.java']"
Spec: Typo an to a (#5123),1,2,2022-06-23 08:52:32-07:00,['spec.md']
Python: Add flake8 bugbear (#5117),1,5,2022-06-23 08:58:02-07:00,['.pre-commit-config.yaml']
Core: Reuse REST client for catalog and table operations (#5125),1,21,2022-06-23 12:16:46-07:00,['RESTSessionCatalog.java']
"Spark 3.2: RewriteDataFiles - Escape special characters in table identifiers (#5112)

* Spark 3.2: Escape table identifier in RewriteDataFiles Procedure/Action

Allows e.g. `db.special-chars`.`table.special-chars`

* mark original method as deprecated

* @deprecated tag in javadoc as well

* keep existing interface",8,113,2022-06-23 13:43:27-07:00,"['ActionsProvider.java', 'IcebergSortCompactionBenchmark.java', 'Spark3Util.java', 'BaseRewriteDataFilesSparkAction.java', 'SparkActions.java', 'SparkBinPackStrategy.java', 'RewriteDataFilesProcedure.java', 'TestRewriteDataFilesAction.java']"
Docs: Change docs layout for new iceberg-theme (#5115),67,945,2022-06-23 13:49:24-07:00,"['_index.md', '_index.md', '_index.md', '_index.md', '_index.md', '_index.md', '_index.md', '_index.md', '_index.md', '_index.md', 'aws.md', 'blogs.md', '_index.md', 'configuration.md', 'contributing.md', '_index.md', '_index.md', 'evolution.md', 'flink-connector.md', 'flink-getting-started.md', '_index.md', '_index.md', 'spec.md', 'terms.md', 'view-spec.md', 'hive.md', '_index.md', 'java-api-quickstart.md', 'java-api.md', 'java-custom-catalog.md', 'jdbc.md', 'join.md', 'maintenance.md', 'nessie.md', 'partitioning.md', 'performance.md', '_index.md', '_index.md', 'benchmarks.md', 'how-to-release.md', 'multi-engine-support.md', 'roadmap.md', 'security.md', 'trademarks.md', 'python-api-intro.md', 'python-feature-support.md', 'python-quickstart.md', '_index.md', '_index.md', '_index.md', '_index.md', '_index.md', 'release-notes.md', 'reliability.md', 'schemas.md', 'spark-configuration.md', 'spark-ddl.md', 'spark-getting-started.md', 'spark-procedures.md', 'spark-queries.md', 'spark-structured-streaming.md', 'spark-writes.md', '_index.md', '_index.md', '_index.md', 'talks.md', '_index.md']"
Flink: Add option to limit the number of snapshots in a planning operation (#4943),4,137,2022-06-24 09:03:08-07:00,"['FlinkSource.java', 'ScanContext.java', 'StreamingMonitorFunction.java', 'TestStreamingMonitorFunction.java']"
ORC: Upgrade to 1.7.5 (#5070),1,2,2022-06-24 09:06:21-07:00,['versions.props']
"Python: Add flake8-comprehensions (#5130)

Its slower to call e.g. `dict()` than using the empty literal `{}`,
because the name dict must be looked up in the global scope in
case it has been rebound.",5,12,2022-06-24 16:20:11-07:00,"['.pre-commit-config.yaml', 'partitioning.py', 'bin_packing.py', 'test_partitioning.py', 'test_bin_packing.py']"
Docs: Use more specific hidden partitioning anchor link (#5128),1,2,2022-06-24 16:21:45-07:00,['spark-writes.md']
Flink: FLIP-27 Iceberg source and builder (#5109),12,1332,2022-06-24 16:43:16-07:00,"['FlinkParquetReaders.java', 'IcebergSource.java', 'ScanContext.java', 'SimpleSplitAssigner.java', 'ContinuousSplitPlannerImpl.java', 'SimpleDataUtil.java', 'TestFixtures.java', 'RowDataToRowMapper.java', 'TestIcebergSourceBounded.java', 'TestIcebergSourceContinuous.java', 'TestIcebergSourceFailover.java', 'TestIcebergSourceReaderDeletes.java']"
Spark: Add compute stats to scan builder also (#5136),3,48,2022-06-27 08:55:37-07:00,"['SparkScanBuilder.java', 'SparkScanBuilder.java', 'SparkScanBuilder.java']"
Parquet: Release the compressor when closing ParquetWriter (#5126),1,3,2022-06-27 12:07:21-07:00,['ParquetWriter.java']
Checkstyle: Add rule for %d in Preconditions.checkArgument (#5057),5,22,2022-06-27 12:12:19-07:00,"['checkstyle.xml', 'BaseIncrementalAppendScan.java', 'AddFilesProcedure.java', 'AddFilesProcedure.java', 'AddFilesProcedure.java']"
Arrow: Avoid extra dictionary buffer copy (#5137),6,129,2022-06-27 12:12:49-07:00,"['ArrowVectorAccessors.java', 'GenericArrowVectorAccessorFactory.java', 'ArrowVectorAccessorFactory.java', 'ArrowVectorAccessorFactory.java', 'ArrowVectorAccessorFactory.java', 'ArrowVectorAccessorFactory.java']"
Core: Fix REST field name case strategy (#5133),3,20,2022-06-27 14:09:58-07:00,"['RESTObjectMapper.java', 'TestCreateTableRequest.java', 'reliability.md']"
Python: Update dependencies (#5142),1,100,2022-06-27 14:53:35-07:00,['poetry.lock']
Docs: A few small fixes to docs markdown files (#5127),9,114,2022-06-27 15:57:24-07:00,"['_index.md', 'blogs.md', 'configuration.md', 'contributing.md', 'join.md', 'talks.md', 'puffin-spec.md', 'spec.md', 'view-spec.md']"
Python: Use Pydantic for serialization and deserialization (#5011),16,2206,2022-06-27 16:42:50-07:00,"['poetry.lock', 'pyproject.toml', 'exceptions.py', 'schema.py', 'serializers.py', 'metadata.py', 'refs.py', 'types.py', 'iceberg_base_model.py', 'singleton.py', 'test_reader.py', 'conftest.py', 'test_metadata.py', 'test_schema.py', 'test_types.py', 'test_bin_packing.py']"
Core: Fix partition clustering to produce table sort order (#5131),2,332,2022-06-27 16:43:54-07:00,"['SortOrderUtil.java', 'TestSortOrderUtil.java']"
"Core: Fix tag ancestor snapshot handling (#5034)

* Core: Fix tag parent snapshot handling.

* Fix import order.",2,84,2022-06-27 17:10:29-07:00,"['RemoveSnapshots.java', 'TestRemoveSnapshots.java']"
Build: Print used JDK version (#5138),1,2,2022-06-27 18:50:28-07:00,['build.gradle']
Spark: Validate HMS uri in SparkSessionCatalog (#5134),2,90,2022-06-27 18:51:33-07:00,"['SparkSessionCatalog.java', 'TestSparkSessionCatalog.java']"
"Spark: Add __metadata_col for metadata columns when converting types (#5075)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",2,51,2022-06-27 19:07:47-07:00,"['TypeToSparkType.java', 'TestSparkSchemaUtil.java']"
"Revert ""Spark: Use original option keys in SparkCatalog (#4903)""

This reverts commit b06a89cebd5099b40b188c4c40ea7b1a23d3427a.",1,3,2022-06-27 19:18:02-07:00,['SparkCatalog.java']
"MR: Clone ANYWHERE location array IcebergSplit (#4984)

`IcebergSplit.ANYWHERE` was a mutable and publicly accessible field, so
someone could modify it. The modification could also be accidental, if
someone modified the array returned from `IcebergSplit.locations()`.",2,8,2022-06-27 19:22:50-07:00,"['IcebergSplit.java', 'TestIcebergInputFormats.java']"
API: Refactor ScanTask hierarchy (#5077),23,718,2022-06-27 20:57:42-07:00,"['BaseScanTaskGroup.java', 'CombinedScanTask.java', 'ContentScanTask.java', 'FileScanTask.java', 'IncrementalAppendScan.java', 'MergeableScanTask.java', 'Scan.java', 'ScanTask.java', 'ScanTaskGroup.java', 'SplittableScanTask.java', 'TableScan.java', 'BaseCombinedScanTask.java', 'BaseFileScanTask.java', 'BaseIncrementalAppendScan.java', 'BaseScan.java', 'BaseTableScan.java', 'TableScanUtil.java', 'ScanTestBase.java', 'TestTableScanUtil.java', 'FlinkSplitPlanner.java', 'FlinkSplitPlanner.java', 'TaskCheckHelper.java', 'TestScanTaskSerialization.java']"
Core: Add source snapshot info to Puffin Blob metadata (#5129),10,78,2022-06-28 07:37:00-07:00,"['Blob.java', 'BlobMetadata.java', 'FileMetadataParser.java', 'PuffinWriter.java', 'PuffinFormatTestUtil.java', 'TestFileMetadataParser.java', 'TestPuffinWriter.java', 'sample-metric-data-compressed-zstd.bin', 'sample-metric-data-uncompressed.bin', 'puffin-spec.md']"
API: Support composite types in Accessors (#5067),2,222,2022-06-28 09:39:39-05:00,"['Accessors.java', 'TestAccessors.java']"
Docs: Add reference to Apache Impala documentation (#5146),1,3,2022-06-28 16:42:29+02:00,['_index.md']
Core: Fix CreateTableRequest to use field names from the REST spec (#5135),4,111,2022-06-28 08:27:10-07:00,"['CreateTableRequest.java', 'RequestResponseTestBase.java', 'TestCreateTableRequest.java', 'TestOAuthTokenResponse.java']"
Core: Update CreateTableRequest Javadoc (#5144),1,3,2022-06-28 08:28:47-07:00,['CreateTableRequest.java']
move spark/v3.2 to spark/v3.3,388,0,2022-06-28 09:14:52-07:00,"['build.gradle', 'IcebergSqlExtensions.g4', 'IcebergSparkSessionExtensions.scala', 'ProjectingInternalRow.scala', 'AlignRowLevelCommandAssignments.scala', 'AlignedRowLevelIcebergCommandCheck.scala', 'AssignmentAlignmentSupport.scala', 'CheckMergeIntoTableConditions.scala', 'MergeIntoIcebergTableResolutionCheck.scala', 'ProcedureArgumentCoercion.scala', 'ResolveMergeIntoTableReferences.scala', 'ResolveProcedures.scala', 'RewriteDeleteFromTable.scala', 'RewriteMergeIntoTable.scala', 'RewriteRowLevelCommand.scala', 'RewriteUpdateTable.scala', 'AssignmentUtils.scala', 'ExtendedV2ExpressionUtils.scala', 'ExtendedReplaceNullWithFalseInPredicate.scala', 'ExtendedSimplifyConditionalsInPredicate.scala', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'RewrittenRowLevelCommand.scala', 'AddPartitionField.scala', 'Call.scala', 'DeleteFromIcebergTable.scala', 'DropIdentifierFields.scala', 'DropPartitionField.scala', 'MergeIntoIcebergTable.scala', 'MergeRows.scala', 'NoStatsUnaryNode.scala', 'ReplaceData.scala', 'ReplacePartitionField.scala', 'RowLevelCommand.scala', 'SetIdentifierFields.scala', 'UnresolvedMergeIntoIcebergTable.scala', 'UpdateIcebergTable.scala', 'V2WriteCommandLike.scala', 'WriteDelta.scala', 'statements.scala', 'RowDeltaUtils.scala', 'WriteDeltaProjections.scala', 'TruncateTransform.scala', 'ExtendedLogicalWriteInfoImpl.scala', 'RowLevelOperationInfoImpl.scala', 'RowLevelOperationTable.scala', 'AddPartitionFieldExec.scala', 'CallExec.scala', 'DropIdentifierFieldsExec.scala', 'DropPartitionFieldExec.scala', 'ExtendedDataSourceV2Implicits.scala', 'ExtendedDataSourceV2Strategy.scala', 'ExtendedDistributionAndOrderingUtils.scala', 'ExtendedV2Writes.scala', 'MergeRowsExec.scala', 'OptimizeMetadataOnlyDeleteFromTable.scala', 'ReplaceDataExec.scala', 'ReplacePartitionFieldExec.scala', 'ReplaceRewrittenRowLevelCommand.scala', 'RowLevelCommandScanRelationPushDown.scala', 'SetIdentifierFieldsExec.scala', 'SetWriteDistributionAndOrderingExec.scala', 'WriteDeltaExec.scala', 'RowLevelCommandDynamicPruning.scala', 'Employee.java', 'SparkExtensionsTestBase.java', 'SparkRowLevelOperationsTestBase.java', 'TestAddFilesProcedure.java', 'TestAlterTablePartitionFields.java', 'TestAlterTableSchema.java', 'TestAncestorsOfProcedure.java', 'TestCallStatementParser.java', 'TestCherrypickSnapshotProcedure.java', 'TestConflictValidation.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestDelete.java', 'TestExpireSnapshotsProcedure.java', 'TestIcebergExpressions.java', 'TestMerge.java', 'TestMergeOnReadDelete.java', 'TestMergeOnReadMerge.java', 'TestMergeOnReadUpdate.java', 'TestMetadataTables.java', 'TestMigrateTableProcedure.java', 'TestRegisterTableProcedure.java', 'TestRemoveOrphanFilesProcedure.java', 'TestRequiredDistributionAndOrdering.java', 'TestRewriteDataFilesProcedure.java', 'TestRewriteManifestsProcedure.java', 'TestRollbackToSnapshotProcedure.java', 'TestRollbackToTimestampProcedure.java', 'TestSetCurrentSnapshotProcedure.java', 'TestSetWriteDistributionAndOrdering.java', 'TestSnapshotTableProcedure.java', 'TestUpdate.java', 'LICENSE', 'NOTICE', 'SmokeTest.java', 'SparkBenchmarkUtil.java', 'IcebergSortCompactionBenchmark.java', 'RandomGeneratingUDF.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'Action.java', 'IcebergSourceBenchmark.java', 'IcebergSourceDeleteBenchmark.java', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'IcebergSourceNestedListDataBenchmark.java', 'WritersBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'IcebergSourceParquetEqDeleteBenchmark.java', 'IcebergSourceParquetMultiDeleteFileBenchmark.java', 'IcebergSourceParquetPosDeleteBenchmark.java', 'IcebergSourceParquetWithUnrelatedDeleteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'BaseCatalog.java', 'CommitMetadata.java', 'FileRewriteCoordinator.java', 'FileScanTaskSetManager.java', 'IcebergSpark.java', 'JobGroupInfo.java', 'JobGroupUtils.java', 'PathIdentifier.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'RollbackStagedTable.java', 'SortOrderToSpark.java', 'Spark3Util.java', 'SparkCatalog.java', 'SparkConfParser.java', 'SparkDataFile.java', 'SparkDistributionAndOrderingUtil.java', 'SparkExceptionUtil.java', 'SparkFilters.java', 'SparkFixupTimestampType.java', 'SparkFixupTypes.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkSQLProperties.java', 'SparkSchemaUtil.java', 'SparkSessionCatalog.java', 'SparkStructLike.java', 'SparkTableUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'SparkUtil.java', 'SparkValueConverter.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'TypeToSparkType.java', 'BaseDeleteOrphanFilesSparkAction.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseExpireSnapshotsSparkAction.java', 'BaseMigrateTableSparkAction.java', 'BaseRewriteDataFilesSparkAction.java', 'BaseRewriteManifestsSparkAction.java', 'BaseSnapshotTableSparkAction.java', 'BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java', 'BaseTableCreationSparkAction.java', 'ManifestFileBean.java', 'SparkActions.java', 'SparkBinPackStrategy.java', 'SparkSortStrategy.java', 'SparkZOrderStrategy.java', 'SparkZOrderUDF.java', 'AvroWithSparkSchemaVisitor.java', 'ParquetWithSparkSchemaVisitor.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'ArrowVectorAccessorFactory.java', 'ArrowVectorAccessors.java', 'ColumnVectorWithFilter.java', 'ColumnarBatchReader.java', 'ConstantColumnVector.java', 'IcebergArrowColumnVector.java', 'RowPositionColumnVector.java', 'VectorizedSparkOrcReaders.java', 'VectorizedSparkParquetReaders.java', 'AddFilesProcedure.java', 'AncestorsOfProcedure.java', 'BaseProcedure.java', 'CherrypickSnapshotProcedure.java', 'ExpireSnapshotsProcedure.java', 'MigrateTableProcedure.java', 'RegisterTableProcedure.java', 'RemoveOrphanFilesProcedure.java', 'RewriteDataFilesProcedure.java', 'RewriteManifestsProcedure.java', 'RollbackToSnapshotProcedure.java', 'RollbackToTimestampProcedure.java', 'SetCurrentSnapshotProcedure.java', 'SnapshotTableProcedure.java', 'SparkProcedures.java', 'BaseDataReader.java', 'BatchDataReader.java', 'EqualityDeleteRowReader.java', 'HasIcebergCatalog.java', 'IcebergSource.java', 'InternalRowWrapper.java', 'RowDataReader.java', 'RowDataRewriter.java', 'SparkAppenderFactory.java', 'SparkBatch.java', 'SparkBatchQueryScan.java', 'SparkCopyOnWriteOperation.java', 'SparkCopyOnWriteScan.java', 'SparkFileWriterFactory.java', 'SparkFilesScan.java', 'SparkFilesScanBuilder.java', 'SparkMetadataColumn.java', 'SparkMicroBatchStream.java', 'SparkPartitionedFanoutWriter.java', 'SparkPartitionedWriter.java', 'SparkPositionDeltaOperation.java', 'SparkPositionDeltaWrite.java', 'SparkPositionDeltaWriteBuilder.java', 'SparkRowLevelOperationBuilder.java', 'SparkScan.java', 'SparkScanBuilder.java', 'SparkTable.java', 'SparkWrite.java', 'SparkWriteBuilder.java', 'StagedSparkTable.java', 'Stats.java', 'StreamingOffset.java', 'StructInternalRow.java', 'NoSuchProcedureException.java', 'Procedure.java', 'ProcedureCatalog.java', 'ProcedureParameter.java', 'ProcedureParameterImpl.java', 'SupportsRowLevelOperations.java', 'DeltaBatchWrite.java', 'DeltaWrite.java', 'DeltaWriteBuilder.java', 'DeltaWriter.java', 'DeltaWriterFactory.java', 'ExtendedLogicalWriteInfo.java', 'RowLevelOperation.java', 'RowLevelOperationBuilder.java', 'RowLevelOperationInfo.java', 'SupportsDelta.java', 'org.apache.spark.sql.sources.DataSourceRegister', 'TransformExpressions.scala', 'SetWriteDistributionAndOrdering.scala', 'SortOrderParserUtil.scala', 'DistributionAndOrderingUtils.scala', 'PlanUtils.scala', 'SparkExpressionConverter.scala', 'KryoHelpers.java', 'TaskCheckHelper.java', 'TestDataFileSerialization.java', 'TestFileIOSerialization.java', 'TestHadoopMetricsContextSerialization.java', 'TestManifestFileSerialization.java', 'TestScanTaskSerialization.java', 'TestTableSerialization.java', 'SparkCatalogConfig.java', 'SparkCatalogTestBase.java', 'SparkTestBase.java', 'SparkTestBaseWithCatalog.java', 'TestFileRewriteCoordinator.java', 'TestSpark3Util.java', 'TestSparkCatalogOperations.java', 'TestSparkDistributionAndOrderingUtil.java', 'TestSparkFilters.java', 'TestSparkSchemaUtil.java', 'TestSparkSessionCatalog.java', 'TestSparkTableUtil.java', 'TestSparkValueConverter.java', 'TestCreateActions.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction3.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'AvroDataTest.java', 'GenericsHelpers.java', 'RandomData.java', 'TestHelpers.java', 'TestOrcWrite.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkAvroEnums.java', 'TestSparkAvroReader.java', 'TestSparkDateTimes.java', 'TestSparkOrcReadMetadataColumns.java', 'TestSparkOrcReader.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkParquetReader.java', 'TestSparkParquetWriter.java', 'TestSparkRecordOrcReaderWriter.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryFallbackToPlainEncodingVectorizedReads.java', 'TestParquetVectorizedReads.java', 'FilePathLastModifiedRecord.java', 'LogMessage.java', 'ManualSource.java', 'SimpleRecord.java', 'TestAvroScan.java', 'TestDataFrameWriterV2.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestFilteredScan.java', 'TestForwardCompatibility.java', 'TestIcebergSource.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSpark.java', 'TestIdentityPartitionData.java', 'TestInternalRowWrapper.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestParquetScan.java', 'TestPartitionPruning.java', 'TestPartitionValues.java', 'TestPathIdentifier.java', 'TestReadProjection.java', 'TestRequiredDistributionAndOrdering.java', 'TestRuntimeFiltering.java', 'TestSnapshotSelection.java', 'TestSparkAppenderFactory.java', 'TestSparkBaseDataReader.java', 'TestSparkCatalog.java', 'TestSparkCatalogCacheExpiration.java', 'TestSparkCatalogHadoopOverrides.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestSparkFileWriterFactory.java', 'TestSparkFilesScan.java', 'TestSparkMergingMetrics.java', 'TestSparkMetadataColumns.java', 'TestSparkPartitioningWriters.java', 'TestSparkPositionDeltaWriters.java', 'TestSparkReadProjection.java', 'TestSparkReaderDeletes.java', 'TestSparkRollingFileWriters.java', 'TestSparkTable.java', 'TestSparkWriterMetrics.java', 'TestStreamingOffset.java', 'TestStructuredStreaming.java', 'TestStructuredStreamingRead3.java', 'TestTables.java', 'TestTimestampWithoutZone.java', 'TestWriteMetricsConfig.java', 'ThreeColumnRecord.java', 'TestAlterTable.java', 'TestCreateTable.java', 'TestCreateTableAsSelect.java', 'TestDeleteFrom.java', 'TestDropTable.java', 'TestNamespaceSQL.java', 'TestPartitionedWrites.java', 'TestPartitionedWritesAsSelect.java', 'TestRefreshTable.java', 'TestSelect.java', 'TestTimestampWithoutZone.java', 'TestUnpartitionedWrites.java']"
make spark 3.3 work,76,774,2022-06-28 09:14:52-07:00,"['checkstyle.xml', 'java-ci.yml', 'jmh-bechmarks.yml', 'publish-snapshot.yml', 'spark-ci.yml', '.gitignore', 'stage-binaries.sh', 'gradle.properties', 'jmh.gradle', 'settings.gradle', 'build.gradle', 'build.gradle', 'IcebergSparkSessionExtensions.scala', 'RewriteDeleteFromIcebergTable.scala', 'RewriteMergeIntoTable.scala', 'RewriteRowLevelIcebergCommand.scala', 'RewriteUpdateTable.scala', 'ExtendedV2ExpressionUtils.scala', 'ExtendedReplaceNullWithFalseInPredicate.scala', 'ExtendedSimplifyConditionalsInPredicate.scala', 'IcebergSparkSqlExtensionsParser.scala', 'RewrittenRowLevelCommand.scala', 'ReplaceIcebergData.scala', 'RowLevelOperationInfoImpl.scala', 'RowLevelOperationTable.scala', 'ExtendedDataSourceV2Strategy.scala', 'ExtendedV2Writes.scala', 'OptimizeMetadataOnlyDeleteFromIcebergTable.scala', 'RowLevelCommandScanRelationPushDown.scala', 'RowLevelCommandDynamicPruning.scala', 'SparkExtensionsTestBase.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'IcebergSourceParquetEqDeleteBenchmark.java', 'IcebergSourceParquetMultiDeleteFileBenchmark.java', 'IcebergSourceParquetPosDeleteBenchmark.java', 'IcebergSourceParquetWithUnrelatedDeleteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'SparkCatalog.java', 'SparkDistributionAndOrderingUtil.java', 'SparkSessionCatalog.java', 'SparkCopyOnWriteOperation.java', 'SparkPositionDeltaOperation.java', 'SparkPositionDeltaWrite.java', 'SparkPositionDeltaWriteBuilder.java', 'SparkRowLevelOperationBuilder.java', 'SparkTable.java', 'SparkWriteBuilder.java', 'SupportsRowLevelOperations.java', 'RowLevelOperation.java', 'RowLevelOperationBuilder.java', 'RowLevelOperationInfo.java', 'SupportsDelta.java', 'TestSparkDistributionAndOrderingUtil.java', 'TestSparkSchemaUtil.java', 'TestCreateActions.java', 'TestSparkParquetReader.java', 'TestDeleteFrom.java', 'TestNamespaceSQL.java']"
copy 3.2 files from 3.3,388,75898,2022-06-28 09:14:52-07:00,"['build.gradle', 'IcebergSqlExtensions.g4', 'IcebergSparkSessionExtensions.scala', 'ProjectingInternalRow.scala', 'AlignRowLevelCommandAssignments.scala', 'AlignedRowLevelIcebergCommandCheck.scala', 'AssignmentAlignmentSupport.scala', 'CheckMergeIntoTableConditions.scala', 'MergeIntoIcebergTableResolutionCheck.scala', 'ProcedureArgumentCoercion.scala', 'ResolveMergeIntoTableReferences.scala', 'ResolveProcedures.scala', 'RewriteDeleteFromTable.scala', 'RewriteMergeIntoTable.scala', 'RewriteRowLevelCommand.scala', 'RewriteUpdateTable.scala', 'AssignmentUtils.scala', 'ExtendedV2ExpressionUtils.scala', 'ExtendedReplaceNullWithFalseInPredicate.scala', 'ExtendedSimplifyConditionalsInPredicate.scala', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'RewrittenRowLevelCommand.scala', 'AddPartitionField.scala', 'Call.scala', 'DeleteFromIcebergTable.scala', 'DropIdentifierFields.scala', 'DropPartitionField.scala', 'MergeIntoIcebergTable.scala', 'MergeRows.scala', 'NoStatsUnaryNode.scala', 'ReplaceData.scala', 'ReplacePartitionField.scala', 'RowLevelCommand.scala', 'SetIdentifierFields.scala', 'UnresolvedMergeIntoIcebergTable.scala', 'UpdateIcebergTable.scala', 'V2WriteCommandLike.scala', 'WriteDelta.scala', 'statements.scala', 'RowDeltaUtils.scala', 'WriteDeltaProjections.scala', 'TruncateTransform.scala', 'ExtendedLogicalWriteInfoImpl.scala', 'RowLevelOperationInfoImpl.scala', 'RowLevelOperationTable.scala', 'AddPartitionFieldExec.scala', 'CallExec.scala', 'DropIdentifierFieldsExec.scala', 'DropPartitionFieldExec.scala', 'ExtendedDataSourceV2Implicits.scala', 'ExtendedDataSourceV2Strategy.scala', 'ExtendedDistributionAndOrderingUtils.scala', 'ExtendedV2Writes.scala', 'MergeRowsExec.scala', 'OptimizeMetadataOnlyDeleteFromTable.scala', 'ReplaceDataExec.scala', 'ReplacePartitionFieldExec.scala', 'ReplaceRewrittenRowLevelCommand.scala', 'RowLevelCommandScanRelationPushDown.scala', 'SetIdentifierFieldsExec.scala', 'SetWriteDistributionAndOrderingExec.scala', 'WriteDeltaExec.scala', 'RowLevelCommandDynamicPruning.scala', 'Employee.java', 'SparkExtensionsTestBase.java', 'SparkRowLevelOperationsTestBase.java', 'TestAddFilesProcedure.java', 'TestAlterTablePartitionFields.java', 'TestAlterTableSchema.java', 'TestAncestorsOfProcedure.java', 'TestCallStatementParser.java', 'TestCherrypickSnapshotProcedure.java', 'TestConflictValidation.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestDelete.java', 'TestExpireSnapshotsProcedure.java', 'TestIcebergExpressions.java', 'TestMerge.java', 'TestMergeOnReadDelete.java', 'TestMergeOnReadMerge.java', 'TestMergeOnReadUpdate.java', 'TestMetadataTables.java', 'TestMigrateTableProcedure.java', 'TestRegisterTableProcedure.java', 'TestRemoveOrphanFilesProcedure.java', 'TestRequiredDistributionAndOrdering.java', 'TestRewriteDataFilesProcedure.java', 'TestRewriteManifestsProcedure.java', 'TestRollbackToSnapshotProcedure.java', 'TestRollbackToTimestampProcedure.java', 'TestSetCurrentSnapshotProcedure.java', 'TestSetWriteDistributionAndOrdering.java', 'TestSnapshotTableProcedure.java', 'TestUpdate.java', 'LICENSE', 'NOTICE', 'SmokeTest.java', 'SparkBenchmarkUtil.java', 'IcebergSortCompactionBenchmark.java', 'RandomGeneratingUDF.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'Action.java', 'IcebergSourceBenchmark.java', 'IcebergSourceDeleteBenchmark.java', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'IcebergSourceNestedListDataBenchmark.java', 'WritersBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'IcebergSourceParquetEqDeleteBenchmark.java', 'IcebergSourceParquetMultiDeleteFileBenchmark.java', 'IcebergSourceParquetPosDeleteBenchmark.java', 'IcebergSourceParquetWithUnrelatedDeleteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'BaseCatalog.java', 'CommitMetadata.java', 'FileRewriteCoordinator.java', 'FileScanTaskSetManager.java', 'IcebergSpark.java', 'JobGroupInfo.java', 'JobGroupUtils.java', 'PathIdentifier.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'RollbackStagedTable.java', 'SortOrderToSpark.java', 'Spark3Util.java', 'SparkCatalog.java', 'SparkConfParser.java', 'SparkDataFile.java', 'SparkDistributionAndOrderingUtil.java', 'SparkExceptionUtil.java', 'SparkFilters.java', 'SparkFixupTimestampType.java', 'SparkFixupTypes.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkSQLProperties.java', 'SparkSchemaUtil.java', 'SparkSessionCatalog.java', 'SparkStructLike.java', 'SparkTableUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'SparkUtil.java', 'SparkValueConverter.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'TypeToSparkType.java', 'BaseDeleteOrphanFilesSparkAction.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseExpireSnapshotsSparkAction.java', 'BaseMigrateTableSparkAction.java', 'BaseRewriteDataFilesSparkAction.java', 'BaseRewriteManifestsSparkAction.java', 'BaseSnapshotTableSparkAction.java', 'BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java', 'BaseTableCreationSparkAction.java', 'ManifestFileBean.java', 'SparkActions.java', 'SparkBinPackStrategy.java', 'SparkSortStrategy.java', 'SparkZOrderStrategy.java', 'SparkZOrderUDF.java', 'AvroWithSparkSchemaVisitor.java', 'ParquetWithSparkSchemaVisitor.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'ArrowVectorAccessorFactory.java', 'ArrowVectorAccessors.java', 'ColumnVectorWithFilter.java', 'ColumnarBatchReader.java', 'ConstantColumnVector.java', 'IcebergArrowColumnVector.java', 'RowPositionColumnVector.java', 'VectorizedSparkOrcReaders.java', 'VectorizedSparkParquetReaders.java', 'AddFilesProcedure.java', 'AncestorsOfProcedure.java', 'BaseProcedure.java', 'CherrypickSnapshotProcedure.java', 'ExpireSnapshotsProcedure.java', 'MigrateTableProcedure.java', 'RegisterTableProcedure.java', 'RemoveOrphanFilesProcedure.java', 'RewriteDataFilesProcedure.java', 'RewriteManifestsProcedure.java', 'RollbackToSnapshotProcedure.java', 'RollbackToTimestampProcedure.java', 'SetCurrentSnapshotProcedure.java', 'SnapshotTableProcedure.java', 'SparkProcedures.java', 'BaseDataReader.java', 'BatchDataReader.java', 'EqualityDeleteRowReader.java', 'HasIcebergCatalog.java', 'IcebergSource.java', 'InternalRowWrapper.java', 'RowDataReader.java', 'RowDataRewriter.java', 'SparkAppenderFactory.java', 'SparkBatch.java', 'SparkBatchQueryScan.java', 'SparkCopyOnWriteOperation.java', 'SparkCopyOnWriteScan.java', 'SparkFileWriterFactory.java', 'SparkFilesScan.java', 'SparkFilesScanBuilder.java', 'SparkMetadataColumn.java', 'SparkMicroBatchStream.java', 'SparkPartitionedFanoutWriter.java', 'SparkPartitionedWriter.java', 'SparkPositionDeltaOperation.java', 'SparkPositionDeltaWrite.java', 'SparkPositionDeltaWriteBuilder.java', 'SparkRowLevelOperationBuilder.java', 'SparkScan.java', 'SparkScanBuilder.java', 'SparkTable.java', 'SparkWrite.java', 'SparkWriteBuilder.java', 'StagedSparkTable.java', 'Stats.java', 'StreamingOffset.java', 'StructInternalRow.java', 'NoSuchProcedureException.java', 'Procedure.java', 'ProcedureCatalog.java', 'ProcedureParameter.java', 'ProcedureParameterImpl.java', 'SupportsRowLevelOperations.java', 'DeltaBatchWrite.java', 'DeltaWrite.java', 'DeltaWriteBuilder.java', 'DeltaWriter.java', 'DeltaWriterFactory.java', 'ExtendedLogicalWriteInfo.java', 'RowLevelOperation.java', 'RowLevelOperationBuilder.java', 'RowLevelOperationInfo.java', 'SupportsDelta.java', 'org.apache.spark.sql.sources.DataSourceRegister', 'TransformExpressions.scala', 'SetWriteDistributionAndOrdering.scala', 'SortOrderParserUtil.scala', 'DistributionAndOrderingUtils.scala', 'PlanUtils.scala', 'SparkExpressionConverter.scala', 'KryoHelpers.java', 'TaskCheckHelper.java', 'TestDataFileSerialization.java', 'TestFileIOSerialization.java', 'TestHadoopMetricsContextSerialization.java', 'TestManifestFileSerialization.java', 'TestScanTaskSerialization.java', 'TestTableSerialization.java', 'SparkCatalogConfig.java', 'SparkCatalogTestBase.java', 'SparkTestBase.java', 'SparkTestBaseWithCatalog.java', 'TestFileRewriteCoordinator.java', 'TestSpark3Util.java', 'TestSparkCatalogOperations.java', 'TestSparkDistributionAndOrderingUtil.java', 'TestSparkFilters.java', 'TestSparkSchemaUtil.java', 'TestSparkSessionCatalog.java', 'TestSparkTableUtil.java', 'TestSparkValueConverter.java', 'TestCreateActions.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction3.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'AvroDataTest.java', 'GenericsHelpers.java', 'RandomData.java', 'TestHelpers.java', 'TestOrcWrite.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkAvroEnums.java', 'TestSparkAvroReader.java', 'TestSparkDateTimes.java', 'TestSparkOrcReadMetadataColumns.java', 'TestSparkOrcReader.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkParquetReader.java', 'TestSparkParquetWriter.java', 'TestSparkRecordOrcReaderWriter.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryFallbackToPlainEncodingVectorizedReads.java', 'TestParquetVectorizedReads.java', 'FilePathLastModifiedRecord.java', 'LogMessage.java', 'ManualSource.java', 'SimpleRecord.java', 'TestAvroScan.java', 'TestDataFrameWriterV2.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestFilteredScan.java', 'TestForwardCompatibility.java', 'TestIcebergSource.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSpark.java', 'TestIdentityPartitionData.java', 'TestInternalRowWrapper.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestParquetScan.java', 'TestPartitionPruning.java', 'TestPartitionValues.java', 'TestPathIdentifier.java', 'TestReadProjection.java', 'TestRequiredDistributionAndOrdering.java', 'TestRuntimeFiltering.java', 'TestSnapshotSelection.java', 'TestSparkAppenderFactory.java', 'TestSparkBaseDataReader.java', 'TestSparkCatalog.java', 'TestSparkCatalogCacheExpiration.java', 'TestSparkCatalogHadoopOverrides.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestSparkFileWriterFactory.java', 'TestSparkFilesScan.java', 'TestSparkMergingMetrics.java', 'TestSparkMetadataColumns.java', 'TestSparkPartitioningWriters.java', 'TestSparkPositionDeltaWriters.java', 'TestSparkReadProjection.java', 'TestSparkReaderDeletes.java', 'TestSparkRollingFileWriters.java', 'TestSparkTable.java', 'TestSparkWriterMetrics.java', 'TestStreamingOffset.java', 'TestStructuredStreaming.java', 'TestStructuredStreamingRead3.java', 'TestTables.java', 'TestTimestampWithoutZone.java', 'TestWriteMetricsConfig.java', 'ThreeColumnRecord.java', 'TestAlterTable.java', 'TestCreateTable.java', 'TestCreateTableAsSelect.java', 'TestDeleteFrom.java', 'TestDropTable.java', 'TestNamespaceSQL.java', 'TestPartitionedWrites.java', 'TestPartitionedWritesAsSelect.java', 'TestRefreshTable.java', 'TestSelect.java', 'TestTimestampWithoutZone.java', 'TestUnpartitionedWrites.java']"
enable ci for 3.2,4,10,2022-06-28 09:14:52-07:00,"['java-ci.yml', 'publish-snapshot.yml', 'spark-ci.yml', 'stage-binaries.sh']"
Docs: Update README.md project description.,1,2,2022-06-28 11:28:15-07:00,['README.md']
Spec: Fix typo in REST catalog spec (#5152),1,4,2022-06-28 16:53:20-07:00,['rest-catalog-open-api.yaml']
Python: Make the VoidTransform a singleton (#5149),2,16,2022-06-28 16:53:53-07:00,"['transforms.py', 'test_singleton.py']"
Spark: Fix regression from Scan refactor (#5143),3,42,2022-06-28 16:58:51-07:00,"['SparkBatch.java', 'SparkScan.java', 'TestExpireSnapshotsAction.java']"
Core: Test serialization of LoadTableResponse (#5118),3,234,2022-06-29 07:37:52-07:00,"['LoadTableResponse.java', 'TestLoadTableResponse.java', 'rest-catalog-open-api.yaml']"
"Spark 3.3: Support AS OF syntax in Spark SQL for time travel (#5156)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",4,155,2022-06-29 07:47:28-07:00,"['SparkCatalog.java', 'SparkSessionCatalog.java', 'IcebergSource.java', 'TestSelect.java']"
Python: Resolve write/read schemas (#5116),8,656,2022-06-29 07:51:58-07:00,"['decoder.py', 'file.py', 'reader.py', 'resolver.py', 'exceptions.py', 'test_decoder.py', 'test_reader.py', 'test_resolver.py']"
Core: Make StreamingDelete public (#5148),1,2,2022-06-29 09:18:48-07:00,['StreamingDelete.java']
Spark: Port performance fix for Spark 3.2 to 3.3 (#5155),3,42,2022-06-29 09:20:18-07:00,"['SparkBatch.java', 'SparkScan.java', 'TestExpireSnapshotsAction.java']"
Spark 3.x: Use original option keys in SparkCatalog (#5044),4,8,2022-06-29 09:26:49-07:00,"['SparkCatalog.java', 'SparkCatalog.java', 'SparkCatalog.java', 'SparkCatalog.java']"
Docs: Add Flink SQL client -i docs (#5003),1,22,2022-06-29 09:56:57-07:00,['flink-getting-started.md']
Spec: Fix language in spec ORC type notes (#4976),1,4,2022-06-29 09:58:25-07:00,['spec.md']
Nessie: Update to 0.30.0 (#4780),1,2,2022-06-29 11:28:27-07:00,['versions.props']
Core: Avoid snapshot ID collisions (#4747),7,158,2022-06-29 11:32:58-07:00,"['build.gradle', 'SnapshotIdGeneratorUtil.java', 'SnapshotProducer.java', 'TableMetadata.java', 'TableOperations.java', 'TestDuplicateSnapshotIDs.java', 'versions.props']"
"Flink: Remove unnecessary switch statement (#4737)

Co-authored-by: jian yonghua <jianyonghua@163.com>",1,15,2022-06-29 11:34:00-07:00,['RowDataConverter.java']
AWS: Support overriding endpoint in DynamoDB (#4726),4,32,2022-06-29 11:36:18-07:00,"['TestDefaultAwsClientFactory.java', 'AssumeRoleAwsClientFactory.java', 'AwsClientFactories.java', 'AwsProperties.java']"
API: Fix version exception when registering metadata (#4946),2,124,2022-06-29 11:39:46-07:00,"['BaseMetastoreTableOperations.java', 'HiveTableTest.java']"
Core: Add reference_snapshot_id filter column to all_manifests table (#4847),7,1273,2022-06-29 15:49:08-07:00,"['AllManifestsTable.java', 'TestMetadataTableScans.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java']"
Docs: Update Hive doc page with the 4.0.0-alpha-1 features (#5161),1,379,2022-06-30 11:34:29+02:00,['hive.md']
API: Fix typo Canout to Cannot (#5164),1,2,2022-06-30 14:30:44+02:00,['ByteBuffers.java']
Python: Add truncate transform (#5030),3,228,2022-06-30 09:27:58-07:00,"['transforms.py', 'decimal.py', 'test_transforms.py']"
API: Access deleted and added delete files in Snapshot (#5105),47,451,2022-06-30 11:41:01-07:00,"['revapi.yml', 'Snapshot.java', 'BaseSnapshot.java', 'CherryPickOperation.java', 'SnapshotUtil.java', 'TestRemoveSnapshots.java', 'TestSnapshot.java', 'TestSnapshotSelection.java', 'TestWapWorkflow.java', 'TestCatalogUtilDropTable.java', 'TestIcebergSourceTablesBase.java', 'SparkMicroBatchStream.java', 'TestExpireSnapshotsAction.java', 'TestRewriteDataFilesAction.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestIcebergSourceTablesBase.java', 'TestRefreshTable.java', 'SparkMicroBatchStream.java', 'TestExpireSnapshotsAction.java', 'TestRewriteDataFilesAction.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestIcebergSourceTablesBase.java', 'TestRefreshTable.java', 'TestMerge.java', 'TestUpdate.java', 'IcebergSourceParquetMultiDeleteFileBenchmark.java', 'IcebergSourceParquetPosDeleteBenchmark.java', 'IcebergSourceParquetWithUnrelatedDeleteBenchmark.java', 'TestExpireSnapshotsAction.java', 'TestRewriteDataFilesAction.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestIcebergSourceTablesBase.java', 'TestRefreshTable.java', 'TestMerge.java', 'TestUpdate.java', 'IcebergSourceParquetMultiDeleteFileBenchmark.java', 'IcebergSourceParquetPosDeleteBenchmark.java', 'IcebergSourceParquetWithUnrelatedDeleteBenchmark.java', 'TestExpireSnapshotsAction.java', 'TestRewriteDataFilesAction.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestIcebergSourceTablesBase.java', 'TestRefreshTable.java']"
"Python: Rename python top-level module pyiceberg, remove src (#5169)",62,310,2022-06-30 11:49:17-07:00,"['Makefile', 'RELEASE.md', '__init__.py', '__init__.py', '__init__.py', 'bzip2.py', 'codec.py', 'deflate.py', 'snappy_codec.py', 'zstandard_codec.py', 'decoder.py', 'file.py', 'reader.py', 'resolver.py', '__init__.py', 'base.py', 'conversions.py', 'exceptions.py', '__init__.py', 'base.py', 'literals.py', 'files.py', '__init__.py', 'base.py', 'memory.py', 'pyarrow.py', 'schema.py', 'serializers.py', '__init__.py', 'base.py', 'metadata.py', 'partitioning.py', 'refs.py', 'transforms.py', 'types.py', '__init__.py', 'bin_packing.py', 'datetime.py', 'decimal.py', 'iceberg_base_model.py', 'schema_conversion.py', 'singleton.py', 'pyproject.toml', 'test_decoder.py', 'test_file.py', 'test_reader.py', 'test_resolver.py', 'test_base.py', 'conftest.py', 'test_expressions_base.py', 'test_literals.py', 'test_io_base.py', 'test_pyarrow.py', 'test_metadata.py', 'test_partitioning.py', 'test_conversions.py', 'test_schema.py', 'test_transforms.py', 'test_types.py', 'test_bin_packing.py', 'test_schema_conversion.py', 'test_singleton.py']"
"Parquet: Add bloom filter options to the write path (#5035)

Co-authored-by: Xi Chen <jshmchenxi@163.com>
Co-authored-by: Hao Lin <linhao1990@gmail.com>
Co-authored-by: Huaxin Gao <huaxin_gao@apple.com>",6,718,2022-06-30 13:50:01-07:00,"['TableProperties.java', 'configuration.md', 'Parquet.java', 'ParquetWriter.java', 'TestSparkReaderWithBloomFilter.java', 'TestSparkReaderWithBloomFilter.java']"
Parquet: Fix bloom filter check for corrupt files (#5172),1,2,2022-06-30 16:45:21-07:00,['ParquetUtil.java']
Python: Move Transforms to Pydantic (#5170),2,277,2022-07-01 08:21:15-07:00,"['transforms.py', 'test_transforms.py']"
"Spec: Sort-order order-id is mandatory (#5177)

Looking at the code, we expect this field:

https://github.com/apache/iceberg/blob/master/core/src/main/java/org/apache/iceberg/SortOrderParser.java#L154

And we always write it on the Java side.",1,1,2022-07-01 08:34:36-07:00,['rest-catalog-open-api.yaml']
"Arrow: Pad decimal bytes before passing to decimal vector (#5168)

* Arrow: Pad decimal bytes before passing to vector

* comment clarification

* optimize fill for neg numbers

* Add overflow check",5,157,2022-07-01 12:55:08-07:00,"['ArrowVectorAccessors.java', 'DecimalVectorUtil.java', 'VectorizedDictionaryEncodedParquetValuesReader.java', 'VectorizedParquetDefinitionLevelReader.java', 'DecimalVectorUtilTest.java']"
"API: Add generic FileIO JSON serialization (#5178)

* API: Add generic FileIO JSON serialization.

* Fix checkstyle.

* Close StringWriter and JsonGenerator.",10,257,2022-07-03 11:59:38-07:00,"['FileIO.java', 'S3FileIO.java', 'TestS3FileIO.java', 'SortOrderParser.java', 'HadoopFileIO.java', 'FileIOParser.java', 'ResolvingFileIO.java', 'JsonUtil.java', 'GCSFileIO.java', 'TestFileIOSerialization.java']"
"Python: Pin bugbear in Python legacy (#5184)

We got a new release on June 1st:
https://pypi.org/project/flake8-bugbear/22.7.1/

This introduced a new rule that actually broke the CI.

It is best to not do global lookups because of scoping and performance,
but I don't feel like rewriting the legacy code either.",1,2,2022-07-03 12:57:29-07:00,['tox.ini']
API: Add a scan for changes (#4870),9,370,2022-07-03 13:04:55-07:00,"['AddedRowsScanTask.java', 'ChangelogOperation.java', 'ChangelogScanTask.java', 'DeletedDataFileScanTask.java', 'DeletedRowsScanTask.java', 'IncrementalAppendScan.java', 'IncrementalChangelogScan.java', 'IncrementalScan.java', 'Table.java']"
Flink: Support write options in FlinkSink builder (#3998),8,549,2022-07-03 13:09:43-07:00,"['flink-getting-started.md', 'FlinkConfParser.java', 'FlinkWriteConf.java', 'FlinkWriteOptions.java', 'FlinkSink.java', 'RowDataTaskWriterFactory.java', 'TestFlinkIcebergSink.java', 'TestIcebergStreamWriter.java']"
"Spark 3.3: Re-enable 2-level Parquet list test (#5179)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",2,4,2022-07-03 13:11:12-07:00,"['SparkTestBase.java', 'TestCreateActions.java']"
API: Add java type to composite TypeID enums (#5154),4,195,2022-07-03 13:14:05-07:00,"['Accessors.java', 'Comparators.java', 'Type.java', 'TestComparators.java']"
"Docs: Add Flink and Iceberg type compatibility tables (#4865)

Co-authored-by:  <wuwenchi@deepexi.com>",1,64,2022-07-03 13:21:31-07:00,['flink-getting-started.md']
Flink: Fix typo in FlinkSink string (#5176),3,6,2022-07-05 08:32:49-07:00,"['FlinkSink.java', 'FlinkSink.java', 'FlinkSink.java']"
Docs: Fix typo in docs (#5202),1,11,2022-07-05 11:04:11-07:00,['hive.md']
Core: Fix ErrorProne Warnings (#5200),10,19,2022-07-05 11:06:00-07:00,"['ManifestFiles.java', 'MetricsModes.java', 'Avro.java', 'InputFilesDecryptor.java', 'JdbcCatalog.java', 'CatalogHandlers.java', 'RESTSessionCatalog.java', 'Tasks.java', 'ZOrderByteUtils.java', 'TestReadProjection.java']"
Arrow: Fix for dictionary encoded fixed length binary decimals (#5198),8,135,2022-07-05 16:36:23-07:00,"['GenericArrowVectorAccessorFactory.java', 'DecimalVectorUtil.java', 'VectorizedDictionaryEncodedParquetValuesReader.java', 'VectorizedParquetDefinitionLevelReader.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'AvroDataTest.java', 'TestParquetVectorizedReads.java']"
Core: Defer reading Avro metadata until ManifestFile is read (#5206),1,57,2022-07-06 07:01:38-07:00,['ManifestGroup.java']
Core: Add length arg to FileIO.newInputFile (#5207),13,83,2022-07-06 07:02:06-07:00,"['FileIO.java', 'S3FileIO.java', 'S3InputFile.java', 'S3OutputFile.java', 'ManifestFiles.java', 'RemoveSnapshots.java', 'HadoopFileIO.java', 'HadoopInputFile.java', 'ResolvingFileIO.java', 'TestCatalogUtilDropTable.java', 'GCSFileIO.java', 'GCSInputFile.java', 'GCSOutputFile.java']"
"Build: Update Parquet and Avro dependencies (#5188)

Co-authored-by: Kyle Bendickson <kjbendickson@gmail.com>",5,19,2022-07-06 07:31:39-07:00,"['build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'versions.props']"
Spark: Add procedure to publish WAP changes using wap.id (#4715),9,855,2022-07-06 14:25:52-07:00,"['TestPublishChangesProcedure.java', 'PublishChangesProcedure.java', 'SparkProcedures.java', 'TestPublishChangesProcedure.java', 'PublishChangesProcedure.java', 'SparkProcedures.java', 'TestPublishChangesProcedure.java', 'PublishChangesProcedure.java', 'SparkProcedures.java']"
"Hive: Return null if Hive inspects a null struct record (#4283)

Fix #4282",3,50,2022-07-06 14:27:09-07:00,"['IcebergRecordObjectInspector.java', 'TestHiveIcebergStorageHandlerWithEngine.java', 'TestIcebergRecordObjectInspector.java']"
Spark 3.3: Skip pushdown of non-evaluable filters (#5204),2,22,2022-07-06 15:18:52-07:00,"['SparkScanBuilder.java', 'TestSelect.java']"
Arrow/AWS/Core/Hive: Fix ErrorProne warnings (#5212),5,9,2022-07-07 08:55:18-05:00,"['ArrowReader.java', 'TestGlueCatalogTable.java', 'GlueTableOperations.java', 'ZOrderByteUtils.java', 'HiveTableOperations.java']"
"Core: Use table partitioning with manual sort order (#5187)

Co-authored-by: Rajarshi Sarkar <srajars@amazon.com>",1,4,2022-07-07 16:17:47-07:00,['SortStrategy.java']
Core: Fix REST catalog when reverting DDL changes. (#5226),2,83,2022-07-07 18:23:19-07:00,"['TableMetadata.java', 'CatalogTests.java']"
"Spark-3.2: Support Zorder option for rewrite_data_files stored procedure (#4902)


Co-authored-by: Ryan Blue <blue@apache.org>",11,283,2022-07-08 09:45:26-05:00,"['Zorder.java', 'spark-procedures.md', 'IcebergSqlExtensions.g4', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'TestRewriteDataFilesProcedure.java', 'ExtendedParser.java', 'Spark3Util.java', 'BaseRewriteDataFilesSparkAction.java', 'SparkZOrderStrategy.java', 'RewriteDataFilesProcedure.java']"
Spark: Provide size estimate for table broadcast (#5225),33,384,2022-07-08 08:14:45-07:00,"['SerializableTable.java', 'SerializableTableWithSize.java', 'SparkBatchScan.java', 'SparkMicroBatchStream.java', 'SparkWrite.java', 'TestFileIOSerialization.java', 'TestTableSerialization.java', 'TestSparkCatalogHadoopOverrides.java', 'SerializableTableWithSize.java', 'SparkBatchScan.java', 'SparkMicroBatchStream.java', 'SparkWrite.java', 'TestFileIOSerialization.java', 'TestTableSerialization.java', 'TestSparkCatalogHadoopOverrides.java', 'BaseSparkAction.java', 'SerializableTableWithSize.java', 'SparkBatch.java', 'SparkMicroBatchStream.java', 'SparkPositionDeltaWrite.java', 'SparkWrite.java', 'TestFileIOSerialization.java', 'TestTableSerialization.java', 'TestSparkCatalogHadoopOverrides.java', 'BaseSparkAction.java', 'SerializableTableWithSize.java', 'SparkBatch.java', 'SparkMicroBatchStream.java', 'SparkPositionDeltaWrite.java', 'SparkWrite.java', 'TestFileIOSerialization.java', 'TestTableSerialization.java', 'TestSparkCatalogHadoopOverrides.java']"
Core: Update MetricsConfig to use a default for first 32 columns (#5215),4,156,2022-07-08 11:24:33-07:00,"['MetricsConfig.java', 'TableProperties.java', 'TestMetricsModes.java', 'TestWriterMetrics.java']"
Spark 3.2: Skip pushdown of non-evaluable filters (#5227),2,22,2022-07-08 11:30:05-07:00,"['SparkScanBuilder.java', 'TestSelect.java']"
Flink: Read RowData by default in FLIP-27 source (#5220),7,73,2022-07-10 10:45:24-07:00,"['IcebergSource.java', 'ArrayPoolDataIteratorBatcher.java', 'RowDataReaderFunction.java', 'TestIcebergSourceBounded.java', 'TestIcebergSourceContinuous.java', 'TestIcebergSourceFailover.java', 'TestIcebergSourceReaderDeletes.java']"
"Flink 1.14: FLIP-27 Iceberg source and builder, port #5109 (#5191)",11,1331,2022-07-10 10:47:36-07:00,"['IcebergSource.java', 'ScanContext.java', 'SimpleSplitAssigner.java', 'ContinuousSplitPlannerImpl.java', 'SimpleDataUtil.java', 'TestFixtures.java', 'RowDataToRowMapper.java', 'TestIcebergSourceBounded.java', 'TestIcebergSourceContinuous.java', 'TestIcebergSourceFailover.java', 'TestIcebergSourceReaderDeletes.java']"
Core: Document prefix in REST catalog spec (#5233),2,90,2022-07-10 10:56:33-07:00,"['open-api.yml', 'rest-catalog-open-api.yaml']"
Build: Add task to generate a git properties file (#5228),1,12,2022-07-10 12:56:00-07:00,['build.gradle']
Build: Add iceberg-build.properties to Jars and release process (#5236),4,35,2022-07-10 14:54:35-07:00,"['build.gradle', 'deploy.gradle', 'source-release.sh', 'tasks.gradle']"
Python: Reenable mypy (#5171),8,58,2022-07-10 15:42:32-07:00,"['.pre-commit-config.yaml', 'base.py', 'memory.py', 'pyproject.toml', 'test_decoder.py', 'conftest.py', 'test_io_base.py', 'test_schema.py']"
Core: Improve in and not_in predicate eval for all_manifests.reference_snapshot_id (#5232),1,10,2022-07-10 15:43:33-07:00,['AllManifestsTable.java']
"Python: Remove operation enum, add In expression (#4816)

Co-authored-by: Samuel Redai <43911210+samredai@users.noreply.github.com>",2,490,2022-07-10 16:10:45-07:00,"['base.py', 'test_expressions_base.py']"
REST: Create commit catalog handler fix (#5235),5,165,2022-07-10 16:47:51-07:00,"['TableMetadata.java', 'CatalogHandlers.java', 'RESTSessionCatalog.java', 'CatalogTests.java', 'TestLoadTableResponse.java']"
"Spark-3.3: Support Zorder option for rewrite_data_files stored procedure (#5229)(Backport #4902)

* Ports #4902",9,248,2022-07-11 09:29:25-05:00,"['IcebergSqlExtensions.g4', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'TestRewriteDataFilesProcedure.java', 'ExtendedParser.java', 'Spark3Util.java', 'BaseRewriteDataFilesSparkAction.java', 'SparkZOrderStrategy.java', 'RewriteDataFilesProcedure.java']"
API: Add IcebergBuild info (#5237),4,219,2022-07-11 09:00:51-07:00,"['IcebergBuild.java', 'TestIcebergBuild.java', 'build.gradle', 'tasks.gradle']"
Core: Add build info to REST requests in HTTP headers (#5238),2,28,2022-07-11 10:51:01-07:00,"['HTTPClientFactory.java', 'TestHTTPClient.java']"
"Docs: Add time travel examples for Spark SQL (#5180)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",1,39,2022-07-11 11:00:54-07:00,['spark-queries.md']
API: Fix API Javadoc (#5190),2,4,2022-07-11 11:07:11-07:00,"['CredentialSupplier.java', 'FileIO.java']"
Spark 3.3: Add procedure to publish WAP changes using wap.id (#5223),3,285,2022-07-11 11:09:58-07:00,"['TestPublishChangesProcedure.java', 'PublishChangesProcedure.java', 'SparkProcedures.java']"
"Flink 1.14: Read RowData by default in FLIP-27 source, port of #5220 (#5241)",7,74,2022-07-11 11:20:30-07:00,"['IcebergSource.java', 'ArrayPoolDataIteratorBatcher.java', 'RowDataReaderFunction.java', 'TestIcebergSourceBounded.java', 'TestIcebergSourceContinuous.java', 'TestIcebergSourceFailover.java', 'TestIcebergSourceReaderDeletes.java']"
Python: Add Makefile argument to pass args to pytest (#5246),2,16,2022-07-11 11:26:20-07:00,"['CONTRIBUTING.md', 'Makefile']"
"Core: Fix wrapper performance for delete filters (#5249)

Core: Add StructLikeWrapper#copyFor to avoid type analysis.
Core: Add InternalRecordWrapper#copyFor to avoid type analysis.

Co-Authored-By: shidayang <530847445@qq.com>
Closes #5242.
Closes #5244.",7,53,2022-07-11 14:59:27-07:00,"['DeleteFileIndex.java', 'BaseRewriteDataFilesAction.java', 'StructLikeMap.java', 'StructLikeSet.java', 'StructLikeWrapper.java', 'DeleteFilter.java', 'InternalRecordWrapper.java']"
Python: Add sort order fields (#5124),10,812,2022-07-11 16:21:31-07:00,"['schema.py', 'metadata.py', 'sorting.py', 'transforms.py', 'types.py', 'parsing.py', 'test_metadata.py', 'test_partitioning.py', 'test_sorting.py', 'test_transforms.py']"
Python: Add BindVisitor to bind a BooleanExpression to a Schema (#5239),3,359,2022-07-11 16:28:27-07:00,"['base.py', 'test_expressions_base.py', 'test_types.py']"
Spark: Add Spark catalog for loading tables from cache (#5247),27,1121,2022-07-11 17:12:59-07:00,"['ActionsProvider.java', 'TestRewriteDataFilesProcedure.java', 'IcebergSortCompactionBenchmark.java', 'SparkCachedTableCatalog.java', 'SparkTableCache.java', 'BaseRewriteDataFilesSparkAction.java', 'SparkActions.java', 'SparkBinPackStrategy.java', 'SparkSortStrategy.java', 'SparkZOrderStrategy.java', 'RewriteDataFilesProcedure.java', 'IcebergSource.java', 'TestSparkCachedTableCatalog.java', 'TestRewriteDataFilesAction.java', 'TestRewriteDataFilesProcedure.java', 'IcebergSortCompactionBenchmark.java', 'SparkCachedTableCatalog.java', 'SparkTableCache.java', 'BaseRewriteDataFilesSparkAction.java', 'SparkActions.java', 'SparkBinPackStrategy.java', 'SparkSortStrategy.java', 'SparkZOrderStrategy.java', 'RewriteDataFilesProcedure.java', 'IcebergSource.java', 'TestSparkCachedTableCatalog.java', 'TestRewriteDataFilesAction.java']"
Spark 3.3: Rename output columns in register_table procedure (#5253),1,6,2022-07-12 08:15:01-07:00,['RegisterTableProcedure.java']
Core: Load equality deletes only initialize once per DeleteFilter (#5195),1,7,2022-07-12 09:54:04-07:00,['DeleteFilter.java']
"Core: Fix REST catalog metadata table loading. (#5255)

* Core: Fix REST catalog metadata table loading.

* Update metadata table test.",3,15,2022-07-12 09:59:12-07:00,"['MetadataTableUtils.java', 'RESTSessionCatalog.java', 'CatalogTests.java']"
Python: Move Snapshot to Pydantic (#5201),4,224,2022-07-12 10:54:22-07:00,"['metadata.py', 'snapshots.py', 'test_metadata.py', 'test_snapshots.py']"
"Core, AWS: Remove throw in finally block (#5222)",3,9,2022-07-12 13:16:33-07:00,"['DynamoDbTableOperations.java', 'GlueTableOperations.java', 'HiveTableOperations.java']"
Spark 3.2: Rename output columns in register_table procedure (#5260),1,6,2022-07-12 13:17:55-07:00,['RegisterTableProcedure.java']
Build: Fix gradle warning for optimizations disabled for API tests (#5252),1,2,2022-07-12 13:21:41-07:00,['build.gradle']
Core: Add copy(withStats) to ContentFile (#5213),5,38,2022-07-12 13:22:51-07:00,"['ContentFile.java', 'FindFiles.java', 'GenericManifestEntry.java', 'ManifestGroup.java', 'ManifestReader.java']"
Python: Bump pre-commit versions (#5203),1,8,2022-07-12 13:23:26-07:00,['.pre-commit-config.yaml']
Flink: Port #3998 to Flink 1.13 & 1.14 (#5194),14,1052,2022-07-12 13:24:01-07:00,"['FlinkConfParser.java', 'FlinkWriteConf.java', 'FlinkWriteOptions.java', 'FlinkSink.java', 'RowDataTaskWriterFactory.java', 'TestFlinkIcebergSink.java', 'TestIcebergStreamWriter.java', 'FlinkConfParser.java', 'FlinkWriteConf.java', 'FlinkWriteOptions.java', 'FlinkSink.java', 'RowDataTaskWriterFactory.java', 'TestFlinkIcebergSink.java', 'TestIcebergStreamWriter.java']"
"API: Fix exception thrown in runSafely, suppress error prone warning (#5259)",1,5,2022-07-12 15:59:03-07:00,['ExceptionUtil.java']
Spark 3.3: Expose action classes in SparkActions (#5257),17,325,2022-07-12 16:00:40-07:00,"['BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java', 'BaseTableCreationSparkAction.java', 'DeleteOrphanFilesSparkAction.java', 'DeleteReachableFilesSparkAction.java', 'ExpireSnapshotsSparkAction.java', 'MigrateTableSparkAction.java', 'RewriteDataFilesSparkAction.java', 'RewriteManifestsSparkAction.java', 'SnapshotTableSparkAction.java', 'SparkActions.java', 'ExpireSnapshotsProcedure.java', 'RemoveOrphanFilesProcedure.java', 'RewriteManifestsProcedure.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRewriteDataFilesAction.java']"
Spark 3.2: Expose action classes in SparkActions (#5261),24,4028,2022-07-12 16:00:50-07:00,"['BaseDeleteOrphanFilesSparkAction.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseExpireSnapshotsSparkAction.java', 'BaseMigrateTableSparkAction.java', 'BaseRewriteDataFilesSparkAction.java', 'BaseRewriteManifestsSparkAction.java', 'BaseSnapshotTableSparkAction.java', 'BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java', 'BaseTableCreationSparkAction.java', 'DeleteOrphanFilesSparkAction.java', 'DeleteReachableFilesSparkAction.java', 'ExpireSnapshotsSparkAction.java', 'MigrateTableSparkAction.java', 'RewriteDataFilesSparkAction.java', 'RewriteManifestsSparkAction.java', 'SnapshotTableSparkAction.java', 'SparkActions.java', 'ExpireSnapshotsProcedure.java', 'RemoveOrphanFilesProcedure.java', 'RewriteManifestsProcedure.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRewriteDataFilesAction.java']"
Spark: Log warning on filter pushdown failure (#5254),2,14,2022-07-12 22:14:48-07:00,"['SparkScanBuilder.java', 'SparkScanBuilder.java']"
Build: Upgrade test dependencies (#5210),5,29,2022-07-12 22:26:13-07:00,"['TestGlueCatalogCommitFailure.java', 'TestHadoopCommits.java', 'TestHiveCommitLocks.java', 'TestHiveCommits.java', 'versions.props']"
"Update License Header (#5265)

This updates the License header for the IDE to be in-line with https://iceberg.apache.org/contribute/#configuring-copyright-for-intellij-idea
and also with the license header in Java files.",1,23,2022-07-13 08:04:08-07:00,['001_apache-2.0.txt']
Python: Move PartitionSpec to Pydantic (#5192),8,199,2022-07-13 12:09:30-07:00,"['base.py', 'base.py', 'metadata.py', 'partitioning.py', 'transforms.py', 'test_base.py', 'test_metadata.py', 'test_partitioning.py']"
"Flink 1.13, 1.14: Port maxPlanningSnapshotCount configuration from #4943 (#5263)",8,272,2022-07-13 12:10:52-07:00,"['FlinkSource.java', 'ScanContext.java', 'StreamingMonitorFunction.java', 'TestStreamingMonitorFunction.java', 'FlinkSource.java', 'ScanContext.java', 'StreamingMonitorFunction.java', 'TestStreamingMonitorFunction.java']"
Build: Unify github action versions (#5211),1,5,2022-07-14 12:05:23-05:00,['api-binary-compatibility.yml']
"Build: Exclude unnecessary git properties from iceberg-build.properties (#5277)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",1,2,2022-07-15 08:32:00-07:00,['build.gradle']
Spark: Remove stack trace from log for filter pushdown failure (#5274),2,16,2022-07-15 11:18:46-07:00,"['SparkScanBuilder.java', 'SparkScanBuilder.java']"
Spark: Update Spark 2.4 JMH instructions for renamed module (#5189),20,80,2022-07-15 13:41:21-05:00,"['SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java']"
Dell: Fix bugs during documenting (#5059),2,5,2022-07-16 19:20:54+08:00,"['DellClientFactory.java', 'PropertiesSerDesUtil.java']"
"Hive: Fix typo depracated to deprecated (#5285)

typos depracated to deprecated",1,2,2022-07-16 13:12:27-07:00,['Catalogs.java']
Build: Fix Scala 2.13 builds in stage-binaries.sh. (#5270),1,4,2022-07-17 23:16:46+08:00,['stage-binaries.sh']
Build: Add iceberg-build.properties to RAT excludes. (#5262),1,1,2022-07-17 23:18:11+08:00,['.rat-excludes']
AWS: DynamoCatalog: Pass CommitFailedException up the stack without wrapping (#5299),1,3,2022-07-18 16:16:56-07:00,['DynamoDbTableOperations.java']
Build: Use Google Java Format for spotless (#5266),3,31,2022-07-19 09:16:40-07:00,"['copyright-header-java.txt', 'baseline.gradle', 'build.gradle']"
AWS: avoid retry for AWS service user errors in GlueTableOperations (#5304),2,81,2022-07-19 10:35:08-07:00,"['TestGlueCatalogCommitFailure.java', 'GlueTableOperations.java']"
AWS: Fix setup of S3 batch deletion tests (#5289),2,50,2022-07-19 11:37:40-07:00,"['TestS3FileIOIntegration.java', 'TestS3FileIO.java']"
"Prevent usage of @Test(expected = ...) and change existing tests (#5221)

We should avoid usage of `@Test(expected = ...)` because it is not
always clear from where exactly an exception is thrown. We should rather
promote using
`Assertions.assertThatThrownBy(...).isInstanceOf(...).hasMessage(...)`
as that makes sure that we are in fact getting the right exception with
the appropriate error message.",18,345,2022-07-19 14:44:27-07:00,"['checkstyle.xml', 'TestExpressionBinding.java', 'TestStringLiteralConversions.java', 'TestResiduals.java', 'TestTypeUtil.java', 'DecimalVectorUtilTest.java', 'HadoopMetricsContext.java', 'TestSingleMessageEncoding.java', 'HiveTableTest.java', 'SchemaUtilTest.java', 'SchemaEvolutionTest.java', 'TestSnapshotSelection.java', 'TestSnapshotSelection.java', 'TestSnapshotSelection.java', 'TestHadoopMetricsContextSerialization.java', 'TestSnapshotSelection.java', 'TestHadoopMetricsContextSerialization.java', 'TestSnapshotSelection.java']"
"API: Avoid hasNext in CloseableIterable.concat (#5306)

Some iterables need to load the first item to check whether there is a next item, which can cause an extra open call.",2,59,2022-07-19 19:43:51-07:00,"['CloseableIterable.java', 'TestCloseableIterable.java']"
API: Introduce DefaultMetricsContext and Timer interface (#5286),9,759,2022-07-19 19:46:43-07:00,"['DefaultMetricsContext.java', 'DefaultTimer.java', 'IntCounter.java', 'LongCounter.java', 'MetricsContext.java', 'Timer.java', 'TestDefaultMetricsContext.java', 'TestDefaultTimer.java', 'GuavaClasses.java']"
Docs: Fix Flink Connector docs with custom catalog (#5045),2,12,2022-07-20 11:56:12+02:00,"['flink-connector.md', 'flink-getting-started.md']"
Spark: Correct SparkCatalog javadoc for supplying custom catalog (#5288),4,28,2022-07-20 13:50:09+02:00,"['SparkCatalog.java', 'SparkCatalog.java', 'SparkCatalog.java', 'SparkCatalog.java']"
StreamingDelete constructor can be called by subclasses (#5271),1,2,2022-07-20 14:39:31+02:00,['StreamingDelete.java']
"Core: Avoid extra manifest read (#5309)

Closes #5308",1,4,2022-07-20 11:14:02-07:00,['ManifestGroup.java']
Python: Add __version__ to the package (#5315),4,38,2022-07-21 08:33:52-07:00,"['RELEASE.md', '__init__.py', 'pyproject.toml', 'test_version.py']"
Python: Remove .python-version file (#5326),1,3,2022-07-21 08:36:42-07:00,['.python-version']
Build: Upgrade slf4j to 1.7.36 (#5320),1,2,2022-07-21 08:40:53-07:00,['versions.props']
Core: Avoid NPE in SchemaParser if a type is missing (#5291),3,72,2022-07-21 10:13:43-07:00,"['SchemaParser.java', 'TestLoadTableResponse.java', 'TableMetadataV1MissingSchemaType.json']"
Build: Upgrade Guava to 31.1-jre (#5322),1,2,2022-07-21 14:50:15-07:00,['versions.props']
Core: Add MetadataLogs metadata table (#5063),5,292,2022-07-21 17:37:45-07:00,"['MetadataLogsTable.java', 'MetadataTableType.java', 'MetadataTableUtils.java', 'TestMetadataTables.java', 'TestMetadataTables.java']"
Core: Implement BaseMetastoreCatalog.registerTable() (#5037),9,287,2022-07-22 11:02:52+02:00,"['TestDynamoDbCatalog.java', 'TestGlueCatalogTable.java', 'BaseMetastoreCatalog.java', 'TestHadoopCatalog.java', 'TestJdbcCatalog.java', 'TestEcsCatalog.java', 'HiveCatalog.java', 'NessieTableOperations.java', 'TestNessieTable.java']"
Python: Bump dependencies to the latest version (#5325),1,270,2022-07-22 08:14:34-07:00,['poetry.lock']
Python: Bump pre-commit plugins to the latest version (#5324),1,8,2022-07-22 08:15:02-07:00,['.pre-commit-config.yaml']
"Python: Remove unused function (#5296)

Less is more",1,4,2022-07-22 08:15:26-07:00,['schema.py']
"Spec: Add sequence-number and parent-snapshot-id (#5196)

* Spec: Add sequence-number and parent-snapshot-id

These fields are read/written by the Java reference implementation:
https://github.com/apache/iceberg/blob/master/core/src/main/java/org/apache/iceberg/SnapshotParser.java

I figured it would be nice to add them here as well.

* Re-arrange in the same order as the spec",1,8,2022-07-22 09:05:48-07:00,['rest-catalog-open-api.yaml']
Build: Let revapi compare API compatibility against apache-iceberg-0.14.0 (#5336),1,2,2022-07-22 10:10:21-07:00,['revapi.yml']
Build: Use apache-iceberg- tag prefix to set SNAPSHOT version (#5341),1,4,2022-07-22 10:14:31-07:00,['build.gradle']
Python: Add dependabot for keeping the dependencies up to date (#5340),1,27,2022-07-22 10:15:04-07:00,['dependabot.yml']
Spark: Support partition transforms with using any case (#5335),8,64,2022-07-22 10:21:28-07:00,"['Spark3Util.java', 'TestCreateTable.java', 'Spark3Util.java', 'TestCreateTable.java', 'Spark3Util.java', 'TestCreateTable.java', 'Spark3Util.java', 'TestCreateTable.java']"
Python: Map Manifest onto Pydantic class (#5298),2,463,2022-07-22 10:28:33-07:00,"['manifest.py', 'test_manifest.py']"
AWS: Fix PUT retry failures by opening new data file streams (#5282),1,8,2022-07-22 10:32:04-07:00,['S3OutputStream.java']
"Bump zstandard from 0.17.0 to 0.18.0 in /python (#5342)

Bumps [zstandard](https://github.com/indygreg/python-zstandard) from 0.17.0 to 0.18.0.
- [Release notes](https://github.com/indygreg/python-zstandard/releases)
- [Changelog](https://github.com/indygreg/python-zstandard/blob/main/docs/news.rst)
- [Commits](https://github.com/indygreg/python-zstandard/compare/0.17.0...0.18.0)

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,211,2022-07-22 13:18:29-07:00,"['poetry.lock', 'pyproject.toml']"
Core: Print date/time strings with +00:00 zone offset (#5337),7,72,2022-07-22 15:30:08-07:00,"['FindFiles.java', 'DateTimeUtil.java', 'TestDateTimeUtil.java', 'TestContinuousSplitPlannerImpl.java', 'TestContinuousSplitPlannerImplStartStrategy.java', 'TestContinuousSplitPlannerImpl.java', 'TestContinuousSplitPlannerImplStartStrategy.java']"
"API: Deprecate Counter#count(), add Counter#value() (#5328)",6,67,2022-07-22 16:08:20-07:00,"['IntCounter.java', 'LongCounter.java', 'MetricsContext.java', 'TestDefaultMetricsContext.java', 'ReaderMetricsContext.java', 'ReaderMetricsContext.java']"
AWS: Add LakeFormation Integration tests (#4423),4,962,2022-07-25 09:24:39-07:00,"['LakeFormationTestBase.java', 'TestLakeFormationDataOperations.java', 'TestLakeFormationMetadataOperations.java', 'GlueTableOperations.java']"
Python: Add more expression classes (#5258),2,677,2022-07-25 12:37:26-07:00,"['base.py', 'test_expressions_base.py']"
Spark: Support _deleted metadata column in vectorized reads (#4888),24,826,2022-07-25 16:52:41-07:00,"['VectorHolder.java', 'VectorizedArrowReader.java', 'VectorizedReaderBuilder.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkParquetReadMetadataColumns.java', 'IcebergSourceBenchmark.java', 'IcebergSourceDeleteBenchmark.java', 'ColumnVectorBuilder.java', 'ColumnVectorWithFilter.java', 'ColumnarBatchReader.java', 'DeletedColumnVector.java', 'IcebergArrowColumnVector.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkReaderDeletes.java', 'IcebergSourceBenchmark.java', 'IcebergSourceDeleteBenchmark.java', 'ColumnVectorBuilder.java', 'ColumnVectorWithFilter.java', 'ColumnarBatchReader.java', 'DeletedColumnVector.java', 'IcebergArrowColumnVector.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkReaderDeletes.java']"
AWS: Make glue endpoint configurable #5095 (#5330),3,28,2022-07-25 16:57:32-07:00,"['TestDefaultAwsClientFactory.java', 'AwsClientFactories.java', 'AwsProperties.java']"
Spark 3.3: Fix typo (#5354),1,2,2022-07-26 09:42:40-07:00,['SparkTableUtil.java']
Spec: Add table statistics tracking (#4945),1,28,2022-07-26 09:57:16-07:00,['spec.md']
Core: Support creating custom tasks in ManifestGroup (#5301),1,68,2022-07-26 10:10:21-07:00,['ManifestGroup.java']
"Spark: Use constants for path, versionAsOf, and timestampAsOf (#5347)",3,19,2022-07-26 10:12:55-07:00,"['SparkReadOptions.java', 'IcebergSource.java', 'TestSelect.java']"
Parquet: Use consistent random for bloom filter tests (#5329),1,12,2022-07-26 10:20:47-07:00,['TestBloomRowGroupFilter.java']
Spark 3.3: Support different task types in readers (#5248),8,685,2022-07-26 12:59:29-07:00,"['PartitionUtil.java', 'BaseBatchReader.java', 'BaseReader.java', 'BaseRowReader.java', 'BatchDataReader.java', 'EqualityDeleteRowReader.java', 'RowDataReader.java', 'TestBaseReader.java']"
"AWS: Verify Mock Invocation in OutputStream Tests  (#5317)


Co-authored-by: Abid Mohammed <abid_mohammed@apple.com>",1,36,2022-07-26 16:54:36-05:00,['TestS3OutputStream.java']
AWS: Fix malformed Javadoc (#5359),1,2,2022-07-26 16:13:05-07:00,['AwsProperties.java']
Spark 3.2: Add prefix mismatch mode for deleting orphan files (#4652),6,565,2022-07-26 18:40:38-07:00,"['DeleteOrphanFiles.java', 'TestRemoveOrphanFilesProcedure.java', 'DeleteOrphanFilesSparkAction.java', 'SetAccumulator.java', 'RemoveOrphanFilesProcedure.java', 'TestRemoveOrphanFilesAction.java']"
Spark 3.2: Support different task types in readers (#5363),7,676,2022-07-26 18:42:41-07:00,"['BaseBatchReader.java', 'BaseReader.java', 'BaseRowReader.java', 'BatchDataReader.java', 'EqualityDeleteRowReader.java', 'RowDataReader.java', 'TestBaseReader.java']"
"Build: Memoize getProjectVersion (#5051)

Moves the call to `getProjectVersion()` out of the ""loop"" that's evaluated for
every Gradle project and memoize the return value",1,4,2022-07-27 09:39:09-05:00,['build.gradle']
Nessie: Do not delete default branch in tests (#5193),2,46,2022-07-27 10:38:33-05:00,"['BaseTestIceberg.java', 'TestNessieCatalog.java']"
Core: Add base implementations for changelog tasks (#5300),14,848,2022-07-27 09:08:01-07:00,"['AddedRowsScanTask.java', 'DeletedDataFileScanTask.java', 'DeletedRowsScanTask.java', 'BaseAddedRowsScanTask.java', 'BaseChangelogContentScanTask.java', 'BaseContentScanTask.java', 'BaseDeletedDataFileScanTask.java', 'BaseDeletedRowsScanTask.java', 'BaseFileScanTask.java', 'FixedSizeSplitScanTaskIterator.java', 'OffsetsAwareSplitScanTaskIterator.java', 'SplitScanTaskIterator.java', 'TestFixedSizeSplitScanTaskIterator.java', 'TestOffsetsBasedSplitScanTaskIterator.java']"
"Remove conflicting checkstyle checks due to Spotless

This is the minimal set of checkstyle rules that were conflicting with
the code format that Spotless would apply. Additionally, this adds a few
`MethodLength` suppressions since those methods will become slightly
longer than the limit after formatting has been applied.",5,64,2022-07-27 11:37:20-07:00,"['checkstyle.xml', 'ArrowReaderTest.java', 'RemoveSnapshots.java', 'TestSchemaUpdate.java', 'TestIcebergObjectInspector.java']"
"Build: Use google-java-format 1.7 for JDK8 compatibility

Given that CI runs builds with JDK 8 & 11, the google-java-format will
actually pick different google-java-format versions depending on the JDK
being used (JDK8=google-java-format 1.7 / JDK11=google-java-format
latest). Those different google-java-format version are actually
producing different formatting results, thus we have to use
google-java-format 1.7 here to make things consistent across JDK
versions.",1,5,2022-07-27 11:37:20-07:00,['baseline.gradle']
"./gradlew spotlessApply

The actual command needs to be executed with JDK 8:
./gradlew spotlessApply -DflinkVersions=1.13,1.14,1.15 -DsparkVersions=2.4,3.0,3.1,3.2,3.3 -DhiveVersions=2,3 --no-build-cache",3078,282453,2022-07-27 11:37:20-07:00,"['AliyunClientFactories.java', 'AliyunClientFactory.java', 'AliyunProperties.java', 'BaseOSSFile.java', 'OSSFileIO.java', 'OSSInputFile.java', 'OSSInputStream.java', 'OSSOutputFile.java', 'OSSOutputStream.java', 'OSSURI.java', 'TestAliyunClientFactories.java', 'TestUtility.java', 'AliyunOSSTestBase.java', 'AliyunOSSTestRule.java', 'OSSIntegrationTestRule.java', 'TestOSSFileIO.java', 'TestOSSInputFile.java', 'TestOSSInputStream.java', 'TestOSSOutputFile.java', 'TestOSSOutputStream.java', 'TestOSSURI.java', 'AliyunOSSMockApp.java', 'AliyunOSSMockLocalController.java', 'AliyunOSSMockLocalStore.java', 'AliyunOSSMockRule.java', 'ObjectMetadata.java', 'Range.java', 'TestLocalAliyunOSS.java', 'Accessor.java', 'Accessors.java', 'AddedRowsScanTask.java', 'AppendFiles.java', 'BaseScanTaskGroup.java', 'ChangelogOperation.java', 'ChangelogScanTask.java', 'CombinedScanTask.java', 'ContentFile.java', 'ContentScanTask.java', 'DataFile.java', 'DataOperations.java', 'DataTask.java', 'DeleteFile.java', 'DeleteFiles.java', 'DeletedDataFileScanTask.java', 'DeletedRowsScanTask.java', 'DistributionMode.java', 'ExpireSnapshots.java', 'FileContent.java', 'FileFormat.java', 'FileScanTask.java', 'Files.java', 'HistoryEntry.java', 'IcebergBuild.java', 'IncrementalAppendScan.java', 'IncrementalChangelogScan.java', 'IncrementalScan.java', 'LockManager.java', 'ManageSnapshots.java', 'ManifestContent.java', 'ManifestFile.java', 'MergeableScanTask.java', 'Metrics.java', 'NullOrder.java', 'OverwriteFiles.java', 'PartitionField.java', 'PartitionKey.java', 'PartitionSpec.java', 'PendingUpdate.java', 'ReplacePartitions.java', 'ReplaceSortOrder.java', 'RewriteFiles.java', 'RewriteJobOrder.java', 'RewriteManifests.java', 'Rollback.java', 'RowDelta.java', 'Scan.java', 'ScanTask.java', 'ScanTaskGroup.java', 'Schema.java', 'Snapshot.java', 'SnapshotRef.java', 'SnapshotRefType.java', 'SnapshotUpdate.java', 'SortDirection.java', 'SortField.java', 'SortOrder.java', 'SortOrderBuilder.java', 'SplittableScanTask.java', 'StructLike.java', 'Table.java', 'TableScan.java', 'Tables.java', 'Transaction.java', 'UnboundPartitionSpec.java', 'UnboundSortOrder.java', 'UpdateLocation.java', 'UpdatePartitionSpec.java', 'UpdateProperties.java', 'UpdateSchema.java', 'Action.java', 'ActionsProvider.java', 'ConvertEqualityDeleteFiles.java', 'DeleteOrphanFiles.java', 'DeleteReachableFiles.java', 'ExpireSnapshots.java', 'MigrateTable.java', 'RewriteDataFiles.java', 'RewriteManifests.java', 'RewritePositionDeleteFiles.java', 'SnapshotTable.java', 'SnapshotUpdate.java', 'Catalog.java', 'Namespace.java', 'SessionCatalog.java', 'SupportsNamespaces.java', 'TableIdentifier.java', 'Record.java', 'EncryptedInputFile.java', 'EncryptedOutputFile.java', 'EncryptionKeyMetadata.java', 'EncryptionManager.java', 'KmsClient.java', 'IncrementalScanEvent.java', 'Listener.java', 'Listeners.java', 'ScanEvent.java', 'AlreadyExistsException.java', 'BadRequestException.java', 'CherrypickAncestorCommitException.java', 'CommitFailedException.java', 'CommitStateUnknownException.java', 'DuplicateWAPCommitException.java', 'ForbiddenException.java', 'NamespaceNotEmptyException.java', 'NoSuchIcebergTableException.java', 'NoSuchNamespaceException.java', 'NoSuchTableException.java', 'NotAuthorizedException.java', 'NotFoundException.java', 'RESTException.java', 'RuntimeIOException.java', 'ServiceFailureException.java', 'UnprocessableEntityException.java', 'ValidationException.java', 'And.java', 'Binder.java', 'Bound.java', 'BoundLiteralPredicate.java', 'BoundPredicate.java', 'BoundReference.java', 'BoundSetPredicate.java', 'BoundTerm.java', 'BoundTransform.java', 'BoundUnaryPredicate.java', 'Evaluator.java', 'Expression.java', 'ExpressionUtil.java', 'ExpressionVisitors.java', 'Expressions.java', 'False.java', 'InclusiveMetricsEvaluator.java', 'Literal.java', 'Literals.java', 'ManifestEvaluator.java', 'NamedReference.java', 'Not.java', 'Or.java', 'Predicate.java', 'Projections.java', 'Reference.java', 'ResidualEvaluator.java', 'RewriteNot.java', 'SerializationProxies.java', 'StrictMetricsEvaluator.java', 'Term.java', 'True.java', 'Unbound.java', 'UnboundPredicate.java', 'UnboundTerm.java', 'UnboundTransform.java', 'BulkDeletionFailureException.java', 'CloseableGroup.java', 'CloseableIterable.java', 'CloseableIterator.java', 'ClosingIterator.java', 'CredentialSupplier.java', 'DelegatingInputStream.java', 'DelegatingOutputStream.java', 'FileAppender.java', 'FileIO.java', 'FileIOMetricsContext.java', 'FileInfo.java', 'FilterIterator.java', 'InputFile.java', 'LocationProvider.java', 'OutputFile.java', 'PositionOutputStream.java', 'RangeReadable.java', 'SeekableInputStream.java', 'SupportsBulkOperations.java', 'SupportsPrefixOperations.java', 'DefaultMetricsContext.java', 'DefaultTimer.java', 'IntCounter.java', 'LongCounter.java', 'MetricsContext.java', 'Timer.java', 'Bucket.java', 'Dates.java', 'Identity.java', 'PartitionSpecVisitor.java', 'ProjectionUtil.java', 'SerializationProxies.java', 'SortOrderVisitor.java', 'Timestamps.java', 'Transform.java', 'TransformUtil.java', 'Transforms.java', 'Truncate.java', 'UnknownTransform.java', 'VoidTransform.java', 'AssignFreshIds.java', 'CheckCompatibility.java', 'Comparators.java', 'Conversions.java', 'FindTypeVisitor.java', 'GetProjectedIds.java', 'IndexById.java', 'IndexByName.java', 'IndexParents.java', 'JavaHash.java', 'JavaHashes.java', 'PrimitiveHolder.java', 'PruneColumns.java', 'ReassignIds.java', 'Type.java', 'TypeUtil.java', 'Types.java', 'BinaryUtil.java', 'ByteBuffers.java', 'CharSequenceSet.java', 'CharSequenceWrapper.java', 'ExceptionUtil.java', 'NaNUtil.java', 'StructProjection.java', 'UUIDUtil.java', 'UnicodeUtil.java', 'AssertHelpers.java', 'PartitionSpecTestBase.java', 'TestAccessors.java', 'TestHelpers.java', 'TestIcebergBuild.java', 'TestMetricsSerialization.java', 'TestPartitionPaths.java', 'TestPartitionSpecValidation.java', 'TestSnapshotRef.java', 'TestTransformSerialization.java', 'TestNamespace.java', 'TestTableIdentifier.java', 'TestListeners.java', 'TestEvaluator.java', 'TestExpressionBinding.java', 'TestExpressionHelpers.java', 'TestExpressionSerialization.java', 'TestExpressionUtil.java', 'TestInclusiveManifestEvaluator.java', 'TestInclusiveMetricsEvaluator.java', 'TestLiteralSerialization.java', 'TestMetricsEvaluatorsNaNHandling.java', 'TestMiscLiteralConversions.java', 'TestNumericLiteralConversions.java', 'TestPredicateBinding.java', 'TestStrictMetricsEvaluator.java', 'TestStringLiteralConversions.java', 'TestCloseableGroup.java', 'TestCloseableIterable.java', 'TestClosingIterator.java', 'TestableCloseableIterable.java', 'TestDefaultMetricsContext.java', 'TestDefaultTimer.java', 'TestBucketing.java', 'TestBucketingProjection.java', 'TestDates.java', 'TestDatesProjection.java', 'TestIdentity.java', 'TestNotStartsWith.java', 'TestProjection.java', 'TestResiduals.java', 'TestStartsWith.java', 'TestTimestamps.java', 'TestTimestampsProjection.java', 'TestTruncate.java', 'TestTruncatesProjection.java', 'TestTruncatesResiduals.java', 'TestBinaryComparator.java', 'TestCharSeqComparator.java', 'TestComparableComparator.java', 'TestComparators.java', 'TestConversions.java', 'TestReadabilityChecks.java', 'TestSerializableTypes.java', 'TestTypeUtil.java', 'RandomUtil.java', 'TestCharSequenceSet.java', 'TestExceptionUtil.java', 'ArrowAllocation.java', 'ArrowSchemaUtil.java', 'ArrowBatchReader.java', 'ArrowReader.java', 'ArrowVectorAccessor.java', 'ArrowVectorAccessors.java', 'BaseBatchReader.java', 'ColumnVector.java', 'ColumnarBatch.java', 'GenericArrowVectorAccessorFactory.java', 'NullabilityHolder.java', 'VectorHolder.java', 'VectorizedArrowReader.java', 'VectorizedReaderBuilder.java', 'VectorizedTableScanIterable.java', 'BaseVectorizedParquetValuesReader.java', 'DecimalVectorUtil.java', 'VectorizedColumnIterator.java', 'VectorizedDictionaryEncodedParquetValuesReader.java', 'VectorizedPageIterator.java', 'VectorizedParquetDefinitionLevelReader.java', 'ArrowSchemaUtilTest.java', 'ArrowReaderTest.java', 'DecimalVectorUtilTest.java', 'AssumeRoleAwsClientFactory.java', 'AwsClientFactories.java', 'AwsClientFactory.java', 'AwsProperties.java', 'DynamoDbCatalog.java', 'DynamoDbLockManager.java', 'DynamoDbTableOperations.java', 'DynamoLockManager.java', 'GlueCatalog.java', 'GlueTableOperations.java', 'GlueToIcebergConverter.java', 'IcebergToGlueConverter.java', 'LakeFormationAwsClientFactory.java', 'BaseS3File.java', 'S3FileIO.java', 'S3InputFile.java', 'S3InputStream.java', 'S3OutputFile.java', 'S3OutputStream.java', 'S3RequestUtil.java', 'S3URI.java', 'TestAwsClientFactories.java', 'TestAwsProperties.java', 'TestGlueCatalog.java', 'TestGlueToIcebergConverter.java', 'TestIcebergToGlueConverter.java', 'TestS3FileIO.java', 'TestS3InputStream.java', 'TestS3OutputStream.java', 'TestS3RequestUtil.java', 'TestS3URI.java', 'GuavaClasses.java', 'DynClasses.java', 'DynConstructors.java', 'DynFields.java', 'DynMethods.java', 'ZOrderByteUtilsBenchmark.java', 'AllDataFilesTable.java', 'AllDeleteFilesTable.java', 'AllEntriesTable.java', 'AllFilesTable.java', 'AllManifestsTable.java', 'BaseAddedRowsScanTask.java', 'BaseAllMetadataTableScan.java', 'BaseChangelogContentScanTask.java', 'BaseCombinedScanTask.java', 'BaseContentScanTask.java', 'BaseDeletedDataFileScanTask.java', 'BaseDeletedRowsScanTask.java', 'BaseFile.java', 'BaseFileScanTask.java', 'BaseFilesTable.java', 'BaseIncrementalAppendScan.java', 'BaseMetadataTable.java', 'BaseMetadataTableScan.java', 'BaseMetastoreCatalog.java', 'BaseMetastoreTableOperations.java', 'BaseOverwriteFiles.java', 'BaseReplacePartitions.java', 'BaseReplaceSortOrder.java', 'BaseRewriteFiles.java', 'BaseRewriteManifests.java', 'BaseRowDelta.java', 'BaseScan.java', 'BaseSnapshot.java', 'BaseTable.java', 'BaseTableScan.java', 'BaseTransaction.java', 'BaseUpdatePartitionSpec.java', 'CachingCatalog.java', 'CatalogProperties.java', 'CatalogUtil.java', 'CherryPickOperation.java', 'ClientPool.java', 'ClientPoolImpl.java', 'CommitCallbackTransaction.java', 'DataFiles.java', 'DataFilesTable.java', 'DataTableScan.java', 'DeleteFileIndex.java', 'DeleteFilesTable.java', 'DoubleFieldMetrics.java', 'FastAppend.java', 'FieldMetrics.java', 'FileMetadata.java', 'FilesTable.java', 'FindFiles.java', 'FixedSizeSplitScanTaskIterator.java', 'FloatFieldMetrics.java', 'GenericDataFile.java', 'GenericDeleteFile.java', 'GenericManifestEntry.java', 'GenericManifestFile.java', 'GenericPartitionFieldSummary.java', 'HasTableOperations.java', 'HistoryTable.java', 'IncrementalDataTableScan.java', 'IndexedStructLike.java', 'InheritableMetadata.java', 'InheritableMetadataFactory.java', 'IsolationLevel.java', 'LocationProviders.java', 'ManifestEntriesTable.java', 'ManifestEntry.java', 'ManifestFiles.java', 'ManifestFilterManager.java', 'ManifestGroup.java', 'ManifestListWriter.java', 'ManifestLists.java', 'ManifestMergeManager.java', 'ManifestReader.java', 'ManifestWriter.java', 'ManifestsTable.java', 'MergeAppend.java', 'MergingSnapshotProducer.java', 'MetadataColumns.java', 'MetadataLogsTable.java', 'MetadataTableType.java', 'MetadataTableUtils.java', 'MetadataUpdate.java', 'MetadataUpdateParser.java', 'MetricsConfig.java', 'MetricsModes.java', 'MetricsUtil.java', 'MicroBatches.java', 'OffsetsAwareSplitScanTaskIterator.java', 'PartitionData.java', 'PartitionSpecParser.java', 'PartitionSummary.java', 'Partitioning.java', 'PartitionsTable.java', 'PropertiesUpdate.java', 'ReachableFileUtil.java', 'RemoveSnapshots.java', 'RollbackToSnapshot.java', 'RowLevelOperationMode.java', 'ScanSummary.java', 'SchemaParser.java', 'SchemaUpdate.java', 'SerializableByteBufferMap.java', 'SerializableTable.java', 'SetLocation.java', 'SetSnapshotOperation.java', 'SnapshotIdGeneratorUtil.java', 'SnapshotManager.java', 'SnapshotParser.java', 'SnapshotProducer.java', 'SnapshotRefParser.java', 'SnapshotSummary.java', 'SnapshotsTable.java', 'SortOrderParser.java', 'SplitScanTaskIterator.java', 'StaticDataTask.java', 'StaticTableOperations.java', 'StaticTableScan.java', 'StreamingDelete.java', 'SystemProperties.java', 'TableMetadata.java', 'TableMetadataParser.java', 'TableOperations.java', 'TableProperties.java', 'TableScanContext.java', 'Transactions.java', 'UpdateSnapshotReferencesOperation.java', 'V1Metadata.java', 'V2Metadata.java', 'BaseAction.java', 'BaseDeleteOrphanFilesActionResult.java', 'BaseDeleteReachableFilesActionResult.java', 'BaseExpireSnapshotsActionResult.java', 'BaseFileGroupRewriteResult.java', 'BaseMigrateTableActionResult.java', 'BaseRewriteDataFilesAction.java', 'BaseRewriteDataFilesFileGroupInfo.java', 'BaseRewriteDataFilesResult.java', 'BaseRewriteManifestsActionResult.java', 'BaseSnapshotTableActionResult.java', 'BaseSnapshotUpdateAction.java', 'BinPackStrategy.java', 'ConvertEqualityDeleteStrategy.java', 'RewriteDataFilesActionResult.java', 'RewriteDataFilesCommitManager.java', 'RewriteFileGroup.java', 'RewritePositionDeleteStrategy.java', 'RewriteStrategy.java', 'SnapshotUpdateAction.java', 'SortStrategy.java', 'Avro.java', 'AvroCustomOrderSchemaVisitor.java', 'AvroEncoderUtil.java', 'AvroFileAppender.java', 'AvroIO.java', 'AvroIterable.java', 'AvroMetrics.java', 'AvroSchemaUtil.java', 'AvroSchemaVisitor.java', 'AvroSchemaWithTypeVisitor.java', 'AvroWithPartnerByStructureVisitor.java', 'BuildAvroProjection.java', 'GenericAvroReader.java', 'GenericAvroWriter.java', 'HasIds.java', 'LogicalMap.java', 'MetricsAwareDatumWriter.java', 'MissingIds.java', 'ProjectionDatumReader.java', 'PruneColumns.java', 'RemoveIds.java', 'SchemaToType.java', 'SupportsRowPosition.java', 'TypeToSchema.java', 'UUIDConversion.java', 'ValueReader.java', 'ValueReaders.java', 'ValueWriter.java', 'ValueWriters.java', 'BaseSessionCatalog.java', 'TableIdentifierParser.java', 'GenericRecord.java', 'IdentityPartitionConverters.java', 'DataReader.java', 'DataWriter.java', 'DecoderResolver.java', 'GenericReaders.java', 'GenericWriters.java', 'IcebergDecoder.java', 'IcebergEncoder.java', 'BitmapPositionDeleteIndex.java', 'Deletes.java', 'EqualityDeleteWriter.java', 'PositionDelete.java', 'PositionDeleteIndex.java', 'PositionDeleteWriter.java', 'BaseEncryptedInputFile.java', 'BaseEncryptedOutputFile.java', 'BaseEncryptionKeyMetadata.java', 'Ciphers.java', 'EncryptedFiles.java', 'EncryptionAlgorithm.java', 'EncryptionKeyMetadatas.java', 'InputFilesDecryptor.java', 'NativeFileCryptoParameters.java', 'NativelyEncryptedFile.java', 'PlaintextEncryptionManager.java', 'CreateSnapshotEvent.java', 'Zorder.java', 'ConfigProperties.java', 'Configurable.java', 'HadoopCatalog.java', 'HadoopConfigurable.java', 'HadoopFileIO.java', 'HadoopInputFile.java', 'HadoopMetricsContext.java', 'HadoopOutputFile.java', 'HadoopStreams.java', 'HadoopTableOperations.java', 'HadoopTables.java', 'HiddenPathFilter.java', 'SerializableConfiguration.java', 'Util.java', 'BasePositionDeltaWriter.java', 'BaseTaskWriter.java', 'ByteBufferInputStream.java', 'ClusteredDataWriter.java', 'ClusteredEqualityDeleteWriter.java', 'ClusteredPositionDeleteWriter.java', 'ClusteredWriter.java', 'DataWriteResult.java', 'DataWriter.java', 'DeleteSchemaUtil.java', 'DeleteWriteResult.java', 'EqualityDeltaWriter.java', 'FanoutDataWriter.java', 'FanoutWriter.java', 'FileAppenderFactory.java', 'FileIOParser.java', 'FileWriter.java', 'FileWriterFactory.java', 'IOUtil.java', 'MultiBufferInputStream.java', 'OutputFileFactory.java', 'PartitionedFanoutWriter.java', 'PartitionedWriter.java', 'PartitioningWriter.java', 'PositionDeltaWriter.java', 'ResolvingFileIO.java', 'RollingDataWriter.java', 'RollingEqualityDeleteWriter.java', 'RollingFileWriter.java', 'RollingPositionDeleteWriter.java', 'SingleBufferInputStream.java', 'SortedPosDeleteWriter.java', 'StructCopy.java', 'TaskWriter.java', 'UnpartitionedWriter.java', 'WriteResult.java', 'JdbcCatalog.java', 'JdbcClientPool.java', 'JdbcTableOperations.java', 'JdbcUtil.java', 'UncheckedInterruptedException.java', 'UncheckedSQLException.java', 'MappedField.java', 'MappedFields.java', 'MappingUtil.java', 'NameMapping.java', 'NameMappingParser.java', 'Blob.java', 'BlobMetadata.java', 'FileMetadata.java', 'FileMetadataParser.java', 'Puffin.java', 'PuffinCompressionCodec.java', 'PuffinFormat.java', 'PuffinReader.java', 'PuffinWriter.java', 'StandardBlobTypes.java', 'StandardPuffinProperties.java', 'CatalogHandlers.java', 'ErrorHandlers.java', 'HTTPClient.java', 'HTTPClientFactory.java', 'RESTCatalog.java', 'RESTClient.java', 'RESTMessage.java', 'RESTObjectMapper.java', 'RESTRequest.java', 'RESTResponse.java', 'RESTSerializers.java', 'RESTSessionCatalog.java', 'RESTTableOperations.java', 'RESTUtil.java', 'ResourcePaths.java', 'OAuth2Properties.java', 'OAuth2Util.java', 'CreateNamespaceRequest.java', 'CreateTableRequest.java', 'RenameTableRequest.java', 'UpdateNamespacePropertiesRequest.java', 'UpdateRequirementParser.java', 'UpdateTableRequest.java', 'ConfigResponse.java', 'CreateNamespaceResponse.java', 'ErrorResponse.java', 'ErrorResponseParser.java', 'GetNamespaceResponse.java', 'ListNamespacesResponse.java', 'ListTablesResponse.java', 'LoadTableResponse.java', 'OAuthTokenResponse.java', 'UpdateNamespacePropertiesResponse.java', 'SchemaWithPartnerVisitor.java', 'UnionByNameVisitor.java', 'FixupTypes.java', 'ArrayUtil.java', 'BinPacking.java', 'CopySortOrderFields.java', 'DateTimeUtil.java', 'DecimalUtil.java', 'EnvironmentUtil.java', 'Exceptions.java', 'Filter.java', 'JsonUtil.java', 'LocationUtil.java', 'LockManagers.java', 'ManifestFileUtil.java', 'Pair.java', 'ParallelIterable.java', 'PartitionSet.java', 'PartitionUtil.java', 'PropertyUtil.java', 'SerializableMap.java', 'SerializableSupplier.java', 'SerializationUtil.java', 'SnapshotUtil.java', 'SortOrderUtil.java', 'SortedMerge.java', 'StructLikeMap.java', 'StructLikeSet.java', 'StructLikeWrapper.java', 'TableScanUtil.java', 'Tasks.java', 'ThreadPools.java', 'WapUtil.java', 'ZOrderByteUtils.java', 'LocalTableOperations.java', 'MockFileScanTask.java', 'ScanTestBase.java', 'TableMetadataParserCodecTest.java', 'TableMetadataParserTest.java', 'TableTestBase.java', 'TestBaseIncrementalAppendScan.java', 'TestCatalogErrorConstructor.java', 'TestCatalogUtil.java', 'TestCreateSnapshotEvent.java', 'TestCreateTransaction.java', 'TestDataTableScan.java', 'TestDeleteFileIndex.java', 'TestDeleteFiles.java', 'TestEntriesMetadataTable.java', 'TestFastAppend.java', 'TestFilterFiles.java', 'TestFindFiles.java', 'TestFixedSizeSplitScanTaskIterator.java', 'TestFormatVersions.java', 'TestIncrementalDataTableScan.java', 'TestLocationProvider.java', 'TestManifestCleanup.java', 'TestManifestListVersions.java', 'TestManifestReader.java', 'TestManifestReaderStats.java', 'TestManifestWriter.java', 'TestManifestWriterVersions.java', 'TestMergeAppend.java', 'TestMetadataTableFilters.java', 'TestMetadataTableScans.java', 'TestMetadataUpdateParser.java', 'TestMetrics.java', 'TestMetricsModes.java', 'TestMetricsTruncation.java', 'TestMicroBatchBuilder.java', 'TestOffsetsBasedSplitScanTaskIterator.java', 'TestOverwrite.java', 'TestOverwriteWithValidation.java', 'TestPartitionSpecInfo.java', 'TestPartitionSpecParser.java', 'TestPartitioning.java', 'TestRemoveSnapshots.java', 'TestReplacePartitions.java', 'TestReplaceTransaction.java', 'TestRewriteFiles.java', 'TestRewriteManifests.java', 'TestRowDelta.java', 'TestScanDataFileColumns.java', 'TestScanSummary.java', 'TestScansAndSchemaEvolution.java', 'TestSchemaAndMappingUpdate.java', 'TestSchemaID.java', 'TestSchemaUnionByFieldName.java', 'TestSchemaUpdate.java', 'TestSequenceNumberForV2Table.java', 'TestSnapshot.java', 'TestSnapshotJson.java', 'TestSnapshotManager.java', 'TestSnapshotRefParser.java', 'TestSnapshotSelection.java', 'TestSnapshotSummary.java', 'TestSortOrder.java', 'TestSortOrderParser.java', 'TestSplitPlanning.java', 'TestTableMetadata.java', 'TestTableMetadataSerialization.java', 'TestTableUpdatePartitionSpec.java', 'TestTables.java', 'TestTimestampPartitions.java', 'TestTransaction.java', 'TestUpdatePartitionSpec.java', 'TestV1ToV2RowDeltaDelete.java', 'TestWapWorkflow.java', 'TestableCachingCatalog.java', 'V2TableTestBase.java', 'TestBinPackStrategy.java', 'TestSortStrategy.java', 'AvroDataTest.java', 'AvroTestHelpers.java', 'RandomAvroData.java', 'TestAvroDataWriter.java', 'TestAvroDeleteWriters.java', 'TestAvroEncoderUtil.java', 'TestAvroEnums.java', 'TestAvroFileSplit.java', 'TestAvroNameMapping.java', 'TestAvroOptionsWithNonNullDefaults.java', 'TestAvroReadProjection.java', 'TestAvroSchemaProjection.java', 'TestBuildAvroProjection.java', 'TestGenericAvro.java', 'TestHasIds.java', 'TestReadProjection.java', 'TestSchemaConversions.java', 'CatalogTests.java', 'TestTableIdentifierParser.java', 'TestEqualityFilter.java', 'TestPositionFilter.java', 'TestCiphers.java', 'KeyStoreKmsClient.java', 'MemoryMockKMS.java', 'HadoopFileIOTest.java', 'HadoopTableTestBase.java', 'TestCachingCatalog.java', 'TestCatalogUtilDropTable.java', 'TestHadoopCatalog.java', 'TestHadoopCommits.java', 'TestHadoopTables.java', 'TestStaticTable.java', 'TestTableSerialization.java', 'InMemoryInputFile.java', 'InMemoryOutputFile.java', 'MockInputStream.java', 'TestByteBufferInputStreams.java', 'TestIOUtil.java', 'TestInMemoryInputFile.java', 'TestInMemoryOutputFile.java', 'TestMultiBufferInputStream.java', 'TestOutputFileFactory.java', 'TestSingleBufferInputStream.java', 'TestJdbcCatalog.java', 'TestJdbcTableConcurrency.java', 'TestJdbcUtil.java', 'TestMappingUpdates.java', 'TestNameMapping.java', 'PuffinFormatTestUtil.java', 'TestFileMetadataParser.java', 'TestPuffinFormat.java', 'TestPuffinReader.java', 'TestPuffinWriter.java', 'HttpMethod.java', 'RESTCatalogAdapter.java', 'RequestResponseTestBase.java', 'TestHTTPClient.java', 'TestRESTCatalog.java', 'TestRESTUtil.java', 'TestResourcePaths.java', 'TestOAuth2Util.java', 'TestCreateNamespaceRequest.java', 'TestCreateTableRequest.java', 'TestRenameTableRequest.java', 'TestUpdateNamespacePropertiesRequest.java', 'TestUpdateRequirementParser.java', 'TestConfigResponse.java', 'TestCreateNamespaceResponse.java', 'TestErrorResponseParser.java', 'TestGetNamespaceResponse.java', 'TestListNamespacesResponse.java', 'TestListTablesResponse.java', 'TestLoadTableResponse.java', 'TestOAuthTokenResponse.java', 'TestUpdateNamespacePropertiesResponse.java', 'FakeTicker.java', 'TestBinPacking.java', 'TestDateTimeUtil.java', 'TestEnvironmentUtil.java', 'TestInMemoryLockManager.java', 'TestLocationUtil.java', 'TestLockManagers.java', 'TestReachableFileUtil.java', 'TestSortOrderUtil.java', 'TestStructLikeMap.java', 'TestStructLikeSet.java', 'TestTableScanUtil.java', 'TestZOrderByteUtil.java', 'GenericOrcReaderBenchmark.java', 'GenericParquetReaderBenchmark.java', 'ReaderBenchmark.java', 'BaseFileWriterFactory.java', 'DeleteFilter.java', 'GenericAppenderFactory.java', 'GenericDeleteFilter.java', 'GenericReader.java', 'IcebergGenerics.java', 'InternalRecordWrapper.java', 'TableMigrationUtil.java', 'TableScanIterable.java', 'RecordWrapperTest.java', 'TestGenericAppenderFactory.java', 'TestMergingMetrics.java', 'TestSplitScan.java', 'DataTest.java', 'DataTestHelpers.java', 'DeleteReadTests.java', 'FileHelpers.java', 'GenericAppenderHelper.java', 'RandomGenericData.java', 'TestDataFileIndexStatsFilters.java', 'TestGenericReaderDeletes.java', 'TestGenericRecord.java', 'TestLocalScan.java', 'TestMetricsRowGroupFilter.java', 'TestMetricsRowGroupFilterTypes.java', 'TestReadProjection.java', 'TestGenericData.java', 'TestGenericReadProjection.java', 'TestSingleMessageEncoding.java', 'TestGenericData.java', 'TestGenericReadProjection.java', 'TestOrcDataWriter.java', 'TestOrcRowIterator.java', 'TestGenericData.java', 'TestGenericReadProjection.java', 'TestAppenderFactory.java', 'TestBaseTaskWriter.java', 'TestFileWriterFactory.java', 'TestGenericSortedPosDeleteWriter.java', 'TestPartitioningWriters.java', 'TestPositionDeltaWriters.java', 'TestRollingFileWriters.java', 'TestTaskEqualityDeltaWriter.java', 'TestWriterMetrics.java', 'WriterTestBase.java', 'TestOrcMetrics.java', 'TestGenericMergingMetrics.java', 'TestParquetMetrics.java', 'DellClientFactories.java', 'DellClientFactory.java', 'DellProperties.java', 'BaseEcsFile.java', 'EcsAppendOutputStream.java', 'EcsCatalog.java', 'EcsFileIO.java', 'EcsInputFile.java', 'EcsOutputFile.java', 'EcsSeekableInputStream.java', 'EcsTableOperations.java', 'EcsURI.java', 'PropertiesSerDesUtil.java', 'TestEcsAppendOutputStream.java', 'TestEcsCatalog.java', 'TestEcsInputFile.java', 'TestEcsOutputFile.java', 'TestEcsSeekableInputStream.java', 'TestEcsTableOperations.java', 'TestEcsURI.java', 'TestPropertiesSerDesUtil.java', 'MockDellClientFactory.java', 'EcsS3MockRule.java', 'MockS3Client.java', 'ObjectData.java', 'ObjectId.java', 'TestExceptionCode.java', 'CatalogLoader.java', 'FlinkCatalog.java', 'FlinkCatalogFactory.java', 'FlinkConfParser.java', 'FlinkConfigOptions.java', 'FlinkDynamicTableFactory.java', 'FlinkFilters.java', 'FlinkFixupTypes.java', 'FlinkSchemaUtil.java', 'FlinkTypeToType.java', 'FlinkTypeVisitor.java', 'FlinkWriteConf.java', 'FlinkWriteOptions.java', 'IcebergTableSink.java', 'IcebergTableSource.java', 'RowDataWrapper.java', 'TableLoader.java', 'TypeToFlinkType.java', 'Actions.java', 'RewriteDataFilesAction.java', 'AvroWithFlinkSchemaVisitor.java', 'FlinkAvroReader.java', 'FlinkAvroWriter.java', 'FlinkOrcReader.java', 'FlinkOrcReaders.java', 'FlinkOrcWriter.java', 'FlinkOrcWriters.java', 'FlinkParquetReaders.java', 'FlinkParquetWriters.java', 'FlinkSchemaVisitor.java', 'FlinkValueReaders.java', 'FlinkValueWriters.java', 'ParquetWithFlinkSchemaVisitor.java', 'RowDataProjection.java', 'RowDataUtil.java', 'BaseDeltaTaskWriter.java', 'DeltaManifests.java', 'DeltaManifestsSerializer.java', 'EqualityFieldKeySelector.java', 'FlinkAppenderFactory.java', 'FlinkFileWriterFactory.java', 'FlinkManifestUtil.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'IcebergStreamWriter.java', 'ManifestOutputFileFactory.java', 'PartitionKeySelector.java', 'PartitionedDeltaWriter.java', 'RowDataTaskWriterFactory.java', 'TaskWriterFactory.java', 'UnpartitionedDeltaWriter.java', 'DataIterator.java', 'FileScanTaskReader.java', 'FlinkInputFormat.java', 'FlinkInputSplit.java', 'FlinkSource.java', 'FlinkSplitGenerator.java', 'RowDataFileScanTaskReader.java', 'RowDataRewriter.java', 'ScanContext.java', 'StreamingMonitorFunction.java', 'StreamingReaderOperator.java', 'FlinkCompatibilityUtil.java', 'FlinkCatalogTestBase.java', 'FlinkTestBase.java', 'MiniClusterResource.java', 'RowDataConverter.java', 'SimpleDataUtil.java', 'TestCatalogTableLoader.java', 'TestChangeLogTable.java', 'TestDataFileSerialization.java', 'TestFixtures.java', 'TestFlinkCatalogDatabase.java', 'TestFlinkCatalogFactory.java', 'TestFlinkCatalogTable.java', 'TestFlinkCatalogTablePartitions.java', 'TestFlinkFilters.java', 'TestFlinkHiveCatalog.java', 'TestFlinkSchemaUtil.java', 'TestFlinkTableSink.java', 'TestFlinkTableSource.java', 'TestFlinkUpsert.java', 'TestHelpers.java', 'TestIcebergConnector.java', 'TestManifestFileSerialization.java', 'TestRowDataWrapper.java', 'TestTableLoader.java', 'TestTableSerialization.java', 'TestRewriteDataFilesAction.java', 'RandomRowData.java', 'TestFlinkAvroReaderWriter.java', 'TestFlinkOrcReaderWriter.java', 'TestFlinkParquetReader.java', 'TestFlinkParquetWriter.java', 'TestRowDataProjection.java', 'TestRowProjection.java', 'TestDeltaTaskWriter.java', 'TestFlinkAppenderFactory.java', 'TestFlinkFileWriterFactory.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkV2.java', 'TestFlinkManifest.java', 'TestFlinkPartitioningWriters.java', 'TestFlinkPositionDeltaWriters.java', 'TestFlinkRollingFileWriters.java', 'TestFlinkWriterMetrics.java', 'TestIcebergFilesCommitter.java', 'TestIcebergStreamWriter.java', 'TestRowDataPartitionKey.java', 'TestTaskWriters.java', 'BoundedTableFactory.java', 'BoundedTestSource.java', 'ChangeLogTableTestBase.java', 'TestBoundedTableFactory.java', 'TestFlinkInputFormat.java', 'TestFlinkInputFormatReaderDeletes.java', 'TestFlinkMergingMetrics.java', 'TestFlinkReaderDeletesBase.java', 'TestFlinkScan.java', 'TestFlinkScanSql.java', 'TestFlinkSource.java', 'TestProjectMetaColumn.java', 'TestStreamScanSql.java', 'TestStreamingMonitorFunction.java', 'TestStreamingReaderOperator.java', 'CatalogLoader.java', 'FlinkCatalog.java', 'FlinkCatalogFactory.java', 'FlinkConfParser.java', 'FlinkConfigOptions.java', 'FlinkDynamicTableFactory.java', 'FlinkFilters.java', 'FlinkFixupTypes.java', 'FlinkSchemaUtil.java', 'FlinkTypeToType.java', 'FlinkTypeVisitor.java', 'FlinkWriteConf.java', 'FlinkWriteOptions.java', 'IcebergTableSink.java', 'IcebergTableSource.java', 'RowDataWrapper.java', 'TableLoader.java', 'TypeToFlinkType.java', 'Actions.java', 'RewriteDataFilesAction.java', 'AvroWithFlinkSchemaVisitor.java', 'FlinkAvroReader.java', 'FlinkAvroWriter.java', 'FlinkOrcReader.java', 'FlinkOrcReaders.java', 'FlinkOrcWriter.java', 'FlinkOrcWriters.java', 'FlinkParquetReaders.java', 'FlinkParquetWriters.java', 'FlinkSchemaVisitor.java', 'FlinkValueReaders.java', 'FlinkValueWriters.java', 'ParquetWithFlinkSchemaVisitor.java', 'RowDataProjection.java', 'RowDataUtil.java', 'BaseDeltaTaskWriter.java', 'DeltaManifests.java', 'DeltaManifestsSerializer.java', 'EqualityFieldKeySelector.java', 'FlinkAppenderFactory.java', 'FlinkFileWriterFactory.java', 'FlinkManifestUtil.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'IcebergStreamWriter.java', 'ManifestOutputFileFactory.java', 'PartitionKeySelector.java', 'PartitionedDeltaWriter.java', 'RowDataTaskWriterFactory.java', 'TaskWriterFactory.java', 'UnpartitionedDeltaWriter.java', 'DataIterator.java', 'FileScanTaskReader.java', 'FlinkInputFormat.java', 'FlinkInputSplit.java', 'FlinkSource.java', 'FlinkSplitPlanner.java', 'IcebergSource.java', 'RowDataFileScanTaskReader.java', 'RowDataRewriter.java', 'ScanContext.java', 'StreamingMonitorFunction.java', 'StreamingReaderOperator.java', 'StreamingStartingStrategy.java', 'GetSplitResult.java', 'SimpleSplitAssigner.java', 'SimpleSplitAssignerFactory.java', 'SplitAssigner.java', 'SplitAssignerFactory.java', 'AbstractIcebergEnumerator.java', 'ContinuousEnumerationResult.java', 'ContinuousIcebergEnumerator.java', 'ContinuousSplitPlanner.java', 'ContinuousSplitPlannerImpl.java', 'IcebergEnumeratorPosition.java', 'IcebergEnumeratorPositionSerializer.java', 'IcebergEnumeratorState.java', 'IcebergEnumeratorStateSerializer.java', 'StaticIcebergEnumerator.java', 'ArrayBatchRecords.java', 'ArrayPoolDataIteratorBatcher.java', 'DataIteratorBatcher.java', 'DataIteratorReaderFunction.java', 'IcebergSourceReader.java', 'IcebergSourceRecordEmitter.java', 'IcebergSourceSplitReader.java', 'ReaderFunction.java', 'ReaderMetricsContext.java', 'RecordAndPosition.java', 'RecordFactory.java', 'RowDataReaderFunction.java', 'RowDataRecordFactory.java', 'IcebergSourceSplit.java', 'IcebergSourceSplitSerializer.java', 'IcebergSourceSplitState.java', 'IcebergSourceSplitStatus.java', 'SplitRequestEvent.java', 'FlinkCompatibilityUtil.java', 'FlinkCatalogTestBase.java', 'FlinkTestBase.java', 'HadoopTableResource.java', 'MiniClusterResource.java', 'RowDataConverter.java', 'SimpleDataUtil.java', 'TestCatalogTableLoader.java', 'TestChangeLogTable.java', 'TestDataFileSerialization.java', 'TestFixtures.java', 'TestFlinkCatalogDatabase.java', 'TestFlinkCatalogFactory.java', 'TestFlinkCatalogTable.java', 'TestFlinkCatalogTablePartitions.java', 'TestFlinkFilters.java', 'TestFlinkHiveCatalog.java', 'TestFlinkSchemaUtil.java', 'TestFlinkTableSink.java', 'TestFlinkTableSource.java', 'TestFlinkUpsert.java', 'TestHelpers.java', 'TestIcebergConnector.java', 'TestManifestFileSerialization.java', 'TestRowDataWrapper.java', 'TestTableLoader.java', 'TestTableSerialization.java', 'TestRewriteDataFilesAction.java', 'RandomRowData.java', 'RowDataToRowMapper.java', 'TestFlinkAvroReaderWriter.java', 'TestFlinkOrcReaderWriter.java', 'TestFlinkParquetReader.java', 'TestFlinkParquetWriter.java', 'TestRowDataProjection.java', 'TestRowProjection.java', 'TestDeltaTaskWriter.java', 'TestFlinkAppenderFactory.java', 'TestFlinkFileWriterFactory.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkV2.java', 'TestFlinkManifest.java', 'TestFlinkPartitioningWriters.java', 'TestFlinkPositionDeltaWriters.java', 'TestFlinkRollingFileWriters.java', 'TestFlinkWriterMetrics.java', 'TestIcebergFilesCommitter.java', 'TestIcebergStreamWriter.java', 'TestRowDataPartitionKey.java', 'TestTaskWriters.java', 'BoundedTableFactory.java', 'BoundedTestSource.java', 'ChangeLogTableTestBase.java', 'SplitHelpers.java', 'TestBoundedTableFactory.java', 'TestFlinkInputFormat.java', 'TestFlinkInputFormatReaderDeletes.java', 'TestFlinkMergingMetrics.java', 'TestFlinkReaderDeletesBase.java', 'TestFlinkScan.java', 'TestFlinkScanSql.java', 'TestFlinkSource.java', 'TestIcebergSourceBounded.java', 'TestIcebergSourceContinuous.java', 'TestIcebergSourceFailover.java', 'TestIcebergSourceReaderDeletes.java', 'TestProjectMetaColumn.java', 'TestStreamScanSql.java', 'TestStreamingMonitorFunction.java', 'TestStreamingReaderOperator.java', 'TestSimpleSplitAssigner.java', 'ManualContinuousSplitPlanner.java', 'TestContinuousIcebergEnumerator.java', 'TestContinuousSplitPlannerImpl.java', 'TestContinuousSplitPlannerImplStartStrategy.java', 'TestIcebergEnumeratorStateSerializer.java', 'ReaderFunctionTestBase.java', 'ReaderUtil.java', 'TestArrayBatchRecords.java', 'TestArrayPoolDataIteratorBatcherRowData.java', 'TestRowDataReaderFunction.java', 'TestIcebergSourceSplitSerializer.java', 'CatalogLoader.java', 'FlinkCatalog.java', 'FlinkCatalogFactory.java', 'FlinkConfParser.java', 'FlinkConfigOptions.java', 'FlinkDynamicTableFactory.java', 'FlinkFilters.java', 'FlinkFixupTypes.java', 'FlinkSchemaUtil.java', 'FlinkTypeToType.java', 'FlinkTypeVisitor.java', 'FlinkWriteConf.java', 'FlinkWriteOptions.java', 'IcebergTableSink.java', 'IcebergTableSource.java', 'RowDataWrapper.java', 'TableLoader.java', 'TypeToFlinkType.java', 'Actions.java', 'RewriteDataFilesAction.java', 'AvroWithFlinkSchemaVisitor.java', 'FlinkAvroReader.java', 'FlinkAvroWriter.java', 'FlinkOrcReader.java', 'FlinkOrcReaders.java', 'FlinkOrcWriter.java', 'FlinkOrcWriters.java', 'FlinkParquetReaders.java', 'FlinkParquetWriters.java', 'FlinkSchemaVisitor.java', 'FlinkValueReaders.java', 'FlinkValueWriters.java', 'ParquetWithFlinkSchemaVisitor.java', 'RowDataProjection.java', 'RowDataUtil.java', 'BaseDeltaTaskWriter.java', 'DeltaManifests.java', 'DeltaManifestsSerializer.java', 'EqualityFieldKeySelector.java', 'FlinkAppenderFactory.java', 'FlinkFileWriterFactory.java', 'FlinkManifestUtil.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'IcebergStreamWriter.java', 'ManifestOutputFileFactory.java', 'PartitionKeySelector.java', 'PartitionedDeltaWriter.java', 'RowDataTaskWriterFactory.java', 'TaskWriterFactory.java', 'UnpartitionedDeltaWriter.java', 'DataIterator.java', 'FileScanTaskReader.java', 'FlinkInputFormat.java', 'FlinkInputSplit.java', 'FlinkSource.java', 'FlinkSplitPlanner.java', 'IcebergSource.java', 'RowDataFileScanTaskReader.java', 'RowDataRewriter.java', 'ScanContext.java', 'StreamingMonitorFunction.java', 'StreamingReaderOperator.java', 'StreamingStartingStrategy.java', 'GetSplitResult.java', 'SimpleSplitAssigner.java', 'SimpleSplitAssignerFactory.java', 'SplitAssigner.java', 'SplitAssignerFactory.java', 'AbstractIcebergEnumerator.java', 'ContinuousEnumerationResult.java', 'ContinuousIcebergEnumerator.java', 'ContinuousSplitPlanner.java', 'ContinuousSplitPlannerImpl.java', 'IcebergEnumeratorPosition.java', 'IcebergEnumeratorPositionSerializer.java', 'IcebergEnumeratorState.java', 'IcebergEnumeratorStateSerializer.java', 'StaticIcebergEnumerator.java', 'ArrayBatchRecords.java', 'ArrayPoolDataIteratorBatcher.java', 'DataIteratorBatcher.java', 'DataIteratorReaderFunction.java', 'IcebergSourceReader.java', 'IcebergSourceRecordEmitter.java', 'IcebergSourceSplitReader.java', 'ReaderFunction.java', 'ReaderMetricsContext.java', 'RecordAndPosition.java', 'RecordFactory.java', 'RowDataReaderFunction.java', 'RowDataRecordFactory.java', 'IcebergSourceSplit.java', 'IcebergSourceSplitSerializer.java', 'IcebergSourceSplitState.java', 'IcebergSourceSplitStatus.java', 'SplitRequestEvent.java', 'FlinkCompatibilityUtil.java', 'FlinkCatalogTestBase.java', 'FlinkTestBase.java', 'HadoopTableResource.java', 'MiniClusterResource.java', 'RowDataConverter.java', 'SimpleDataUtil.java', 'TestCatalogTableLoader.java', 'TestChangeLogTable.java', 'TestDataFileSerialization.java', 'TestFixtures.java', 'TestFlinkCatalogDatabase.java', 'TestFlinkCatalogFactory.java', 'TestFlinkCatalogTable.java', 'TestFlinkCatalogTablePartitions.java', 'TestFlinkFilters.java', 'TestFlinkHiveCatalog.java', 'TestFlinkSchemaUtil.java', 'TestFlinkTableSink.java', 'TestFlinkTableSource.java', 'TestFlinkUpsert.java', 'TestHelpers.java', 'TestIcebergConnector.java', 'TestManifestFileSerialization.java', 'TestRowDataWrapper.java', 'TestTableLoader.java', 'TestTableSerialization.java', 'TestRewriteDataFilesAction.java', 'RandomRowData.java', 'RowDataToRowMapper.java', 'TestFlinkAvroReaderWriter.java', 'TestFlinkOrcReaderWriter.java', 'TestFlinkParquetReader.java', 'TestFlinkParquetWriter.java', 'TestRowDataProjection.java', 'TestRowProjection.java', 'TestDeltaTaskWriter.java', 'TestFlinkAppenderFactory.java', 'TestFlinkFileWriterFactory.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkV2.java', 'TestFlinkManifest.java', 'TestFlinkPartitioningWriters.java', 'TestFlinkPositionDeltaWriters.java', 'TestFlinkRollingFileWriters.java', 'TestFlinkWriterMetrics.java', 'TestIcebergFilesCommitter.java', 'TestIcebergStreamWriter.java', 'TestRowDataPartitionKey.java', 'TestTaskWriters.java', 'BoundedTableFactory.java', 'BoundedTestSource.java', 'ChangeLogTableTestBase.java', 'SplitHelpers.java', 'TestBoundedTableFactory.java', 'TestFlinkInputFormat.java', 'TestFlinkInputFormatReaderDeletes.java', 'TestFlinkMergingMetrics.java', 'TestFlinkReaderDeletesBase.java', 'TestFlinkScan.java', 'TestFlinkScanSql.java', 'TestFlinkSource.java', 'TestIcebergSourceBounded.java', 'TestIcebergSourceContinuous.java', 'TestIcebergSourceFailover.java', 'TestIcebergSourceReaderDeletes.java', 'TestProjectMetaColumn.java', 'TestStreamScanSql.java', 'TestStreamingMonitorFunction.java', 'TestStreamingReaderOperator.java', 'TestSimpleSplitAssigner.java', 'ManualContinuousSplitPlanner.java', 'TestContinuousIcebergEnumerator.java', 'TestContinuousSplitPlannerImpl.java', 'TestContinuousSplitPlannerImplStartStrategy.java', 'TestIcebergEnumeratorStateSerializer.java', 'ReaderFunctionTestBase.java', 'ReaderUtil.java', 'TestArrayBatchRecords.java', 'TestArrayPoolDataIteratorBatcherRowData.java', 'TestRowDataReaderFunction.java', 'TestIcebergSourceSplitSerializer.java', 'GCPProperties.java', 'BaseGCSFile.java', 'GCSFileIO.java', 'GCSInputFile.java', 'GCSInputStream.java', 'GCSOutputFile.java', 'GCSOutputStream.java', 'GCSFileIOTest.java', 'GCSInputStreamTest.java', 'GCSOutputStreamTest.java', 'CachedClientPool.java', 'HiveCatalog.java', 'HiveClientPool.java', 'HiveSchemaConverter.java', 'HiveSchemaUtil.java', 'HiveTableOperations.java', 'MetastoreUtil.java', 'RuntimeMetaException.java', 'HiveCreateReplaceTableTest.java', 'HiveMetastoreTest.java', 'HiveTableBaseTest.java', 'HiveTableTest.java', 'ScriptRunner.java', 'TestCachedClientPool.java', 'TestHiveCatalog.java', 'TestHiveClientPool.java', 'TestHiveCommitLocks.java', 'TestHiveCommits.java', 'TestHiveMetastore.java', 'TestHiveSchemaUtil.java', 'TestHiveTableConcurrency.java', 'OrcSplit.java', 'IcebergDateObjectInspectorHive3.java', 'IcebergTimestampObjectInspectorHive3.java', 'IcebergTimestampWithZoneObjectInspectorHive3.java', 'CompatibilityHiveVectorUtils.java', 'HiveIcebergVectorizedRecordReader.java', 'HiveVectorizedReader.java', 'ParquetSchemaFieldNameVisitor.java', 'VectorizedRowBatchIterator.java', 'VectorizedReadUtils.java', 'TestHiveSchemaUtilHive3.java', 'TestIcebergDateObjectInspectorHive3.java', 'TestIcebergTimestampObjectInspectorHive3.java', 'TestIcebergTimestampWithZoneObjectInspectorHive3.java', 'VectorizedSupport.java', 'Catalogs.java', 'InputFormatConfig.java', 'Deserializer.java', 'HiveIcebergFilterFactory.java', 'HiveIcebergInputFormat.java', 'HiveIcebergMetaHook.java', 'HiveIcebergOutputCommitter.java', 'HiveIcebergOutputFormat.java', 'HiveIcebergRecordWriter.java', 'HiveIcebergSerDe.java', 'HiveIcebergSplit.java', 'HiveIcebergStorageHandler.java', 'TezUtil.java', 'IcebergBinaryObjectInspector.java', 'IcebergDateObjectInspector.java', 'IcebergDecimalObjectInspector.java', 'IcebergFixedObjectInspector.java', 'IcebergObjectInspector.java', 'IcebergRecordObjectInspector.java', 'IcebergTimeObjectInspector.java', 'IcebergTimestampObjectInspector.java', 'IcebergTimestampWithZoneObjectInspector.java', 'IcebergUUIDObjectInspector.java', 'WriteObjectInspector.java', 'AbstractMapredIcebergRecordReader.java', 'Container.java', 'MapredIcebergInputFormat.java', 'IcebergInputFormat.java', 'IcebergSplit.java', 'IcebergSplitContainer.java', 'TestCatalogs.java', 'TestHelper.java', 'TestIcebergInputFormats.java', 'TestInputFormatReaderDeletes.java', 'HiveIcebergStorageHandlerTestUtils.java', 'HiveIcebergTestUtils.java', 'TestDeserializer.java', 'TestHiveIcebergFilterFactory.java', 'TestHiveIcebergOutputCommitter.java', 'TestHiveIcebergSerDe.java', 'TestHiveIcebergStorageHandlerLocalScan.java', 'TestHiveIcebergStorageHandlerNoScan.java', 'TestHiveIcebergStorageHandlerTimezone.java', 'TestHiveIcebergStorageHandlerWithEngine.java', 'TestHiveIcebergStorageHandlerWithMultipleCatalogs.java', 'TestHiveShell.java', 'TestTables.java', 'TestIcebergBinaryObjectInspector.java', 'TestIcebergDateObjectInspector.java', 'TestIcebergDecimalObjectInspector.java', 'TestIcebergFixedObjectInspector.java', 'TestIcebergObjectInspector.java', 'TestIcebergRecordObjectInspector.java', 'TestIcebergTimeObjectInspector.java', 'TestIcebergTimestampObjectInspector.java', 'TestIcebergTimestampWithZoneObjectInspector.java', 'TestIcebergUUIDObjectInspector.java', 'NessieCatalog.java', 'NessieIcebergClient.java', 'NessieTableOperations.java', 'NessieUtil.java', 'UpdateableReference.java', 'BaseTestIceberg.java', 'TestBranchVisibility.java', 'TestCustomNessieClient.java', 'TestNamespace.java', 'TestNessieCatalog.java', 'TestNessieIcebergClient.java', 'TestNessieTable.java', 'TestNessieUtil.java', 'GenericOrcReader.java', 'GenericOrcReaders.java', 'GenericOrcWriter.java', 'GenericOrcWriters.java', 'ApplyNameMapping.java', 'EstimateOrcAvgWidthVisitor.java', 'ExpressionToSearchArgument.java', 'HasIds.java', 'IdToOrcName.java', 'ORC.java', 'ORCSchemaUtil.java', 'OrcBatchReader.java', 'OrcFileAppender.java', 'OrcIterable.java', 'OrcMetrics.java', 'OrcRowReader.java', 'OrcRowWriter.java', 'OrcSchemaVisitor.java', 'OrcSchemaWithTypeVisitor.java', 'OrcToIcebergVisitor.java', 'OrcValueReader.java', 'OrcValueReaders.java', 'OrcValueWriter.java', 'RemoveIds.java', 'VectorizedRowBatchIterator.java', 'TestBuildOrcProjection.java', 'TestEstimateOrcAvgWidthVisitor.java', 'TestExpressionToSearchArgument.java', 'TestIdToOrcName.java', 'TestORCSchemaUtil.java', 'TestOrcDeleteWriters.java', 'TestTableProperties.java', 'BaseParquetReaders.java', 'BaseParquetWriter.java', 'GenericParquetReaders.java', 'GenericParquetWriter.java', 'ApplyNameMapping.java', 'BaseColumnIterator.java', 'BasePageIterator.java', 'ColumnIterator.java', 'ColumnWriter.java', 'MessageTypeToType.java', 'PageIterator.java', 'Parquet.java', 'ParquetAvro.java', 'ParquetAvroReader.java', 'ParquetAvroValueReaders.java', 'ParquetAvroWriter.java', 'ParquetBloomRowGroupFilter.java', 'ParquetConversions.java', 'ParquetDictionaryRowGroupFilter.java', 'ParquetFilters.java', 'ParquetIO.java', 'ParquetIterable.java', 'ParquetMetricsRowGroupFilter.java', 'ParquetReadSupport.java', 'ParquetReader.java', 'ParquetSchemaUtil.java', 'ParquetTypeVisitor.java', 'ParquetUtil.java', 'ParquetValueReader.java', 'ParquetValueReaders.java', 'ParquetValueWriter.java', 'ParquetValueWriters.java', 'ParquetWriteAdapter.java', 'ParquetWriteSupport.java', 'ParquetWriter.java', 'PruneColumns.java', 'ReadConf.java', 'RemoveIds.java', 'TripleIterator.java', 'TripleWriter.java', 'TypeToMessageType.java', 'TypeWithSchemaVisitor.java', 'ValuesAsBytesReader.java', 'VectorizedParquetReader.java', 'VectorizedReader.java', 'TestHelpers.java', 'TestParquetReadProjection.java', 'TestReadProjection.java', 'ParquetWritingTestUtils.java', 'TestBloomRowGroupFilter.java', 'TestCDHParquetStatistics.java', 'TestDictionaryRowGroupFilter.java', 'TestParquet.java', 'TestParquetDataWriter.java', 'TestParquetDeleteWriters.java', 'TestParquetSchemaUtil.java', 'TestPruneColumns.java', 'IcebergPigInputFormat.java', 'IcebergStorage.java', 'PigParquetReader.java', 'SchemaUtil.java', 'SchemaUtilTest.java', 'SparkBenchmarkUtil.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'Action.java', 'IcebergSourceBenchmark.java', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'IcebergSourceNestedListDataBenchmark.java', 'WritersBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'Actions.java', 'RewriteDataFilesAction.java', 'SparkActions.java', 'IcebergSpark.java', 'JobGroupInfo.java', 'JobGroupUtils.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'SparkConfParser.java', 'SparkDataFile.java', 'SparkExceptionUtil.java', 'SparkFilters.java', 'SparkFixupTimestampType.java', 'SparkFixupTypes.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkSQLProperties.java', 'SparkSchemaUtil.java', 'SparkStructLike.java', 'SparkTableUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'SparkUtil.java', 'SparkValueConverter.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'TypeToSparkType.java', 'BaseDeleteOrphanFilesSparkAction.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseExpireSnapshotsSparkAction.java', 'BaseRewriteManifestsSparkAction.java', 'BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java', 'BaseSparkActions.java', 'ManifestFileBean.java', 'SparkActions.java', 'AvroWithSparkSchemaVisitor.java', 'ParquetWithSparkSchemaVisitor.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'ArrowVectorAccessorFactory.java', 'ArrowVectorAccessors.java', 'ColumnarBatchReader.java', 'ConstantColumnVector.java', 'IcebergArrowColumnVector.java', 'RowPositionColumnVector.java', 'VectorizedSparkOrcReaders.java', 'VectorizedSparkParquetReaders.java', 'BaseDataReader.java', 'BatchDataReader.java', 'CustomCatalogs.java', 'EqualityDeleteRowReader.java', 'IcebergSource.java', 'InternalRowWrapper.java', 'Reader.java', 'RowDataReader.java', 'RowDataRewriter.java', 'SparkAppenderFactory.java', 'SparkFileWriterFactory.java', 'SparkPartitionedFanoutWriter.java', 'SparkPartitionedWriter.java', 'Stats.java', 'StreamingOffset.java', 'StreamingWriter.java', 'StructInternalRow.java', 'Writer.java', 'KryoHelpers.java', 'TaskCheckHelper.java', 'TestDataFileSerialization.java', 'TestFileIOSerialization.java', 'TestManifestFileSerialization.java', 'TestScanTaskSerialization.java', 'TestTableSerialization.java', 'TestRewriteDataFilesAction.java', 'ConcurrencyTest.java', 'ReadAndWriteTablesTest.java', 'SchemaEvolutionTest.java', 'SimpleRecord.java', 'SnapshotFunctionalityTest.java', 'SparkTestBase.java', 'TestSparkSchemaUtil.java', 'TestSparkValueConverter.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRewriteManifestsAction.java', 'AvroDataTest.java', 'GenericsHelpers.java', 'RandomData.java', 'TestHelpers.java', 'TestOrcWrite.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkAvroEnums.java', 'TestSparkAvroReader.java', 'TestSparkDateTimes.java', 'TestSparkOrcReadMetadataColumns.java', 'TestSparkOrcReader.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkParquetReader.java', 'TestSparkParquetWriter.java', 'TestSparkRecordOrcReaderWriter.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryFallbackToPlainEncodingVectorizedReads.java', 'TestParquetVectorizedReads.java', 'LogMessage.java', 'ManualSource.java', 'SimpleRecord.java', 'TestAvroScan.java', 'TestCatalog.java', 'TestCustomCatalog.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestFilteredScan.java', 'TestForwardCompatibility.java', 'TestIcebergSource.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSpark.java', 'TestIdentityPartitionData.java', 'TestInternalRowWrapper.java', 'TestNameMappingProjection.java', 'TestParquetScan.java', 'TestPartitionPruning.java', 'TestPartitionValues.java', 'TestReadProjection.java', 'TestSelect.java', 'TestSnapshotSelection.java', 'TestSparkAppenderFactory.java', 'TestSparkBaseDataReader.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestSparkFileWriterFactory.java', 'TestSparkMergingMetrics.java', 'TestSparkPartitioningWriters.java', 'TestSparkPositionDeltaWriters.java', 'TestSparkReadProjection.java', 'TestSparkReaderDeletes.java', 'TestSparkRollingFileWriters.java', 'TestSparkSchema.java', 'TestSparkTableUtil.java', 'TestSparkTableUtilWithInMemoryCatalog.java', 'TestSparkWriterMetrics.java', 'TestStreamingOffset.java', 'TestStructuredStreaming.java', 'TestTables.java', 'TestTimestampWithoutZone.java', 'TestWriteMetricsConfig.java', 'ThreeColumnRecord.java', 'Employee.java', 'SparkExtensionsTestBase.java', 'SparkRowLevelOperationsTestBase.java', 'TestAddFilesProcedure.java', 'TestAlterTablePartitionFields.java', 'TestAlterTableSchema.java', 'TestAncestorsOfProcedure.java', 'TestCallStatementParser.java', 'TestCherrypickSnapshotProcedure.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestDelete.java', 'TestExpireSnapshotsProcedure.java', 'TestIcebergExpressions.java', 'TestMerge.java', 'TestMigrateTableProcedure.java', 'TestPublishChangesProcedure.java', 'TestRemoveOrphanFilesProcedure.java', 'TestRewriteDataFilesProcedure.java', 'TestRewriteManifestsProcedure.java', 'TestRollbackToSnapshotProcedure.java', 'TestRollbackToTimestampProcedure.java', 'TestSetCurrentSnapshotProcedure.java', 'TestSetWriteDistributionAndOrdering.java', 'TestSnapshotTableProcedure.java', 'TestUpdate.java', 'SparkBenchmarkUtil.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'Action.java', 'IcebergSourceBenchmark.java', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'IcebergSourceNestedListDataBenchmark.java', 'WritersBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'BaseCatalog.java', 'CommitMetadata.java', 'FileRewriteCoordinator.java', 'FileScanTaskSetManager.java', 'IcebergSpark.java', 'JobGroupInfo.java', 'JobGroupUtils.java', 'OrderField.java', 'PathIdentifier.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'RollbackStagedTable.java', 'SortOrderToSpark.java', 'Spark3Util.java', 'Spark3VersionUtil.java', 'SparkCatalog.java', 'SparkConfParser.java', 'SparkDataFile.java', 'SparkExceptionUtil.java', 'SparkFilters.java', 'SparkFixupTimestampType.java', 'SparkFixupTypes.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkSQLProperties.java', 'SparkSchemaUtil.java', 'SparkSessionCatalog.java', 'SparkStructLike.java', 'SparkTableUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'SparkUtil.java', 'SparkValueConverter.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'TypeToSparkType.java', 'BaseDeleteOrphanFilesSparkAction.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseExpireSnapshotsSparkAction.java', 'BaseMigrateTableSparkAction.java', 'BaseRewriteDataFilesSpark3Action.java', 'BaseRewriteDataFilesSparkAction.java', 'BaseRewriteManifestsSparkAction.java', 'BaseSnapshotTableSparkAction.java', 'BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java', 'BaseSparkActions.java', 'BaseTableCreationSparkAction.java', 'ManifestFileBean.java', 'Spark3BinPackStrategy.java', 'Spark3SortStrategy.java', 'SparkActions.java', 'AvroWithSparkSchemaVisitor.java', 'ParquetWithSparkSchemaVisitor.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'ArrowVectorAccessorFactory.java', 'ArrowVectorAccessors.java', 'ColumnarBatchReader.java', 'ConstantColumnVector.java', 'IcebergArrowColumnVector.java', 'RowPositionColumnVector.java', 'VectorizedSparkOrcReaders.java', 'VectorizedSparkParquetReaders.java', 'AddFilesProcedure.java', 'AncestorsOfProcedure.java', 'BaseProcedure.java', 'CherrypickSnapshotProcedure.java', 'ExpireSnapshotsProcedure.java', 'MigrateTableProcedure.java', 'PublishChangesProcedure.java', 'RemoveOrphanFilesProcedure.java', 'RewriteDataFilesProcedure.java', 'RewriteManifestsProcedure.java', 'RollbackToSnapshotProcedure.java', 'RollbackToTimestampProcedure.java', 'SetCurrentSnapshotProcedure.java', 'SnapshotTableProcedure.java', 'SparkProcedures.java', 'BaseDataReader.java', 'BatchDataReader.java', 'EqualityDeleteRowReader.java', 'IcebergSource.java', 'InternalRowWrapper.java', 'RowDataReader.java', 'RowDataRewriter.java', 'SerializableTableWithSize.java', 'SparkAppenderFactory.java', 'SparkBatchQueryScan.java', 'SparkBatchScan.java', 'SparkFileWriterFactory.java', 'SparkFilesScan.java', 'SparkFilesScanBuilder.java', 'SparkMergeBuilder.java', 'SparkMergeScan.java', 'SparkMicroBatchStream.java', 'SparkPartitionedFanoutWriter.java', 'SparkPartitionedWriter.java', 'SparkRewriteBuilder.java', 'SparkScanBuilder.java', 'SparkTable.java', 'SparkWrite.java', 'SparkWriteBuilder.java', 'StagedSparkTable.java', 'Stats.java', 'StreamingOffset.java', 'StructInternalRow.java', 'NoSuchProcedureException.java', 'ExtendedSupportsDelete.java', 'Procedure.java', 'ProcedureCatalog.java', 'ProcedureParameter.java', 'ProcedureParameterImpl.java', 'SupportsMerge.java', 'ClusteredDistribution.java', 'Distribution.java', 'Distributions.java', 'OrderedDistribution.java', 'UnspecifiedDistribution.java', 'ClusterDistributionImpl.java', 'OrderedDistributionImpl.java', 'UnspecifiedDistributionImpl.java', 'NullOrdering.java', 'SortDirection.java', 'SortOrder.java', 'SupportsFileFilter.java', 'MergeBuilder.java', 'KryoHelpers.java', 'TaskCheckHelper.java', 'TestDataFileSerialization.java', 'TestFileIOSerialization.java', 'TestManifestFileSerialization.java', 'TestScanTaskSerialization.java', 'TestTableSerialization.java', 'SparkCatalogConfig.java', 'SparkCatalogTestBase.java', 'SparkTestBase.java', 'SparkTestBaseWithCatalog.java', 'TestFileRewriteCoordinator.java', 'TestSpark3Util.java', 'TestSparkCatalogOperations.java', 'TestSparkFilters.java', 'TestSparkSchemaUtil.java', 'TestSparkTableUtil.java', 'TestSparkValueConverter.java', 'TestCreateActions.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction3.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'AvroDataTest.java', 'GenericsHelpers.java', 'RandomData.java', 'TestHelpers.java', 'TestOrcWrite.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkAvroEnums.java', 'TestSparkAvroReader.java', 'TestSparkDateTimes.java', 'TestSparkOrcReadMetadataColumns.java', 'TestSparkOrcReader.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkParquetReader.java', 'TestSparkParquetWriter.java', 'TestSparkRecordOrcReaderWriter.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryFallbackToPlainEncodingVectorizedReads.java', 'TestParquetVectorizedReads.java', 'LogMessage.java', 'ManualSource.java', 'SimpleRecord.java', 'SparkTestTable.java', 'TestAvroScan.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestFilteredScan.java', 'TestForwardCompatibility.java', 'TestIcebergSource.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSpark.java', 'TestIdentityPartitionData.java', 'TestInternalRowWrapper.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestParquetScan.java', 'TestPartitionPruning.java', 'TestPartitionValues.java', 'TestPathIdentifier.java', 'TestReadProjection.java', 'TestSnapshotSelection.java', 'TestSparkAppenderFactory.java', 'TestSparkBaseDataReader.java', 'TestSparkCatalog.java', 'TestSparkCatalogCacheExpiration.java', 'TestSparkCatalogHadoopOverrides.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestSparkFileWriterFactory.java', 'TestSparkFilesScan.java', 'TestSparkMergingMetrics.java', 'TestSparkMetadataColumns.java', 'TestSparkPartitioningWriters.java', 'TestSparkPositionDeltaWriters.java', 'TestSparkReadProjection.java', 'TestSparkReaderDeletes.java', 'TestSparkRollingFileWriters.java', 'TestSparkTable.java', 'TestSparkWriterMetrics.java', 'TestStreamingOffset.java', 'TestStructuredStreaming.java', 'TestStructuredStreamingRead3.java', 'TestTables.java', 'TestTimestampWithoutZone.java', 'TestWriteMetricsConfig.java', 'ThreeColumnRecord.java', 'TestAlterTable.java', 'TestCreateTable.java', 'TestCreateTableAsSelect.java', 'TestDeleteFrom.java', 'TestNamespaceSQL.java', 'TestPartitionedWrites.java', 'TestRefreshTable.java', 'TestSelect.java', 'TestTimestampWithoutZone.java', 'TestUnpartitionedWrites.java', 'Employee.java', 'SparkExtensionsTestBase.java', 'SparkRowLevelOperationsTestBase.java', 'TestAddFilesProcedure.java', 'TestAlterTablePartitionFields.java', 'TestAlterTableSchema.java', 'TestAncestorsOfProcedure.java', 'TestCallStatementParser.java', 'TestCherrypickSnapshotProcedure.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestDelete.java', 'TestExpireSnapshotsProcedure.java', 'TestIcebergExpressions.java', 'TestMerge.java', 'TestMigrateTableProcedure.java', 'TestPublishChangesProcedure.java', 'TestRemoveOrphanFilesProcedure.java', 'TestRewriteDataFilesProcedure.java', 'TestRewriteManifestsProcedure.java', 'TestRollbackToSnapshotProcedure.java', 'TestRollbackToTimestampProcedure.java', 'TestSetCurrentSnapshotProcedure.java', 'TestSetWriteDistributionAndOrdering.java', 'TestSnapshotTableProcedure.java', 'TestUpdate.java', 'SparkBenchmarkUtil.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'Action.java', 'IcebergSourceBenchmark.java', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'IcebergSourceNestedListDataBenchmark.java', 'WritersBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'BaseCatalog.java', 'CommitMetadata.java', 'FileRewriteCoordinator.java', 'FileScanTaskSetManager.java', 'IcebergSpark.java', 'JobGroupInfo.java', 'JobGroupUtils.java', 'OrderField.java', 'PathIdentifier.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'RollbackStagedTable.java', 'SortOrderToSpark.java', 'Spark3Util.java', 'SparkCatalog.java', 'SparkConfParser.java', 'SparkDataFile.java', 'SparkExceptionUtil.java', 'SparkFilters.java', 'SparkFixupTimestampType.java', 'SparkFixupTypes.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkSQLProperties.java', 'SparkSchemaUtil.java', 'SparkSessionCatalog.java', 'SparkStructLike.java', 'SparkTableUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'SparkUtil.java', 'SparkValueConverter.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'TypeToSparkType.java', 'BaseDeleteOrphanFilesSparkAction.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseExpireSnapshotsSparkAction.java', 'BaseMigrateTableSparkAction.java', 'BaseRewriteDataFilesSpark3Action.java', 'BaseRewriteDataFilesSparkAction.java', 'BaseRewriteManifestsSparkAction.java', 'BaseSnapshotTableSparkAction.java', 'BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java', 'BaseSparkActions.java', 'BaseTableCreationSparkAction.java', 'ManifestFileBean.java', 'Spark3BinPackStrategy.java', 'Spark3SortStrategy.java', 'SparkActions.java', 'AvroWithSparkSchemaVisitor.java', 'ParquetWithSparkSchemaVisitor.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'ArrowVectorAccessorFactory.java', 'ArrowVectorAccessors.java', 'ColumnarBatchReader.java', 'ConstantColumnVector.java', 'IcebergArrowColumnVector.java', 'RowPositionColumnVector.java', 'VectorizedSparkOrcReaders.java', 'VectorizedSparkParquetReaders.java', 'AddFilesProcedure.java', 'AncestorsOfProcedure.java', 'BaseProcedure.java', 'CherrypickSnapshotProcedure.java', 'ExpireSnapshotsProcedure.java', 'MigrateTableProcedure.java', 'PublishChangesProcedure.java', 'RemoveOrphanFilesProcedure.java', 'RewriteDataFilesProcedure.java', 'RewriteManifestsProcedure.java', 'RollbackToSnapshotProcedure.java', 'RollbackToTimestampProcedure.java', 'SetCurrentSnapshotProcedure.java', 'SnapshotTableProcedure.java', 'SparkProcedures.java', 'BaseDataReader.java', 'BatchDataReader.java', 'EqualityDeleteRowReader.java', 'IcebergSource.java', 'InternalRowWrapper.java', 'RowDataReader.java', 'RowDataRewriter.java', 'SerializableTableWithSize.java', 'SparkAppenderFactory.java', 'SparkBatchQueryScan.java', 'SparkBatchScan.java', 'SparkFileWriterFactory.java', 'SparkFilesScan.java', 'SparkFilesScanBuilder.java', 'SparkMergeBuilder.java', 'SparkMergeScan.java', 'SparkMicroBatchStream.java', 'SparkPartitionedFanoutWriter.java', 'SparkPartitionedWriter.java', 'SparkRewriteBuilder.java', 'SparkScanBuilder.java', 'SparkTable.java', 'SparkWrite.java', 'SparkWriteBuilder.java', 'StagedSparkTable.java', 'Stats.java', 'StreamingOffset.java', 'StructInternalRow.java', 'NoSuchProcedureException.java', 'ExtendedSupportsDelete.java', 'Procedure.java', 'ProcedureCatalog.java', 'ProcedureParameter.java', 'ProcedureParameterImpl.java', 'SupportsMerge.java', 'ClusteredDistribution.java', 'Distribution.java', 'Distributions.java', 'OrderedDistribution.java', 'UnspecifiedDistribution.java', 'ClusterDistributionImpl.java', 'OrderedDistributionImpl.java', 'UnspecifiedDistributionImpl.java', 'NullOrdering.java', 'SortDirection.java', 'SortOrder.java', 'SupportsFileFilter.java', 'MergeBuilder.java', 'KryoHelpers.java', 'TaskCheckHelper.java', 'TestDataFileSerialization.java', 'TestFileIOSerialization.java', 'TestManifestFileSerialization.java', 'TestScanTaskSerialization.java', 'TestTableSerialization.java', 'SparkCatalogConfig.java', 'SparkCatalogTestBase.java', 'SparkTestBase.java', 'SparkTestBaseWithCatalog.java', 'TestFileRewriteCoordinator.java', 'TestSpark3Util.java', 'TestSparkCatalogOperations.java', 'TestSparkFilters.java', 'TestSparkSchemaUtil.java', 'TestSparkTableUtil.java', 'TestSparkValueConverter.java', 'TestCreateActions.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction3.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'AvroDataTest.java', 'GenericsHelpers.java', 'RandomData.java', 'TestHelpers.java', 'TestOrcWrite.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkAvroEnums.java', 'TestSparkAvroReader.java', 'TestSparkDateTimes.java', 'TestSparkOrcReadMetadataColumns.java', 'TestSparkOrcReader.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkParquetReader.java', 'TestSparkParquetWriter.java', 'TestSparkRecordOrcReaderWriter.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryFallbackToPlainEncodingVectorizedReads.java', 'TestParquetVectorizedReads.java', 'LogMessage.java', 'ManualSource.java', 'SimpleRecord.java', 'SparkTestTable.java', 'TestAvroScan.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestFilteredScan.java', 'TestForwardCompatibility.java', 'TestIcebergSource.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSpark.java', 'TestIdentityPartitionData.java', 'TestInternalRowWrapper.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestParquetScan.java', 'TestPartitionPruning.java', 'TestPartitionValues.java', 'TestPathIdentifier.java', 'TestReadProjection.java', 'TestSnapshotSelection.java', 'TestSparkAppenderFactory.java', 'TestSparkBaseDataReader.java', 'TestSparkCatalog.java', 'TestSparkCatalogCacheExpiration.java', 'TestSparkCatalogHadoopOverrides.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestSparkFileWriterFactory.java', 'TestSparkFilesScan.java', 'TestSparkMergingMetrics.java', 'TestSparkMetadataColumns.java', 'TestSparkPartitioningWriters.java', 'TestSparkPositionDeltaWriters.java', 'TestSparkReadProjection.java', 'TestSparkReaderDeletes.java', 'TestSparkRollingFileWriters.java', 'TestSparkTable.java', 'TestSparkWriterMetrics.java', 'TestStreamingOffset.java', 'TestStructuredStreaming.java', 'TestStructuredStreamingRead3.java', 'TestTables.java', 'TestTimestampWithoutZone.java', 'TestWriteMetricsConfig.java', 'ThreeColumnRecord.java', 'TestAlterTable.java', 'TestCreateTable.java', 'TestCreateTableAsSelect.java', 'TestDeleteFrom.java', 'TestDropTable.java', 'TestNamespaceSQL.java', 'TestPartitionedWrites.java', 'TestRefreshTable.java', 'TestSelect.java', 'TestTimestampWithoutZone.java', 'TestUnpartitionedWrites.java', 'Employee.java', 'SparkExtensionsTestBase.java', 'SparkRowLevelOperationsTestBase.java', 'TestAddFilesProcedure.java', 'TestAlterTablePartitionFields.java', 'TestAlterTableSchema.java', 'TestAncestorsOfProcedure.java', 'TestCallStatementParser.java', 'TestCherrypickSnapshotProcedure.java', 'TestConflictValidation.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestDelete.java', 'TestDuplicateSnapshotIDs.java', 'TestExpireSnapshotsProcedure.java', 'TestIcebergExpressions.java', 'TestMerge.java', 'TestMergeOnReadDelete.java', 'TestMergeOnReadMerge.java', 'TestMergeOnReadUpdate.java', 'TestMetadataTables.java', 'TestMigrateTableProcedure.java', 'TestPublishChangesProcedure.java', 'TestRegisterTableProcedure.java', 'TestRemoveOrphanFilesProcedure.java', 'TestRequiredDistributionAndOrdering.java', 'TestRewriteDataFilesProcedure.java', 'TestRewriteManifestsProcedure.java', 'TestRollbackToSnapshotProcedure.java', 'TestRollbackToTimestampProcedure.java', 'TestSetCurrentSnapshotProcedure.java', 'TestSetWriteDistributionAndOrdering.java', 'TestSnapshotTableProcedure.java', 'TestUpdate.java', 'SparkBenchmarkUtil.java', 'IcebergSortCompactionBenchmark.java', 'RandomGeneratingUDF.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'Action.java', 'IcebergSourceBenchmark.java', 'IcebergSourceDeleteBenchmark.java', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'IcebergSourceNestedListDataBenchmark.java', 'WritersBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'IcebergSourceParquetEqDeleteBenchmark.java', 'IcebergSourceParquetMultiDeleteFileBenchmark.java', 'IcebergSourceParquetPosDeleteBenchmark.java', 'IcebergSourceParquetWithUnrelatedDeleteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'BaseCatalog.java', 'CommitMetadata.java', 'ExtendedParser.java', 'FileRewriteCoordinator.java', 'FileScanTaskSetManager.java', 'IcebergSpark.java', 'JobGroupInfo.java', 'JobGroupUtils.java', 'PathIdentifier.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'RollbackStagedTable.java', 'SortOrderToSpark.java', 'Spark3Util.java', 'SparkCachedTableCatalog.java', 'SparkCatalog.java', 'SparkConfParser.java', 'SparkDataFile.java', 'SparkDistributionAndOrderingUtil.java', 'SparkExceptionUtil.java', 'SparkFilters.java', 'SparkFixupTimestampType.java', 'SparkFixupTypes.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkSQLProperties.java', 'SparkSchemaUtil.java', 'SparkSessionCatalog.java', 'SparkStructLike.java', 'SparkTableCache.java', 'SparkTableUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'SparkUtil.java', 'SparkValueConverter.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'TypeToSparkType.java', 'BaseDeleteOrphanFilesSparkAction.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseExpireSnapshotsSparkAction.java', 'BaseMigrateTableSparkAction.java', 'BaseRewriteDataFilesSparkAction.java', 'BaseRewriteManifestsSparkAction.java', 'BaseSnapshotTableSparkAction.java', 'BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java', 'BaseTableCreationSparkAction.java', 'DeleteOrphanFilesSparkAction.java', 'DeleteReachableFilesSparkAction.java', 'ExpireSnapshotsSparkAction.java', 'ManifestFileBean.java', 'MigrateTableSparkAction.java', 'RewriteDataFilesSparkAction.java', 'RewriteManifestsSparkAction.java', 'SetAccumulator.java', 'SnapshotTableSparkAction.java', 'SparkActions.java', 'SparkBinPackStrategy.java', 'SparkSortStrategy.java', 'SparkZOrderStrategy.java', 'SparkZOrderUDF.java', 'AvroWithSparkSchemaVisitor.java', 'ParquetWithSparkSchemaVisitor.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'ArrowVectorAccessorFactory.java', 'ArrowVectorAccessors.java', 'ColumnVectorBuilder.java', 'ColumnVectorWithFilter.java', 'ColumnarBatchReader.java', 'ConstantColumnVector.java', 'DeletedColumnVector.java', 'IcebergArrowColumnVector.java', 'RowPositionColumnVector.java', 'VectorizedSparkOrcReaders.java', 'VectorizedSparkParquetReaders.java', 'AddFilesProcedure.java', 'AncestorsOfProcedure.java', 'BaseProcedure.java', 'CherrypickSnapshotProcedure.java', 'ExpireSnapshotsProcedure.java', 'MigrateTableProcedure.java', 'PublishChangesProcedure.java', 'RegisterTableProcedure.java', 'RemoveOrphanFilesProcedure.java', 'RewriteDataFilesProcedure.java', 'RewriteManifestsProcedure.java', 'RollbackToSnapshotProcedure.java', 'RollbackToTimestampProcedure.java', 'SetCurrentSnapshotProcedure.java', 'SnapshotTableProcedure.java', 'SparkProcedures.java', 'BaseBatchReader.java', 'BaseReader.java', 'BaseRowReader.java', 'BatchDataReader.java', 'EqualityDeleteRowReader.java', 'HasIcebergCatalog.java', 'IcebergSource.java', 'InternalRowWrapper.java', 'RowDataReader.java', 'RowDataRewriter.java', 'SerializableTableWithSize.java', 'SparkAppenderFactory.java', 'SparkBatch.java', 'SparkBatchQueryScan.java', 'SparkCopyOnWriteOperation.java', 'SparkCopyOnWriteScan.java', 'SparkFileWriterFactory.java', 'SparkFilesScan.java', 'SparkFilesScanBuilder.java', 'SparkMetadataColumn.java', 'SparkMicroBatchStream.java', 'SparkPartitionedFanoutWriter.java', 'SparkPartitionedWriter.java', 'SparkPositionDeltaOperation.java', 'SparkPositionDeltaWrite.java', 'SparkPositionDeltaWriteBuilder.java', 'SparkRowLevelOperationBuilder.java', 'SparkScan.java', 'SparkScanBuilder.java', 'SparkTable.java', 'SparkWrite.java', 'SparkWriteBuilder.java', 'StagedSparkTable.java', 'Stats.java', 'StreamingOffset.java', 'StructInternalRow.java', 'NoSuchProcedureException.java', 'Procedure.java', 'ProcedureCatalog.java', 'ProcedureParameter.java', 'ProcedureParameterImpl.java', 'SupportsRowLevelOperations.java', 'DeltaBatchWrite.java', 'DeltaWrite.java', 'DeltaWriteBuilder.java', 'DeltaWriter.java', 'DeltaWriterFactory.java', 'ExtendedLogicalWriteInfo.java', 'RowLevelOperation.java', 'RowLevelOperationBuilder.java', 'RowLevelOperationInfo.java', 'SupportsDelta.java', 'KryoHelpers.java', 'TaskCheckHelper.java', 'TestDataFileSerialization.java', 'TestFileIOSerialization.java', 'TestHadoopMetricsContextSerialization.java', 'TestManifestFileSerialization.java', 'TestScanTaskSerialization.java', 'TestTableSerialization.java', 'SparkCatalogConfig.java', 'SparkCatalogTestBase.java', 'SparkTestBase.java', 'SparkTestBaseWithCatalog.java', 'TestFileRewriteCoordinator.java', 'TestSpark3Util.java', 'TestSparkCachedTableCatalog.java', 'TestSparkCatalogOperations.java', 'TestSparkDistributionAndOrderingUtil.java', 'TestSparkFilters.java', 'TestSparkSchemaUtil.java', 'TestSparkSessionCatalog.java', 'TestSparkTableUtil.java', 'TestSparkValueConverter.java', 'TestCreateActions.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction3.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'AvroDataTest.java', 'GenericsHelpers.java', 'RandomData.java', 'TestHelpers.java', 'TestOrcWrite.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkAvroEnums.java', 'TestSparkAvroReader.java', 'TestSparkDateTimes.java', 'TestSparkOrcReadMetadataColumns.java', 'TestSparkOrcReader.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkParquetReader.java', 'TestSparkParquetWriter.java', 'TestSparkRecordOrcReaderWriter.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryFallbackToPlainEncodingVectorizedReads.java', 'TestParquetVectorizedReads.java', 'FilePathLastModifiedRecord.java', 'LogMessage.java', 'ManualSource.java', 'SimpleRecord.java', 'TestAvroScan.java', 'TestBaseReader.java', 'TestDataFrameWriterV2.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestFilteredScan.java', 'TestForwardCompatibility.java', 'TestIcebergSource.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSpark.java', 'TestIdentityPartitionData.java', 'TestInternalRowWrapper.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestParquetScan.java', 'TestPartitionPruning.java', 'TestPartitionValues.java', 'TestPathIdentifier.java', 'TestReadProjection.java', 'TestRequiredDistributionAndOrdering.java', 'TestRuntimeFiltering.java', 'TestSnapshotSelection.java', 'TestSparkAppenderFactory.java', 'TestSparkCatalog.java', 'TestSparkCatalogCacheExpiration.java', 'TestSparkCatalogHadoopOverrides.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestSparkFileWriterFactory.java', 'TestSparkFilesScan.java', 'TestSparkMergingMetrics.java', 'TestSparkMetadataColumns.java', 'TestSparkPartitioningWriters.java', 'TestSparkPositionDeltaWriters.java', 'TestSparkReadProjection.java', 'TestSparkReaderDeletes.java', 'TestSparkReaderWithBloomFilter.java', 'TestSparkRollingFileWriters.java', 'TestSparkTable.java', 'TestSparkWriterMetrics.java', 'TestStreamingOffset.java', 'TestStructuredStreaming.java', 'TestStructuredStreamingRead3.java', 'TestTables.java', 'TestTimestampWithoutZone.java', 'TestWriteMetricsConfig.java', 'ThreeColumnRecord.java', 'TestAlterTable.java', 'TestCreateTable.java', 'TestCreateTableAsSelect.java', 'TestDeleteFrom.java', 'TestDropTable.java', 'TestNamespaceSQL.java', 'TestPartitionedWrites.java', 'TestPartitionedWritesAsSelect.java', 'TestRefreshTable.java', 'TestSelect.java', 'TestTimestampWithoutZone.java', 'TestUnpartitionedWrites.java', 'Employee.java', 'SparkExtensionsTestBase.java', 'SparkRowLevelOperationsTestBase.java', 'TestAddFilesProcedure.java', 'TestAlterTablePartitionFields.java', 'TestAlterTableSchema.java', 'TestAncestorsOfProcedure.java', 'TestCallStatementParser.java', 'TestCherrypickSnapshotProcedure.java', 'TestConflictValidation.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestDelete.java', 'TestExpireSnapshotsProcedure.java', 'TestIcebergExpressions.java', 'TestMerge.java', 'TestMergeOnReadDelete.java', 'TestMergeOnReadMerge.java', 'TestMergeOnReadUpdate.java', 'TestMetadataTables.java', 'TestMigrateTableProcedure.java', 'TestPublishChangesProcedure.java', 'TestRegisterTableProcedure.java', 'TestRemoveOrphanFilesProcedure.java', 'TestRequiredDistributionAndOrdering.java', 'TestRewriteDataFilesProcedure.java', 'TestRewriteManifestsProcedure.java', 'TestRollbackToSnapshotProcedure.java', 'TestRollbackToTimestampProcedure.java', 'TestSetCurrentSnapshotProcedure.java', 'TestSetWriteDistributionAndOrdering.java', 'TestSnapshotTableProcedure.java', 'TestUpdate.java', 'SparkBenchmarkUtil.java', 'IcebergSortCompactionBenchmark.java', 'RandomGeneratingUDF.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'Action.java', 'IcebergSourceBenchmark.java', 'IcebergSourceDeleteBenchmark.java', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'IcebergSourceNestedListDataBenchmark.java', 'WritersBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'IcebergSourceParquetEqDeleteBenchmark.java', 'IcebergSourceParquetMultiDeleteFileBenchmark.java', 'IcebergSourceParquetPosDeleteBenchmark.java', 'IcebergSourceParquetWithUnrelatedDeleteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'BaseCatalog.java', 'CommitMetadata.java', 'ExtendedParser.java', 'FileRewriteCoordinator.java', 'FileScanTaskSetManager.java', 'IcebergSpark.java', 'JobGroupInfo.java', 'JobGroupUtils.java', 'PathIdentifier.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'RollbackStagedTable.java', 'SortOrderToSpark.java', 'Spark3Util.java', 'SparkCachedTableCatalog.java', 'SparkCatalog.java', 'SparkConfParser.java', 'SparkDataFile.java', 'SparkDistributionAndOrderingUtil.java', 'SparkExceptionUtil.java', 'SparkFilters.java', 'SparkFixupTimestampType.java', 'SparkFixupTypes.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkSQLProperties.java', 'SparkSchemaUtil.java', 'SparkSessionCatalog.java', 'SparkStructLike.java', 'SparkTableCache.java', 'SparkTableUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'SparkUtil.java', 'SparkValueConverter.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'TypeToSparkType.java', 'BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java', 'BaseTableCreationSparkAction.java', 'DeleteOrphanFilesSparkAction.java', 'DeleteReachableFilesSparkAction.java', 'ExpireSnapshotsSparkAction.java', 'ManifestFileBean.java', 'MigrateTableSparkAction.java', 'RewriteDataFilesSparkAction.java', 'RewriteManifestsSparkAction.java', 'SnapshotTableSparkAction.java', 'SparkActions.java', 'SparkBinPackStrategy.java', 'SparkSortStrategy.java', 'SparkZOrderStrategy.java', 'SparkZOrderUDF.java', 'AvroWithSparkSchemaVisitor.java', 'ParquetWithSparkSchemaVisitor.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'ArrowVectorAccessorFactory.java', 'ArrowVectorAccessors.java', 'ColumnVectorBuilder.java', 'ColumnVectorWithFilter.java', 'ColumnarBatchReader.java', 'ConstantColumnVector.java', 'DeletedColumnVector.java', 'IcebergArrowColumnVector.java', 'RowPositionColumnVector.java', 'VectorizedSparkOrcReaders.java', 'VectorizedSparkParquetReaders.java', 'AddFilesProcedure.java', 'AncestorsOfProcedure.java', 'BaseProcedure.java', 'CherrypickSnapshotProcedure.java', 'ExpireSnapshotsProcedure.java', 'MigrateTableProcedure.java', 'PublishChangesProcedure.java', 'RegisterTableProcedure.java', 'RemoveOrphanFilesProcedure.java', 'RewriteDataFilesProcedure.java', 'RewriteManifestsProcedure.java', 'RollbackToSnapshotProcedure.java', 'RollbackToTimestampProcedure.java', 'SetCurrentSnapshotProcedure.java', 'SnapshotTableProcedure.java', 'SparkProcedures.java', 'BaseBatchReader.java', 'BaseReader.java', 'BaseRowReader.java', 'BatchDataReader.java', 'EqualityDeleteRowReader.java', 'HasIcebergCatalog.java', 'IcebergSource.java', 'InternalRowWrapper.java', 'RowDataReader.java', 'RowDataRewriter.java', 'SerializableTableWithSize.java', 'SparkAppenderFactory.java', 'SparkBatch.java', 'SparkBatchQueryScan.java', 'SparkCopyOnWriteOperation.java', 'SparkCopyOnWriteScan.java', 'SparkFileWriterFactory.java', 'SparkFilesScan.java', 'SparkFilesScanBuilder.java', 'SparkMetadataColumn.java', 'SparkMicroBatchStream.java', 'SparkPartitionedFanoutWriter.java', 'SparkPartitionedWriter.java', 'SparkPositionDeltaOperation.java', 'SparkPositionDeltaWrite.java', 'SparkPositionDeltaWriteBuilder.java', 'SparkRowLevelOperationBuilder.java', 'SparkScan.java', 'SparkScanBuilder.java', 'SparkTable.java', 'SparkWrite.java', 'SparkWriteBuilder.java', 'StagedSparkTable.java', 'Stats.java', 'StreamingOffset.java', 'StructInternalRow.java', 'NoSuchProcedureException.java', 'Procedure.java', 'ProcedureCatalog.java', 'ProcedureParameter.java', 'ProcedureParameterImpl.java', 'DeltaBatchWrite.java', 'DeltaWrite.java', 'DeltaWriteBuilder.java', 'DeltaWriter.java', 'DeltaWriterFactory.java', 'ExtendedLogicalWriteInfo.java', 'SupportsDelta.java', 'KryoHelpers.java', 'TaskCheckHelper.java', 'TestDataFileSerialization.java', 'TestFileIOSerialization.java', 'TestHadoopMetricsContextSerialization.java', 'TestManifestFileSerialization.java', 'TestScanTaskSerialization.java', 'TestTableSerialization.java', 'SparkCatalogConfig.java', 'SparkCatalogTestBase.java', 'SparkTestBase.java', 'SparkTestBaseWithCatalog.java', 'TestFileRewriteCoordinator.java', 'TestSpark3Util.java', 'TestSparkCachedTableCatalog.java', 'TestSparkCatalogOperations.java', 'TestSparkDistributionAndOrderingUtil.java', 'TestSparkFilters.java', 'TestSparkSchemaUtil.java', 'TestSparkSessionCatalog.java', 'TestSparkTableUtil.java', 'TestSparkValueConverter.java', 'TestCreateActions.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction3.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'AvroDataTest.java', 'GenericsHelpers.java', 'RandomData.java', 'TestHelpers.java', 'TestOrcWrite.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkAvroEnums.java', 'TestSparkAvroReader.java', 'TestSparkDateTimes.java', 'TestSparkOrcReadMetadataColumns.java', 'TestSparkOrcReader.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkParquetReader.java', 'TestSparkParquetWriter.java', 'TestSparkRecordOrcReaderWriter.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryFallbackToPlainEncodingVectorizedReads.java', 'TestParquetVectorizedReads.java', 'FilePathLastModifiedRecord.java', 'LogMessage.java', 'ManualSource.java', 'SimpleRecord.java', 'TestAvroScan.java', 'TestBaseReader.java', 'TestDataFrameWriterV2.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestFilteredScan.java', 'TestForwardCompatibility.java', 'TestIcebergSource.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSpark.java', 'TestIdentityPartitionData.java', 'TestInternalRowWrapper.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestParquetScan.java', 'TestPartitionPruning.java', 'TestPartitionValues.java', 'TestPathIdentifier.java', 'TestReadProjection.java', 'TestRequiredDistributionAndOrdering.java', 'TestRuntimeFiltering.java', 'TestSnapshotSelection.java', 'TestSparkAppenderFactory.java', 'TestSparkCatalog.java', 'TestSparkCatalogCacheExpiration.java', 'TestSparkCatalogHadoopOverrides.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestSparkFileWriterFactory.java', 'TestSparkFilesScan.java', 'TestSparkMergingMetrics.java', 'TestSparkMetadataColumns.java', 'TestSparkPartitioningWriters.java', 'TestSparkPositionDeltaWriters.java', 'TestSparkReadProjection.java', 'TestSparkReaderDeletes.java', 'TestSparkReaderWithBloomFilter.java', 'TestSparkRollingFileWriters.java', 'TestSparkTable.java', 'TestSparkWriterMetrics.java', 'TestStreamingOffset.java', 'TestStructuredStreaming.java', 'TestStructuredStreamingRead3.java', 'TestTables.java', 'TestTimestampWithoutZone.java', 'TestWriteMetricsConfig.java', 'ThreeColumnRecord.java', 'TestAlterTable.java', 'TestCreateTable.java', 'TestCreateTableAsSelect.java', 'TestDeleteFrom.java', 'TestDropTable.java', 'TestNamespaceSQL.java', 'TestPartitionedWrites.java', 'TestPartitionedWritesAsSelect.java', 'TestRefreshTable.java', 'TestSelect.java', 'TestTimestampWithoutZone.java', 'TestUnpartitionedWrites.java']"
Docs: Mention how to fix code style,1,3,2022-07-27 11:37:20-07:00,['README.md']
Format: Fix broken link to Parquet LogicalTypes in spec.md (#5352),1,2,2022-07-27 14:02:40-07:00,['spec.md']
Flink: Support FLIP-27 source through SQL (#5318),23,1383,2022-07-28 08:52:12-07:00,"['FlinkConfigOptions.java', 'FlinkDynamicTableFactory.java', 'FlinkSource.java', 'IcebergSource.java', 'IcebergTableSource.java', 'SourceUtil.java', 'SplitAssignerType.java', 'StaticIcebergEnumerator.java', 'HadoopCatalogResource.java', 'HadoopTableResource.java', 'SimpleDataUtil.java', 'SqlHelpers.java', 'TestFlinkInputFormat.java', 'TestFlinkScan.java', 'TestFlinkScanSql.java', 'TestFlinkSource.java', 'TestFlinkSourceSql.java', 'TestFlinkTableSource.java', 'TestIcebergSourceBounded.java', 'TestIcebergSourceBoundedSql.java', 'TestIcebergSourceSql.java', 'TestSourceUtil.java', 'TestSqlBase.java']"
Flink 1.14: Support FLIP-27 source through SQL (#5344),23,1570,2022-07-28 09:21:22-07:00,"['FlinkConfigOptions.java', 'FlinkDynamicTableFactory.java', 'FlinkSource.java', 'IcebergSource.java', 'IcebergTableSource.java', 'SourceUtil.java', 'SplitAssignerType.java', 'StaticIcebergEnumerator.java', 'HadoopCatalogResource.java', 'HadoopTableResource.java', 'SimpleDataUtil.java', 'SqlHelpers.java', 'TestFlinkInputFormat.java', 'TestFlinkScan.java', 'TestFlinkScanSql.java', 'TestFlinkSource.java', 'TestFlinkSourceSql.java', 'TestFlinkTableSource.java', 'TestIcebergSourceBounded.java', 'TestIcebergSourceBoundedSql.java', 'TestIcebergSourceSql.java', 'TestSourceUtil.java', 'TestSqlBase.java']"
Parquet: Add option to set page row count limit (#5345),3,30,2022-07-28 10:59:05-07:00,"['TableProperties.java', 'configuration.md', 'Parquet.java']"
AWS: S3FileIOIntegration fix prefix list test (#5383),1,2,2022-07-29 08:57:52-07:00,['TestS3FileIOIntegration.java']
Spark 3.3: Add prefix mismatch mode for deleting orphan files (#5385),5,533,2022-07-29 09:26:29-07:00,"['TestRemoveOrphanFilesProcedure.java', 'DeleteOrphanFilesSparkAction.java', 'SetAccumulator.java', 'RemoveOrphanFilesProcedure.java', 'TestRemoveOrphanFilesAction.java']"
"Python: Refactor unary and set expressions (#5362)

* Python: Refactor unary expressions.

* Python: Add SetPredicate and BoundSetPredicate to simply in cases.

* Update for review comments.

* Fix type checks.

* Fix linting.

* Fix mypy issues.

* Add LiteralPredicate and refactor.

* Rename inequalities.

* Python: Ignore false positive pylint W0221 for 3.8.",3,984,2022-07-29 11:17:49-07:00,"['base.py', 'literals.py', 'test_expressions_base.py']"
Core: Update TestEnvironmentUtil for environments with no USER (#5353),1,19,2022-07-29 14:17:21-07:00,['TestEnvironmentUtil.java']
"API: Track name and unit in Counter, Timer (#5386)",8,178,2022-07-30 11:30:26-07:00,"['DefaultMetricsContext.java', 'DefaultTimer.java', 'IntCounter.java', 'LongCounter.java', 'MetricsContext.java', 'Timer.java', 'TestDefaultMetricsContext.java', 'TestDefaultTimer.java']"
"Python: Add REST catalog implementation (#5287)

This does not implement table commits, but does implement the catalog portion of the REST API.",18,1540,2022-07-30 12:40:53-07:00,"['open-api.yml', '.pre-commit-config.yaml', 'poetry.lock', 'base.py', 'rest.py', 'exceptions.py', 'schema.py', 'base.py', 'metadata.py', 'partitioning.py', 'iceberg_base_model.py', 'pyproject.toml', 'test_base.py', 'test_rest.py', 'conftest.py', 'test_metadata.py', 'test_schema.py', 'test_bin_packing.py']"
Flink: Produce Flink metrics directly (#5393),8,308,2022-07-30 14:35:56-07:00,"['IcebergSource.java', 'IcebergSourceReader.java', 'IcebergSourceSplitReader.java', 'ReaderMetricsContext.java', 'IcebergSource.java', 'IcebergSourceReader.java', 'IcebergSourceSplitReader.java', 'ReaderMetricsContext.java']"
"Python: Bump fastavro from 1.5.3 to 1.5.4 in /python (#5396)

Bumps [fastavro](https://github.com/fastavro/fastavro) from 1.5.3 to 1.5.4.
- [Release notes](https://github.com/fastavro/fastavro/releases)
- [Changelog](https://github.com/fastavro/fastavro/blob/master/ChangeLog)
- [Commits](https://github.com/fastavro/fastavro/compare/1.5.3...1.5.4)

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,180,2022-07-31 09:44:13-07:00,"['poetry.lock', 'pyproject.toml']"
Github: Add issue form (#4867),3,103,2022-07-31 13:30:50-07:00,"['iceberg_bug_report.yml', 'iceberg_improvement.yml', 'iceberg_question.yml']"
Build: Add an action to handle stale Github issues (#4949),1,48,2022-07-31 13:33:20-07:00,['stale.yml']
Flink: Support write options in the in-line SQL comments (#5050),4,67,2022-08-01 09:47:17-07:00,"['flink-getting-started.md', 'FlinkDynamicTableFactory.java', 'IcebergTableSink.java', 'TestFlinkUpsert.java']"
"AWS: Call abortUpload only once when any of the completable future fails (#5366)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",2,28,2022-08-01 13:32:29-05:00,"['S3OutputStream.java', 'TestS3OutputStream.java']"
Spark: Implement FunctionCatalog (#5377),5,347,2022-08-01 11:43:11-07:00,"['BaseCatalog.java', 'SparkSessionCatalog.java', 'IcebergVersionFunction.java', 'SparkFunctions.java', 'TestFunctionCatalog.java']"
"Python: Refactor expression hierarchy (#5389)

* Convert And, Or, and Not to dataclasses.

* Refactor base expression types.",2,151,2022-08-01 11:49:15-07:00,"['base.py', 'test_expressions_base.py']"
API: Fix ID assignment in schema merging (#5395),2,26,2022-08-01 12:36:13-07:00,"['TypeUtil.java', 'TestTypeUtil.java']"
Spark 3.2: Backport FunctionCatalog to Spark 3.2 (#5411),4,335,2022-08-01 15:22:27-07:00,"['BaseCatalog.java', 'IcebergVersionFunction.java', 'SparkFunctions.java', 'TestFunctionCatalog.java']"
Nessie: Bump to 0.40.3 (#5406),1,2,2022-08-01 16:29:42-07:00,['versions.props']
Python: Minor REST catalog updates (#5402),3,137,2022-08-01 16:30:06-07:00,"['rest.py', 'exceptions.py', 'test_rest.py']"
AWS: S3OutputStream - failure to close should persist on subsequent close calls (#5311),2,33,2022-08-02 12:33:52-05:00,"['S3OutputStream.java', 'TestS3OutputStream.java']"
Core: Change table name to metadata_log_entries (#5367),6,109,2022-08-02 10:58:44-07:00,"['MetadataLogEntriesTable.java', 'MetadataTableType.java', 'MetadataTableUtils.java', 'spark-queries.md', 'TestMetadataTables.java', 'TestMetadataTables.java']"
AWS: Cleanup prefix in S3FileIO integration tests (#5413),1,4,2022-08-02 11:03:42-07:00,['TestS3FileIOIntegration.java']
Python: Cleanup catalog docstring (#5421),5,94,2022-08-02 15:33:03-07:00,"['base.py', 'rest.py', 'exceptions.py', 'test_base.py', 'test_rest.py']"
Core: Add JSON single value parser (#4871),4,651,2022-08-02 15:53:23-07:00,"['DefaultValueParser.java', 'DateTimeUtil.java', 'TestDefaultValueParser.java', 'spec.md']"
Python: Add Hive Catalog (#5391),19,119319,2022-08-02 16:50:17-07:00,"['.pre-commit-config.yaml', 'LICENSE', 'Makefile', 'poetry.lock', 'base.py', 'hive.py', 'rest.py', 'base.py', 'pyproject.toml', 'test_hive.py', 'README.md', 'FacebookService.py', '__init__.py', 'constants.py', 'ttypes.py', 'ThriftHiveMetastore.py', '__init__.py', 'constants.py', 'ttypes.py']"
Python: Handle OAuthErrorResponse properly (#5416),3,80,2022-08-03 09:56:42-07:00,"['rest.py', 'exceptions.py', 'test_rest.py']"
Python: Add and cleanup tests (#5422),2,54,2022-08-03 09:57:34-07:00,"['rest.py', 'test_resolver.py']"
Build: Update actions/stale to 5.1.1 (#5420),1,2,2022-08-03 09:58:45-07:00,['stale.yml']
"API, Core: Add scan metrics reporter and logging (#5268)",20,1202,2022-08-03 11:29:07-07:00,"['CloseableIterable.java', 'CloseableIterator.java', 'IntCounter.java', 'LoggingScanReporter.java', 'LongCounter.java', 'MetricsContext.java', 'ScanReport.java', 'ScanReporter.java', 'TestCloseableIterable.java', 'TestScanReport.java', 'BaseTable.java', 'BaseTableScan.java', 'DataTableScan.java', 'DeleteFileIndex.java', 'ManifestGroup.java', 'ManifestReader.java', 'TableScanContext.java', 'RESTSessionCatalog.java', 'TestTables.java', 'TestScanPlanningAndReporting.java']"
Core: Simplify scan planning & reporting tests (#5428),1,153,2022-08-03 15:44:32-07:00,['TestScanPlanningAndReporting.java']
Hive: Fix concurrent transactions overwriting commits by adding hive lock heartbeats. (#5036),4,162,2022-08-04 09:46:29+02:00,"['CommitStateUnknownException.java', 'HiveTableOperations.java', 'HiveMetastoreTest.java', 'TestHiveCommitLocks.java']"
Hive: Hadoop Path fails on s3 endpoint (#5405),2,31,2022-08-04 13:03:04+02:00,"['HiveCatalog.java', 'TestHiveCatalog.java']"
API: Allow schema updates to find fields with case-insensitivity (#5440),7,370,2022-08-04 16:27:38-05:00,"['UpdateSchema.java', 'ReassignIds.java', 'TypeUtil.java', 'TestTypeUtil.java', 'SchemaUpdate.java', 'UnionByNameVisitor.java', 'TestSchemaUpdate.java']"
Spark 3.3: Spark mergeSchema to respect Spark Case Sensitivity Configuration (#5441),4,103,2022-08-04 16:38:43-05:00,"['SparkSchemaUtil.java', 'SparkWriteConf.java', 'SparkWriteBuilder.java', 'TestDataFrameWriterV2.java']"
Core: Implement IncrementalChangelogScan without deletes (#5382),18,988,2022-08-04 20:48:29-07:00,"['revapi.yml', 'Scan.java', 'TableScan.java', 'BaseIncrementalAppendScan.java', 'BaseIncrementalChangelogScan.java', 'BaseIncrementalScan.java', 'BaseScan.java', 'BaseTable.java', 'BaseTableScan.java', 'DataTableScan.java', 'IncrementalDataTableScan.java', 'PartitionsTable.java', 'SnapshotUtil.java', 'ScanTestBase.java', 'TableTestBase.java', 'TestBaseIncrementalAppendScan.java', 'TestBaseIncrementalChangelogScan.java', 'TestDataTableScan.java']"
"Core, API: Add getting refs and snapshot by ref to the Table API (#4428)",6,46,2022-08-05 09:35:18-07:00,"['revapi.yml', 'Table.java', 'BaseMetadataTable.java', 'BaseTable.java', 'BaseTransaction.java', 'SerializableTable.java']"
Flink: missed IcebergSourceReader group in PR #5393 for FLIP-27 source reader metrics (#5401),6,28,2022-08-05 20:33:40+02:00,"['IcebergSource.java', 'IcebergSourceReader.java', 'IcebergSourceSplitReader.java', 'IcebergSource.java', 'IcebergSourceReader.java', 'IcebergSourceSplitReader.java']"
"Python: Add http status code to RESTError (#5449)

If it isn't caught, we still want to know what the error code was",1,2,2022-08-05 12:03:29-07:00,['rest.py']
API: Avoid unnecessary wrapping of CloseableIterable.iterator() (#5446),1,2,2022-08-05 12:10:47-07:00,['CloseableIterable.java']
Doc: Add docs for the Flink FLIP-27 source (#5423),1,83,2022-08-05 12:19:08-07:00,['flink-getting-started.md']
Spark 3.3: Count delete files in DeleteReachableFiles (#5451),7,372,2022-08-05 18:32:08-07:00,"['revapi.yml', 'DeleteReachableFiles.java', 'BaseDeleteReachableFilesActionResult.java', 'BaseSparkAction.java', 'DeleteReachableFilesSparkAction.java', 'ExpireSnapshotsSparkAction.java', 'TestDeleteReachableFilesAction.java']"
"Bump coverage from 6.4.2 to 6.4.3 in /python (#5454)

Bumps [coverage](https://github.com/nedbat/coveragepy) from 6.4.2 to 6.4.3.
- [Release notes](https://github.com/nedbat/coveragepy/releases)
- [Changelog](https://github.com/nedbat/coveragepy/blob/master/CHANGES.rst)
- [Commits](https://github.com/nedbat/coveragepy/compare/6.4.2...6.4.3)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,199,2022-08-07 09:14:07-07:00,"['poetry.lock', 'pyproject.toml']"
Python: Ensure that the streams use context managers (#5436),4,36,2022-08-07 09:53:46-07:00,"['base.py', 'memory.py', 'serializers.py', 'test_decoder.py']"
Python: Move io package base.py classes to __init__.py (#5456),14,442,2022-08-07 13:08:46-07:00,"['decoder.py', 'file.py', '__init__.py', 'base.py', 'memory.py', 'pyarrow.py', 'manifest.py', 'serializers.py', 'test_decoder.py', 'test_reader.py', 'conftest.py', 'test_io.py', 'test_pyarrow.py', 'test_manifest.py']"
Python: Move catalog package base.py classes to __init__.py (#5457),9,558,2022-08-07 13:24:29-07:00,"['__init__.py', 'base.py', 'hive.py', 'rest.py', 'base.py', 'typedef.py', 'test_base.py', 'test_hive.py', 'test_rest.py']"
Python: Move table module base.py classes to __init__.py (#5458),6,52,2022-08-07 14:54:09-07:00,"['__init__.py', 'hive.py', 'rest.py', '__init__.py', 'base.py', 'test_base.py']"
CI: Enable dependabot for Github Actions (#5429),1,6,2022-08-07 15:13:19-07:00,['dependabot.yml']
API: Align error messages in CloseableIterable and CloseableIterator (#5433),4,28,2022-08-07 15:23:21-07:00,"['CloseableIterable.java', 'CloseableIterator.java', 'TestCloseableIterable.java', 'TestClosingIterator.java']"
"Bump actions/setup-python from 3 to 4 (#5460)

Bumps [actions/setup-python](https://github.com/actions/setup-python) from 3 to 4.
- [Release notes](https://github.com/actions/setup-python/releases)
- [Commits](https://github.com/actions/setup-python/compare/v3...v4)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",3,6,2022-08-07 16:05:36-07:00,"['open-api.yml', 'python-ci.yml', 'python-legacy-ci.yml']"
CI: Enable dependabot for gradle (#5464),1,6,2022-08-08 15:37:05-07:00,['dependabot.yml']
"Python: Initialize the properties with an empty dict (#5465)

* Python: Initialize the properties with a frozendict

Instead of having an optional property. I think this is a nicer
API and it also removes the awkward `properties or {}` logic.

We can't use a {} in the constructor since that will always
reference the same object, and therefore is a source of weird bugs.

https://florimond.dev/en/posts/2018/08/python-mutable-defaults-are-the-source-of-all-evil/

Next to that, we can also use the frozendict in the future when
we want to return immutable data: https://pypi.org/project/frozendict/

The frozendict is sometimes faster than the default impl:
https://github.com/Marco-Sulla/python-frozendict#benchmarks
Next to that, it is also hashable, which is also a nice property.

The package itself doesn't depend on anything, so we pull in very little
additional requirements.

I've added it into `typedef.py` which will also be introduced in:

https://github.com/apache/iceberg/pull/5360

I didn't want to create a new file for it, and also didn't find any
places where it could fit in.

* Remove package

* Implement FrozenDict ourselves",8,96,2022-08-08 15:43:36-07:00,"['__init__.py', 'hive.py', 'rest.py', 'metadata.py', 'typedef.py', 'test_base.py', 'test_schema.py', 'test_typedef.py']"
AWS: Cleanup warning about Lambda should be method reference (#5476),1,2,2022-08-08 20:43:56-07:00,['TestLakeFormationMetadataOperations.java']
"Build: Bump nebula.dependency-recommender from 9.0.2 to 11.0.0 (#5474)

Bumps nebula.dependency-recommender from 9.0.2 to 11.0.0.

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2022-08-09 09:14:31-07:00,['build.gradle']
"Python: Bump pyarrow from 8.0.0 to 9.0.0 in /python (#5455)

Bumps [pyarrow](https://github.com/apache/arrow) from 8.0.0 to 9.0.0.
- [Release notes](https://github.com/apache/arrow/releases)
- [Commits](https://github.com/apache/arrow/compare/go/v8.0.0...go/v9.0.0)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,62,2022-08-09 09:16:07-07:00,"['poetry.lock', 'pyproject.toml']"
Core: Partition filter pushdown for entries table (#5443),4,425,2022-08-09 11:09:10-07:00,"['AllEntriesTable.java', 'BaseEntriesTable.java', 'ManifestEntriesTable.java', 'TestMetadataTableFilters.java']"
AWS: Fix/Suppress ErrorProne warnings (#5368),1,2,2022-08-09 11:21:15-07:00,['TestS3FileIOIntegration.java']
"Build: Bump hiveVersion from 3.1.2 to 3.1.3 (#5470)

Bumps `hiveVersion` from 3.1.2 to 3.1.3.
Updates `hive-metastore` from 3.1.2 to 3.1.3
Updates `hive-serde` from 3.1.2 to 3.1.3
Updates `hive-service` from 3.1.2 to 3.1.3

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2022-08-09 13:12:42-07:00,['build.gradle']
Doc: Update Flink unit test URL (#5484),1,2,2022-08-10 20:50:03+08:00,['flink-getting-started.md']
Python: Validate identifiers in REST catalog (#5485),2,103,2022-08-10 09:35:37-07:00,"['rest.py', 'test_rest.py']"
Spark 3.3: Use typed beans in BaseSparkAction (#5469),7,313,2022-08-10 10:28:11-07:00,"['BaseSparkAction.java', 'DeleteOrphanFilesSparkAction.java', 'DeleteReachableFilesSparkAction.java', 'ExpireSnapshotsSparkAction.java', 'FileInfo.java', 'ManifestFileBean.java', 'TestExpireSnapshotsAction.java']"
"Python: Fix docstring (#5489)

Follow up of https://github.com/apache/iceberg/pull/5465",2,10,2022-08-10 11:10:14-07:00,"['__init__.py', 'hive.py']"
Core: Prevent potential NPEs when retrieving JSON fields (#5438),9,54,2022-08-10 12:58:37-07:00,"['MetadataUpdateParser.java', 'PartitionSpecParser.java', 'SchemaParser.java', 'SortOrderParser.java', 'TableMetadataParser.java', 'FileMetadataParser.java', 'ErrorResponseParser.java', 'JsonUtil.java', 'TestFileMetadataParser.java']"
Spark 3.2: Count delete files in DeleteReachableFiles (#5491),4,331,2022-08-10 13:12:44-07:00,"['BaseSparkAction.java', 'DeleteReachableFilesSparkAction.java', 'ExpireSnapshotsSparkAction.java', 'TestDeleteReachableFilesAction.java']"
Spark 3.2: Use typed beans in BaseSparkAction (#5494),7,313,2022-08-10 14:30:07-07:00,"['BaseSparkAction.java', 'DeleteOrphanFilesSparkAction.java', 'DeleteReachableFilesSparkAction.java', 'ExpireSnapshotsSparkAction.java', 'FileInfo.java', 'ManifestFileBean.java', 'TestExpireSnapshotsAction.java']"
AWS: S3FIleIO will by default use thread pool when performing batch deletion (#5379),4,129,2022-08-10 16:03:07-07:00,"['SupportsBulkOperations.java', 'TestS3FileIOIntegration.java', 'S3FileIO.java', 'TestS3FileIO.java']"
"Core, API: Performing operations on a snapshot branch ref (#4926)

Co-authored-by: Amogh Jahagirdar <jahamogh@amazon.com>",16,199,2022-08-10 17:22:45-07:00,"['revapi.yml', 'SnapshotUpdate.java', 'BaseOverwriteFiles.java', 'BaseReplacePartitions.java', 'BaseRewriteFiles.java', 'BaseRewriteManifests.java', 'BaseRowDelta.java', 'CherryPickOperation.java', 'FastAppend.java', 'MergingSnapshotProducer.java', 'SnapshotProducer.java', 'TestFastAppend.java', 'TestOverwrite.java', 'TestReplacePartitions.java', 'TestRewriteManifests.java', 'TestRowDelta.java']"
Spark 3.3: Support truncate in FunctionCatalog (#5431),7,975,2022-08-12 08:30:28-07:00,"['Truncate.java', 'BinaryUtil.java', 'TruncateUtil.java', 'TestTruncateUtil.java', 'SparkFunctions.java', 'TruncateFunction.java', 'TestSparkTruncateFunction.java']"
Python: Add __str__ implementation to SortOrder and SortField (#5490),2,77,2022-08-12 08:32:02-07:00,"['sorting.py', 'test_sorting.py']"
Spark 3.1: Port #3721 to Spark 3.1 (#5497),3,27,2022-08-12 08:38:28-07:00,"['SparkConfParser.java', 'SparkWriteConf.java', 'SparkWrite.java']"
Spark 3.1: Port #3287 #4381 #3535 #4419 to Spark 3.1 (#5498),14,831,2022-08-12 08:42:12-07:00,"['IcebergSourceBenchmark.java', 'IcebergSourceDeleteBenchmark.java', 'IcebergSourceParquetDeleteBenchmark.java', 'IcebergSourceParquetMultiDeleteFileBenchmark.java', 'IcebergSourceParquetWithUnrelatedDeleteBenchmark.java', 'ColumnVectorWithFilter.java', 'ColumnarBatchReader.java', 'IcebergArrowColumnVector.java', 'VectorizedSparkParquetReaders.java', 'BaseDataReader.java', 'BatchDataReader.java', 'SparkBatchScan.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkReaderDeletes.java']"
Spark 3.1: Port #4198 to Spark 3.1 (#5499),4,29,2022-08-12 08:43:01-07:00,"['BaseDeleteOrphanFilesSparkAction.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseExpireSnapshotsSparkAction.java', 'BaseSparkAction.java']"
Spark 3.1: Port #3373 to Spark 3.1 (#5500),4,97,2022-08-12 08:43:57-07:00,"['SparkMetadataColumn.java', 'SparkTable.java', 'TestSparkCatalog.java', 'TestSparkMetadataColumns.java']"
Spark 3.1: Port #3491 to Spark 3.1 (#5502),2,4,2022-08-12 08:44:27-07:00,"['SparkWriteConf.java', 'SparkWriteOptions.java']"
"Spark 3.1: Validate table columns don't conflict with metadata columns (#5501)

Backport of #3456.",3,59,2022-08-14 10:08:14-07:00,"['SparkSchemaUtil.java', 'SparkBatchScan.java', 'TestSparkMetadataColumns.java']"
Spark 3.2: Support truncate in FunctionCatalog (#5514),3,830,2022-08-14 10:10:57-07:00,"['SparkFunctions.java', 'TruncateFunction.java', 'TestSparkTruncateFunction.java']"
"Build: Bump spotless-plugin-gradle from 6.8.0 to 6.9.1 (#5521)

Bumps [spotless-plugin-gradle](https://github.com/diffplug/spotless) from 6.8.0 to 6.9.1.
- [Release notes](https://github.com/diffplug/spotless/releases)
- [Changelog](https://github.com/diffplug/spotless/blob/main/CHANGES.md)
- [Commits](https://github.com/diffplug/spotless/compare/gradle/6.8.0...gradle/6.9.1)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2022-08-14 10:11:49-07:00,['build.gradle']
"Build: Bump pydantic from 1.9.1 to 1.9.2 in /python (#5522)

Bumps [pydantic](https://github.com/samuelcolvin/pydantic) from 1.9.1 to 1.9.2.
- [Release notes](https://github.com/samuelcolvin/pydantic/releases)
- [Changelog](https://github.com/pydantic/pydantic/blob/master/HISTORY.md)
- [Commits](https://github.com/samuelcolvin/pydantic/compare/v1.9.1...v1.9.2)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,122,2022-08-14 10:12:12-07:00,"['poetry.lock', 'pyproject.toml']"
"Core: Commit empty operations from SetSnapshotOperation (#5536)

Change-Id: I9b481ca173a12457cb6773ade0c8a1ebd0b40cbc",2,21,2022-08-15 12:43:44-07:00,"['SetSnapshotOperation.java', 'TestSnapshotManager.java']"
AWS: Support preload S3 client mode for S3FileIO (#5508),2,27,2022-08-15 13:19:54-07:00,"['AwsProperties.java', 'S3FileIO.java']"
Python: Implement Hive create and load table (#5447),8,643,2022-08-15 13:40:17-07:00,"['hive.py', '__init__.py', 'schema.py', 'metadata.py', 'test_hive.py', 'conftest.py', 'test_metadata.py', 'test_sorting.py']"
Python: Add support for hierarchical namespaces (#5467),6,46,2022-08-15 14:23:53-07:00,"['__init__.py', 'hive.py', 'rest.py', 'test_base.py', 'test_hive.py', 'test_rest.py']"
Python: Add a CLI to interact with catalogs (#5417),17,2109,2022-08-15 15:25:40-07:00,"['poetry.lock', '__init__.py', 'hive.py', 'rest.py', '__init__.py', 'console.py', 'output.py', 'exceptions.py', 'metadata.py', 'pyproject.toml', 'test_base.py', 'test_hive.py', 'test_rest.py', '__init__.py', 'test_console.py', 'test_output.py', 'conftest.py']"
Python: Fix typo metadataLocation -> metadata-location (#5448),4,38,2022-08-15 16:06:16-07:00,"['rest.py', '__init__.py', 'test_base.py', 'test_rest.py']"
Build: Resolve unchecked Map type cast in TestAvroNameMapping (#5541),1,1,2022-08-15 19:13:35-07:00,['TestAvroNameMapping.java']
"Fix linter and test failures (#5542)

* Fix linter and test failures

* Replace pipe with Union

* Update python/tests/catalog/test_hive.py

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* Update python/pyiceberg/catalog/rest.py

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* Update python/pyiceberg/cli/console.py

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* Update python/tests/catalog/test_rest.py

Co-authored-by: Fokko Driesprong <fokko@apache.org>

Co-authored-by: Fokko Driesprong <fokko@apache.org>",3,6,2022-08-16 08:22:55-07:00,"['test_hive.py', 'test_rest.py', 'test_console.py']"
Flink 1.13&1.14: Port #5050 to Flink 1.13&1.14 (#5531),6,122,2022-08-16 17:26:07+02:00,"['FlinkDynamicTableFactory.java', 'IcebergTableSink.java', 'TestFlinkUpsert.java', 'FlinkDynamicTableFactory.java', 'IcebergTableSink.java', 'TestFlinkUpsert.java']"
Python: Remove unused `# type: ignore` (#5534),3,7,2022-08-16 08:52:00-07:00,"['serializers.py', 'typedef.py', 'pyproject.toml']"
"Python: Bump pre-commit to the latest version (#5466)

Periodic maintenance",1,6,2022-08-16 08:52:30-07:00,['.pre-commit-config.yaml']
"API: Deprecate generic Counter<T extends Number>, replace with long Counter (#5505)",7,541,2022-08-16 09:34:33-07:00,"['Counter.java', 'DefaultCounter.java', 'DefaultMetricsContext.java', 'IntCounter.java', 'LongCounter.java', 'MetricsContext.java', 'TestDefaultCounter.java']"
"API, Core: Add ScanReportResult related parsers (#5427)",15,1749,2022-08-16 09:52:39-07:00,"['MetricsContext.java', 'ScanReport.java', 'TestScanReport.java', 'BaseTableScan.java', 'DataTableScan.java', 'ManifestGroup.java', 'CounterResultParser.java', 'ScanMetricsResultParser.java', 'ScanReportParser.java', 'TimerResultParser.java', 'TestScanPlanningAndReporting.java', 'TestCounterResultParser.java', 'TestScanMetricsResultParser.java', 'TestScanReportParser.java', 'TestTimerResultParser.java']"
Build: Bump gradle-git-version from 0.12.3 to 0.15.0 (#5532),1,7,2022-08-16 09:55:49-07:00,['build.gradle']
Core: Put property names at the end in JsonUtil error messages (#5434),6,69,2022-08-16 09:57:12-07:00,"['JsonUtil.java', 'TestMetadataUpdateParser.java', 'TestSnapshotRefParser.java', 'TestTableIdentifierParser.java', 'TestRenameTableRequest.java', 'TestOAuthTokenResponse.java']"
"API, Core: Replace deprecated Counter with new Counter API (#5506)",17,283,2022-08-16 11:16:24-07:00,"['OSSInputStream.java', 'OSSOutputStream.java', 'CloseableIterable.java', 'CloseableIterator.java', 'ScanReport.java', 'TestCloseableIterable.java', 'S3InputStream.java', 'S3OutputStream.java', 'HadoopMetricsContext.java', 'TestCounterResultParser.java', 'TestScanReportParser.java', 'TestTimerResultParser.java', 'EcsAppendOutputStream.java', 'EcsSeekableInputStream.java', 'GCSInputStream.java', 'GCSOutputStream.java', 'TestHadoopMetricsContextSerialization.java']"
Spark 3.1: Port #3505 to Spark 3.1 (#5503),9,149,2022-08-16 13:52:04-07:00,"['Spark3Util.java', 'SparkConfParser.java', 'SparkReadConf.java', 'SparkBatchQueryScan.java', 'SparkBatchScan.java', 'SparkFilesScan.java', 'SparkFilesScanBuilder.java', 'SparkMergeScan.java', 'SparkScanBuilder.java']"
Python: Write the column docs as well (#5547),2,6,2022-08-16 13:54:10-07:00,"['output.py', 'test_console.py']"
Flink: Suppress Nanosecond Warning for TimestampTz ORC value writer in Flink 1.13 to match later Flink versions (#5552),1,1,2022-08-17 08:45:17+02:00,['FlinkOrcWriters.java']
"Core: Add tests for JsonUtil, reduce duplication (#5526)",2,219,2022-08-17 16:28:14-07:00,"['JsonUtil.java', 'TestJsonUtil.java']"
AWS: Support S3 acceleration mode (#5555),3,40,2022-08-18 09:13:22-07:00,"['AwsClientFactories.java', 'AwsProperties.java', 'aws.md']"
Spark 3.3: Reduce serialization in DeleteOrphanFilesSparkAction (#5495),4,397,2022-08-18 09:22:39-07:00,"['BaseSparkAction.java', 'DeleteOrphanFilesSparkAction.java', 'ExpireSnapshotsSparkAction.java', 'TestRemoveOrphanFilesAction.java']"
Python: Implement __repr__ for SnapshotRefType (#5564),2,37,2022-08-18 09:42:25-07:00,"['refs.py', 'test_refs.py']"
Python: Implement __repr__ for Summary and Operation (#5563),2,101,2022-08-18 09:43:11-07:00,"['snapshots.py', 'test_snapshots.py']"
API: Remove counter name (#5559),17,386,2022-08-18 09:45:23-07:00,"['Counter.java', 'DefaultCounter.java', 'DefaultMetricsContext.java', 'DefaultTimer.java', 'MetricsContext.java', 'ScanReport.java', 'Timer.java', 'TestDefaultCounter.java', 'TestDefaultMetricsContext.java', 'TestDefaultTimer.java', 'HadoopMetricsContext.java', 'CounterResultParser.java', 'ScanMetricsResultParser.java', 'TimerResultParser.java', 'TestCounterResultParser.java', 'TestScanMetricsResultParser.java', 'TestTimerResultParser.java']"
Spark 3.3: Support bucket in FunctionCatalog (#5513),6,819,2022-08-18 09:49:25-07:00,"['Bucket.java', 'BucketUtil.java', 'TestBucketing.java', 'BucketFunction.java', 'SparkFunctions.java', 'TestSparkBucketFunction.java']"
Spark 3.2: Support bucket in FunctionCatalog (#5571),3,672,2022-08-18 12:04:14-07:00,"['BucketFunction.java', 'SparkFunctions.java', 'TestSparkBucketFunction.java']"
Core: Fix snapshot log with intermediate transaction snapshots (#5568),2,30,2022-08-18 12:06:36-07:00,"['TableMetadata.java', 'TestTransaction.java']"
Flink: fix the bug where metrics are registered in split reader. Also updated reader metric group to be more consistent with Flink metrics style. (#5554),16,838,2022-08-18 21:49:55+02:00,"['IcebergSource.java', 'IcebergSourceReader.java', 'IcebergSourceReaderMetrics.java', 'IcebergSourceSplitReader.java', 'ReaderFunctionTestBase.java', 'ReaderUtil.java', 'TestIcebergSourceReader.java', 'TestingMetricGroup.java', 'IcebergSource.java', 'IcebergSourceReader.java', 'IcebergSourceReaderMetrics.java', 'IcebergSourceSplitReader.java', 'ReaderFunctionTestBase.java', 'ReaderUtil.java', 'TestIcebergSourceReader.java', 'TestingMetricGroup.java']"
Spark 3.3: Align formatting in bucket and truncate functions (#5573),2,50,2022-08-18 16:12:01-07:00,"['BucketFunction.java', 'TruncateFunction.java']"
Spark 3.2: Reduce serialization in DeleteOrphanFilesSparkAction (#5572),4,397,2022-08-18 16:19:13-07:00,"['BaseSparkAction.java', 'DeleteOrphanFilesSparkAction.java', 'ExpireSnapshotsSparkAction.java', 'TestRemoveOrphanFilesAction.java']"
ORC: Upgrade to 1.7.6 (#5580),1,2,2022-08-18 21:30:29-07:00,['versions.props']
Python: Update copy_on_model_validation (#5583),1,1,2022-08-19 08:38:53-07:00,['iceberg_base_model.py']
Spark 3.2: Delete deprecated action classes (#5575),9,486,2022-08-19 08:40:38-07:00,"['BaseDeleteOrphanFilesSparkAction.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseExpireSnapshotsSparkAction.java', 'BaseMigrateTableSparkAction.java', 'BaseRewriteDataFilesSparkAction.java', 'BaseRewriteManifestsSparkAction.java', 'BaseSnapshotTableSparkAction.java', 'SparkActions.java', 'TestRewriteDataFilesAction.java']"
"Build: Bump gradle-processors from 3.3.0 to 3.7.0 (#5582)

Bumps gradle-processors from 3.3.0 to 3.7.0.

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2022-08-19 08:43:44-07:00,['build.gradle']
Spark 3.2: Align formatting in bucket and truncate functions (#5574),2,50,2022-08-19 08:45:22-07:00,"['BucketFunction.java', 'TruncateFunction.java']"
Core: Add alias for REST catalog (#5570),1,8,2022-08-19 08:48:17-07:00,['CatalogUtil.java']
Flink: Add monitor metrics for Flink sink (#5410),6,440,2022-08-19 09:32:23-07:00,"['build.gradle', 'CommitSummary.java', 'IcebergFilesCommitter.java', 'IcebergFilesCommitterMetrics.java', 'IcebergStreamWriter.java', 'IcebergStreamWriterMetrics.java']"
Python: Add Table API methods (#5562),11,358,2022-08-19 09:51:04-07:00,"['console.py', 'output.py', '__init__.py', 'metadata.py', 'snapshots.py', 'sorting.py', 'test_hive.py', 'test_console.py', 'conftest.py', 'test_init.py', 'test_metadata.py']"
API: Add Histogram metric type (#5348),6,400,2022-08-19 11:53:42-07:00,"['DefaultMetricsContext.java', 'FixedReservoirHistogram.java', 'Histogram.java', 'MetricsContext.java', 'TestDefaultMetricsContext.java', 'TestFixedReservoirHistogram.java']"
Flink 1.14: Add sink monitoring metrics (#5589),6,439,2022-08-19 11:54:24-07:00,"['build.gradle', 'CommitSummary.java', 'IcebergFilesCommitter.java', 'IcebergFilesCommitterMetrics.java', 'IcebergStreamWriter.java', 'IcebergStreamWriterMetrics.java']"
Python: Add wrapper to handle CLI exit code (#5546),2,351,2022-08-19 15:20:02-07:00,"['console.py', 'test_console.py']"
Python: Add configuration (#5488),13,766,2022-08-19 15:44:27-07:00,"['__init__.py', 'hive.py', 'rest.py', 'console.py', 'exceptions.py', 'typedef.py', 'config.py', 'test_base.py', 'test_hive.py', 'test_rest.py', 'test_console.py', 'conftest.py', 'test_config.py']"
"Build: Bump jackson-annotations from 2.6.5 to 2.13.3 (#5596)

Bumps [jackson-annotations](https://github.com/FasterXML/jackson) from 2.6.5 to 2.13.3.
- [Release notes](https://github.com/FasterXML/jackson/releases)
- [Commits](https://github.com/FasterXML/jackson/commits)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,4,2022-08-21 12:17:48-07:00,"['build.gradle', 'build.gradle']"
"Build: Bump coverage from 6.4.3 to 6.4.4 in /python (#5599)

Bumps [coverage](https://github.com/nedbat/coveragepy) from 6.4.3 to 6.4.4.
- [Release notes](https://github.com/nedbat/coveragepy/releases)
- [Changelog](https://github.com/nedbat/coveragepy/blob/master/CHANGES.rst)
- [Commits](https://github.com/nedbat/coveragepy/compare/6.4.3...6.4.4)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,346,2022-08-21 12:18:21-07:00,"['poetry.lock', 'pyproject.toml']"
Build: Add Fokko as a collaborator (#5600),1,3,2022-08-21 12:18:54-07:00,['.asf.yaml']
Python: Fix CLI after properties refactor (#5594),7,74,2022-08-21 22:10:18+02:00,"['__init__.py', 'hive.py', 'rest.py', 'console.py', 'output.py', 'test_hive.py', 'test_rest.py']"
Python: Add logic for loading custom FileIO (#5588),3,160,2022-08-21 13:21:20-07:00,"['hive.py', '__init__.py', 'test_io.py']"
Build: Enforce LambdaMethodReference check at compile-time (#5529),1,2,2022-08-21 15:19:35-07:00,['baseline.gradle']
API: Extend FileIO in optional interfaces (#5576),2,4,2022-08-21 15:24:28-07:00,"['SupportsBulkOperations.java', 'SupportsPrefixOperations.java']"
Flink: Fix Javadoc in ContinuousSplitPlannerImpl (#5551),2,4,2022-08-21 15:28:07-07:00,"['ContinuousSplitPlannerImpl.java', 'ContinuousSplitPlannerImpl.java']"
"Core: Add expression JSON parser (#5602)

Co-authored-by: Eduard Tudenhoefner <etudenhoefner@gmail.com>",10,1196,2022-08-22 12:27:01-07:00,"['revapi.yml', 'BoundReference.java', 'ExpressionVisitors.java', 'Expressions.java', 'NamedReference.java', 'Reference.java', 'SingleValueParser.java', 'ExpressionParser.java', 'TestSingleValueParser.java', 'TestExpressionParser.java']"
Build: Bump AWS SDK version (#5612),1,2,2022-08-22 12:33:33-07:00,['versions.props']
"Build: Bump tezVersion from 0.10.1 to 0.10.2 (#5520)

Bumps `tezVersion` from 0.10.1 to 0.10.2.
Updates `tez-dag` from 0.10.1 to 0.10.2
Updates `tez-mapreduce` from 0.10.1 to 0.10.2

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2022-08-22 12:38:55-07:00,['build.gradle']
Docs: Flink `Streaming upsert write` (#5380),1,48,2022-08-23 07:38:35+02:00,['flink-getting-started.md']
"Fix message pattern in checkArgument invocation (#5621)

Core: Fix checkArgument placeholder",1,2,2022-08-23 17:03:36+02:00,['MetadataUpdateParser.java']
"Core: Add snapshot references metadata table (#4807)

Co-authored-by: Bhavay Pahuja <bhavayp@amazon.com>",4,234,2022-08-23 10:07:56-07:00,"['MetadataTableType.java', 'MetadataTableUtils.java', 'RefsTable.java', 'TestMetadataTables.java']"
Python: Add additional information to the describe command (#5609),5,39,2022-08-24 12:19:16-07:00,"['output.py', 'manifest.py', '__init__.py', 'snapshots.py', 'test_console.py']"
Core: Add TableMetadata support for statistics information (#5450),12,872,2022-08-24 15:17:27-07:00,"['BlobMetadata.java', 'StatisticsFile.java', 'GenericBlobMetadata.java', 'GenericStatisticsFile.java', 'MetadataUpdate.java', 'MetadataUpdateParser.java', 'StatisticsFileParser.java', 'TableMetadata.java', 'TableMetadataParser.java', 'TestMetadataUpdateParser.java', 'TestTableMetadata.java', 'TableMetadataStatisticsFiles.json']"
"Docs: Added missing doc for REPLACE PARTITION FIELD (#5624)

* Added missing doc for REPLACE PARTITION FIELD

* Update docs/spark-ddl.md

* Update docs/spark-ddl.md

Co-authored-by: Jan Justesen <janj@tlt.local>
Co-authored-by: Fokko Driesprong <fokko@apache.org>",1,10,2022-08-25 09:59:07+02:00,['spark-ddl.md']
"Python: Add types to bin packing (#5617)

* Python: Add types to bin packing

* Change int into T",2,82,2022-08-25 10:03:52+02:00,"['bin_packing.py', 'test_bin_packing.py']"
Core: Transform parquet bloom filter props when updating schema (#5426),4,111,2022-08-25 18:05:53-07:00,"['MetricsConfig.java', 'SchemaUpdate.java', 'PropertyUtil.java', 'TestSchemaAndMappingUpdate.java']"
AWS: Deprecate AwsClientFactories.s3Configuration() (#5592),1,7,2022-08-26 08:28:52-07:00,['AwsClientFactories.java']
Spark 3.3: Add SparkV2Filters (#5302),2,605,2022-08-26 09:19:53-07:00,"['SparkV2Filters.java', 'TestSparkV2Filters.java']"
API: Deprecate old incremental append scans (#5577),1,6,2022-08-26 10:55:18-07:00,['TableScan.java']
"Remove deprecations for Rollback and Overwrite Files (#5639)

* Removed deprecations for overwrite files and rollback

* Spotless

* Fix tests and older spark versions

* Accept breaking api changes",18,277,2022-08-27 10:55:29-07:00,"['revapi.yml', 'OverwriteFiles.java', 'Rollback.java', 'RowDelta.java', 'Table.java', 'BaseMetadataTable.java', 'BaseTable.java', 'BaseTransaction.java', 'RollbackToSnapshot.java', 'SerializableTable.java', 'TestIncrementalDataTableScan.java', 'TestRowDelta.java', 'SnapshotFunctionalityTest.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java']"
Core: Use Bulk Delete when dropping table data and metadata (#5459),3,122,2022-08-27 12:49:35-07:00,"['GlueTestBase.java', 'TestGlueCatalogTable.java', 'CatalogUtil.java']"
Python: Add annotations typedef (#5628),2,8,2022-08-28 15:16:15-07:00,"['typedef.py', 'test_typedef.py']"
MR: Remove deprecated properties for 1.0 release (#5657),5,168,2022-08-28 15:21:17-07:00,"['Catalogs.java', 'InputFormatConfig.java', 'TestCatalogs.java', 'TestIcebergInputFormats.java', 'TestInputFormatReaderDeletes.java']"
Aliyun: Remove deprecated classes for 1.0 release (#5654),2,12,2022-08-28 15:21:54-07:00,"['OSSInputFile.java', 'OSSInputStream.java']"
"Build: Bump spotless-plugin-gradle from 6.9.1 to 6.10.0 (#5650)

Bumps [spotless-plugin-gradle](https://github.com/diffplug/spotless) from 6.9.1 to 6.10.0.
- [Release notes](https://github.com/diffplug/spotless/releases)
- [Changelog](https://github.com/diffplug/spotless/blob/main/CHANGES.md)
- [Commits](https://github.com/diffplug/spotless/compare/gradle/6.9.1...gradle/6.10.0)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2022-08-28 15:22:09-07:00,['build.gradle']
Docs: Switch post- and pre- around (#5633),1,4,2022-08-28 15:33:05-07:00,['TypeUtil.java']
"Python: Add year, month, day, and hour transforms (#5462)

* add time (year, month, day, hour) transforms

* address the comments

* update the PR to address the comments",3,454,2022-08-29 15:31:15+02:00,"['transforms.py', 'datetime.py', 'test_transforms.py']"
Deprections for 1.0 release: remove dynamo lock manager and OBE properties (#5655),3,58,2022-08-29 10:26:54-07:00,"['AwsProperties.java', 'DynamoLockManager.java', 'hive.md']"
AWS: Support S3 Dual Stack (#5644),3,35,2022-08-29 12:29:24-07:00,"['AwsClientFactories.java', 'AwsProperties.java', 'aws.md']"
Python: Fix date/time transforms. (#5667),1,22,2022-08-29 22:37:20+02:00,['datetime.py']
API: Add API changes for table statistics tracking (#5021),8,85,2022-08-30 09:01:37-07:00,"['revapi.yml', 'Table.java', 'Transaction.java', 'UpdateStatistics.java', 'BaseMetadataTable.java', 'BaseTransaction.java', 'CommitCallbackTransaction.java', 'SerializableTable.java']"
"Python: Include PyYaml as a dependency (#5674)

Currently it is missing:

```
root@88de3a02961f:/# pip install ""git+https://github.com/apache/iceberg.git#subdirectory=python[pyarrow]""^C
root@88de3a02961f:/# pyiceberg
Traceback (most recent call last):
  File ""/usr/local/bin/pyiceberg"", line 5, in <module>
    from pyiceberg.cli.console import run
  File ""/usr/local/lib/python3.9/site-packages/pyiceberg/cli/console.py"", line 30, in <module>
    from pyiceberg.catalog import Catalog, load_catalog
  File ""/usr/local/lib/python3.9/site-packages/pyiceberg/catalog/__init__.py"", line 37, in <module>
    from pyiceberg.utils.config import Config, merge_config
  File ""/usr/local/lib/python3.9/site-packages/pyiceberg/utils/config.py"", line 21, in <module>
    import yaml
ModuleNotFoundError: No module named 'yaml'
```",2,361,2022-08-30 19:01:19+02:00,"['poetry.lock', 'pyproject.toml']"
"Python: Reassign schema/partition-spec/sort-order IDs  (#5627)

* Python: Reassign schema/partition-spec/sort-order ids

When creating a new schema

Resolves #5468

* Convert into pre-order

* Small docstring improvements

* Fix order of the structs/lists/maps",16,628,2022-08-31 19:28:25+02:00,"['poetry.lock', 'hive.py', 'rest.py', 'schema.py', 'serializers.py', '__init__.py', 'metadata.py', 'partitioning.py', 'sorting.py', 'types.py', 'iceberg_base_model.py', 'test_hive.py', 'test_console.py', 'test_init.py', 'test_metadata.py', 'test_sorting.py']"
AWS: fix wrong config key for useArnRegionEnabled in AssumeRoleAwsClientFactory (#5680),1,2,2022-08-31 10:50:47-07:00,['AssumeRoleAwsClientFactory.java']
Spark 3.3: Add row-based changelog reader (#5578),2,409,2022-08-31 15:31:59-07:00,"['ChangelogRowReader.java', 'TestChangelogReader.java']"
Spark 3.2: Add row-based changelog reader (#5682),2,409,2022-08-31 20:49:10-07:00,"['ChangelogRowReader.java', 'TestChangelogReader.java']"
[Python] FsspecFileIO that wraps any fsspec filesystem (#5332),6,783,2022-09-01 11:34:12+02:00,"['Makefile', 'poetry.lock', 'fsspec.py', 'pyproject.toml', 'conftest.py', 'test_fsspec.py']"
"Core: Fix exception handling in BaseTaskWriter (#5683)

* Core: Fix exception handling in BaseTaskWriter.

* Fix state check.",4,128,2022-09-01 12:44:19-07:00,"['S3OutputStream.java', 'TestS3OutputStream.java', 'BaseTaskWriter.java', 'SortedPosDeleteWriter.java']"
Core: Support deleting tables without metadata files (#5510),6,90,2022-09-01 12:48:32-07:00,"['DynamoDbCatalog.java', 'GlueCatalog.java', 'JdbcCatalog.java', 'TestJdbcCatalog.java', 'HiveCatalog.java', 'TestHiveCatalog.java']"
"Core, AWS: Fix Kryo serialization failure for FileIO (#5437)",10,194,2022-09-01 15:37:16-07:00,"['TestHelpers.java', 'S3FileIO.java', 'TestS3FileIO.java', 'build.gradle', 'ResolvingFileIO.java', 'HadoopFileIOTest.java', 'TestResolvingIO.java', 'GCSFileIO.java', 'GCSFileIOTest.java', 'versions.props']"
Parquet: Close zstd input stream early to avoid memory pressure (#5681),2,105,2022-09-01 15:54:53-07:00,"['Parquet.java', 'ParquetCodecFactory.java']"
"Spark: Fix stats in rewrite metadata action (#5691)

* Core: Don't show dropped fields from the partition spec

* Use projection instead

* Use StructProjection in SparkDataFile.

Co-authored-by: Fokko Driesprong <fokko@apache.org>",6,218,2022-09-02 08:20:57+02:00,"['TestRewriteManifestsProcedure.java', 'SparkDataFile.java', 'RewriteManifestsSparkAction.java', 'TestRewriteManifestsProcedure.java', 'SparkDataFile.java', 'RewriteManifestsSparkAction.java']"
"Docs: Show most recent AWS SDK version (#5661)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",1,12,2022-09-02 08:23:36+02:00,['aws.md']
Python: Fix issues with optional dependencies (#5687),5,39,2022-09-02 17:26:57+02:00,"['poetry.lock', 'console.py', '__init__.py', 'pyproject.toml', 'test_io.py']"
Docs: Update partitions metadata table (#5662),1,15,2022-09-02 10:34:18-07:00,['spark-queries.md']
Core: Add CommitStateUnknownException handling to REST (#5694),3,52,2022-09-02 12:50:39-07:00,"['ServiceFailureException.java', 'ServiceUnavailableException.java', 'ErrorHandlers.java']"
API: Remove source type from Transform (#5601),65,2564,2022-09-02 14:00:15-07:00,"['revapi.yml', 'PartitionKey.java', 'PartitionSpec.java', 'SortOrder.java', 'UnboundPartitionSpec.java', 'UnboundSortOrder.java', 'BoundTransform.java', 'ExpressionUtil.java', 'Expressions.java', 'UnboundTransform.java', 'Bucket.java', 'Dates.java', 'Days.java', 'Hours.java', 'Identity.java', 'Months.java', 'PartitionSpecVisitor.java', 'ProjectionUtil.java', 'SerializationProxies.java', 'SortOrderVisitor.java', 'TimeTransform.java', 'Timestamps.java', 'Transform.java', 'Transforms.java', 'Truncate.java', 'UnknownTransform.java', 'VoidTransform.java', 'Years.java', 'SerializableFunction.java', 'PartitionSpecTestBase.java', 'TestPartitionPaths.java', 'TestPartitionSpecValidation.java', 'TestExpressionHelpers.java', 'TestBucketing.java', 'TestBucketingProjection.java', 'TestDates.java', 'TestDatesProjection.java', 'TestIdentity.java', 'TestNotStartsWith.java', 'TestResiduals.java', 'TestStartsWith.java', 'TestTimestamps.java', 'TestTimestampsProjection.java', 'TestTransformSerialization.java', 'TestTruncate.java', 'TestTruncatesProjection.java', 'BaseMetadataTable.java', 'BaseUpdatePartitionSpec.java', 'LocationProviders.java', 'ManifestsTable.java', 'TableMetadata.java', 'ExpressionParser.java', 'TestReplaceTransaction.java', 'TestTableMetadata.java', 'TestTableUpdatePartitionSpec.java', 'TestUpdatePartitionSpec.java', 'TestHadoopCatalog.java', 'TestHadoopTables.java', 'TestJdbcCatalog.java', 'WritersBenchmark.java', 'IcebergSpark.java', 'TransformExpressions.scala', 'TestFilteredScan.java', 'TestIcebergSpark.java', 'TestPartitionPruning.java']"
Spark: Add custom metric for number of deletes applied by a SparkScan (#4588),30,932,2022-09-03 08:07:35+02:00,"['DeleteCounter.java', 'Deletes.java', 'DeleteFilter.java', 'DeleteReadTests.java', 'ColumnarBatchReader.java', 'BaseReader.java', 'BatchDataReader.java', 'ChangelogRowReader.java', 'EqualityDeleteRowReader.java', 'RowDataReader.java', 'SparkScan.java', 'NumDeletes.java', 'NumSplits.java', 'TaskNumDeletes.java', 'TaskNumSplits.java', 'SparkSQLExecutionHelper.java', 'TestSparkReaderDeletes.java', 'ColumnarBatchReader.java', 'BaseReader.java', 'BatchDataReader.java', 'ChangelogRowReader.java', 'EqualityDeleteRowReader.java', 'RowDataReader.java', 'SparkScan.java', 'NumDeletes.java', 'NumSplits.java', 'TaskNumDeletes.java', 'TaskNumSplits.java', 'SparkSQLExecutionHelper.java', 'TestSparkReaderDeletes.java']"
Flink: fix missing generic types for some IcebergSource$Builder methods (#5697),2,84,2022-09-04 10:36:59+02:00,"['IcebergSource.java', 'IcebergSource.java']"
"API, Core: Include Expression filter in ScanReport (#5705)",6,79,2022-09-05 09:11:12-07:00,"['ScanReport.java', 'TestScanReport.java', 'BaseTableScan.java', 'ExpressionParser.java', 'ScanReportParser.java', 'TestScanReportParser.java']"
Build: Update Avro to 1.11.1 (#5483),3,6,2022-09-05 09:26:29-07:00,"['build.gradle', 'build.gradle', 'versions.props']"
Core: Avoid useless metadata retries (#5696),5,123,2022-09-05 09:32:01-07:00,"['S3InputStream.java', 'StaticClientFactory.java', 'TestS3FileIO.java', 'build.gradle', 'BaseMetastoreTableOperations.java']"
"Build: Bump pytest from 7.1.2 to 7.1.3 in /python (#5703)

Bumps [pytest](https://github.com/pytest-dev/pytest) from 7.1.2 to 7.1.3.
- [Release notes](https://github.com/pytest-dev/pytest/releases)
- [Changelog](https://github.com/pytest-dev/pytest/blob/main/CHANGELOG.rst)
- [Commits](https://github.com/pytest-dev/pytest/compare/7.1.2...7.1.3)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,592,2022-09-05 09:32:32-07:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump jackson-annotations from 2.13.3 to 2.13.4 (#5702)

Bumps [jackson-annotations](https://github.com/FasterXML/jackson) from 2.13.3 to 2.13.4.
- [Release notes](https://github.com/FasterXML/jackson/releases)
- [Commits](https://github.com/FasterXML/jackson/commits)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,4,2022-09-05 09:33:18-07:00,"['build.gradle', 'build.gradle']"
"Build: Bump jmh-gradle-plugin from 0.6.6 to 0.6.7 (#5700)

Bumps jmh-gradle-plugin from 0.6.6 to 0.6.7.

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2022-09-05 09:34:05-07:00,['build.gradle']
Build: Update ORC to 1.8.0 (#5699),1,2,2022-09-05 09:36:15-07:00,['versions.props']
Python: Remove fs_properties pass-through (#5689),1,10,2022-09-05 09:37:21-07:00,['fsspec.py']
"Build: Enforce logging conventions with errorprone (#5528)

These errorprone checks are just warnings by default:
https://github.com/palantir/gradle-baseline/blob/4.0.0/baseline-error-prone/src/main/java/com/palantir/baseline/errorprone/Slf4jThrowable.java#L41
https://github.com/palantir/gradle-baseline/blob/4.0.0/baseline-error-prone/src/main/java/com/palantir/baseline/errorprone/LoggerEnclosingClass.java#L41
https://github.com/palantir/gradle-baseline/blob/4.0.0/baseline-error-prone/src/main/java/com/palantir/baseline/errorprone/PreferStaticLoggers.java#L43

Since the codebase has no violations we should increase the severity to
ERROR and enforce these conventions automatically going forward.",1,4,2022-09-05 19:38:12+02:00,['baseline.gradle']
"Build: Upgrade to Gradle 7.5.1 (#5278)

See https://docs.gradle.org/7.5.1/release-notes.html

Upgraded by running the following command twice and manually
re-applying iceberg customizations:

./gradlew wrapper --gradle-version 7.5.1 --distribution-type bin",2,12,2022-09-06 10:11:43+08:00,"['gradle-wrapper.properties', 'gradlew']"
"Python: Pass through the location for the FileIO (#5709)

This way we can determine to load the correct FileIO",1,2,2022-09-06 16:00:28+02:00,['hive.py']
Flink: Fixed an issue where Flink batch entry was not accurate (#5642),2,39,2022-09-07 06:43:08+02:00,"['IcebergStreamWriter.java', 'TestIcebergStreamWriter.java']"
Dell: Add document. (#4993),1,135,2022-09-07 14:03:28+08:00,['dell.md']
Python:Fix FileIO fallback to pyarrow when s3fs not present. (#5717),2,7,2022-09-07 12:27:03+02:00,"['__init__.py', 'fsspec.py']"
"Nessie: Prevent accidental deletion of referenced files (#5718)

Files that are still referenced by other branches/tags",2,25,2022-09-08 13:40:37+02:00,"['NessieTableOperations.java', 'TestNessieTable.java']"
Flink: Fixed an issue where Flink1.14 batch entry was not accurate (#5716),2,38,2022-09-08 16:00:11+02:00,"['IcebergStreamWriter.java', 'TestIcebergStreamWriter.java']"
API: Add estimatedRowsCount to ScanTask (#5720),5,95,2022-09-08 16:56:29+02:00,"['ContentScanTask.java', 'ScanTask.java', 'ScanTaskGroup.java', 'TestDataTableScan.java', 'SparkScan.java']"
Docs: Add snapshot references metadata table (#5725),1,13,2022-09-08 11:16:58-07:00,['spark-queries.md']
Flink: Fixed an issue where Flink1.13 batch entry was not accurate (#5731),2,52,2022-09-09 09:41:27+02:00,"['IcebergStreamWriter.java', 'TestIcebergStreamWriter.java']"
"Build: Bump fastavro from 1.6.0 to 1.6.1 in /python (#5745)

Bumps [fastavro](https://github.com/fastavro/fastavro) from 1.6.0 to 1.6.1.
- [Release notes](https://github.com/fastavro/fastavro/releases)
- [Changelog](https://github.com/fastavro/fastavro/blob/master/ChangeLog)
- [Commits](https://github.com/fastavro/fastavro/compare/1.6.0...1.6.1)

---
updated-dependencies:
- dependency-name: fastavro
  dependency-type: direct:development
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,40,2022-09-13 09:00:46-07:00,"['poetry.lock', 'pyproject.toml']"
"Python: Bump pydantic from 1.10.1 to 1.10.2 (#5744)

Bumps [pydantic](https://github.com/pydantic/pydantic) from 1.10.1 to 1.10.2.
- [Release notes](https://github.com/pydantic/pydantic/releases)
- [Changelog](https://github.com/pydantic/pydantic/blob/main/HISTORY.md)
- [Commits](https://github.com/pydantic/pydantic/compare/v1.10.1...v1.10.2)

---
updated-dependencies:
- dependency-name: pydantic
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,78,2022-09-13 09:53:04-07:00,"['poetry.lock', 'pyproject.toml']"
"API: Use hashCode instead of hash (#5751)

Noticed this in the output, and decided to fix it right away:
```
/Users/fokkodriesprong/Desktop/iceberg/api/src/main/java/org/apache/iceberg/transforms/UnknownTransform.java:89: warning: [ObjectsHashCodeUnnecessaryVarargs] java.util.Objects.hash(non-varargs) should be
replaced with java.util.Objects.hashCode(value) to avoid unnecessary varargs array allocations.
    return Objects.hash(transform);
                       ^
```",2,4,2022-09-13 14:05:20-07:00,"['UnknownTransform.java', 'baseline.gradle']"
"Python: Make Get Properties CLI options consistent. (#5736)

Consistent with Set and Remove CLI options

* Python: Make Get Properties CLI options consistent with Set and Remove CLI Options
* Python: Explicitly specify command names in the annotations and not infer it from the method name to fix F811 lint issues of duplicate method declaration.",2,120,2022-09-14 08:08:37-07:00,"['console.py', 'test_console.py']"
AWS: Preload S3 client in GlueCatalog For LakeFormation enabled tables (#5756),2,63,2022-09-14 13:23:10-07:00,"['GlueCatalog.java', 'GlueTableOperations.java']"
Build - Remove unused global flink dependency from versions.props (#5758),1,1,2022-09-15 07:24:43+02:00,['versions.props']
Build - Move global Spark 2.4 dependency in version.props to Spark 2.4 subproject (#5759),2,8,2022-09-15 07:27:41+02:00,"['build.gradle', 'versions.props']"
Build: Fix names and jobs (#5749),2,9,2022-09-15 06:42:15-07:00,"['open-api.yml', 'python-ci.yml']"
"JdbcCatalog don't override namespace location if set (#5737)

* JdbcCatalog don't override namespace location if set

* Add namespace location tests

* Spotless",2,28,2022-09-15 08:47:40-07:00,"['JdbcCatalog.java', 'TestJdbcCatalog.java']"
"Spark: Exclude Scala library files from JAR (#5754)

* Spark: Fix runtime jars packaging scala library files

* apply review comments",2,4,2022-09-15 11:10:42-07:00,"['build.gradle', 'build.gradle']"
"Python: Add CLI command to list files (#5690)

This makes it easy to check the FileIO:

```
> pyiceberg files nyc.taxis
Snapshots: nyc.taxis
 Snapshot 5937117119577207079, schema 0: file:/Users/fokkodriesprong/Desktop/docker-spark-iceberg/wh/nyc.db/taxis/metadata/snap-5937117119577207079-1-94656c4f-4c66-4600-a4ca-f30377300527.avro
     Manifest: file:/Users/fokkodriesprong/Desktop/docker-spark-iceberg/wh/nyc.db/taxis/metadata/94656c4f-4c66-4600-a4ca-f30377300527-m0.avro
         Datafile: file:/Users/fokkodriesprong/Desktop/docker-spark-iceberg/wh/nyc.db/taxis/data/00003-4-a245d9ee-8462-4a08-8cbc-26b8b33b9377-00001.parquet
```",8,472,2022-09-15 20:21:22-07:00,"['console.py', 'output.py', 'manifest.py', 'snapshots.py', 'test_reader.py', 'conftest.py', 'test_snapshots.py', 'test_manifest.py']"
Build: Relocate httpclient5 dependency for runtime jars (#5761),9,9,2022-09-16 10:00:47-07:00,"['build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle']"
Python: Bump fsspec and s3fs to 2022.8.2 (#5757),2,632,2022-09-16 10:09:25-07:00,"['poetry.lock', 'pyproject.toml']"
AWS: Refactor util methods for applying AWS clients configurations (#5684),6,634,2022-09-17 17:32:26-07:00,"['AssumeRoleAwsClientFactory.java', 'AwsClientFactories.java', 'AwsProperties.java', 'LakeFormationAwsClientFactory.java', 'TestAwsClientFactories.java', 'TestAwsProperties.java']"
"Build: Bump actions/stale from 5.1.1 to 5.2.0 (#5785)

Bumps [actions/stale](https://github.com/actions/stale) from 5.1.1 to 5.2.0.
- [Release notes](https://github.com/actions/stale/releases)
- [Changelog](https://github.com/actions/stale/blob/main/CHANGELOG.md)
- [Commits](https://github.com/actions/stale/compare/v5.1.1...v5.2.0)

---
updated-dependencies:
- dependency-name: actions/stale
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2022-09-18 19:29:04+02:00,['stale.yml']
"Build: Bump spotless-plugin-gradle from 6.10.0 to 6.11.0 (#5786)

Bumps [spotless-plugin-gradle](https://github.com/diffplug/spotless) from 6.10.0 to 6.11.0.
- [Release notes](https://github.com/diffplug/spotless/releases)
- [Changelog](https://github.com/diffplug/spotless/blob/main/CHANGES.md)
- [Commits](https://github.com/diffplug/spotless/compare/gradle/6.10.0...gradle/6.11.0)

---
updated-dependencies:
- dependency-name: com.diffplug.spotless:spotless-plugin-gradle
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2022-09-18 19:29:39+02:00,['build.gradle']
"Python: Set the Iceberg Spec version (#5766)

We pass in the version of the response that we expect for a certain
version. If we change anything in the future in the spec, we can
maintain backward compatibility until the version is being bumped.",1,5,2022-09-19 08:37:20+02:00,['rest.py']
"Python: Add docker-compose for s3 tests (#5750)

This PR adds a docker-compose.yml with the right configuration to
run the s3 tests",5,96,2022-09-19 08:38:19+02:00,"['python-ci.yml', 'CONTRIBUTING.md', 'Makefile', 'docker-compose.yml', 'run-minio.sh']"
"Python: Remove the pre-validators (#5686)

I would like to remove the pre-validators because they are confusing.

Mostly because in the pre-validators the defaults and aliases aren't
applied, do we have to check all the cases. Removing those requires
setting defaults, and checking them afterward.",1,57,2022-09-19 08:39:22+02:00,['metadata.py']
Python: PyArrow support for S3/S3A with properties (#5747),3,176,2022-09-19 15:36:54+02:00,"['pyarrow.py', 'test_io.py', 'test_pyarrow.py']"
"REST: implement handling of OAuth error responses (#5698)

* WIP error handling for OAuth

* cleanup

* tests

* handle non-oauth errors in oauth

* add comment

* allow null fields

* more tests

* more cleanup

* remove unneeded precondition checks

* Fix test

* use assert4j",19,674,2022-09-19 15:56:08-07:00,"['ErrorHandler.java', 'ErrorHandlers.java', 'HTTPClient.java', 'RESTClient.java', 'RESTErrorResponse.java', 'RESTSerializers.java', 'RESTTableOperations.java', 'OAuth2Properties.java', 'OAuth2Util.java', 'ErrorResponse.java', 'ErrorResponseParser.java', 'OAuthErrorResponse.java', 'OAuthErrorResponseParser.java', 'RESTCatalogAdapter.java', 'TestHTTPClient.java', 'TestRESTCatalog.java', 'TestErrorResponseParser.java', 'TestOAuthErrorResponseParser.java', 'rest-catalog-open-api.yaml']"
AWS: Allow users to set the assume role session name (#5765),2,18,2022-09-19 18:53:16-07:00,"['AssumeRoleAwsClientFactory.java', 'AwsProperties.java']"
Python: Fine-tune the API (#5672),13,212,2022-09-19 19:11:08-07:00,"['schema.py', 'metadata.py', 'partitioning.py', 'sorting.py', 'pyproject.toml', 'test_base.py', 'test_hive.py', 'test_rest.py', 'test_init.py', 'test_metadata.py', 'test_partitioning.py', 'test_sorting.py', 'test_schema.py']"
"Python: Handle optional Avro fields in conversion. (#5796)

Found by processing fields in manifestentry with empty split_offsets field.

For pos_to_dict, check if values is None before processing as list,
struct, or dict. Added unit tests to verify.

Thanks to @fokko for the fix.",2,66,2022-09-20 20:07:36+02:00,"['manifest.py', 'test_reader.py']"
"Revert ""REST: implement handling of OAuth error responses (#5698)"" (#5810)

This reverts commit c293af2f1d962f44bb5b67a20ef3c67bd5823a38.",19,674,2022-09-20 12:50:35-07:00,"['ErrorHandler.java', 'ErrorHandlers.java', 'HTTPClient.java', 'RESTClient.java', 'RESTErrorResponse.java', 'RESTSerializers.java', 'RESTTableOperations.java', 'OAuth2Properties.java', 'OAuth2Util.java', 'ErrorResponse.java', 'ErrorResponseParser.java', 'OAuthErrorResponse.java', 'OAuthErrorResponseParser.java', 'RESTCatalogAdapter.java', 'TestHTTPClient.java', 'TestRESTCatalog.java', 'TestErrorResponseParser.java', 'TestOAuthErrorResponseParser.java', 'rest-catalog-open-api.yaml']"
Flink 1.14&1.15 backport: Set custom Hadoop configuration (#5775),3,43,2022-09-20 22:37:12+02:00,"['flink-getting-started.md', 'FlinkCatalogFactory.java', 'FlinkCatalogFactory.java']"
"API/Core: Make ScanReport and its related classes Immutable (#5780)

* Use true immutable objects that are type-safe, thread-safe, null-safe
* Get builder classes for free

This is relying on https://immutables.github.io/ (Apache License 2.0), which allows generating immutable objects and builders via annotation processing.
* Immutable objects are serialization ready (including JSON and its binary forms)
* Supports lazy, derived and optional attributes
* Immutable objects are constructed once, in a consistent state, and can be safely shared
  * Will fail if mandatory attributes are missing
  * Cannot be sneakily modified when passed to other code
* Immutable objects are naturally thread-safe and can therefore be safely shared among threads
  * No excessive copying
  * No excessive synchronization
* Object definitions are pleasant to write and read
  * No boilerplate setter and getters
  * No ugly IDE-generated hashCode, equals and toString methods that end up being stored in source control.

Note that we are specifically preventing people from using Jackson-related annotations (`@JsonSerialize` & `@JsonDeserialize`) in order to avoid potential runtime classpath dependency issues where annotations can be missing and lead to different behavior.",18,816,2022-09-20 16:53:24-07:00,"['checkstyle.xml', 'ScanReport.java', 'TestScanReport.java', 'baseline.gradle', 'build.gradle', 'BaseTableScan.java', 'DeleteFileIndex.java', 'ManifestGroup.java', 'ManifestReader.java', 'CounterResultParser.java', 'ScanMetricsResultParser.java', 'ScanReportParser.java', 'TimerResultParser.java', 'TestCounterResultParser.java', 'TestScanMetricsResultParser.java', 'TestScanReportParser.java', 'TestTimerResultParser.java', 'versions.props']"
Python: Remove duplicate dispatch types (#5808),1,16,2022-09-20 16:54:39-07:00,['base.py']
API: Remove unneeded class variable (#5805),1,5,2022-09-20 16:57:39-07:00,['ManifestEvaluator.java']
Python: Fix docstring (#5804),1,2,2022-09-20 16:58:24-07:00,['base.py']
Core: Serialize statistics files in TableMetadata (#5799),2,22,2022-09-20 17:00:50-07:00,"['TableMetadataParser.java', 'TestTableMetadata.java']"
Core: Reduce duplicated code in JSON Parsers (#5802),12,183,2022-09-21 09:23:15+02:00,"['MetadataUpdateParser.java', 'PartitionSpecParser.java', 'SchemaParser.java', 'SingleValueParser.java', 'SnapshotParser.java', 'SnapshotRefParser.java', 'StatisticsFileParser.java', 'TableIdentifierParser.java', 'NameMappingParser.java', 'FileMetadataParser.java', 'OAuth2Util.java', 'UpdateRequirementParser.java']"
"API,Core: Add scan planning metrics for skipped data/delete files (#5788)",10,250,2022-09-21 10:56:20+02:00,"['DefaultCounter.java', 'ScanReport.java', 'Timer.java', 'DeleteFileIndex.java', 'ManifestGroup.java', 'ManifestReader.java', 'ScanMetricsResultParser.java', 'TestScanPlanningAndReporting.java', 'TestScanMetricsResultParser.java', 'TestScanReportParser.java']"
"Python: Split Python docs (#5727)

* Python: Split Python docs

This PR will split the Python docs in a separate site. The main reason
for this is that the docs are part of the Java release, which is not in
sync with the Python release cylce. Meaning that there is a high probability
that the docs does not match with current version of the code.

This will publish the docs to Github pages, by pushing this to the `gh-pages`
branch. We can set up an alias from Apache, and point pyiceberg.apache.org to
the github pages endpoint.

I also tried readthedocs, but I found that not straightforward. Mostly because
they have a build process on their end that will pull the code, and build the
docs. This involves another pipeline that we have to monitor, and we have to
set up webhooks. I am a simple man, and I like simple things, therefore I went
for mkdocs. This can push the docs to github pages in a single command:
https://www.mkdocs.org/user-guide/deploying-your-docs/#project-pages

Considerations:

- Decided to keep it to a single page for now, we can break it out into different
  pages later on. Let me know what you think of this.
- We build the docs now when we push to master, probably we'll change this
  later to trigger on tags.
- I've removed the Python docs from the other docs to avoid confusion and make sure
  that we have a single source of truth.

An example is shown here: https://fokko.github.io/incubator-iceberg/
(Once this is merged, I'll remove that one)

Closes #363
Closes #3283

* Comments",12,1028,2022-09-21 21:30:52+02:00,"['.asf.yaml', 'python-ci-docs.yml', 'python-api-intro.md', 'python-feature-support.md', 'python-quickstart.md', '.pre-commit-config.yaml', 'CONTRIBUTING.md', 'README.md', 'README.md', 'index.md', 'mkdocs.yml', 'requirements.txt']"
Github: Update issue template with latest release (#5818),1,3,2022-09-21 22:02:23+02:00,['iceberg_bug_report.yml']
"Core: Use JsonUtil.generate in ErrorResponseParser (#5816)

This has been fixed by #5698 but then reverted by #5810",1,15,2022-09-22 09:39:34+02:00,['ErrorResponseParser.java']
Build: Fix Python mkdocs path (#5821),1,2,2022-09-22 09:43:24+02:00,['python-ci-docs.yml']
"Build: Add the path to the Action yaml (#5828)

The paths was invalid, but after fixing it, the Action did
not run because it isn't part of the paths. I think it would
be good to add this as well ",1,1,2022-09-22 08:09:26-07:00,['python-ci-docs.yml']
"Python: Include the tests in source distribution (#5829)

Adds the tests to the source distribution so we
can run them when validating a release.",1,1,2022-09-22 08:09:43-07:00,['pyproject.toml']
"Build: Apply spotless on integration modules as well  (#5827)

This was unintentionally forgotten and usually spotless is able to infer
all java files from the source sets. However, the way we defined the
source sets doesn't seem working with spotless and so
we were defining relevant modules via `target`.",22,2650,2022-09-22 09:32:09-07:00,"['AwsIntegTestUtil.java', 'TestAssumeRoleAwsClientFactory.java', 'TestDefaultAwsClientFactory.java', 'TestDynamoDbCatalog.java', 'TestDynamoDbLockManager.java', 'GlueTestBase.java', 'TestGlueCatalogCommitFailure.java', 'TestGlueCatalogLock.java', 'TestGlueCatalogNamespace.java', 'TestGlueCatalogTable.java', 'LakeFormationTestBase.java', 'TestLakeFormationAwsClientFactory.java', 'TestLakeFormationDataOperations.java', 'TestLakeFormationMetadataOperations.java', 'S3TestUtil.java', 'TestS3FileIOIntegration.java', 'TestS3MultipartUpload.java', 'baseline.gradle', 'SmokeTest.java', 'SmokeTest.java', 'SmokeTest.java', 'SmokeTest.java']"
Core: Do not copy stats because a scan filter is true (#5815),2,11,2022-09-22 14:21:59-07:00,"['ManifestGroup.java', 'ManifestReader.java']"
"Python: Add BoundBooleanExpressionVisitor for bound expressions (#5303)

Co-authored-by: Fokko Driesprong <fokko@apache.org>",2,495,2022-09-22 16:33:30-07:00,"['base.py', 'test_expressions_base.py']"
Python: Test if version is PEP440 compliant (#5834),2,17,2022-09-22 16:35:15-07:00,"['pyproject.toml', 'test_version.py']"
"REST: implement handling of OAuth error responses followup (#5820)

* WIP error handling for OAuth

* cleanup

* tests

* handle non-oauth errors in oauth

* add comment

* allow null fields

* more tests

* more cleanup

* remove unneeded precondition checks

* Fix test

* use assert4j

* Keep client API the same

* Keep ErrorResponse the same

* PR feedback

* handle invalid error response body format",10,367,2022-09-22 19:51:43-07:00,"['ErrorHandler.java', 'ErrorHandlers.java', 'HTTPClient.java', 'OAuth2Properties.java', 'OAuth2Util.java', 'OAuthErrorResponseParser.java', 'TestHTTPClient.java', 'TestCatalogErrorResponseParser.java', 'TestOAuthErrorResponseParser.java', 'rest-catalog-open-api.yaml']"
"Add REST Servlet/Server Implementations (#5781)

* Add REST servlet implementation

* Update accessors

* Add util for form decoding and tests

* Update test dependency

* Spotless",7,364,2022-09-22 19:54:08-07:00,"['build.gradle', 'RESTUtil.java', 'RESTCatalogAdapter.java', 'RESTCatalogServlet.java', 'TestRESTCatalog.java', 'TestRESTUtil.java', 'versions.props']"
"Python: Add the Makefile to the source distribution (#5838)

This makes it easier for testing.

```
  python git:(fd-add-makefile-to-sdist)  poetry build
Building pyiceberg (0.1.0.dev0)
  - Building sdist
  - Built pyiceberg-0.1.0.dev0.tar.gz
  - Building wheel
  - Built pyiceberg-0.1.0.dev0-py3-none-any.whl
  python git:(fd-add-makefile-to-sdist)  cd dist
  dist git:(fd-add-makefile-to-sdist)  tar -xf pyiceberg-0.1.0.dev0.tar.gz
  dist git:(fd-add-makefile-to-sdist)  cd pyiceberg-0.1.0.dev0
  pyiceberg-0.1.0.dev0 git:(fd-add-makefile-to-sdist)  find . | grep Makefile
./Makefile
  pyiceberg-0.1.0.dev0 git:(fd-add-makefile-to-sdist)  head Makefile
```",1,1,2022-09-23 08:55:41-07:00,['pyproject.toml']
AWS: update AWS Integration Test to fix false positives (#5784),5,45,2022-09-23 09:41:48-07:00,"['TestAssumeRoleAwsClientFactory.java', 'TestDefaultAwsClientFactory.java', 'GlueTestBase.java', 'TestGlueCatalogLock.java', 'TestGlueCatalog.java']"
"Python: Add NOTICE to source dist and wheel (#5843)

```
  python git:(master)  poetry build
Building pyiceberg (0.1.0.dev0)
  - Building sdist
  - Built pyiceberg-0.1.0.dev0.tar.gz
  - Building wheel
  - Built pyiceberg-0.1.0.dev0-py3-none-any.whl
  python git:(master)  cd dist
  dist git:(master)  tar -xf pyiceberg-0.1.0.tar.gz
tar: Error opening archive: Failed to open 'pyiceberg-0.1.0.tar.gz'
  dist git:(master)  tar -xf pyiceberg-0.1.0.dev0.tar.gz
  dist git:(master)  cd pyiceberg-0.1.0.dev0
  pyiceberg-0.1.0.dev0 git:(master)  ls -lah | grep -i notice
-rw-r--r--   1 fokkodriesprong  staff   251B Jun 14 21:52 NOTICE
```",1,3,2022-09-23 20:30:28+02:00,['pyproject.toml']
"Python: Add license checker to the source distribution (#5840)

* Python: Add license checker to the source distribution

* Missing comma",3,80,2022-09-23 23:49:46+02:00,"['Makefile', 'check-license', 'pyproject.toml']"
"API, Core: Remove deprecated methods from Snapshot API (#5734)

This also refactors the Snapshot API to track v1 manifest locations and lazily load them when needed, thus removing the need for `FileIO` in the different parsers",31,581,2022-09-23 14:58:11-07:00,"['revapi.yml', 'Snapshot.java', 'BaseIncrementalAppendScan.java', 'BaseSnapshot.java', 'MetadataUpdateParser.java', 'SnapshotParser.java', 'SnapshotProducer.java', 'TableMetadataParser.java', 'TestMetadataUpdateParser.java', 'TestSnapshotJson.java', 'TestTableMetadata.java', 'TestLoadTableResponse.java', 'NessieUtil.java', 'BaseRewriteManifestsSparkAction.java', 'SnapshotFunctionalityTest.java', 'TestExpireSnapshotsAction.java', 'TestRewriteManifestsAction.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestIcebergSourceTablesBase.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestIcebergSourceTablesBase.java', 'IcebergSourceParquetDeleteBenchmark.java', 'IcebergSourceParquetMultiDeleteFileBenchmark.java', 'IcebergSourceParquetWithUnrelatedDeleteBenchmark.java', 'TestIcebergSourceTablesBase.java', 'SparkMicroBatchStream.java', 'TestIcebergSourceTablesBase.java', 'SparkMicroBatchStream.java', 'TestIcebergSourceTablesBase.java']"
Python: Bump pre-commit (#5842),1,10,2022-09-23 17:14:33-07:00,['.pre-commit-config.yaml']
Build: Bump Rat to 0.15 (#5839),1,2,2022-09-23 17:14:59-07:00,['check-license']
Python: Remove version modifier (#5835),1,2,2022-09-24 07:45:15+02:00,['pyproject.toml']
AWS: Add socket connection timeout for Apache Http Builder (#5787),3,193,2022-09-24 16:12:01-07:00,"['AwsProperties.java', 'TestAwsProperties.java', 'PropertyUtil.java']"
Core: Add strict-mode property to JDBC Catalog (#5830),4,171,2022-09-26 09:05:13-07:00,"['JdbcCatalog.java', 'JdbcTableOperations.java', 'JdbcUtil.java', 'TestJdbcCatalog.java']"
"core: Provide mechanism to cache manifest file content (#4518)

* Core: Add CONTENT_CACHES in ManifestFiles.java

* Fix kryo serialization failure for HadoopFileIO

* Add DEBUG log if ContentCache is not created

* Rename properties related to manifest caching

* Fix small string mistakes in testWeakFileIOReferenceCleanUp

* Clarify config documentation and change access modifier

* Fix checkstyle and catch UnsupportedOperationException",6,780,2022-09-26 09:10:27-07:00,"['CatalogProperties.java', 'ManifestFiles.java', 'SystemProperties.java', 'HadoopFileIO.java', 'ContentCache.java', 'TestManifestCaching.java']"
"API: Support setting table statistics (#5794)

Implements `Transaction.updateStatistics` API.",5,220,2022-09-26 09:36:04-07:00,"['UpdateStatistics.java', 'BaseTable.java', 'BaseTransaction.java', 'SetStatistics.java', 'TestSetStatistics.java']"
"Core: Ignore TestManifestCaching#testWeakFileIOReferenceCleanUp (#5865)

A flaky test that we'll disable for now.

Issue opened https://github.com/apache/iceberg/issues/5861",1,2,2022-09-27 13:31:20+02:00,['TestManifestCaching.java']
"Spark 3.2, 3.3: Fix nullability propagation for MergeRows node (#5679)",4,74,2022-09-27 08:50:31-07:00,"['RewriteMergeIntoTable.scala', 'TestCopyOnWriteMerge.java', 'RewriteMergeIntoTable.scala', 'TestCopyOnWriteMerge.java']"
Docs: Make it clear metadata tables support time travel in Spark (#4709),2,57,2022-09-27 10:11:19-07:00,"['spark-queries.md', 'spec.md']"
Docs: Update output of expire_snapshots procedure (#5866),1,2,2022-09-27 10:14:14-07:00,['spark-procedures.md']
Ensure the default value of hive.in.test to avoid overwriting (#5844),1,3,2022-09-27 15:00:22-07:00,['TestHiveMetastore.java']
"API: Extended some deprecation comments in API folder (#5726)

There are some deprecation comments added after 0.14.0 in the API folder
where there is no indication when the particular functionality is going
to be dropped. I marked them to be dropped in 2.0.0.",3,10,2022-09-28 08:07:50-07:00,"['DefaultMetricsContext.java', 'MetricsContext.java', 'Truncate.java']"
Core: Deprecate functions in TableMetadata and DataWriter (#5772),3,39,2022-09-28 08:13:22-07:00,"['TableMetadata.java', 'DataWriter.java', 'TestWriterMetrics.java']"
"Core: Deprecate functions in DeleteWriters (#5771)

There are some functions marked to be deprecated in 0.14. As we passed
that release already and getting close to 1.0.0 this might be the time
to drop them.
This patch takes care of the functions in EqualityDeleteWriter and
PositionDeleteWriter classes in the core/ folder.",17,125,2022-09-28 08:16:03-07:00,"['EqualityDeleteWriter.java', 'PositionDeleteWriter.java', 'BaseTaskWriter.java', 'SortedPosDeleteWriter.java', 'TestAvroDeleteWriters.java', 'FileHelpers.java', 'TestAppenderFactory.java', 'TestFileWriterFactory.java', 'SimpleDataUtil.java', 'SimpleDataUtil.java', 'SimpleDataUtil.java', 'TestOrcDeleteWriters.java', 'TestParquetDeleteWriters.java', 'TestRewriteDataFilesAction.java', 'TestRewriteDataFilesAction.java', 'TestRewriteDataFilesAction.java', 'TestRewriteDataFilesAction.java']"
AWS: Add table level S3 tags (#4402),5,185,2022-09-28 08:42:17-07:00,"['TestGlueCatalogTable.java', 'AwsProperties.java', 'GlueCatalog.java', 'GlueTableOperations.java', 'TestGlueCatalog.java']"
Core: Avoid extra getFileStatus call in HadoopInputFile (#5864),2,22,2022-09-28 10:31:42-07:00,"['HadoopInputFile.java', 'HadoopFileIOTest.java']"
"Orc: Obtain ORC stripe offsets from writer (#5778)

Closes #5777",3,138,2022-09-28 13:11:26-07:00,"['build.gradle', 'OrcFileAppender.java', 'TestOrcDataWriter.java']"
Flink: Add defensive check in IcebergFilesCommitter for restoring state (#5873),3,39,2022-09-29 07:16:53+02:00,"['IcebergFilesCommitter.java', 'IcebergFilesCommitter.java', 'IcebergFilesCommitter.java']"
Spark 3.x: Backport snapshot references metadata table test (#5806),1,123,2022-09-29 10:25:16-07:00,['TestMetadataTables.java']
Build: Fix & run spark integration tests on CI (#5819),4,6,2022-09-29 13:28:13-07:00,"['build.gradle', 'build.gradle', 'build.gradle', 'build.gradle']"
"API, Core: Add scan planning metrics for scanned/skipped delete manifests (#5792)",6,97,2022-09-29 14:19:02-07:00,"['ScanReport.java', 'DeleteFileIndex.java', 'ScanMetricsResultParser.java', 'TestScanPlanningAndReporting.java', 'TestScanMetricsResultParser.java', 'TestScanReportParser.java']"
Docs: Update default value for read.parquet.vectorization.enabled (#5776),1,4,2022-09-29 14:29:50-07:00,['configuration.md']
Nessie: Bump Nessie to 0.43.0 (#5807),1,2,2022-09-29 14:30:27-07:00,['versions.props']
Docs: Update lock catalog properties to correct units (#5708),1,8,2022-09-29 14:46:05-07:00,['configuration.md']
"Build: Bump hadoop-client from 3.1.0 to 3.3.4 (#5519)

Bumps hadoop-client from 3.1.0 to 3.3.4.
Signed-off-by: dependabot[bot] <support@github.com>",1,2,2022-09-29 14:47:46-07:00,['build.gradle']
Spark: Bump Spark version for vulnerability (#5292),2,4,2022-09-29 14:48:38-07:00,"['build.gradle', 'build.gradle']"
API: Expose table statistics in Table API (#4741),6,31,2022-09-29 14:56:48-07:00,"['revapi.yml', 'Table.java', 'BaseMetadataTable.java', 'BaseTable.java', 'BaseTransaction.java', 'SerializableTable.java']"
Python: Don't throw missing URI error when --uri was provided (#5885),1,8,2022-09-29 15:01:11-07:00,['console.py']
Python: Update README test instructions (#5869),1,4,2022-09-29 15:11:29-07:00,['README.md']
Docs: Fix formatting in Python CLI (#5868),1,4,2022-09-29 15:12:12-07:00,['index.md']
Build: Cache gradle wrapper in workflows (#4165),5,72,2022-09-29 15:56:12-07:00,"['flink-ci.yml', 'hive-ci.yml', 'java-ci.yml', 'jmh-bechmarks.yml', 'spark-ci.yml']"
"Python: Add code conventions for Python (#5879)

* Python: Add code conventions for Python

* Comments",2,78,2022-09-30 15:03:45+02:00,"['CONTRIBUTING.md', 'deprecated.py']"
"API,Core: Add scan planning metrics for indexed/eq/pos delete files (#5809)

* API,Core: Add scan planning metrics for indexed/eq/pos delete files

* evaluate deletes files only once",6,134,2022-09-30 08:07:52-07:00,"['ScanReport.java', 'DeleteFileIndex.java', 'ScanMetricsResultParser.java', 'TestScanPlanningAndReporting.java', 'TestScanMetricsResultParser.java', 'TestScanReportParser.java']"
"Build: Bump gradle-baseline-java from 4.0.0 to 4.42.0 (#5530)

* Build: Bump gradle-baseline-java from 4.0.0 to 4.42.0

* increase gradle heap size

* fixup! Build: Bump gradle-baseline-java from 4.0.0 to 4.42.0",8,26,2022-09-30 08:16:37-07:00,"['LakeFormationTestBase.java', 'DynamoDbLockManager.java', 'baseline.gradle', 'build.gradle', 'GuavaClasses.java', 'CatalogUtil.java', 'HadoopCatalog.java', 'gradle.properties']"
Docs: Add table and namespace S3 tags doc (#5894),1,11,2022-09-30 08:52:49-07:00,['aws.md']
"Core, Spark: Retain statistics files during orphan files removal (#5795)",19,929,2022-09-30 08:58:25-07:00,"['GenericBlobMetadata.java', 'ReachableFileUtil.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseSparkAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesProcedure.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseSparkAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesProcedure.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseSparkAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesProcedure.java', 'BaseSparkAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesProcedure.java', 'BaseSparkAction.java', 'TestRemoveOrphanFilesAction.java']"
[Docs] Update drop table behavior in spark-ddl docs (#5645),1,18,2022-09-30 20:33:53+02:00,['spark-ddl.md']
Spark 3.3: Fix failing jmh benchmarks under org.apache.iceberg.spark.data.parquet package (#5635),4,6,2022-09-30 20:36:07+02:00,"['SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java']"
"Core: Only validate the current partition specs (#5707)

If a fields is being deleted that used to be part of a partition spec,
that will throw an error because it cannot resolve the field anymore.

Closes #5676
Closes #5707
Closes #5399",4,87,2022-09-30 16:19:38-07:00,"['PartitionSpec.java', 'TableMetadataParser.java', 'TestAlterTablePartitionFields.java', 'TestAlterTablePartitionFields.java']"
Core: Add RESTScanReporter to send scan report to REST endpoint (#5407),18,798,2022-09-30 16:29:09-07:00,"['LoggingMetricsReporter.java', 'MetricsReport.java', 'MetricsReporter.java', 'ScanReport.java', 'BaseTable.java', 'BaseTableScan.java', 'TableScanContext.java', 'ScanReportParser.java', 'RESTSerializers.java', 'RESTSessionCatalog.java', 'ResourcePaths.java', 'ReportMetricsRequest.java', 'ReportMetricsRequestParser.java', 'TestScanPlanningAndReporting.java', 'TestTables.java', 'RESTCatalogAdapter.java', 'TestReportMetricsRequestParser.java', 'rest-catalog-open-api.yaml']"
"Build: Bump jmh-gradle-plugin from 0.6.7 to 0.6.8 (#5850)

Bumps jmh-gradle-plugin from 0.6.7 to 0.6.8.

---
updated-dependencies:
- dependency-name: me.champeau.jmh:jmh-gradle-plugin
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2022-10-01 11:52:22+02:00,['build.gradle']
"Build: Bump actions/stale from 5.2.0 to 6.0.0 (#5851)

Bumps [actions/stale](https://github.com/actions/stale) from 5.2.0 to 6.0.0.
- [Release notes](https://github.com/actions/stale/releases)
- [Changelog](https://github.com/actions/stale/blob/main/CHANGELOG.md)
- [Commits](https://github.com/actions/stale/compare/v5.2.0...v6.0.0)

---
updated-dependencies:
- dependency-name: actions/stale
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2022-10-01 11:52:54+02:00,['stale.yml']
"Build: Bump jinja2 from 3.0.3 to 3.1.2 in /python (#5849)

Bumps [jinja2](https://github.com/pallets/jinja) from 3.0.3 to 3.1.2.
- [Release notes](https://github.com/pallets/jinja/releases)
- [Changelog](https://github.com/pallets/jinja/blob/main/CHANGES.rst)
- [Commits](https://github.com/pallets/jinja/compare/3.0.3...3.1.2)

---
updated-dependencies:
- dependency-name: jinja2
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2022-10-01 11:53:04+02:00,['requirements.txt']
"Build: Bump coverage from 6.4.4 to 6.5.0 in /python (#5904)

Bumps [coverage](https://github.com/nedbat/coveragepy) from 6.4.4 to 6.5.0.
- [Release notes](https://github.com/nedbat/coveragepy/releases)
- [Changelog](https://github.com/nedbat/coveragepy/blob/master/CHANGES.rst)
- [Commits](https://github.com/nedbat/coveragepy/compare/6.4.4...6.5.0)

---
updated-dependencies:
- dependency-name: coverage
  dependency-type: direct:development
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,516,2022-10-02 20:59:50+02:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump rich from 12.5.1 to 12.6.0 in /python (#5905)

Bumps [rich](https://github.com/willmcgugan/rich) from 12.5.1 to 12.6.0.
- [Release notes](https://github.com/willmcgugan/rich/releases)
- [Changelog](https://github.com/Textualize/rich/blob/master/CHANGELOG.md)
- [Commits](https://github.com/willmcgugan/rich/compare/v12.5.1...v12.6.0)

---
updated-dependencies:
- dependency-name: rich
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,6,2022-10-02 22:00:13+02:00,['poetry.lock']
"Build: Bump pytest-checkdocs from 2.7.1 to 2.8.1 in /python (#5903)

Bumps [pytest-checkdocs](https://github.com/jaraco/pytest-checkdocs) from 2.7.1 to 2.8.1.
- [Release notes](https://github.com/jaraco/pytest-checkdocs/releases)
- [Changelog](https://github.com/jaraco/pytest-checkdocs/blob/main/CHANGES.rst)
- [Commits](https://github.com/jaraco/pytest-checkdocs/compare/v2.7.1...v2.8.1)

---
updated-dependencies:
- dependency-name: pytest-checkdocs
  dependency-type: direct:development
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,42,2022-10-02 22:44:56+02:00,"['poetry.lock', 'pyproject.toml']"
Core: Rename misleading local variable in planFiles() (#5889),1,4,2022-10-03 16:14:18+02:00,['BaseTableScan.java']
"Infra: Avoid running engine tests on ISSUE_TEMPLATE update (#5859)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",4,4,2022-10-03 16:15:02+02:00,"['flink-ci.yml', 'hive-ci.yml', 'java-ci.yml', 'spark-ci.yml']"
"API, Core: Support scanning tags and branches (#5364)",6,151,2022-10-03 08:34:47-07:00,"['revapi.yml', 'TableScan.java', 'BaseAllMetadataTableScan.java', 'BaseTableScan.java', 'IncrementalDataTableScan.java', 'TestDataTableScan.java']"
Spark: Set the version explicitly (#5907),2,12,2022-10-04 08:08:12-07:00,"['TestAlterTablePartitionFields.java', 'TestAlterTablePartitionFields.java']"
API: Make COUNT default unit when creating a Counter (#5912),11,61,2022-10-04 09:01:36-07:00,"['OSSInputStream.java', 'OSSOutputStream.java', 'MetricsContext.java', 'ScanReport.java', 'TestCloseableIterable.java', 'S3InputStream.java', 'S3OutputStream.java', 'EcsAppendOutputStream.java', 'EcsSeekableInputStream.java', 'GCSInputStream.java', 'GCSOutputStream.java']"
Core: Reuse PositionDelete (#5896),10,26,2022-10-04 09:29:07-07:00,"['PositionDeleteWriter.java', 'SortedPosDeleteWriter.java', 'TestAvroDeleteWriters.java', 'FileHelpers.java', 'TestAppenderFactory.java', 'TestFileWriterFactory.java', 'SimpleDataUtil.java', 'SimpleDataUtil.java', 'SimpleDataUtil.java', 'TestParquetDeleteWriters.java']"
Python: Fix the link in the README (#5898),1,2,2022-10-04 10:04:57-07:00,['README.md']
Spark 3.3: Fix nullability in merge-on-read projections (#5880),4,149,2022-10-04 17:46:22-07:00,"['RewriteMergeIntoTable.scala', 'RewriteRowLevelIcebergCommand.scala', 'TestCopyOnWriteMerge.java', 'TestMerge.java']"
Spark 3.2: Fix nullability in merge-on-read projections (#5917),4,150,2022-10-05 14:32:38+02:00,"['RewriteMergeIntoTable.scala', 'RewriteRowLevelCommand.scala', 'TestCopyOnWriteMerge.java', 'TestMerge.java']"
"Python: Bump version to 0.2.0.dev0 (#5906)

* Python: Bump version to 0.2.0

In preparation of the next release

* Add dev modifier",1,2,2022-10-05 14:33:57+02:00,['pyproject.toml']
Python: Pin the version in the codebase (#5854),3,15,2022-10-05 10:11:09-07:00,"['__init__.py', 'pyproject.toml', 'test_version.py']"
"Tests: Replace and ban ExpectedException usage (#5921)

It is generally not good practice to use the `ExpectedException` rule,
because it is difficult to determine in multi-line tests where exactly
an exception is thrown, since the rule is very broad.",16,164,2022-10-05 11:24:26-07:00,"['checkstyle.xml', 'TableMetadataParserCodecTest.java', 'TestMetricsModes.java', 'TestSchemaUnionByFieldName.java', 'TestMetricsRowGroupFilter.java', 'TestBuildOrcProjection.java', 'TestStructuredStreaming.java', 'TestTimestampWithoutZone.java', 'TestStructuredStreaming.java', 'TestTimestampWithoutZone.java', 'TestStructuredStreaming.java', 'TestTimestampWithoutZone.java', 'TestStructuredStreaming.java', 'TestTimestampWithoutZone.java', 'TestStructuredStreaming.java', 'TestTimestampWithoutZone.java']"
Python: Add rewriteNot (#5925),2,94,2022-10-05 13:33:18-07:00,"['base.py', 'test_expressions_base.py']"
Python: Add more expression tests (#5923),3,527,2022-10-05 13:45:49-07:00,"['base.py', 'schema.py', 'test_expressions_base.py']"
Python: Remove the __init__ from the tests (#5919),10,148,2022-10-05 13:48:49-07:00,"['pyproject.toml', '__init__.py', '__init__.py', '__init__.py', '__init__.py', '__init__.py', '__init__.py', 'test_io.py', '__init__.py', '__init__.py']"
API: Handle negative/zero in expression sanitizer (#5928),2,23,2022-10-06 11:55:21-07:00,"['ExpressionUtil.java', 'TestExpressionUtil.java']"
Core: Provide better error message on invalid enums (#5910),28,184,2022-10-06 11:56:45-07:00,"['DistributionMode.java', 'RewriteJobOrder.java', 'SnapshotRefType.java', 'SortDirection.java', 'DeleteOrphanFiles.java', 'Expression.java', 'MetricsContext.java', 'IsolationLevel.java', 'MetadataUpdateParser.java', 'SnapshotRefParser.java', 'SortOrderParser.java', 'TableMetadataParser.java', 'ExpressionParser.java', 'TimerResultParser.java', 'ReportMetricsRequest.java', 'ReportMetricsRequestParser.java', 'TableMetadataParserCodecTest.java', 'TestSnapshotRefParser.java', 'TestSortOrderParser.java', 'TestExpressionParser.java', 'TestCounterResultParser.java', 'TestTimerResultParser.java', 'TestReportMetricsRequestParser.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSink.java', 'SparkMergeBuilder.java', 'SparkMergeBuilder.java']"
Python: Update release instructions (#5856),1,84,2022-10-06 15:55:15-07:00,['RELEASE.md']
API: Reduce sanitized expression string length for large IN lists (#5908),2,95,2022-10-06 16:09:19-07:00,"['ExpressionUtil.java', 'TestExpressionUtil.java']"
Core: Deprecate write.manifest-lists.enabled (#5773),6,463,2022-10-07 09:33:23-07:00,"['BaseSnapshot.java', 'SnapshotProducer.java', 'TableProperties.java', 'TestMetadataUpdateParser.java', 'TestSnapshotJson.java', 'TestTableMetadata.java']"
Spark 3.3: Add SparkChangelogTable (#5740),17,1158,2022-10-07 10:23:48-07:00,"['ChangelogUtil.java', 'MetadataColumns.java', 'Util.java', 'TestChangelogBatchReads.java', 'SparkCatalog.java', 'ChangelogRowReader.java', 'SparkBatch.java', 'SparkChangelogBatch.java', 'SparkChangelogScan.java', 'SparkChangelogTable.java', 'SparkInputPartition.java', 'SparkMicroBatchStream.java', 'SparkScan.java', 'SparkScanBuilder.java', 'SparkTable.java', 'TestRemoveOrphanFilesAction3.java', 'TestPathIdentifier.java']"
Python: Add partition_type to partition_spec (#5929),2,47,2022-10-07 13:53:43-07:00,"['partitioning.py', 'test_partitioning.py']"
Core: Fix data seq number handling in ManifestEntry (#5913),19,414,2022-10-08 18:13:20-07:00,"['ManifestFile.java', 'DeleteFileIndex.java', 'GenericManifestEntry.java', 'InheritableMetadataFactory.java', 'ManifestEntry.java', 'ManifestFilterManager.java', 'ManifestWriter.java', 'V1Metadata.java', 'V2Metadata.java', 'TableTestBase.java', 'TestManifestWriter.java', 'TestManifestWriterVersions.java', 'TestMergeAppend.java', 'TestRewriteFiles.java', 'TestRewriteManifests.java', 'TestRowDelta.java', 'TestSequenceNumberForV2Table.java', 'TestV1ToV2RowDeltaDelete.java', 'spec.md']"
AWS: Add socket connection timeout for UrlConnectionHttpClient (#5900),2,144,2022-10-09 10:07:18-07:00,"['AwsProperties.java', 'TestAwsProperties.java']"
"Python: Ability to Prune Columns (#5931)

This is required if we want to implement `.select(*columns: str)`",3,402,2022-10-09 13:18:54-07:00,"['schema.py', 'types.py', 'test_schema.py']"
AWS: Add additional configurations for ApacheHttpClientBuilder (#5899),3,314,2022-10-09 15:37:55-07:00,"['AwsProperties.java', 'TestAwsProperties.java', 'PropertyUtil.java']"
Docs: Add doc for HTTP client configurations (#5902),1,50,2022-10-09 15:45:10-07:00,['aws.md']
"Build: Bump actions/stale from 6.0.0 to 6.0.1 (#5940)

Bumps [actions/stale](https://github.com/actions/stale) from 6.0.0 to 6.0.1.
- [Release notes](https://github.com/actions/stale/releases)
- [Changelog](https://github.com/actions/stale/blob/main/CHANGELOG.md)
- [Commits](https://github.com/actions/stale/compare/v6.0.0...v6.0.1)

---
updated-dependencies:
- dependency-name: actions/stale
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2022-10-10 09:27:19+02:00,['stale.yml']
"Build: Bump pytest-checkdocs from 2.8.1 to 2.9.0 in /python (#5941)

Bumps [pytest-checkdocs](https://github.com/jaraco/pytest-checkdocs) from 2.8.1 to 2.9.0.
- [Release notes](https://github.com/jaraco/pytest-checkdocs/releases)
- [Changelog](https://github.com/jaraco/pytest-checkdocs/blob/main/CHANGES.rst)
- [Commits](https://github.com/jaraco/pytest-checkdocs/compare/v2.8.1...v2.9.0)

---
updated-dependencies:
- dependency-name: pytest-checkdocs
  dependency-type: direct:development
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,14,2022-10-10 09:27:31+02:00,"['poetry.lock', 'pyproject.toml']"
"Python: Catch ValidationError on invalid REST response (#5897)

* Python: Catch ValidationError on invalid REST response

If an implementation of the rest catalog returns something different than
we expect, we just propagate the ValidationError, which subclasses the
ValueError. When using the CLI, it will tell you that the URI is not set,
but actually it is, it is just invalid.

This will return the json to the user, and also tell what's wrong with the
response.

* Fix the formatting",2,23,2022-10-10 11:36:41+02:00,"['rest.py', 'test_rest.py']"
"Core: Deflake TestManifestCaching.testWeakFileIOReferenceCleanUp (#5862)

* Core: Deflake TestManifestCaching.testWeakFileIOReferenceCleanUp

* Simplify testWeakFileIOReferenceCleanUp by not exceeding IO_MANIFEST_CACHE_MAX_FILEIO_DEFAULT

* Include GcFinalization into iceberg-bundled-guava

* Exclude com.google.errorprone from guava-testlib

* Exclude com.google.code.findbugs and com.google.j2objc from guava-testlib

* Supress BanUnrelocatedGuavaClasses for test files

* Add rule BanGuavaTesting

* Replace awaitFullGc with awaitDone",6,90,2022-10-10 11:38:38-07:00,"['checkstyle-suppressions.xml', 'checkstyle.xml', 'build.gradle', 'ManifestFiles.java', 'TestManifestCaching.java', 'versions.props']"
AWS: Fix NotSerializableException when using AssumeRoleAwsClientFactory in Spark (#5939),2,92,2022-10-11 08:51:59-07:00,"['AssumeRoleAwsClientFactory.java', 'TestAwsClientFactories.java']"
API: Provide better error message for invalid FileFormat enum (#5918),89,310,2022-10-11 10:34:33-07:00,"['FileFormat.java', 'BaseFile.java', 'DataFiles.java', 'FileMetadata.java', 'OutputFileFactory.java', 'TestSplitScan.java', 'FileHelpers.java', 'TestLocalScan.java', 'TestMetricsRowGroupFilter.java', 'TestMetricsRowGroupFilterTypes.java', 'TestAppenderFactory.java', 'TestBaseTaskWriter.java', 'TestGenericSortedPosDeleteWriter.java', 'TestTaskEqualityDeltaWriter.java', 'FlinkWriteConf.java', 'FlinkFileWriterFactory.java', 'RowDataRewriter.java', 'TestDeltaTaskWriter.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkV2.java', 'TestIcebergFilesCommitter.java', 'TestIcebergStreamWriter.java', 'TestTaskWriters.java', 'TestFlinkScan.java', 'FlinkWriteConf.java', 'FlinkFileWriterFactory.java', 'RowDataRewriter.java', 'TestDeltaTaskWriter.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkV2.java', 'TestIcebergFilesCommitter.java', 'TestIcebergStreamWriter.java', 'TestTaskWriters.java', 'TestFlinkScan.java', 'FlinkWriteConf.java', 'FlinkFileWriterFactory.java', 'RowDataRewriter.java', 'TestDeltaTaskWriter.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkV2.java', 'TestIcebergFilesCommitter.java', 'TestIcebergStreamWriter.java', 'TestTaskWriters.java', 'TestFlinkScan.java', 'HiveIcebergOutputFormat.java', 'TestIcebergInputFormats.java', 'SparkDataFile.java', 'SparkWriteConf.java', 'RowDataRewriter.java', 'SparkFileWriterFactory.java', 'TestFilteredScan.java', 'TestSparkDataWrite.java', 'TestSparkReadProjection.java', 'TestSparkTableUtil.java', 'TestTimestampWithoutZone.java', 'SparkDataFile.java', 'SparkWriteConf.java', 'RowDataRewriter.java', 'SparkFileWriterFactory.java', 'TestFilteredScan.java', 'TestSparkDataWrite.java', 'TestSparkReadProjection.java', 'TestTimestampWithoutZone.java', 'SparkDataFile.java', 'SparkWriteConf.java', 'RowDataRewriter.java', 'SparkFileWriterFactory.java', 'TestFilteredScan.java', 'TestSparkDataWrite.java', 'TestSparkReadProjection.java', 'TestTimestampWithoutZone.java', 'SparkDataFile.java', 'SparkWriteConf.java', 'RowDataRewriter.java', 'SparkFileWriterFactory.java', 'TestFilteredScan.java', 'TestSparkDataWrite.java', 'TestSparkReadProjection.java', 'TestSparkReaderWithBloomFilter.java', 'TestTimestampWithoutZone.java', 'SparkDataFile.java', 'SparkWriteConf.java', 'RowDataRewriter.java', 'SparkFileWriterFactory.java', 'TestFilteredScan.java', 'TestSparkDataWrite.java', 'TestSparkReadProjection.java', 'TestSparkReaderWithBloomFilter.java', 'TestTimestampWithoutZone.java']"
"API: Optimize the Array creation (#5733)

* code optimization

* better optimization",1,5,2022-10-12 09:21:32+02:00,['PartitionSpec.java']
Docs: Fix table name (#5962),1,2,2022-10-12 09:23:12+02:00,['flink-connector.md']
Core: Make testEnvironmentSubstitution effective when USER is not set (#5770),1,24,2022-10-12 08:38:31-07:00,['TestEnvironmentUtil.java']
API: Fix estimated row count in ContentScanTask (#5755),2,82,2022-10-12 12:57:22-07:00,"['ContentScanTask.java', 'TestSparkScan.java']"
"Core: Clear queue and future task when close ParallelIterable (#5887)

Co-authored-by: zhouyuhao <zhouyuhao@xiaomi.com>",2,85,2022-10-12 16:08:03-07:00,"['ParallelIterable.java', 'TestParallelIterable.java']"
Python: Manifest evaluator (#5845),5,1114,2022-10-12 16:31:55-07:00,"['base.py', 'manifest.py', 'test_expressions_base.py', 'test_snapshots.py', 'test_manifest.py']"
Core: Expire Snapshots reachability analysis (#5669),5,1030,2022-10-12 16:44:48-07:00,"['FileCleanupStrategy.java', 'IncrementalFileCleanup.java', 'ReachableFileCleanup.java', 'RemoveSnapshots.java', 'TestRemoveSnapshots.java']"
Python: Bump pre-commit versions (#5943),1,6,2022-10-13 11:23:59-07:00,['.pre-commit-config.yaml']
"Python: Fix incorrect annotation, StringType to BinaryType (#5950)",1,28,2022-10-13 11:25:29-07:00,['reader.py']
Spark 3.3: Split SparkScan and SparkBatch (#5934),2,68,2022-10-13 14:22:05-07:00,"['SparkBatch.java', 'SparkScan.java']"
"Core, Spark: Fix Kryo deserialization of SerializableTable (#5975)",2,18,2022-10-13 21:24:37-07:00,"['SerializableTable.java', 'TestTableSerialization.java']"
Flink: Revise columns of TestFlinkUpsert to make tables are partitioned by date and more understandable (#5486) (#5486),2,213,2022-10-13 21:56:58-07:00,"['TestFlinkUpsert.java', 'TestFlinkUpsert.java']"
Spark: Optimize snapshot expiry (#3457),10,395,2022-10-13 22:31:12-07:00,"['AllManifestsTable.java', 'ReachableFileUtil.java', 'BaseSparkAction.java', 'ExpireSnapshotsSparkAction.java', 'TestExpireSnapshotsAction.java', 'TestHelpers.java', 'BaseSparkAction.java', 'ExpireSnapshotsSparkAction.java', 'TestExpireSnapshotsAction.java', 'TestHelpers.java']"
"Docs: Fix incorrect glue catalog class name (#5973)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",1,2,2022-10-14 18:49:16+02:00,['hive.md']
Core: Remove confusing log from RemoveSnapshots (#5478),1,5,2022-10-14 13:48:14-07:00,['RemoveSnapshots.java']
API: Add BatchScan (#5922),6,380,2022-10-14 14:37:41-07:00,"['BatchScan.java', 'BatchScanAdapter.java', 'Scan.java', 'Table.java', 'TableScan.java', 'TestBatchScans.java']"
Docs: Fix typo in DataFrameReader table load (#5978),2,8,2022-10-14 15:00:18-07:00,"['spark-queries.md', 'IcebergSource.java']"
API: Fix Transforms javadoc (#5980),2,14,2022-10-14 16:33:12-07:00,"['Transforms.java', 'spec.md']"
"Python: Cleanup inconsistencies around OAuth responses (#5957)

* Python: Cleanup inconsistency in OAuth responses

401 also returns oauth token reponse
https://github.com/apache/iceberg/blob/master/open-api/rest-catalog-open-api.yaml#L170-L178

* Comments

* Switch them around",5,94,2022-10-17 13:11:51+02:00,"['__init__.py', 'rest.py', 'console.py', 'exceptions.py', 'test_rest.py']"
"AWS: Fix format string in error message (#5995)

Change-Id: Ib131ad89ddc554238e534f1d03cefefacd428ebe",1,5,2022-10-17 09:58:54-07:00,['AwsProperties.java']
Spark: Fix date_add in IcebergSourceFlatParquetDataWriteBenchmark (#5991),5,10,2022-10-17 16:02:59-07:00,"['IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java']"
Core: Support performing delete files and merge appends on branches (#5618),6,612,2022-10-17 18:03:51-07:00,"['MergeAppend.java', 'StreamingDelete.java', 'TableTestBase.java', 'TestDeleteFiles.java', 'TestMergeAppend.java', 'TestRemoveSnapshots.java']"
Build: Bump Nessie from 0.43.0 to 0.44.0 (#6008),1,2,2022-10-18 17:14:37+02:00,['versions.props']
"Docx: Typos related to date transforms (#5992)

This commit fixes typos in the Javadoc for the
month/day/hour transforms.",1,6,2022-10-18 18:33:49+02:00,['Transforms.java']
Spark: Add option to remove backup table after successful migrate action (#5622),14,228,2022-10-18 11:28:50-07:00,"['revapi.yml', 'MigrateTable.java', 'TestMigrateTableProcedure.java', 'BaseMigrateTableSparkAction.java', 'MigrateTableProcedure.java', 'TestMigrateTableProcedure.java', 'BaseMigrateTableSparkAction.java', 'MigrateTableProcedure.java', 'TestMigrateTableProcedure.java', 'MigrateTableSparkAction.java', 'MigrateTableProcedure.java', 'TestMigrateTableProcedure.java', 'MigrateTableSparkAction.java', 'MigrateTableProcedure.java']"
Core: Fix NPE in SnapshotUtil when parent snapshot ID is null (#6005),2,160,2022-10-18 12:30:12-07:00,"['SnapshotUtil.java', 'TestSnapshotUtil.java']"
"Flink: Fix NoClassDefFound with Flink runtime jar / Add integration test (#6001)

* Flink: Fix NoClassDefFound with Flink runtime jar

* Flink: Add Smoke test",4,206,2022-10-18 14:10:33-07:00,"['build.gradle', 'IcebergConnectorSmokeTest.java', 'build.gradle', 'IcebergConnectorSmokeTest.java']"
Spark 3.2: Use ScanTaskGroup methods when computing stats (#6011),1,16,2022-10-18 15:26:02-07:00,['SparkScan.java']
Spark 3.2: Add SparkChangelogTable (#6013),13,1004,2022-10-18 16:16:34-07:00,"['TestChangelogBatchReads.java', 'SparkCatalog.java', 'ChangelogRowReader.java', 'SparkBatch.java', 'SparkChangelogBatch.java', 'SparkChangelogScan.java', 'SparkChangelogTable.java', 'SparkInputPartition.java', 'SparkMicroBatchStream.java', 'SparkScan.java', 'SparkScanBuilder.java', 'TestRemoveOrphanFilesAction3.java', 'TestPathIdentifier.java']"
Spark 3.2: Remove redundant imports in SparkScan (#6016),1,2,2022-10-18 19:55:14-07:00,['SparkScan.java']
Core: Fix flaky test in TestSnapshotUtil (#6015),1,9,2022-10-19 07:28:47-07:00,['TestSnapshotUtil.java']
Spark 3.2: Split SparkScan and SparkBatch (#6014),2,68,2022-10-19 10:09:04-07:00,"['SparkBatch.java', 'SparkScan.java']"
"Core: Parallelize reading reachable manifests, improve logs (#5981)",3,112,2022-10-19 10:33:39-07:00,"['FileCleanupStrategy.java', 'IncrementalFileCleanup.java', 'ReachableFileCleanup.java']"
Orc: Support row group bloom filters (#5313),5,214,2022-10-20 16:47:36+02:00,"['build.gradle', 'TableProperties.java', 'configuration.md', 'ORC.java', 'TestBloomFilter.java']"
"Python: Add SSL support for REST Catalog (#6019)

* Python: Add support for providing SSL config for REST Catalog client.

* Python: Add documentation on mTLS REST Catalog config. Encapsulate headers as well as it no longer needs to be a property.

* Update python/pyiceberg/catalog/rest.py

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* Update python/pyiceberg/catalog/rest.py

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* Python: Refactor to initialize requests session in a single method.

* Python: Set the HTTP headers after fetching the OAuth token as the Oauth token call expects the Content-Type application/x-www-form-urlencoded. Enforce the content-type check for oauth calls in unit tests as well.

Co-authored-by: Fokko Driesprong <fokko@apache.org>",3,161,2022-10-20 20:16:49+02:00,"['index.md', 'rest.py', 'test_rest.py']"
Core: Add modeName to RowLevelOperationMode (#6006),22,126,2022-10-20 12:14:05-07:00,"['RowLevelOperationMode.java', 'TableProperties.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'SparkTable.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'SparkTable.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestMergeOnReadDelete.java', 'TestMergeOnReadMerge.java', 'TestMergeOnReadUpdate.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestMergeOnReadDelete.java', 'TestMergeOnReadMerge.java', 'TestMergeOnReadUpdate.java']"
Python: BOTO_STS_CLIENT lazy initialization (#5930),1,10,2022-10-21 00:25:06+02:00,['s3_filesystem.py']
Core: Avoid scan planning failure if REST metric reporting fails (#6023),1,16,2022-10-20 16:59:17-07:00,['RESTSessionCatalog.java']
Nessie: Do not post metadata JSON to Nessie (#5999),3,126,2022-10-20 17:05:18-07:00,"['NessieTableOperations.java', 'NessieUtil.java', 'TestNessieUtil.java']"
"Core: Deprecate HTTPClientFactory, configure ObjectMapper for HTTPClient (#5998)",6,47,2022-10-20 17:06:54-07:00,"['HTTPClient.java', 'HTTPClientFactory.java', 'RESTCatalog.java', 'RESTSessionCatalog.java', 'TestHTTPClient.java', 'TestRESTCatalog.java']"
"Hive: Forward catalog-specific Hive configuration properties (#5989)

Closes #5988.",2,21,2022-10-20 17:08:24-07:00,"['HiveCatalog.java', 'TestHiveCatalog.java']"
"Python: Split expressions base (#5987)

I also played around with a bound.py, but it is so intertwined with the
unbound, that I think it makes more sense to have it into a single file.",5,3085,2022-10-20 17:10:36-07:00,"['__init__.py', 'visitors.py', 'test_expressions.py', 'test_visitors.py', 'test_schema.py']"
"Docs: Add an example of CTAS with PARTITIONED BY, from #3854 (#6020)

Co-authored-by: kyle-cx <2410753379@qq.com>",1,10,2022-10-20 17:11:19-07:00,['spark-ddl.md']
Hive: Set the Table owner on table creation (#5763),3,110,2022-10-21 07:37:17+02:00,"['TableProperties.java', 'HiveTableOperations.java', 'TestHiveCatalog.java']"
Tests: Replace Assert.fail usage with AssertJ (#6029),39,890,2022-10-21 08:16:02-07:00,"['TestLocalAliyunOSS.java', 'TestHelpers.java', 'TestExpressionUtil.java', 'TestPredicateBinding.java', 'TestExceptionUtil.java', 'TestAssumeRoleAwsClientFactory.java', 'TestAwsClientFactories.java', 'TestReadProjection.java', 'TestHadoopCommits.java', 'TestReadProjection.java', 'TestExceptionCode.java', 'TestRowDataWrapper.java', 'TestRowDataWrapper.java', 'TestRowDataWrapper.java', 'TestHiveIcebergOutputCommitter.java', 'TestBloomFilter.java', 'TestReadProjection.java', 'TestDataFrameWrites.java', 'TestReadProjection.java', 'TestDelete.java', 'TestMerge.java', 'TestUpdate.java', 'TestDataFrameWrites.java', 'TestReadProjection.java', 'TestDelete.java', 'TestMerge.java', 'TestUpdate.java', 'TestDataFrameWrites.java', 'TestReadProjection.java', 'TestDelete.java', 'TestMerge.java', 'TestUpdate.java', 'TestDataFrameWrites.java', 'TestReadProjection.java', 'TestDelete.java', 'TestMerge.java', 'TestUpdate.java', 'TestDataFrameWrites.java', 'TestReadProjection.java']"
"Spark/Flink: Replace & Ban Hamcrest usage (#6030)

Most of the time using Hamcrest Matchers is much more clunky and so we
should rather use AssertJ assertions as those are more fluent and more
flexible in their usage & readability.",8,51,2022-10-21 20:00:16+02:00,"['checkstyle.xml', 'TestContinuousIcebergEnumerator.java', 'TestContinuousIcebergEnumerator.java', 'TestSparkParquetReader.java', 'TestSparkParquetReader.java', 'TestSparkParquetReader.java', 'TestSparkParquetReader.java', 'TestSparkParquetReader.java']"
API: Update expression sanitization for relative dates and times (#5944),2,399,2022-10-21 11:13:49-07:00,"['ExpressionUtil.java', 'TestExpressionUtil.java']"
Core: Rename TableTestBase.Assertions to not conflict with AssertJ Assertions (#6022),3,22,2022-10-21 12:57:04-07:00,"['TableTestBase.java', 'TestSortOrderParser.java', 'TestTransaction.java']"
"Python: Visitor to convert Iceberg to PyArrow schema (#5949)

This is required for manually specifying datasets:
https://arrow.apache.org/docs/python/dataset.html#manual-specification-of-the-dataset

From PyArrow:

The dataset() function allows easy creation of a Dataset viewing a directory,
crawling all subdirectories for files and partitioning information.
However sometimes discovery is not required and the datasets files and
partitions are already known (for example, when this information is stored in metadata).
In this case it is possible to create a Dataset explicitly without any automatic discovery or inference.",2,283,2022-10-21 13:06:25-07:00,"['pyarrow.py', 'test_pyarrow.py']"
Python: Implement Schema.select (#5966),2,71,2022-10-21 13:15:32-07:00,"['schema.py', 'test_schema.py']"
Python: Implement S3V4RestSigner (#5969),5,166,2022-10-21 14:15:29-07:00,"['exceptions.py', '__init__.py', 'fsspec.py', 'pyproject.toml', 'test_fsspec.py']"
Docs: Add section on semantic versioning and deprecations (#6032),1,62,2022-10-23 10:34:49-07:00,['CONTRIBUTING.md']
"Core: Increase inferred column metrics limit to 100 (#5916)

Co-authored-by: Eduard Tudenhoefner <etudenhoefner@gmail.com>",2,8,2022-10-23 14:19:17-07:00,"['TableProperties.java', 'TestWriterMetrics.java']"
"Build: Bump mkdocs from 1.3.1 to 1.4.1 in /python (#6033)

Bumps [mkdocs](https://github.com/mkdocs/mkdocs) from 1.3.1 to 1.4.1.
- [Release notes](https://github.com/mkdocs/mkdocs/releases)
- [Commits](https://github.com/mkdocs/mkdocs/compare/1.3.1...1.4.1)

---
updated-dependencies:
- dependency-name: mkdocs
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2022-10-24 10:15:56+02:00,['requirements.txt']
"API,Core: Move ScanReport to core module / extract TimerResult/CounterResult/ScanMetricsResult into own classes (#6037)

The motivation behind moving `ScanReport` to `iceberg-core` is because we don't
actually need it in the `iceberg-api`, since `MetricsReporter` only
requires to have `MetricsReport` in the `iceberg-api` module.

The motivation for extracting all of those classes out of `ScanReport`
is so that we can reuse them in order to introduce an
`IncrementalScanReport` class, which slightly differs from `ScanReport`
around the snapshot (since it requires from/to snapshot IDs)",22,724,2022-10-24 14:08:17-07:00,"['LoggingMetricsReporter.java', 'ScanReport.java', 'BaseTableScan.java', 'DeleteFileIndex.java', 'ManifestGroup.java', 'ManifestReader.java', 'CounterResult.java', 'CounterResultParser.java', 'ScanMetrics.java', 'ScanMetricsResult.java', 'ScanMetricsResultParser.java', 'ScanReport.java', 'ScanReportParser.java', 'TimerResult.java', 'TimerResultParser.java', 'TestScanPlanningAndReporting.java', 'TestCounterResultParser.java', 'TestScanMetricsResultParser.java', 'TestScanReport.java', 'TestScanReportParser.java', 'TestTimerResultParser.java', 'TestReportMetricsRequestParser.java']"
Spark 3.3: Ensure rowStartPosInBatch in ColumnarBatchReader is set correctly (#6026),2,100,2022-10-24 16:13:41-07:00,"['BaseBatchReader.java', 'TestSparkReaderDeletes.java']"
Spark 3.2: Ensure rowStartPosInBatch in ColumnarBatchReader is set correctly(#6041),2,104,2022-10-24 20:23:00-07:00,"['BaseBatchReader.java', 'TestSparkReaderDeletes.java']"
"Core, Spark: Add Aggregate expressions (#5961)",12,527,2022-10-25 14:21:57-07:00,"['Aggregate.java', 'Binder.java', 'BoundAggregate.java', 'Expression.java', 'ExpressionVisitors.java', 'Expressions.java', 'UnboundAggregate.java', 'TestAggregateBinding.java', 'SparkAggregates.java', 'SparkUtil.java', 'SparkV2Filters.java', 'TestSparkAggregates.java']"
"Flink: Add Sink options to override the compression properties of the Table (#6049)

* Flink compression properties

* Review comments

Co-authored-by: Peter Vary <peter_vary4@apple.com>",10,415,2022-10-26 08:54:16-07:00,"['flink-getting-started.md', 'FlinkWriteConf.java', 'FlinkWriteOptions.java', 'FlinkSink.java', 'RowDataTaskWriterFactory.java', 'RowDataRewriter.java', 'TestCompressionSettings.java', 'TestDeltaTaskWriter.java', 'TestTaskWriters.java', 'TestProjectMetaColumn.java']"
"Spec, Core: Add file seq number to ManifestEntry (#6002)",22,773,2022-10-26 21:31:31-07:00,"['GenericManifestEntry.java', 'InheritableMetadataFactory.java', 'ManifestEntry.java', 'ManifestWriter.java', 'V1Metadata.java', 'V2Metadata.java', 'TableTestBase.java', 'TestFastAppend.java', 'TestManifestWriter.java', 'TestManifestWriterVersions.java', 'TestMergeAppend.java', 'TestReplacePartitions.java', 'TestRewriteFiles.java', 'TestRowDelta.java', 'TestSequenceNumberForV2Table.java', 'TestV1ToV2RowDeltaDelete.java', 'spec.md', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java']"
Spark 3.1: Ensure rowStartPosInBatch in ColumnarBatchReader is set correctly (#6046),2,100,2022-10-27 10:15:42-07:00,"['BatchDataReader.java', 'TestSparkReaderDeletes.java']"
"Core: Replace projected Schema with schemaId/fieldIds/fieldNames in ScanReport (#6047)

The motivation behind this change is that the projected schema might get
quite big and contain information such as doc comments, which make it
quite hard to read/consume. This change makes sure that we only include
the minimal set of information from a schema
(schemaId/fieldIds/fieldNames).",7,326,2022-10-27 15:03:45-07:00,"['BaseTableScan.java', 'ScanReport.java', 'ScanReportParser.java', 'TestScanReport.java', 'TestScanReportParser.java', 'TestReportMetricsRequestParser.java', 'rest-catalog-open-api.yaml']"
Spark 3.2: #6041 follow-up/cleanup (#6063),1,32,2022-10-28 09:46:27-07:00,['TestSparkReaderDeletes.java']
Build: Update Spark to 3.3.1 (#5783),1,12,2022-10-28 16:02:24-07:00,['build.gradle']
"Build: Bump pytest from 7.1.3 to 7.2.0 in /python (#6080)

Bumps [pytest](https://github.com/pytest-dev/pytest) from 7.1.3 to 7.2.0.
- [Release notes](https://github.com/pytest-dev/pytest/releases)
- [Changelog](https://github.com/pytest-dev/pytest/blob/main/CHANGELOG.rst)
- [Commits](https://github.com/pytest-dev/pytest/compare/7.1.3...7.2.0)

---
updated-dependencies:
- dependency-name: pytest
  dependency-type: direct:development
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,47,2022-10-30 21:56:42+01:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump pyarrow from 9.0.0 to 10.0.0 in /python (#6081)

Bumps [pyarrow](https://github.com/apache/arrow) from 9.0.0 to 10.0.0.
- [Release notes](https://github.com/apache/arrow/releases)
- [Commits](https://github.com/apache/arrow/compare/go/v9.0.0...go/v10.0.0)

---
updated-dependencies:
- dependency-name: pyarrow
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,54,2022-10-30 22:09:30+01:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump zstandard from 0.18.0 to 0.19.0 in /python (#6082),2,101,2022-10-30 22:53:26+01:00,"['poetry.lock', 'pyproject.toml']"
"Python: PyArrow timestamp in microseconds (#6070)

The Iceberg spec keeps timestamp in microsecond format so we should
convert to a PyArrow type that doesn't lose precision.

ms = millisecond
us = microsecond",2,8,2022-10-31 17:44:00+01:00,"['pyarrow.py', 'test_pyarrow.py']"
Spark 3.3: Use separate scan during file filtering in copy-on-write ops (#6077),10,614,2022-10-31 22:25:07-07:00,"['build.gradle', 'RowLevelCommandDynamicPruning.scala', 'SparkRowLevelOperationsTestBase.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestDelete.java', 'TestMerge.java', 'TestUpdate.java', 'SparkCopyOnWriteScan.java']"
Spark: Remove redundant max_concurrent_deletes check (#6083),8,16,2022-11-01 09:01:46+01:00,"['ExpireSnapshotsProcedure.java', 'RemoveOrphanFilesProcedure.java', 'ExpireSnapshotsProcedure.java', 'RemoveOrphanFilesProcedure.java', 'ExpireSnapshotsProcedure.java', 'RemoveOrphanFilesProcedure.java', 'ExpireSnapshotsProcedure.java', 'RemoveOrphanFilesProcedure.java']"
"Infra: Publish nightly build for Spark-3.3_2.13 (#6054)

Iceberg Spark-3.3 also supports scala-2.13 build. 
So, including this in the nightly build publish.",1,2,2022-11-01 09:17:54+01:00,['publish-snapshot.yml']
"Infra: Update slack invite link (#6052)

Recently we have updated slack invite link in iceberg-docs repo. It needs to be updated here also.",1,2,2022-11-01 09:18:55+01:00,['iceberg_question.yml']
"Docs: Fix link in the Java Custom Catalog page (#6068)

* refer custom catalog implementation to the corrcet place

* change heading to Custom Catalog",1,2,2022-11-01 15:12:58+01:00,['java-custom-catalog.md']
Infra: Add 1.0.0 in issue template dropdown (#6057),1,3,2022-11-01 16:20:42+01:00,['iceberg_bug_report.yml']
Flink: Remove Flink 1.13 (#6103),138,26945,2022-11-02 08:46:50-07:00,"['flink-ci.yml', 'java-ci.yml', 'publish-snapshot.yml', 'stage-binaries.sh', 'build.gradle', 'build.gradle', 'LICENSE', 'NOTICE', 'CatalogLoader.java', 'FlinkCatalog.java', 'FlinkCatalogFactory.java', 'FlinkConfParser.java', 'FlinkConfigOptions.java', 'FlinkDynamicTableFactory.java', 'FlinkFilters.java', 'FlinkFixupTypes.java', 'FlinkSchemaUtil.java', 'FlinkTypeToType.java', 'FlinkTypeVisitor.java', 'FlinkWriteConf.java', 'FlinkWriteOptions.java', 'IcebergTableSink.java', 'IcebergTableSource.java', 'RowDataWrapper.java', 'TableLoader.java', 'TypeToFlinkType.java', 'Actions.java', 'RewriteDataFilesAction.java', 'AvroWithFlinkSchemaVisitor.java', 'FlinkAvroReader.java', 'FlinkAvroWriter.java', 'FlinkOrcReader.java', 'FlinkOrcReaders.java', 'FlinkOrcWriter.java', 'FlinkOrcWriters.java', 'FlinkParquetReaders.java', 'FlinkParquetWriters.java', 'FlinkSchemaVisitor.java', 'FlinkValueReaders.java', 'FlinkValueWriters.java', 'ParquetWithFlinkSchemaVisitor.java', 'RowDataProjection.java', 'RowDataUtil.java', 'BaseDeltaTaskWriter.java', 'DeltaManifests.java', 'DeltaManifestsSerializer.java', 'EqualityFieldKeySelector.java', 'FlinkAppenderFactory.java', 'FlinkFileWriterFactory.java', 'FlinkManifestUtil.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'IcebergStreamWriter.java', 'ManifestOutputFileFactory.java', 'PartitionKeySelector.java', 'PartitionedDeltaWriter.java', 'RowDataTaskWriterFactory.java', 'TaskWriterFactory.java', 'UnpartitionedDeltaWriter.java', 'DataIterator.java', 'FileScanTaskReader.java', 'FlinkInputFormat.java', 'FlinkInputSplit.java', 'FlinkSource.java', 'FlinkSplitGenerator.java', 'RowDataFileScanTaskReader.java', 'RowDataRewriter.java', 'ScanContext.java', 'StreamingMonitorFunction.java', 'StreamingReaderOperator.java', 'FlinkCompatibilityUtil.java', 'org.apache.flink.table.factories.Factory', 'org.apache.flink.table.factories.TableFactory', 'FlinkCatalogTestBase.java', 'FlinkTestBase.java', 'MiniClusterResource.java', 'RowDataConverter.java', 'SimpleDataUtil.java', 'TestCatalogTableLoader.java', 'TestChangeLogTable.java', 'TestDataFileSerialization.java', 'TestFixtures.java', 'TestFlinkCatalogDatabase.java', 'TestFlinkCatalogFactory.java', 'TestFlinkCatalogTable.java', 'TestFlinkCatalogTablePartitions.java', 'TestFlinkFilters.java', 'TestFlinkHiveCatalog.java', 'TestFlinkSchemaUtil.java', 'TestFlinkTableSink.java', 'TestFlinkTableSource.java', 'TestFlinkUpsert.java', 'TestHelpers.java', 'TestIcebergConnector.java', 'TestManifestFileSerialization.java', 'TestRowDataWrapper.java', 'TestTableLoader.java', 'TestTableSerialization.java', 'TestRewriteDataFilesAction.java', 'RandomRowData.java', 'TestFlinkAvroReaderWriter.java', 'TestFlinkOrcReaderWriter.java', 'TestFlinkParquetReader.java', 'TestFlinkParquetWriter.java', 'TestRowDataProjection.java', 'TestRowProjection.java', 'TestDeltaTaskWriter.java', 'TestFlinkAppenderFactory.java', 'TestFlinkFileWriterFactory.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkV2.java', 'TestFlinkManifest.java', 'TestFlinkPartitioningWriters.java', 'TestFlinkPositionDeltaWriters.java', 'TestFlinkRollingFileWriters.java', 'TestFlinkWriterMetrics.java', 'TestIcebergFilesCommitter.java', 'TestIcebergStreamWriter.java', 'TestRowDataPartitionKey.java', 'TestTaskWriters.java', 'BoundedTableFactory.java', 'BoundedTestSource.java', 'ChangeLogTableTestBase.java', 'TestBoundedTableFactory.java', 'TestFlinkInputFormat.java', 'TestFlinkInputFormatReaderDeletes.java', 'TestFlinkMergingMetrics.java', 'TestFlinkReaderDeletesBase.java', 'TestFlinkScan.java', 'TestFlinkScanSql.java', 'TestFlinkSource.java', 'TestProjectMetaColumn.java', 'TestStreamScanSql.java', 'TestStreamingMonitorFunction.java', 'TestStreamingReaderOperator.java', 'org.apache.flink.table.factories.Factory', 'gradle.properties', 'settings.gradle']"
"Core, Spark: Fix raw generics usage of ManifestWriter (#6059)",11,22,2022-11-02 09:03:56-07:00,"['FastAppend.java', 'TestManifestFileSerialization.java', 'TestForwardCompatibility.java', 'TestManifestFileSerialization.java', 'TestForwardCompatibility.java', 'TestManifestFileSerialization.java', 'TestForwardCompatibility.java', 'TestManifestFileSerialization.java', 'TestForwardCompatibility.java', 'TestManifestFileSerialization.java', 'TestForwardCompatibility.java']"
Spark 3.2: Use separate scan during file filtering in copy-on-write ops (#6095),10,615,2022-11-02 09:57:17-07:00,"['build.gradle', 'RowLevelCommandDynamicPruning.scala', 'SparkRowLevelOperationsTestBase.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestDelete.java', 'TestMerge.java', 'TestUpdate.java', 'SparkCopyOnWriteScan.java']"
Spark 3.3: Relocate all Netty classes (#6107),1,11,2022-11-02 14:39:44-07:00,['build.gradle']
Spark 3.2: Relocate all Netty classes (#6109),1,11,2022-11-02 19:21:02-07:00,['build.gradle']
Spark: Optimize Preconditions.checkArgument in procedures (#6096),8,24,2022-11-03 08:15:30+01:00,"['ExpireSnapshotsProcedure.java', 'RemoveOrphanFilesProcedure.java', 'ExpireSnapshotsProcedure.java', 'RemoveOrphanFilesProcedure.java', 'ExpireSnapshotsProcedure.java', 'RemoveOrphanFilesProcedure.java', 'ExpireSnapshotsProcedure.java', 'RemoveOrphanFilesProcedure.java']"
"Docs: Update spotless apply command for non-default versions (#6101)

* Docs: Update spotless apply command for non-default versions

While working on https://github.com/apache/iceberg/pull/6096, I learnt that `./gradlew spotlessApply` only works on default versions.
I assumed that it works for all the folders. Which was not true.

Hence, updating the document for new users.

* Adding example

* Remove filnk 1.13",1,4,2022-11-03 08:16:53+01:00,['README.md']
"Core: Improve collection handling in JsonUtil (#6051)

This aligns all collection methods to show the same error message and
behave the same with null/empty/invalid json values.
Additionally, this also adds the property name of the collection when
showing an error message",4,246,2022-11-03 09:25:40+01:00,"['JsonUtil.java', 'TestScanReportParser.java', 'TestFileMetadataParser.java', 'TestJsonUtil.java']"
Build: Add gaborkaszab as a collaborator (#6036),1,1,2022-11-03 11:07:22+01:00,['.asf.yaml']
Flink: Move flink/v1.15 to flink/v1.16,201,0,2022-11-03 08:46:36-07:00,"['build.gradle', 'LICENSE', 'NOTICE', 'IcebergConnectorSmokeTest.java', 'CatalogLoader.java', 'FlinkCatalog.java', 'FlinkCatalogFactory.java', 'FlinkConfParser.java', 'FlinkConfigOptions.java', 'FlinkDynamicTableFactory.java', 'FlinkFilters.java', 'FlinkFixupTypes.java', 'FlinkSchemaUtil.java', 'FlinkTypeToType.java', 'FlinkTypeVisitor.java', 'FlinkWriteConf.java', 'FlinkWriteOptions.java', 'IcebergTableSink.java', 'RowDataWrapper.java', 'TableLoader.java', 'TypeToFlinkType.java', 'Actions.java', 'RewriteDataFilesAction.java', 'AvroWithFlinkSchemaVisitor.java', 'FlinkAvroReader.java', 'FlinkAvroWriter.java', 'FlinkOrcReader.java', 'FlinkOrcReaders.java', 'FlinkOrcWriter.java', 'FlinkOrcWriters.java', 'FlinkParquetReaders.java', 'FlinkParquetWriters.java', 'FlinkSchemaVisitor.java', 'FlinkValueReaders.java', 'FlinkValueWriters.java', 'ParquetWithFlinkSchemaVisitor.java', 'RowDataProjection.java', 'RowDataUtil.java', 'BaseDeltaTaskWriter.java', 'CommitSummary.java', 'DeltaManifests.java', 'DeltaManifestsSerializer.java', 'EqualityFieldKeySelector.java', 'FlinkAppenderFactory.java', 'FlinkFileWriterFactory.java', 'FlinkManifestUtil.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'IcebergFilesCommitterMetrics.java', 'IcebergStreamWriter.java', 'IcebergStreamWriterMetrics.java', 'ManifestOutputFileFactory.java', 'PartitionKeySelector.java', 'PartitionedDeltaWriter.java', 'RowDataTaskWriterFactory.java', 'TaskWriterFactory.java', 'UnpartitionedDeltaWriter.java', 'DataIterator.java', 'FileScanTaskReader.java', 'FlinkInputFormat.java', 'FlinkInputSplit.java', 'FlinkSource.java', 'FlinkSplitPlanner.java', 'IcebergSource.java', 'IcebergTableSource.java', 'RowDataFileScanTaskReader.java', 'RowDataRewriter.java', 'ScanContext.java', 'SourceUtil.java', 'StreamingMonitorFunction.java', 'StreamingReaderOperator.java', 'StreamingStartingStrategy.java', 'GetSplitResult.java', 'SimpleSplitAssigner.java', 'SimpleSplitAssignerFactory.java', 'SplitAssigner.java', 'SplitAssignerFactory.java', 'SplitAssignerType.java', 'AbstractIcebergEnumerator.java', 'ContinuousEnumerationResult.java', 'ContinuousIcebergEnumerator.java', 'ContinuousSplitPlanner.java', 'ContinuousSplitPlannerImpl.java', 'IcebergEnumeratorPosition.java', 'IcebergEnumeratorPositionSerializer.java', 'IcebergEnumeratorState.java', 'IcebergEnumeratorStateSerializer.java', 'StaticIcebergEnumerator.java', 'ArrayBatchRecords.java', 'ArrayPoolDataIteratorBatcher.java', 'DataIteratorBatcher.java', 'DataIteratorReaderFunction.java', 'IcebergSourceReader.java', 'IcebergSourceReaderMetrics.java', 'IcebergSourceRecordEmitter.java', 'IcebergSourceSplitReader.java', 'ReaderFunction.java', 'RecordAndPosition.java', 'RecordFactory.java', 'RowDataReaderFunction.java', 'RowDataRecordFactory.java', 'IcebergSourceSplit.java', 'IcebergSourceSplitSerializer.java', 'IcebergSourceSplitState.java', 'IcebergSourceSplitStatus.java', 'SplitRequestEvent.java', 'FlinkCompatibilityUtil.java', 'org.apache.flink.table.factories.Factory', 'org.apache.flink.table.factories.TableFactory', 'FlinkCatalogTestBase.java', 'FlinkTestBase.java', 'HadoopCatalogResource.java', 'HadoopTableResource.java', 'MiniClusterResource.java', 'RowDataConverter.java', 'SimpleDataUtil.java', 'TestCatalogTableLoader.java', 'TestChangeLogTable.java', 'TestDataFileSerialization.java', 'TestFixtures.java', 'TestFlinkCatalogDatabase.java', 'TestFlinkCatalogFactory.java', 'TestFlinkCatalogTable.java', 'TestFlinkCatalogTablePartitions.java', 'TestFlinkFilters.java', 'TestFlinkHiveCatalog.java', 'TestFlinkSchemaUtil.java', 'TestFlinkTableSink.java', 'TestFlinkUpsert.java', 'TestHelpers.java', 'TestIcebergConnector.java', 'TestManifestFileSerialization.java', 'TestRowDataWrapper.java', 'TestTableLoader.java', 'TestTableSerialization.java', 'TestRewriteDataFilesAction.java', 'RandomRowData.java', 'RowDataToRowMapper.java', 'TestFlinkAvroReaderWriter.java', 'TestFlinkOrcReaderWriter.java', 'TestFlinkParquetReader.java', 'TestFlinkParquetWriter.java', 'TestRowDataProjection.java', 'TestRowProjection.java', 'TestCompressionSettings.java', 'TestDeltaTaskWriter.java', 'TestFlinkAppenderFactory.java', 'TestFlinkFileWriterFactory.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkV2.java', 'TestFlinkManifest.java', 'TestFlinkPartitioningWriters.java', 'TestFlinkPositionDeltaWriters.java', 'TestFlinkRollingFileWriters.java', 'TestFlinkWriterMetrics.java', 'TestIcebergFilesCommitter.java', 'TestIcebergStreamWriter.java', 'TestRowDataPartitionKey.java', 'TestTaskWriters.java', 'BoundedTableFactory.java', 'BoundedTestSource.java', 'ChangeLogTableTestBase.java', 'SplitHelpers.java', 'SqlHelpers.java', 'TestBoundedTableFactory.java', 'TestFlinkInputFormat.java', 'TestFlinkInputFormatReaderDeletes.java', 'TestFlinkMergingMetrics.java', 'TestFlinkReaderDeletesBase.java', 'TestFlinkScan.java', 'TestFlinkScanSql.java', 'TestFlinkSource.java', 'TestFlinkSourceSql.java', 'TestFlinkTableSource.java', 'TestIcebergSourceBounded.java', 'TestIcebergSourceBoundedSql.java', 'TestIcebergSourceContinuous.java', 'TestIcebergSourceFailover.java', 'TestIcebergSourceReaderDeletes.java', 'TestIcebergSourceSql.java', 'TestProjectMetaColumn.java', 'TestSourceUtil.java', 'TestSqlBase.java', 'TestStreamScanSql.java', 'TestStreamingMonitorFunction.java', 'TestStreamingReaderOperator.java', 'TestSimpleSplitAssigner.java', 'ManualContinuousSplitPlanner.java', 'TestContinuousIcebergEnumerator.java', 'TestContinuousSplitPlannerImpl.java', 'TestContinuousSplitPlannerImplStartStrategy.java', 'TestIcebergEnumeratorStateSerializer.java', 'ReaderFunctionTestBase.java', 'ReaderUtil.java', 'TestArrayBatchRecords.java', 'TestArrayPoolDataIteratorBatcherRowData.java', 'TestIcebergSourceReader.java', 'TestRowDataReaderFunction.java', 'TestingMetricGroup.java', 'TestIcebergSourceSplitSerializer.java', 'org.apache.flink.table.factories.Factory']"
Flink: Copy flink/1.15 files from flink/1.16,201,35262,2022-11-03 08:46:36-07:00,"['build.gradle', 'LICENSE', 'NOTICE', 'IcebergConnectorSmokeTest.java', 'CatalogLoader.java', 'FlinkCatalog.java', 'FlinkCatalogFactory.java', 'FlinkConfParser.java', 'FlinkConfigOptions.java', 'FlinkDynamicTableFactory.java', 'FlinkFilters.java', 'FlinkFixupTypes.java', 'FlinkSchemaUtil.java', 'FlinkTypeToType.java', 'FlinkTypeVisitor.java', 'FlinkWriteConf.java', 'FlinkWriteOptions.java', 'IcebergTableSink.java', 'RowDataWrapper.java', 'TableLoader.java', 'TypeToFlinkType.java', 'Actions.java', 'RewriteDataFilesAction.java', 'AvroWithFlinkSchemaVisitor.java', 'FlinkAvroReader.java', 'FlinkAvroWriter.java', 'FlinkOrcReader.java', 'FlinkOrcReaders.java', 'FlinkOrcWriter.java', 'FlinkOrcWriters.java', 'FlinkParquetReaders.java', 'FlinkParquetWriters.java', 'FlinkSchemaVisitor.java', 'FlinkValueReaders.java', 'FlinkValueWriters.java', 'ParquetWithFlinkSchemaVisitor.java', 'RowDataProjection.java', 'RowDataUtil.java', 'BaseDeltaTaskWriter.java', 'CommitSummary.java', 'DeltaManifests.java', 'DeltaManifestsSerializer.java', 'EqualityFieldKeySelector.java', 'FlinkAppenderFactory.java', 'FlinkFileWriterFactory.java', 'FlinkManifestUtil.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'IcebergFilesCommitterMetrics.java', 'IcebergStreamWriter.java', 'IcebergStreamWriterMetrics.java', 'ManifestOutputFileFactory.java', 'PartitionKeySelector.java', 'PartitionedDeltaWriter.java', 'RowDataTaskWriterFactory.java', 'TaskWriterFactory.java', 'UnpartitionedDeltaWriter.java', 'DataIterator.java', 'FileScanTaskReader.java', 'FlinkInputFormat.java', 'FlinkInputSplit.java', 'FlinkSource.java', 'FlinkSplitPlanner.java', 'IcebergSource.java', 'IcebergTableSource.java', 'RowDataFileScanTaskReader.java', 'RowDataRewriter.java', 'ScanContext.java', 'SourceUtil.java', 'StreamingMonitorFunction.java', 'StreamingReaderOperator.java', 'StreamingStartingStrategy.java', 'GetSplitResult.java', 'SimpleSplitAssigner.java', 'SimpleSplitAssignerFactory.java', 'SplitAssigner.java', 'SplitAssignerFactory.java', 'SplitAssignerType.java', 'AbstractIcebergEnumerator.java', 'ContinuousEnumerationResult.java', 'ContinuousIcebergEnumerator.java', 'ContinuousSplitPlanner.java', 'ContinuousSplitPlannerImpl.java', 'IcebergEnumeratorPosition.java', 'IcebergEnumeratorPositionSerializer.java', 'IcebergEnumeratorState.java', 'IcebergEnumeratorStateSerializer.java', 'StaticIcebergEnumerator.java', 'ArrayBatchRecords.java', 'ArrayPoolDataIteratorBatcher.java', 'DataIteratorBatcher.java', 'DataIteratorReaderFunction.java', 'IcebergSourceReader.java', 'IcebergSourceReaderMetrics.java', 'IcebergSourceRecordEmitter.java', 'IcebergSourceSplitReader.java', 'ReaderFunction.java', 'RecordAndPosition.java', 'RecordFactory.java', 'RowDataReaderFunction.java', 'RowDataRecordFactory.java', 'IcebergSourceSplit.java', 'IcebergSourceSplitSerializer.java', 'IcebergSourceSplitState.java', 'IcebergSourceSplitStatus.java', 'SplitRequestEvent.java', 'FlinkCompatibilityUtil.java', 'org.apache.flink.table.factories.Factory', 'org.apache.flink.table.factories.TableFactory', 'FlinkCatalogTestBase.java', 'FlinkTestBase.java', 'HadoopCatalogResource.java', 'HadoopTableResource.java', 'MiniClusterResource.java', 'RowDataConverter.java', 'SimpleDataUtil.java', 'TestCatalogTableLoader.java', 'TestChangeLogTable.java', 'TestDataFileSerialization.java', 'TestFixtures.java', 'TestFlinkCatalogDatabase.java', 'TestFlinkCatalogFactory.java', 'TestFlinkCatalogTable.java', 'TestFlinkCatalogTablePartitions.java', 'TestFlinkFilters.java', 'TestFlinkHiveCatalog.java', 'TestFlinkSchemaUtil.java', 'TestFlinkTableSink.java', 'TestFlinkUpsert.java', 'TestHelpers.java', 'TestIcebergConnector.java', 'TestManifestFileSerialization.java', 'TestRowDataWrapper.java', 'TestTableLoader.java', 'TestTableSerialization.java', 'TestRewriteDataFilesAction.java', 'RandomRowData.java', 'RowDataToRowMapper.java', 'TestFlinkAvroReaderWriter.java', 'TestFlinkOrcReaderWriter.java', 'TestFlinkParquetReader.java', 'TestFlinkParquetWriter.java', 'TestRowDataProjection.java', 'TestRowProjection.java', 'TestCompressionSettings.java', 'TestDeltaTaskWriter.java', 'TestFlinkAppenderFactory.java', 'TestFlinkFileWriterFactory.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkV2.java', 'TestFlinkManifest.java', 'TestFlinkPartitioningWriters.java', 'TestFlinkPositionDeltaWriters.java', 'TestFlinkRollingFileWriters.java', 'TestFlinkWriterMetrics.java', 'TestIcebergFilesCommitter.java', 'TestIcebergStreamWriter.java', 'TestRowDataPartitionKey.java', 'TestTaskWriters.java', 'BoundedTableFactory.java', 'BoundedTestSource.java', 'ChangeLogTableTestBase.java', 'SplitHelpers.java', 'SqlHelpers.java', 'TestBoundedTableFactory.java', 'TestFlinkInputFormat.java', 'TestFlinkInputFormatReaderDeletes.java', 'TestFlinkMergingMetrics.java', 'TestFlinkReaderDeletesBase.java', 'TestFlinkScan.java', 'TestFlinkScanSql.java', 'TestFlinkSource.java', 'TestFlinkSourceSql.java', 'TestFlinkTableSource.java', 'TestIcebergSourceBounded.java', 'TestIcebergSourceBoundedSql.java', 'TestIcebergSourceContinuous.java', 'TestIcebergSourceFailover.java', 'TestIcebergSourceReaderDeletes.java', 'TestIcebergSourceSql.java', 'TestProjectMetaColumn.java', 'TestSourceUtil.java', 'TestSqlBase.java', 'TestStreamScanSql.java', 'TestStreamingMonitorFunction.java', 'TestStreamingReaderOperator.java', 'TestSimpleSplitAssigner.java', 'ManualContinuousSplitPlanner.java', 'TestContinuousIcebergEnumerator.java', 'TestContinuousSplitPlannerImpl.java', 'TestContinuousSplitPlannerImplStartStrategy.java', 'TestIcebergEnumeratorStateSerializer.java', 'ReaderFunctionTestBase.java', 'ReaderUtil.java', 'TestArrayBatchRecords.java', 'TestArrayPoolDataIteratorBatcherRowData.java', 'TestIcebergSourceReader.java', 'TestRowDataReaderFunction.java', 'TestingMetricGroup.java', 'TestIcebergSourceSplitSerializer.java', 'org.apache.flink.table.factories.Factory']"
Flink: Make flink 1.16 work,10,108,2022-11-03 08:46:36-07:00,"['flink-ci.yml', 'java-ci.yml', 'publish-snapshot.yml', 'stage-binaries.sh', 'build.gradle', 'build.gradle', 'IcebergTableSink.java', 'TestFlinkTableSource.java', 'gradle.properties', 'settings.gradle']"
Python: Use Types from Typing (#6114),8,132,2022-11-03 10:39:12-07:00,"['.pre-commit-config.yaml', 'CONTRIBUTING.md', '__init__.py', 'file.py', 'reader.py', '__init__.py', 'literals.py', 'schema_conversion.py']"
Python: Add the REST token to the properties (#6086),3,19,2022-11-03 11:14:53-07:00,"['__init__.py', 'rest.py', 'fsspec.py']"
"Python: Pin versions explicitly (#6078)

PR apache#6076 fails because the
poetry update command also bumped the version of FastAvro.

I don't think this is wanted behavior, therefore I suggest to pin
the versions, instead of providing a lower bound. Dependabot will
take care of the bumping of the versions every week.",2,343,2022-11-03 11:18:34-07:00,"['poetry.lock', 'pyproject.toml']"
Python: Fix Github pages (#6038),1,1,2022-11-03 16:31:37-07:00,['python-ci-docs.yml']
Core: Avoid reading ManifestFile when creating ManifestReader (#5632),6,58,2022-11-03 17:54:35-07:00,"['BaseRewriteManifests.java', 'FastAppend.java', 'FileCleanupStrategy.java', 'ManifestFiles.java', 'ManifestReader.java', 'MergingSnapshotProducer.java']"
Python: Struct fields should be provided to Schema constructor (#6115),1,3,2022-11-04 06:55:55+01:00,['visitors.py']
"Remove Fokko from the list of collaborators (#6119)

* Remove Fokko from the list of collaborators

* Don't run all the test suites",5,5,2022-11-04 10:54:51+01:00,"['.asf.yaml', 'flink-ci.yml', 'hive-ci.yml', 'java-ci.yml', 'spark-ci.yml']"
Python: Fix the caching (#6010),2,41,2022-11-04 13:10:01-07:00,"['pyarrow.py', 'test_pyarrow.py']"
AWS: Fix AWSProperties Kryo serialization (#5812),4,47,2022-11-05 00:04:24-07:00,"['AwsProperties.java', 'TestAwsProperties.java', 'TestS3FileIO.java', 'PropertyUtil.java']"
Docs: Update migrate drop_backup flag (#6025),1,3,2022-11-05 00:07:57-07:00,['spark-procedures.md']
"Spark: Strip trailing slash from metadatalocation (#6121)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",4,22,2022-11-05 19:59:37+01:00,"['BaseMetastoreTableOperations.java', 'RESTTableOperations.java', 'BaseTableCreationSparkAction.java', 'AddFilesProcedure.java']"
Build: Bump mkdocs from 1.4.1 to 1.4.2 in /python (#6130),1,2,2022-11-06 09:39:51+01:00,['requirements.txt']
API: Hash floats -0.0 and 0.0 to the same bucket (#6110),3,100,2022-11-06 13:02:24-08:00,"['BucketUtil.java', 'TestBucketing.java', 'spec.md']"
Spark 3.0: Remove 3.0 from docs and builds (#6093),32,170,2022-11-06 13:06:47-08:00,"['labeler.yml', 'java-ci.yml', 'publish-snapshot.yml', 'spark-ci.yml', '.gitignore', 'README.md', 'stage-binaries.sh', 'aws.md', 'java-api.md', 'nessie.md', 'spark-configuration.md', 'spark-ddl.md', 'spark-procedures.md', 'spark-queries.md', 'spark-structured-streaming.md', 'spark-writes.md', 'gradle.properties', 'jmh.gradle', 'settings.gradle', 'build.gradle', 'Actions.java', 'RewriteDataFilesAction.java', 'SparkActions.java', 'README.md', 'TestDataFrameWrites.java', 'TestSparkDataWrite.java', 'TestDataFrameWrites.java', 'TestSparkDataWrite.java', 'TestDataFrameWrites.java', 'TestSparkDataWrite.java', 'TestDataFrameWrites.java', 'TestSparkDataWrite.java']"
"Python: Replace mmh3 with mmhash3 (#6076)

The mmh3 project is abandoned, and not being maintained.

Solves #5901",2,70,2022-11-06 13:10:34-08:00,"['poetry.lock', 'pyproject.toml']"
Parquet: Support 2-level list and maps type in RemoveIds (#6064),1,18,2022-11-06 13:14:03-08:00,['RemoveIds.java']
API: Fix TestAggregateBinding (#6065),2,58,2022-11-06 13:15:42-08:00,"['Expressions.java', 'TestAggregateBinding.java']"
"Spark: Reduce logging from SparkBatchQueryScan (#6108)

Closes #6106.",2,14,2022-11-06 16:10:18-08:00,"['SparkBatchQueryScan.java', 'SparkBatchQueryScan.java']"
"Python: Support creating a DateLiteral from a date (#6123)

Closes #6120.",4,39,2022-11-06 16:28:51-08:00,"['literals.py', 'datetime.py', 'test_literals.py', 'test_transforms.py']"
"Python: Fix typo in `_ManifestEvalVisitor.visit_equal` (#6117)

* Fix typo in `_ManifestEvalVisitor.visit_equal`

* Fix linting

Co-authored-by: Fokko Driesprong <fokko@apache.org>",1,4,2022-11-07 10:16:01+01:00,['visitors.py']
Python: Implement pythonic `__len__` (#6135),5,32,2022-11-07 15:31:28+01:00,"['reader.py', 'literals.py', 'pyarrow.py', 'types.py', 'test_types.py']"
Flink: Optimize test code of TestSourceUtil (#6143),3,24,2022-11-08 08:54:12+01:00,"['TestSourceUtil.java', 'TestSourceUtil.java', 'TestSourceUtil.java']"
Spark: Remove Spark 3.0 (#6094),343,67105,2022-11-08 14:55:02+01:00,"['build.gradle', 'IcebergSqlExtensions.g4', 'IcebergSparkSessionExtensions.scala', 'AlignRowLevelOperations.scala', 'AssignmentAlignmentSupport.scala', 'ProcedureArgumentCoercion.scala', 'ResolveProcedures.scala', 'RowLevelOperationsPredicateCheck.scala', 'AccumulateFiles.scala', 'OptimizeConditionsInRowLevelOperations.scala', 'PullupCorrelatedPredicatesInRowLevelOperations.scala', 'RewriteDelete.scala', 'RewriteMergeInto.scala', 'RewriteUpdate.scala', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'AddPartitionField.scala', 'Call.scala', 'DropIdentifierFields.scala', 'DropPartitionField.scala', 'DynamicFileFilter.scala', 'MergeInto.scala', 'ReplaceData.scala', 'ReplacePartitionField.scala', 'SetIdentifierFields.scala', 'statements.scala', 'RewriteRowLevelOperationHelper.scala', 'SetAccumulator.scala', 'AddPartitionFieldExec.scala', 'CallExec.scala', 'DropIdentifierFieldsExec.scala', 'DropPartitionFieldExec.scala', 'DynamicFileFilterExec.scala', 'ExtendedBatchScanExec.scala', 'ExtendedDataSourceV2Implicits.scala', 'ExtendedDataSourceV2Strategy.scala', 'MergeIntoExec.scala', 'ReplaceDataExec.scala', 'ReplacePartitionFieldExec.scala', 'SetIdentifierFieldsExec.scala', 'SetWriteDistributionAndOrderingExec.scala', 'Employee.java', 'SparkExtensionsTestBase.java', 'SparkRowLevelOperationsTestBase.java', 'TestAddFilesProcedure.java', 'TestAlterTablePartitionFields.java', 'TestAlterTableSchema.java', 'TestAncestorsOfProcedure.java', 'TestCallStatementParser.java', 'TestCherrypickSnapshotProcedure.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestDelete.java', 'TestExpireSnapshotsProcedure.java', 'TestIcebergExpressions.java', 'TestMerge.java', 'TestMigrateTableProcedure.java', 'TestPublishChangesProcedure.java', 'TestRemoveOrphanFilesProcedure.java', 'TestRewriteDataFilesProcedure.java', 'TestRewriteManifestsProcedure.java', 'TestRollbackToSnapshotProcedure.java', 'TestRollbackToTimestampProcedure.java', 'TestSetCurrentSnapshotProcedure.java', 'TestSetWriteDistributionAndOrdering.java', 'TestSnapshotTableProcedure.java', 'TestUpdate.java', 'LICENSE', 'NOTICE', 'SmokeTest.java', 'SparkBenchmarkUtil.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'Action.java', 'IcebergSourceBenchmark.java', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'IcebergSourceNestedListDataBenchmark.java', 'WritersBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'BaseCatalog.java', 'CommitMetadata.java', 'FileRewriteCoordinator.java', 'FileScanTaskSetManager.java', 'IcebergSpark.java', 'JobGroupInfo.java', 'JobGroupUtils.java', 'OrderField.java', 'PathIdentifier.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'RollbackStagedTable.java', 'SortOrderToSpark.java', 'Spark3Util.java', 'Spark3VersionUtil.java', 'SparkCatalog.java', 'SparkConfParser.java', 'SparkDataFile.java', 'SparkExceptionUtil.java', 'SparkFilters.java', 'SparkFixupTimestampType.java', 'SparkFixupTypes.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkSQLProperties.java', 'SparkSchemaUtil.java', 'SparkSessionCatalog.java', 'SparkStructLike.java', 'SparkTableUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'SparkUtil.java', 'SparkValueConverter.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'TypeToSparkType.java', 'BaseDeleteOrphanFilesSparkAction.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseExpireSnapshotsSparkAction.java', 'BaseMigrateTableSparkAction.java', 'BaseRewriteDataFilesSpark3Action.java', 'BaseRewriteDataFilesSparkAction.java', 'BaseRewriteManifestsSparkAction.java', 'BaseSnapshotTableSparkAction.java', 'BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java', 'BaseSparkActions.java', 'BaseTableCreationSparkAction.java', 'ManifestFileBean.java', 'Spark3BinPackStrategy.java', 'Spark3SortStrategy.java', 'SparkActions.java', 'AvroWithSparkSchemaVisitor.java', 'ParquetWithSparkSchemaVisitor.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'ArrowVectorAccessorFactory.java', 'ArrowVectorAccessors.java', 'ColumnarBatchReader.java', 'ConstantColumnVector.java', 'IcebergArrowColumnVector.java', 'RowPositionColumnVector.java', 'VectorizedSparkOrcReaders.java', 'VectorizedSparkParquetReaders.java', 'AddFilesProcedure.java', 'AncestorsOfProcedure.java', 'BaseProcedure.java', 'CherrypickSnapshotProcedure.java', 'ExpireSnapshotsProcedure.java', 'MigrateTableProcedure.java', 'PublishChangesProcedure.java', 'RemoveOrphanFilesProcedure.java', 'RewriteDataFilesProcedure.java', 'RewriteManifestsProcedure.java', 'RollbackToSnapshotProcedure.java', 'RollbackToTimestampProcedure.java', 'SetCurrentSnapshotProcedure.java', 'SnapshotTableProcedure.java', 'SparkProcedures.java', 'BaseDataReader.java', 'BatchDataReader.java', 'EqualityDeleteRowReader.java', 'IcebergSource.java', 'InternalRowWrapper.java', 'RowDataReader.java', 'RowDataRewriter.java', 'SerializableTableWithSize.java', 'SparkAppenderFactory.java', 'SparkBatchQueryScan.java', 'SparkBatchScan.java', 'SparkFileWriterFactory.java', 'SparkFilesScan.java', 'SparkFilesScanBuilder.java', 'SparkMergeBuilder.java', 'SparkMergeScan.java', 'SparkMicroBatchStream.java', 'SparkPartitionedFanoutWriter.java', 'SparkPartitionedWriter.java', 'SparkRewriteBuilder.java', 'SparkScanBuilder.java', 'SparkTable.java', 'SparkWrite.java', 'SparkWriteBuilder.java', 'StagedSparkTable.java', 'Stats.java', 'StreamingOffset.java', 'StructInternalRow.java', 'NoSuchProcedureException.java', 'ExtendedSupportsDelete.java', 'Procedure.java', 'ProcedureCatalog.java', 'ProcedureParameter.java', 'ProcedureParameterImpl.java', 'SupportsMerge.java', 'ClusteredDistribution.java', 'Distribution.java', 'Distributions.java', 'OrderedDistribution.java', 'UnspecifiedDistribution.java', 'ClusterDistributionImpl.java', 'OrderedDistributionImpl.java', 'UnspecifiedDistributionImpl.java', 'NullOrdering.java', 'SortDirection.java', 'SortOrder.java', 'SupportsFileFilter.java', 'MergeBuilder.java', 'org.apache.spark.sql.sources.DataSourceRegister', 'TransformExpressions.scala', 'SetWriteDistributionAndOrdering.scala', 'SortOrderParserUtil.scala', 'DistributionAndOrderingUtils.scala', 'PlanUtils.scala', 'SparkExpressionConverter.scala', 'KryoHelpers.java', 'TaskCheckHelper.java', 'TestDataFileSerialization.java', 'TestFileIOSerialization.java', 'TestManifestFileSerialization.java', 'TestScanTaskSerialization.java', 'TestTableSerialization.java', 'SparkCatalogConfig.java', 'SparkCatalogTestBase.java', 'SparkTestBase.java', 'SparkTestBaseWithCatalog.java', 'TestFileRewriteCoordinator.java', 'TestSpark3Util.java', 'TestSparkCatalogOperations.java', 'TestSparkFilters.java', 'TestSparkSchemaUtil.java', 'TestSparkTableUtil.java', 'TestSparkValueConverter.java', 'TestCreateActions.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction3.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'AvroDataTest.java', 'GenericsHelpers.java', 'RandomData.java', 'TestHelpers.java', 'TestOrcWrite.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkAvroEnums.java', 'TestSparkAvroReader.java', 'TestSparkDateTimes.java', 'TestSparkOrcReadMetadataColumns.java', 'TestSparkOrcReader.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkParquetReader.java', 'TestSparkParquetWriter.java', 'TestSparkRecordOrcReaderWriter.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryFallbackToPlainEncodingVectorizedReads.java', 'TestParquetVectorizedReads.java', 'LogMessage.java', 'ManualSource.java', 'SimpleRecord.java', 'SparkTestTable.java', 'TestAvroScan.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestFilteredScan.java', 'TestForwardCompatibility.java', 'TestIcebergSource.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSpark.java', 'TestIdentityPartitionData.java', 'TestInternalRowWrapper.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestParquetScan.java', 'TestPartitionPruning.java', 'TestPartitionValues.java', 'TestPathIdentifier.java', 'TestReadProjection.java', 'TestSnapshotSelection.java', 'TestSparkAppenderFactory.java', 'TestSparkBaseDataReader.java', 'TestSparkCatalog.java', 'TestSparkCatalogCacheExpiration.java', 'TestSparkCatalogHadoopOverrides.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestSparkFileWriterFactory.java', 'TestSparkFilesScan.java', 'TestSparkMergingMetrics.java', 'TestSparkMetadataColumns.java', 'TestSparkPartitioningWriters.java', 'TestSparkPositionDeltaWriters.java', 'TestSparkReadProjection.java', 'TestSparkReaderDeletes.java', 'TestSparkRollingFileWriters.java', 'TestSparkTable.java', 'TestSparkWriterMetrics.java', 'TestStreamingOffset.java', 'TestStructuredStreaming.java', 'TestStructuredStreamingRead3.java', 'TestTables.java', 'TestTimestampWithoutZone.java', 'TestWriteMetricsConfig.java', 'ThreeColumnRecord.java', 'TestAlterTable.java', 'TestCreateTable.java', 'TestCreateTableAsSelect.java', 'TestDeleteFrom.java', 'TestNamespaceSQL.java', 'TestPartitionedWrites.java', 'TestRefreshTable.java', 'TestSelect.java', 'TestTimestampWithoutZone.java', 'TestUnpartitionedWrites.java']"
Core: Fix metadata table read failure due to illegal character (#4577),4,329,2022-11-08 15:33:12+01:00,"['BuildAvroProjection.java', 'MetadataTableScanTestBase.java', 'TestMetadataTableScans.java', 'TestMetadataTableScansWithPartitionEvolution.java']"
"Core: Pass purgeRequested flag to REST server (#6073)

The motivation behind this change is that the REST server should know
whether a `purge` was requested or not, rather than having the REST
client throw an error.",7,69,2022-11-08 08:40:50-08:00,"['CatalogHandlers.java', 'HTTPClient.java', 'RESTClient.java', 'RESTSessionCatalog.java', 'CatalogTests.java', 'RESTCatalogAdapter.java', 'TestHTTPClient.java']"
"Python: Pin mypy (#6147)

The CI is failing because a new version of mypy 
has been released yesterday:
https://pypi.org/project/mypy/0.982/",1,2,2022-11-08 10:25:30-08:00,['tox.ini']
Build: Let revapi compare API compatibility against apache-iceberg-1.0.0 (#6053),3,9,2022-11-08 15:52:38-08:00,"['api-binary-compatibility.yml', 'revapi.yml', 'build.gradle']"
Core: Rename HMS_TABLE_OWNER to follow naming convention (#6154),1,2,2022-11-09 10:50:39+01:00,['TableProperties.java']
Docs: Update spotless apply command (#6157),1,2,2022-11-09 11:07:02+01:00,['README.md']
"Python: Cache Poetry install (#6158)

Signed-off-by: Jelmer Draaijer <info@jelmert.nl>

Signed-off-by: Jelmer Draaijer <info@jelmert.nl>",1,5,2022-11-09 13:19:17+01:00,['python-ci.yml']
Nessie: Nessie Catalog to return a unique path for different tables with same name (#4826),3,101,2022-11-09 10:33:33-06:00,"['NessieCatalog.java', 'TestBranchVisibility.java', 'TestNessieTable.java']"
Spark: Support reading from a tag or branch (#5150),5,211,2022-11-09 09:03:30-08:00,"['SparkReadConf.java', 'SparkReadOptions.java', 'SparkBatchQueryScan.java', 'SparkScanBuilder.java', 'TestSnapshotSelection.java']"
Core: Cache dropStats in ManifestReader iterator (#5836),2,23,2022-11-09 12:57:08-08:00,"['ManifestReader.java', 'TestManifestReaderStats.java']"
Core: Reduce code duplication around writing JSON collections (#6113),13,210,2022-11-09 12:58:32-08:00,"['MetadataUpdateParser.java', 'SchemaParser.java', 'SnapshotParser.java', 'StatisticsFileParser.java', 'TableMetadataParser.java', 'FileIOParser.java', 'NameMappingParser.java', 'ScanReportParser.java', 'FileMetadataParser.java', 'ErrorResponseParser.java', 'JsonUtil.java', 'TestTableMetadata.java', 'TestJsonUtil.java']"
"Python: Fix Evaluator tests (#6140)

This uses the same tests as the JVM implementation.",1,1094,2022-11-09 13:15:06-08:00,['test_visitors.py']
"Core: Sync client/server properties in REST catalog (#6150)

* Core: Sync client/server properties in REST catalog.

* Apply spotless.",2,37,2022-11-09 13:19:09-08:00,"['RESTSessionCatalog.java', 'TestRESTCatalog.java']"
Python: Use FileIO from Table and forward S3 credentials (#6161),8,93,2022-11-09 16:45:52-08:00,"['hive.py', 'rest.py', 'console.py', 'output.py', 'fsspec.py', 'pyarrow.py', '__init__.py', 'test_console.py']"
Flink: Port #6049 to Flink 1.14 to add Sink options of compression properties (#6166),9,398,2022-11-10 10:13:14+01:00,"['FlinkWriteConf.java', 'FlinkWriteOptions.java', 'FlinkSink.java', 'RowDataTaskWriterFactory.java', 'RowDataRewriter.java', 'TestCompressionSettings.java', 'TestDeltaTaskWriter.java', 'TestTaskWriters.java', 'TestProjectMetaColumn.java']"
"Build: Bump jackson-annotations from 2.13.4 to 2.14.0 (#6129)

Bumps [jackson-annotations](https://github.com/FasterXML/jackson) from 2.13.4 to 2.14.0.
- [Release notes](https://github.com/FasterXML/jackson/releases)
- [Commits](https://github.com/FasterXML/jackson/commits)

---
updated-dependencies:
- dependency-name: com.fasterxml.jackson.core:jackson-annotations
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,4,2022-11-10 12:36:12+01:00,"['build.gradle', 'build.gradle']"
Python: Add initial TableScan implementation (#6145),2,186,2022-11-10 09:14:37-08:00,"['__init__.py', 'test_init.py']"
Build: Add -DallVersions property that exposes all component versions (#6167),4,13,2022-11-10 09:17:54-08:00,"['java-ci.yml', 'publish-snapshot.yml', 'README.md', 'settings.gradle']"
Python: Move FileIO initialization to the catalog (#6170),9,57,2022-11-10 19:32:22+01:00,"['__init__.py', 'hive.py', 'rest.py', '__init__.py', '__init__.py', 'test_base.py', 'test_rest.py', 'test_console.py', 'test_init.py']"
"Core,Spark: Add metadata to Scan Report (#6058)",6,132,2022-11-11 08:57:16-08:00,"['BaseTableScan.java', 'EnvironmentContext.java', 'ScanReport.java', 'ScanReportParser.java', 'TestScanReportParser.java', 'SparkCatalog.java']"
"Python: Fix previous metadata location property

Co-authored-by: Alec Heifetz <alec@hudson-trading.com>",1,2,2022-11-11 21:53:29+01:00,['hive.py']
AWS: Fix catalog name in LakeFormationTestBase (#5767),1,4,2022-11-14 08:06:05-08:00,['LakeFormationTestBase.java']
Spark: Backport setting the EnvironmentContext for Spark (#6183),3,18,2022-11-14 08:39:23-08:00,"['CustomCatalogs.java', 'SparkCatalog.java', 'SparkCatalog.java']"
"Flink: Add engine name, version to EnvironmentContext (#6184)",3,12,2022-11-14 10:41:15-08:00,"['FlinkCatalog.java', 'FlinkCatalog.java', 'FlinkCatalog.java']"
Core: Add Iceberg version to EnvironmentContext (#6185),1,4,2022-11-14 10:42:17-08:00,['EnvironmentContext.java']
"Python: Make invalid Literal conversions explicit (#6141)

Currently we silently turn Literals into None if we can't convert
them, instead I prefer to raise an exception. This can cause silent
bugs like: EqualTo(Reference(""id""), StringLiteral(""123a"")) will turn
into a IsNull predicate since 123a cannot be casted to an Long
(assuming that the `id` column is a Long).",2,398,2022-11-14 14:00:58-08:00,"['literals.py', 'test_literals.py']"
Core: Add a util method to combine tasks by partition (#2276),6,267,2022-11-14 14:49:37-08:00,"['ContentScanTask.java', 'PartitionScanTask.java', 'StructProjection.java', 'TableScanUtil.java', 'MockFileScanTask.java', 'TestTableScanUtil.java']"
Spark 3.3: Support Java 8 time API in SparkValueConverter (#5860),2,105,2022-11-14 15:34:41-08:00,"['TestRewriteManifestsProcedure.java', 'SparkValueConverter.java']"
"Build: Enable revapi on checked modules, fix API breaks (#6146)",17,353,2022-11-14 16:22:28-08:00,"['revapi.yml', 'TableScan.java', 'MigrateTable.java', 'build.gradle', 'BaseReplacePartitions.java', 'BaseRewriteManifests.java', 'BaseTableScan.java', 'FastAppend.java', 'ManifestReader.java', 'MergingSnapshotProducer.java', 'SnapshotProducer.java', 'Deletes.java', 'Util.java', 'HTTPClient.java', 'RESTClient.java', 'PartitionUtil.java', 'RESTCatalogAdapter.java']"
Spark 3.3: Preserve file seq numbers while rewriting manifests (#6176),3,158,2022-11-14 16:26:23-08:00,"['RewriteManifestsSparkAction.java', 'ValidationHelpers.java', 'TestRewriteManifestsAction.java']"
Docs: fix link of `Write options` in Flink,1,2,2022-11-14 21:46:37-08:00,['flink-getting-started.md']
Core: Remove unused toTaskGroupStream from TableScanUtil (#6189),1,13,2022-11-14 21:51:37-08:00,['TableScanUtil.java']
Spark 3.2: Preserve file seq numbers while rewriting manifests (#6192),3,158,2022-11-15 08:03:56+01:00,"['RewriteManifestsSparkAction.java', 'ValidationHelpers.java', 'TestRewriteManifestsAction.java']"
Spark 3.1: Preserve file seq numbers while rewriting manifests (#6193),3,158,2022-11-15 08:04:23+01:00,"['BaseRewriteManifestsSparkAction.java', 'ValidationHelpers.java', 'TestRewriteManifestsAction.java']"
Flink: Add 'cache.expiration-interval-ms' option to FlinkCatalog (#6111),10,117,2022-11-15 08:47:41-08:00,"['flink-getting-started.md', 'FlinkCatalog.java', 'FlinkCatalogFactory.java', 'TestFlinkCatalogTablePartitions.java', 'FlinkCatalog.java', 'FlinkCatalogFactory.java', 'TestFlinkCatalogTablePartitions.java', 'FlinkCatalog.java', 'FlinkCatalogFactory.java', 'TestFlinkCatalogTablePartitions.java']"
Core: Method for building grouping key type (#6163),2,345,2022-11-15 09:57:28-08:00,"['Partitioning.java', 'TestPartitioning.java']"
"Revert ""Hive: Forward catalog-specific Hive configuration properties (#5989)"" (#6187)

This reverts commit 4b5e39d32f1c1d07d4d8d131f96beef962143e94.",2,21,2022-11-16 08:06:40-08:00,"['HiveCatalog.java', 'TestHiveCatalog.java']"
Core: Add time zone info to LocalDate in ExpressionUtil tests (#6200),1,6,2022-11-16 08:06:57-08:00,['TestExpressionUtil.java']
REST: Assign metadata UUID on create transaction (#6201),3,14,2022-11-16 08:25:43-08:00,"['MetadataUpdate.java', 'TableMetadata.java', 'RESTSessionCatalog.java']"
"Python: Fix rough edges around literals (#6197)

* Python: Fix rough edges around literals

* timezone -> zone offset",3,92,2022-11-16 21:48:45+01:00,"['literals.py', 'datetime.py', 'test_literals.py']"
"API, Core: Move micros and days conversions to DateTimeUtil (#6199)",4,114,2022-11-16 23:42:01-08:00,"['Dates.java', 'Timestamps.java', 'DateTimeUtil.java', 'TestDateTimeUtil.java']"
Core: Remove redundant initialization (#6178),4,12,2022-11-17 14:54:20+01:00,"['ManifestFiles.java', 'PartitionData.java', 'AvroFileAppender.java', 'UnionByNameVisitor.java']"
Flink: Extract Flink package version programmatically for EnvironmentContext engine-version (#6206),6,108,2022-11-17 14:56:04+01:00,"['FlinkCatalog.java', 'FlinkPackage.java', 'FlinkCatalog.java', 'FlinkPackage.java', 'FlinkCatalog.java', 'FlinkPackage.java']"
Flink: Add unit test for FlinkPackage util class (#6213),3,93,2022-11-18 08:04:04+01:00,"['TestFlinkPackage.java', 'TestFlinkPackage.java', 'TestFlinkPackage.java']"
Parquet: Fix null values when selecting nested field partition column (#4627),9,345,2022-11-18 16:05:52+01:00,"['FlinkParquetReaders.java', 'TestFlinkInputFormat.java', 'BaseParquetReaders.java', 'ParquetValueReaders.java', 'PigParquetReader.java', 'SparkParquetReaders.java', 'ComplexRecord.java', 'NestedRecord.java', 'TestPartitionValues.java']"
"Python: Update mypy to 0.991 (#6159)

* Update mypy and fix mypy errors

* Remove coalesce method",6,29,2022-11-18 17:06:38+01:00,"['.pre-commit-config.yaml', '__init__.py', 'typedef.py', 'config.py', 'pyproject.toml', 'test_decoder.py']"
Python: Remove dataclasses (#6139),10,2046,2022-11-19 14:21:28-08:00,"['poetry.lock', '__init__.py', 'literals.py', 'visitors.py', 'typedef.py', 'pyproject.toml', 'test_expressions.py', 'test_literals.py', 'test_visitors.py', 'test_init.py']"
Python: Fix type nits from expression refactor (#6225),5,68,2022-11-19 14:34:37-08:00,"['__init__.py', 'literals.py', 'visitors.py', 'typedef.py', 'test_expressions.py']"
Python: Add expression evaluator (#6127),8,314,2022-11-20 11:35:26-08:00,"['reader.py', '__init__.py', 'visitors.py', 'files.py', 'schema.py', 'typedef.py', 'test_evaluator.py', 'test_schema.py']"
API: Fix Transform backward compatibility in PartitionSpec (#6220),6,77,2022-11-20 12:02:40-08:00,"['PartitionField.java', 'PartitionSpec.java', 'SortField.java', 'UnboundPartitionSpec.java', 'ProjectionUtil.java', 'SortOrderUtil.java']"
Spark: Add missing override (#6227),1,1,2022-11-20 12:03:52-08:00,['WritersBenchmark.java']
API: Ignore case when comparing truncate (#6226),1,4,2022-11-20 12:08:07-08:00,['Transforms.java']
Release: Fix the template of the version (#6195),1,2,2022-11-20 23:53:01-08:00,['source-release.sh']
Replace ImmutableMap.Builder.build() with buildOrThrow() (#6212),35,89,2022-11-21 13:29:29+01:00,"['Comparators.java', 'Types.java', 'TestInclusiveMetricsEvaluator.java', 'TestMetricsEvaluatorsNaNHandling.java', 'TestStrictMetricsEvaluator.java', 'GlueCatalog.java', 'MetadataUpdateParser.java', 'JdbcCatalog.java', 'UpdateRequirementParser.java', 'TestManifestCaching.java', 'HadoopTableTestBase.java', 'RESTCatalogAdapter.java', 'FlinkFilters.java', 'TestFlinkScan.java', 'FlinkFilters.java', 'TestFlinkScan.java', 'FlinkFilters.java', 'TestFlinkScan.java', 'TestHiveCatalog.java', 'BaseTestIceberg.java', 'ParquetWriteSupport.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'SparkFilters.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'SparkFilters.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'SparkFilters.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'SparkAggregates.java', 'SparkFilters.java', 'SparkV2Filters.java']"
"Python: Minor fixes to expression types (#6228)

* Python: Minor fixes to expression types.

* Fix bind return types.",3,52,2022-11-21 13:29:48+01:00,"['__init__.py', 'visitors.py', 'test_expressions.py']"
"Python: Add support for GlueCatalog (#6034)

* add glueCatalog bone

* add boto3

* first draft based on previous PR

* add personal test and implements load_table

* test create table functionality

* tested drop table functionality

* reformat create_table and load_table and perform some test

* add some todo item

* reimplement create_table and load_table

* update load_table's io initialization

* suggestions 1 - 4

* remain: refactor constant name

* refactor code structure and add exception caught

* fix some typo and make constants defined above

* format fix partially

* update environment

* fix style issue

* let comment be more specific

* add ignore missing boto3 to mypy config

* skip test_glue temporarily

* fix typo PROP_GLUE_TABLE_TYPE

* change dict[str, str] to properties

* fix all sanity issue

* make boto3 optional

* implement list namespaces, change aws account for test

* fix keyerror in default warehouse location

* fix keyerror in default warehouse location

* update apache header

* add unit test prototype

* format unit test

* fix the fixture scope issue

* add comment for the gist

* add apache head

* move fixtures to conftest in utils

* rollback changes to hive apache license header

* update nit, error messages. solve case sensitive error. remove duplicate code in create_table

* update format

* put io instantiation to _convert_glue_to_iceberg and make it consistent

* make boto3 and moto extra

* update makeFile to include boto3 and moto

* add NoSuchIcebergTableError

* use NoSuchPropertyException

* make global var consistent with hive

* move common global variable to pyiceberg.catalog.base

* complete rest of gluecatalog first_draft

* add comments for class methods

* add integration test and fix some small bugs

* add next_token for list_tables

* add next_token for list_namespaces

* make create_table's description key consistent with that of create_namespace

* add unit tests for table-related operations

* add unit tests for namespace-related operations

* formalize integration test

* aggregate all GlueCatalog instance to a fixture

* remove redundant print

* optimize test for rename table

* refactor duplicated code segment and details

* fix some potential keyError issue

* reimplement purge_table to correct logic

* add load glue catalog and move shared variables to __init__.py

* fix format issue

* move delete_data_files, delete_files to __init__.py

* rename and make constant strings variables

* fix minor style issues

* fix configuration after rebase

* add doc for glue catalog

* handle loading database created by AWS Glue Console

* add comment to helper functions

* add check to disable hierarchical namespace, add removing strips for database_location and warehouse path

* refactor the rename_table logic to add check if the table is a valid iceberg table

* revise comments

* fix create table input key error

* persist table description when renaming the table

* update after rebase",10,1836,2022-11-21 15:35:30+01:00,"['Makefile', 'index.md', 'poetry.lock', '__init__.py', 'glue.py', 'exceptions.py', 'pyproject.toml', 'integration_test_glue.py', 'test_glue.py', 'conftest.py']"
"Python: Disallow Any generics (#6232)

Mypy allows us to warn us when a type is missing:
`List`, should be `List[str]`

This way we don't accidentially forget any type.",21,232,2022-11-21 21:25:42+01:00,"['reader.py', 'rest.py', '__init__.py', 'literals.py', 'fsspec.py', 'pyarrow.py', 'manifest.py', 'schema.py', 'metadata.py', 'partitioning.py', 'sorting.py', 'transforms.py', 'bin_packing.py', 'deprecated.py', 'parsing.py', 'schema_conversion.py', 'singleton.py', 'pyproject.toml', 'test_expressions.py', 'test_visitors.py', 'test_transforms.py']"
Python: Implement DataScan.plan_files (#6233),24,473,2022-11-21 14:26:02-08:00,"['index.md', 'poetry.lock', '__init__.py', 'glue.py', 'hive.py', 'rest.py', 'output.py', 'visitors.py', 'manifest.py', 'partitioning.py', '__init__.py', 'metadata.py', 'snapshots.py', 'typedef.py', 'pyproject.toml', 'test_base.py', 'test_hive.py', 'test_rest.py', 'test_console.py', 'test_init.py', 'test_metadata.py', 'test_partitioning.py', 'test_snapshots.py', 'test_manifest.py']"
Python: Implement project in Transform implementations (#6128),5,718,2022-11-21 15:37:27-08:00,"['__init__.py', 'literals.py', 'transforms.py', 'test_literals.py', 'test_transforms.py']"
"Core: Allow dropping a column used by old SortOrder (#6211)

Co-authored-by: Islam Ismailov <iismailov@netflix.com>",1,20,2022-11-22 08:48:00+01:00,['TestSortOrder.java']
"Nessie: Refactor NessieTableOperations#doCommit (#6240)

* Nessie: Refactor NessieTableOperations

* Expose refName",2,175,2022-11-22 13:40:36+01:00,"['NessieIcebergClient.java', 'NessieTableOperations.java']"
"API: Restore the type of the identity transform (#6242)

* API: Restore the type of the identity transform

This caused some regression for the Iceberg 1.1.0 release:

```
2022-11-21T12:05:46.6549795Z [ERROR] io.trino.plugin.iceberg.TestIcebergSystemTables.testManifestsTable  Time elapsed: 0.701 s  <<< FAILURE!
2022-11-21T12:05:46.6550853Z java.lang.AssertionError:
2022-11-21T12:05:46.6551986Z [Rows for query [SELECT added_data_files_count, existing_rows_count, added_rows_count, deleted_data_files_count, deleted_rows_count, partitions FROM test_schema.""test_table$manifests""]]
2022-11-21T12:05:46.6553075Z Expecting:
2022-11-21T12:05:46.6553593Z   <(2, 0, 3, 0, 0, [[false, false, 18148, 18149]]), (2, 0, 3, 0, 0, [[false, false, 18147, 18148]])>
2022-11-21T12:05:46.6553980Z to contain exactly in any order:
2022-11-21T12:05:46.6554557Z   <[(2, 0, 3, 0, 0, [[false, false, 2019-09-08, 2019-09-09]]),
2022-11-21T12:05:46.6554992Z     (2, 0, 3, 0, 0, [[false, false, 2019-09-09, 2019-09-10]])]>
2022-11-21T12:05:46.6555273Z elements not found:
2022-11-21T12:05:46.6555804Z   <(2, 0, 3, 0, 0, [[false, false, 2019-09-08, 2019-09-09]]), (2, 0, 3, 0, 0, [[false, false, 2019-09-09, 2019-09-10]])>
2022-11-21T12:05:46.6556132Z and elements not expected:
2022-11-21T12:05:46.6556488Z   <(2, 0, 3, 0, 0, [[false, false, 18148, 18149]]), (2, 0, 3, 0, 0, [[false, false, 18147, 18148]])>
```

The system tables (manifests in this example above), would return
the days since epoch instead of a date.

* Restore equals

* Bind SortOrder as well

* Add todo",5,84,2022-11-22 13:40:53+01:00,"['SortOrder.java', 'UnboundSortOrder.java', 'Identity.java', 'Transforms.java', 'TestIdentity.java']"
Python: Pass warehouse location to config (#6260),4,40,2022-11-23 11:21:30-08:00,"['__init__.py', 'glue.py', 'rest.py', 'test_rest.py']"
Spark 3.3: Add years transform function (#6207),4,280,2022-11-23 16:09:55-08:00,"['SparkFunctions.java', 'UnaryUnboundFunction.java', 'YearsFunction.java', 'TestSparkYearsFunction.java']"
"Flink: Fix tests creating catalog after FLINK-29677 (#6248)

* Flink: Fix tests creating catalog after FLINK-29677

* enhanced drop

Co-authored-by: Peter Vary <peter_vary4@apple.com>",5,21,2022-11-24 11:27:34-08:00,"['FlinkCatalogTestBase.java', 'FlinkTestBase.java', 'TestChangeLogTable.java', 'TestFlinkHiveCatalog.java', 'TestFlinkTableSource.java']"
"API: Fix ErrorProne warning around Immutable Enums (#6264)

This should fix the ErrorProne warning
```
> Task :iceberg-api:compileJava
/home/nastra/Development/workspace/iceberg/api/src/main/java/org/apache/iceberg/transforms/Timestamps.java:69: warning: [ImmutableEnumChecker] enums should be immutable: 'Timestamps' has field 'apply' of type 'org.apache.iceberg.util.SerializableFunction<java.lang.Long,java.lang.Integer>', the declaration of type 'org.apache.iceberg.util.SerializableFunction<java.lang.Long,java.lang.Integer>' is not annotated with @com.google.errorprone.annotations.Immutable
  private final SerializableFunction<Long, Integer> apply;
                                                    ^
    (see https://errorprone.info/bugpattern/ImmutableEnumChecker)
/home/nastra/Development/workspace/iceberg/api/src/main/java/org/apache/iceberg/transforms/Dates.java:66: warning: [ImmutableEnumChecker] enums should be immutable: 'Dates' has field 'apply' of type 'org.apache.iceberg.transforms.Dates.Apply', the declaration of type 'org.apache.iceberg.transforms.Dates.Apply' is not annotated with @com.google.errorprone.annotations.Immutable
  private final Apply apply;
                      ^
    (see https://errorprone.info/bugpattern/ImmutableEnumChecker)
```",2,6,2022-11-25 09:07:35+01:00,"['Dates.java', 'Timestamps.java']"
"Docs: Update slack invite link (#6278)

Follow up to https://github.com/apache/iceberg-docs/commit/59f1a607d318fff8c2423b2ab4e667dd24125767",1,2,2022-11-26 07:57:51+01:00,['iceberg_question.yml']
Spark 3.3: Add months transform function (#6261),3,234,2022-11-26 13:31:54-08:00,"['MonthsFunction.java', 'SparkFunctions.java', 'TestSparkMonthsFunction.java']"
Python (legacy): Pin flake8 (#6270),1,4,2022-11-26 13:34:47-08:00,['tox.ini']
Python: Refactor catalog constants (#6277),1,15,2022-11-27 08:59:11-08:00,['hive.py']
Spec: Clarify auth responses in the REST spec. (#6251),1,11,2022-11-27 10:26:52-08:00,['rest-catalog-open-api.yaml']
"Spec: Add spec for AES GCM Stream (#5432)

Co-authored-by: Gidon Gershinsky <ggershinsky@apple.com>",1,88,2022-11-27 14:08:38-08:00,['gcm-stream-spec.md']
Docs: Fix minor typos in the view spec (#6214),1,8,2022-11-27 14:34:45-08:00,['view-spec.md']
Spark 3.3: Fix a separate table cache being created for each rewriteFiles (#5392),4,38,2022-11-27 14:41:20-08:00,"['RewriteDataFilesSparkAction.java', 'SparkBinPackStrategy.java', 'SparkSortStrategy.java', 'SparkZOrderStrategy.java']"
"Build: Bump microprofile-openapi-api from 3.0 to 3.1 (#6279)

Bumps [microprofile-openapi-api](https://github.com/eclipse/microprofile-open-api) from 3.0 to 3.1.
- [Release notes](https://github.com/eclipse/microprofile-open-api/releases)
- [Commits](https://github.com/eclipse/microprofile-open-api/compare/3.0...3.1)

---
updated-dependencies:
- dependency-name: org.eclipse.microprofile.openapi:microprofile-openapi-api
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2022-11-28 08:13:18+01:00,['build.gradle']
"Python: Fix Avro scan performance in PyArrow (#6283)

* Python: Fix Avro scan performance.

* Python: Fix EOF handling.",2,25,2022-11-28 08:19:24+01:00,"['decoder.py', 'file.py']"
"Build: Bump spotless-plugin-gradle from 6.11.0 to 6.12.0 (#6281)

Bumps [spotless-plugin-gradle](https://github.com/diffplug/spotless) from 6.11.0 to 6.12.0.
- [Release notes](https://github.com/diffplug/spotless/releases)
- [Changelog](https://github.com/diffplug/spotless/blob/main/CHANGES.md)
- [Commits](https://github.com/diffplug/spotless/compare/gradle/6.11.0...gradle/6.12.0)

---
updated-dependencies:
- dependency-name: com.diffplug.spotless:spotless-plugin-gradle
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2022-11-28 08:20:49+01:00,['build.gradle']
"Build: Bump jackson-annotations from 2.14.0 to 2.14.1 (#6280)

Bumps [jackson-annotations](https://github.com/FasterXML/jackson) from 2.14.0 to 2.14.1.
- [Release notes](https://github.com/FasterXML/jackson/releases)
- [Commits](https://github.com/FasterXML/jackson/commits)

---
updated-dependencies:
- dependency-name: com.fasterxml.jackson.core:jackson-annotations
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,4,2022-11-28 08:22:40+01:00,"['build.gradle', 'build.gradle']"
"Docs: Fix redundant the (#6286)

Co-authored-by: slfan1989 <louj1988@@>",1,2,2022-11-28 08:23:51+01:00,['reliability.md']
"Infra: Add 1.1.0 to issue template (#6287)

As 1.1.0 release is pushed to maven central, 
https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-3.3_2.13/1.1.0/

Also dependabots / renovate bots started raising version bump PR. 
https://github.com/projectnessie/nessie/pull/5582",1,3,2022-11-28 11:12:52+01:00,['iceberg_bug_report.yml']
Hive: Set the database owner on namespace creation (#6045),4,457,2022-11-28 15:51:57+01:00,"['TableProperties.java', 'HiveCatalog.java', 'HiveTableOperations.java', 'TestHiveCatalog.java']"
Flink: Add metricsConfig to EqDeleteWriter & PosDeleteWriter (#6271),3,9,2022-11-28 08:11:10-08:00,"['FlinkAppenderFactory.java', 'FlinkAppenderFactory.java', 'FlinkAppenderFactory.java']"
Python: Implement inclusive projection (#6247),7,500,2022-11-28 08:50:24-08:00,"['visitors.py', 'partitioning.py', '__init__.py', 'transforms.py', 'test_projection.py', 'test_init.py', 'test_partitioning.py']"
Python: Implement PyArrow row level filtering (#6258),6,503,2022-11-28 12:15:43-08:00,"['visitors.py', 'pyarrow.py', '__init__.py', 'test_evaluator.py', 'test_visitors.py', 'test_pyarrow.py']"
"Python: Update feature matrix (#6298)

We actually don't have support for changing tables
We have recently added support for planning scans",1,26,2022-11-28 12:45:24-08:00,['index.md']
"Python: Bump FastAvro to 1.7.0 (#6294)

Bumps [fastavro](https://github.com/fastavro/fastavro) from 1.6.1 to 1.7.0.
- [Release notes](https://github.com/fastavro/fastavro/releases)
- [Changelog](https://github.com/fastavro/fastavro/blob/master/ChangeLog)
- [Commits](https://github.com/fastavro/fastavro/compare/1.6.1...1.7.0)

Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",4,192,2022-11-28 12:47:27-08:00,"['poetry.lock', 'pyproject.toml', 'test_reader.py', 'conftest.py']"
"Python: Add boolean expression parser (#6259)

Co-authored-by: Fokko Driesprong <fokko@apache.org>",5,432,2022-11-28 13:05:09-08:00,"['literals.py', 'parser.py', 'pyproject.toml', 'test_literals.py', 'test_parser.py']"
Python: Produce constants when binding produces AboveMax or BelowMin (#6256),4,276,2022-11-28 13:12:05-08:00,"['__init__.py', 'literals.py', 'test_expressions.py', 'test_literals.py']"
Spark 3.3: Add days transform function (#6300),3,219,2022-11-29 09:35:49-06:00,"['DaysFunction.java', 'SparkFunctions.java', 'TestSparkDaysFunction.java']"
Build: Bump Gradle from 7.5.1 to 7.6 (#6276),2,8,2022-11-29 19:14:20+01:00,"['gradle-wrapper.properties', 'gradlew']"
"API, Core: Add groupingKey to ScanTaskGroup (#6304)",5,169,2022-11-29 15:54:23-08:00,"['BaseScanTaskGroup.java', 'EmptyStructLike.java', 'ScanTaskGroup.java', 'PartitionData.java', 'TableScanUtil.java']"
Build: Let revapi compare against 1.1.0 (#6275),1,2,2022-11-29 16:33:39-08:00,['build.gradle']
Core: Clarify and test behavior of write.metadata.delete-after-commit.enabled (#6217),4,70,2022-11-29 16:55:53-08:00,"['BaseMetastoreTableOperations.java', 'CatalogTests.java', 'configuration.md', 'maintenance.md']"
Bump Nessie from 0.44.0 to 0.45.0 (#6310),1,2,2022-11-30 10:30:27+01:00,['versions.props']
Core: Re-add and deprecate HMS_TABLE_OWNER to TableProperties (#6314),1,3,2022-11-30 09:49:10-06:00,['TableProperties.java']
Python: Bump PyArrow (#6295),2,362,2022-11-30 14:25:07-08:00,"['poetry.lock', 'pyproject.toml']"
"Core: Use lower lengths for iceberg_namespace_properties / iceberg_tables in JdbcCatalog (#6338)

Users are running into issues when hooking up the `JdbcCatalog` with
`MySql` or other Databases, which actually impose lower limits than
[sqlite](https://www.sqlite.org/limits.html) (which we use for testing the `JdbcCatalog`.",1,8,2022-12-01 08:37:23-08:00,['JdbcUtil.java']
Core: Fix NPE in CloseableIterable.close() (#6322),2,12,2022-12-01 08:38:33-08:00,"['CloseableIterable.java', 'TestCloseableIterable.java']"
"Core: MetadataUpdateParser should write updates/removals fields rather than updated/removed (#6317)

According to the REST API Spec the parser needs to write
updates/removals rather than updated/removed. However, we indefinitely
need to support reading both versions for backward compatibility.",2,71,2022-12-01 08:43:03-08:00,"['MetadataUpdateParser.java', 'TestMetadataUpdateParser.java']"
Spark 2.4: Preserve file seq numbers while rewriting manifests (#6289),3,158,2022-12-01 09:35:44-08:00,"['BaseRewriteManifestsSparkAction.java', 'ValidationHelpers.java', 'TestRewriteManifestsAction.java']"
Python: Set version to 0.2.0 (#6328),3,6,2022-12-01 10:03:41-08:00,"['RELEASE.md', '__init__.py', 'pyproject.toml']"
Python: Add warning on projection by name (#6334),1,5,2022-12-01 10:04:30-08:00,['__init__.py']
Spark 3.3: Add hours transform function (#6339),3,172,2022-12-01 11:05:44-08:00,"['HoursFunction.java', 'SparkFunctions.java', 'TestSparkHoursFunction.java']"
Spark 3.3: Support arbitrary scans in SparkBatchQueryScan (#6309),6,212,2022-12-01 11:41:40-08:00,"['SparkBatch.java', 'SparkBatchQueryScan.java', 'SparkCopyOnWriteScan.java', 'SparkFilesScan.java', 'SparkScan.java', 'SparkScanBuilder.java']"
Spark 3.3: Remove unused RowDataRewriter (#6343),1,179,2022-12-01 13:43:42-08:00,['RowDataRewriter.java']
Doc: Replace build with append in the Flink doc (#6336),1,6,2022-12-02 09:28:51+01:00,['flink-getting-started.md']
Flink: Port #4627 to Flink 1.14/1.15 (#6333),4,124,2022-12-02 18:54:49+01:00,"['FlinkParquetReaders.java', 'TestFlinkInputFormat.java', 'FlinkParquetReaders.java', 'TestFlinkInputFormat.java']"
Spark: Port #4627 to Spark 2.4/3.1/3.2 (#6331),12,648,2022-12-02 18:55:50+01:00,"['SparkParquetReaders.java', 'ComplexRecord.java', 'NestedRecord.java', 'TestPartitionValues.java', 'SparkParquetReaders.java', 'ComplexRecord.java', 'NestedRecord.java', 'TestPartitionValues.java', 'SparkParquetReaders.java', 'ComplexRecord.java', 'NestedRecord.java', 'TestPartitionValues.java']"
"Build: Keep Scala Compiler Alive Between Sessions(#6311)

Default behavior is one compiler instance per ""session"", this change
updates it to keep the compiler alive with the Gradle daemon.
(This uses a new feature from Gradle 7.6.)",1,6,2022-12-02 12:48:51-06:00,['build.gradle']
Spark 3.3: Choose readers based on task types (#6345),12,470,2022-12-02 15:54:18-08:00,"['BatchDataReader.java', 'ChangelogRowReader.java', 'EqualityDeleteRowReader.java', 'RowDataReader.java', 'SparkBatch.java', 'SparkChangelogBatch.java', 'SparkChangelogScan.java', 'SparkColumnarReaderFactory.java', 'SparkInputPartition.java', 'SparkMicroBatchStream.java', 'SparkRowReaderFactory.java', 'SparkScan.java']"
"Python: Fix PyArrow Type conversion (#6346)

* Python: Fix PyArrow Type conversion

It turns out that we need to cast the literal to the right type:

```
ArrowNotImplementedError: Function 'greater_equal' has no kernel matching input types (timestamp[us, tz=+00:00], int64)
```

After casting the scalar, it works perfect. One awkward thing to note that
we don't have to do this for the `isin` predicate. There this is done
for us. Please check the Jupyter notebook.

* Explicitly set the type",1,25,2022-12-04 19:50:18+01:00,['pyarrow.py']
API: Override equals and hashCode methods for primitive types (#6305),2,22,2022-12-04 15:59:18-08:00,"['Type.java', 'TypeUtil.java']"
Core: Change SingleBufferInputStream .read signature to match super (#6221),1,4,2022-12-05 15:12:18+01:00,['SingleBufferInputStream.java']
"API: Add view interfaces (#4925)

Co-authored-by: anjalinorwood@gmail.com
Co-authored-by: jahamogh@amazon.com",9,609,2022-12-05 09:58:23-08:00,"['ViewCatalog.java', 'NoSuchViewException.java', 'SQLViewRepresentation.java', 'UpdateViewProperties.java', 'View.java', 'ViewBuilder.java', 'ViewHistoryEntry.java', 'ViewRepresentation.java', 'ViewVersion.java']"
Core: Add readable_metrics columns to files metadata tables (#5376),14,1436,2022-12-05 10:08:50-08:00,"['Schema.java', 'TypeUtil.java', 'BaseFilesTable.java', 'MetricsUtil.java', 'TestMetadataTableScans.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestMetadataTables.java', 'TestHelpers.java', 'TestIcebergSourceTablesBase.java', 'TestMetadataTables.java', 'TestHelpers.java', 'TestIcebergSourceTablesBase.java', 'TestMetadataTableReadableMetrics.java']"
"Flink: support split discovery throttling for streaming read (#6299)

* Flink: support split discovery throttling for streaming read in case of lagging behind or intentially delayed assumption.

This is to avoid eagerly discovering too many splits and tracking them in memory when the Flink job falling behind too much. It helps to keep memory footprint and enumerator checkpoint size in check.",14,807,2022-12-05 13:11:27-08:00,"['IcebergSource.java', 'SimpleSplitAssigner.java', 'SplitAssigner.java', 'ContinuousIcebergEnumerator.java', 'ContinuousSplitPlannerImpl.java', 'EnumerationHistory.java', 'IcebergEnumeratorState.java', 'IcebergEnumeratorStateSerializer.java', 'StaticIcebergEnumerator.java', 'ManualContinuousSplitPlanner.java', 'TestContinuousIcebergEnumerator.java', 'TestContinuousSplitPlannerImpl.java', 'TestEnumerationHistory.java', 'TestIcebergEnumeratorStateSerializer.java']"
"Build: Bump moto from 4.0.10 to 4.0.11 in /python (#6356)

Bumps [moto](https://github.com/spulec/moto) from 4.0.10 to 4.0.11.
- [Release notes](https://github.com/spulec/moto/releases)
- [Changelog](https://github.com/spulec/moto/blob/master/CHANGELOG.md)
- [Commits](https://github.com/spulec/moto/compare/4.0.10...4.0.11)

---
updated-dependencies:
- dependency-name: moto
  dependency-type: direct:development
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,233,2022-12-06 09:06:09+01:00,"['poetry.lock', 'pyproject.toml']"
Docs: Update Iceberg Hive documentation (#6337),1,52,2022-12-06 12:59:29+01:00,['hive.md']
Build: Update ORC to 1.8.1 (#6349),1,2,2022-12-06 18:59:50+01:00,['versions.props']
Python: Fix PyArrow import (#6362),1,3,2022-12-06 12:32:34-08:00,['__init__.py']
Flink: backport split discovery throttling for FLIP-27 source to 1.14 and 1.15 (#6363),28,1614,2022-12-06 13:25:06-08:00,"['IcebergSource.java', 'SimpleSplitAssigner.java', 'SplitAssigner.java', 'ContinuousIcebergEnumerator.java', 'ContinuousSplitPlannerImpl.java', 'EnumerationHistory.java', 'IcebergEnumeratorState.java', 'IcebergEnumeratorStateSerializer.java', 'StaticIcebergEnumerator.java', 'ManualContinuousSplitPlanner.java', 'TestContinuousIcebergEnumerator.java', 'TestContinuousSplitPlannerImpl.java', 'TestEnumerationHistory.java', 'TestIcebergEnumeratorStateSerializer.java', 'IcebergSource.java', 'SimpleSplitAssigner.java', 'SplitAssigner.java', 'ContinuousIcebergEnumerator.java', 'ContinuousSplitPlannerImpl.java', 'EnumerationHistory.java', 'IcebergEnumeratorState.java', 'IcebergEnumeratorStateSerializer.java', 'StaticIcebergEnumerator.java', 'ManualContinuousSplitPlanner.java', 'TestContinuousIcebergEnumerator.java', 'TestContinuousSplitPlannerImpl.java', 'TestEnumerationHistory.java', 'TestIcebergEnumeratorStateSerializer.java']"
"Docs: Update Zorder spark support versions. (#6360)

Some users are using Zorder with spark-3.1 and facing a confusing error message.
Hence, updating the document.

Also thought about updating the code to throw the unsupported exception.
But maybe not required to modify the code as it is only the older versions.",1,2,2022-12-07 09:12:12-06:00,['spark-procedures.md']
Docs: Remove backticks from Spark procedure headings (#6374),1,2,2022-12-07 09:18:04-06:00,['spark-procedures.md']
"Python: Fix incorrect description when set a property (#6372)

* [Python] Fix incorrect description when set a property

* Fix wording

Co-authored-by: Steve Zhang <hongyue_zhang@apple.com>",1,12,2022-12-07 16:57:24+01:00,['console.py']
Core: Allow dropping a column that was part of a previous spec (#6268),1,27,2022-12-07 17:48:20+01:00,['TestPartitionSpecInfo.java']
Python: Make types required (#6308),64,2846,2022-12-07 14:00:22-08:00,"['decoder.py', 'file.py', 'reader.py', 'hive.py', 'rest.py', 'console.py', 'conversions.py', '__init__.py', 'literals.py', 'visitors.py', '__init__.py', 'fsspec.py', 'memory.py', 'pyarrow.py', 'partitioning.py', 'schema.py', '__init__.py', 'metadata.py', 'snapshots.py', 'sorting.py', 'transforms.py', 'types.py', 'config.py', 'datetime.py', 'deprecated.py', 'iceberg_base_model.py', 'singleton.py', 'pyproject.toml', 'test_decoder.py', 'test_file.py', 'test_reader.py', 'test_resolver.py', 'integration_test_glue.py', 'test_base.py', 'test_glue.py', 'test_hive.py', 'test_rest.py', 'test_console.py', 'conftest.py', 'test_evaluator.py', 'test_expressions.py', 'test_literals.py', 'test_parser.py', 'test_projection.py', 'test_visitors.py', 'test_fsspec.py', 'test_io.py', 'test_pyarrow.py', 'test_init.py', 'test_metadata.py', 'test_partitioning.py', 'test_refs.py', 'test_snapshots.py', 'test_sorting.py', 'test_conversions.py', 'test_schema.py', 'test_transforms.py', 'test_types.py', 'test_version.py', 'test_bin_packing.py', 'test_config.py', 'test_manifest.py', 'test_schema_conversion.py', 'test_singleton.py']"
Fix Spark JMH Benchmarks (#6385),4,8,2022-12-08 08:03:01-08:00,"['SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java']"
"Build: Bump jackson from 2.11.4 to 2.14.1 (#6168)

After we enabled RevAPI on `iceberg-core`, we've see RevAPI failures on all JSON Deserializer classes because of a new checked exception, but it is a subclass of an existing checked exception.",4,199,2022-12-08 08:33:37-08:00,"['revapi.yml', 'build.gradle', 'build.gradle', 'versions.props']"
Core: Throw CommitStateUnknownException for 502 responses. (#6391),2,15,2022-12-08 11:27:48-08:00,"['ErrorHandlers.java', 'rest-catalog-open-api.yaml']"
Flink: Support read options in flink source (#5967),9,698,2022-12-08 13:03:00-08:00,"['flink-getting-started.md', 'FlinkConfParser.java', 'FlinkReadConf.java', 'FlinkReadOptions.java', 'FlinkSource.java', 'FlinkSplitPlanner.java', 'IcebergSource.java', 'ScanContext.java', 'TestFlinkSourceConfig.java']"
"Build: Fix ./gradlew refreshJavadoc (#6390)

Since site/ folder was added to .gitignore the refreshJavadoc task started to
fail. The reson is that as a last step it wanted to do a 'git add' on the
Javadoc files, however it couldn't due to site/ being added to gitignore. The
Javadoc files anyway were generated successfully.
Not adding these files to git is on purpose as they are meant to be copied over
to iceberg-docs repo and released from there. So this 'git add' step is removed
from the task.",1,3,2022-12-09 09:26:16+01:00,['tasks.gradle']
"Build: Bump certifi from 2022.9.24 to 2022.12.7 in /python (#6396)

Bumps [certifi](https://github.com/certifi/python-certifi) from 2022.9.24 to 2022.12.7.
- [Release notes](https://github.com/certifi/python-certifi/releases)
- [Commits](https://github.com/certifi/python-certifi/compare/2022.09.24...2022.12.07)

---
updated-dependencies:
- dependency-name: certifi
  dependency-type: indirect
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,6,2022-12-09 12:12:51+01:00,['poetry.lock']
Python: Set lower bound pip version (#6384),1,2,2022-12-09 12:34:02+01:00,['README.md']
"Python: Improve docs (#6389)

* Python: Improve docs

This improves the docs by turning into a multi page site.

Also merges in the `CONTRIBUTING.md` and `RELEASE.md` to have
everything into a single place.

Also changed to the readthedocs theme since that has a much
cleaner multi page layout (navigation on the left instead
of the top).

* Rework the docs",10,1564,2022-12-09 13:34:50+01:00,"['.pre-commit-config.yaml', 'api.md', 'cli.md', 'configuration.md', 'contributing.md', 'feature-support.md', 'how-to-release.md', 'index.md', 'verify-release.md', 'mkdocs.yml']"
Flink: Fix minor compiler warning (#6395),3,6,2022-12-09 06:27:54-08:00,"['FlinkPackage.java', 'FlinkPackage.java', 'FlinkPackage.java']"
Build: Bump Arrow from 7.0.0 to 10.0.1 (#6386),1,4,2022-12-09 09:18:53-08:00,['versions.props']
Docs: Fix Python release variable (#6341),1,2,2022-12-09 09:54:18-08:00,['how-to-release.md']
"Python: Add support for 3.11 (#6329)

Since https://github.com/apache/iceberg/pull/6295 and https://github.com/apache/iceberg/pull/6294 have been merged, we should be ready to support 3.11

Closes #6124",2,5,2022-12-09 09:54:54-08:00,"['python-ci.yml', 'pyproject.toml']"
API: IsPartitioned to return true for V1 Tables with all void transforms (#3059),7,44,2022-12-09 16:51:03-06:00,"['PartitionSpec.java', 'Transform.java', 'VoidTransform.java', 'DataFiles.java', 'FileMetadata.java', 'TestPartitionSpecInfo.java', 'TestPartitioning.java']"
Spark 3.3: Check fileIO instead of reading location when determining localityEnabled (#6354),1,9,2022-12-09 15:03:59-08:00,['SparkReadConf.java']
Python: Implement `to_pandas` (#6254),3,73,2022-12-11 20:30:20+01:00,"['poetry.lock', '__init__.py', 'pyproject.toml']"
"Build: Bump duckdb from 0.6.0 to 0.6.1 in /python (#6403)

Bumps [duckdb](https://github.com/duckdb/duckdb) from 0.6.0 to 0.6.1.
- [Release notes](https://github.com/duckdb/duckdb/releases)
- [Changelog](https://github.com/duckdb/duckdb/blob/master/tools/release-pip.py)
- [Commits](https://github.com/duckdb/duckdb/compare/v0.6.0...v0.6.1)

---
updated-dependencies:
- dependency-name: duckdb
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,100,2022-12-11 21:00:39+01:00,"['poetry.lock', 'pyproject.toml']"
"Python: Introduce SchemaVisitorPerPrimitiveType (#6342)

* Python: Introduce SchemaVisitorPerPrimitiveType

Instead of having another visitor to go over the primitives
I think it is nicer to have an extended schema visitor that also
goes over the primitive types

* Fix merge conflicts",2,227,2022-12-12 10:35:17+01:00,"['pyarrow.py', 'schema.py']"
Python: Add missing types (#6409),1,4,2022-12-12 11:17:00+01:00,['pyarrow.py']
"Flink: Port Support read options in flink source to 1.14 & 1.16 (#6394)

* Flink: Port Support read options in flink source to 1.14 & 1.16",22,1344,2022-12-12 10:09:12-08:00,"['FlinkConfParser.java', 'FlinkReadConf.java', 'FlinkReadOptions.java', 'FlinkSource.java', 'FlinkSplitPlanner.java', 'IcebergSource.java', 'IcebergTableSource.java', 'ScanContext.java', 'TestFlinkSourceConfig.java', 'FlinkConfParser.java', 'FlinkSource.java', 'IcebergSource.java', 'IcebergTableSource.java', 'FlinkConfParser.java', 'FlinkReadConf.java', 'FlinkReadOptions.java', 'FlinkSource.java', 'FlinkSplitPlanner.java', 'IcebergSource.java', 'IcebergTableSource.java', 'ScanContext.java', 'TestFlinkSourceConfig.java']"
Python: Textual improvements and cleanup of docs (#6413),3,179,2022-12-13 14:53:39+01:00,"['CONTRIBUTING.md', 'README.md', 'contributing.md']"
Docs: Add register table Spark procedure documentation (#6376),1,34,2022-12-13 09:36:36-06:00,['spark-procedures.md']
"Flink: add util class to generate test data with extensive coverage d (#6377)

* Flink: add util class to generate test data with extensive coverage different field types: from primitives to complex nested types

* extract BIG_DECIMAL_NEGATIVE",2,783,2022-12-13 08:20:49-08:00,"['DataGenerator.java', 'DataGenerators.java']"
Spark 3.2: Fix a separate table cache being created for each rewriteFiles (#6284),4,37,2022-12-13 14:06:05-08:00,"['RewriteDataFilesSparkAction.java', 'SparkBinPackStrategy.java', 'SparkSortStrategy.java', 'SparkZOrderStrategy.java']"
Spark 3.1: Fix a separate table cache being created for each rewriteFiles (#6285),3,24,2022-12-13 14:07:11-08:00,"['BaseRewriteDataFilesSparkAction.java', 'Spark3BinPackStrategy.java', 'Spark3SortStrategy.java']"
Spark: Cleanup commented out code in SparkValueReaders (#6408),1,4,2022-12-13 14:56:53-08:00,['SparkValueReaders.java']
"Flink: use correct metric config for position deletes (#6313)

* Flink: use correct metric config for position deletes",21,165,2022-12-14 08:33:24-08:00,"['FlinkAppenderFactory.java', 'RowDataTaskWriterFactory.java', 'SimpleDataUtil.java', 'TestFlinkAppenderFactory.java', 'TestFlinkManifest.java', 'TestIcebergFilesCommitter.java', 'TestFlinkMergingMetrics.java', 'FlinkAppenderFactory.java', 'RowDataTaskWriterFactory.java', 'SimpleDataUtil.java', 'TestFlinkAppenderFactory.java', 'TestFlinkManifest.java', 'TestIcebergFilesCommitter.java', 'TestFlinkMergingMetrics.java', 'FlinkAppenderFactory.java', 'RowDataTaskWriterFactory.java', 'SimpleDataUtil.java', 'TestFlinkAppenderFactory.java', 'TestFlinkManifest.java', 'TestIcebergFilesCommitter.java', 'TestFlinkMergingMetrics.java']"
Spark 3.3: Time range query of changelog tables (#6350),5,226,2022-12-14 15:09:29-08:00,"['SnapshotUtil.java', 'TestChangelogTable.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkScanBuilder.java']"
Doc: Modify some options refer to Read-options in flink streaming read chapter (#6412),1,5,2022-12-15 09:04:07-08:00,['flink-getting-started.md']
Spark 3.2: Time range query of changelog tables (#6427),4,223,2022-12-15 10:52:44-08:00,"['TestChangelogTable.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkScanBuilder.java']"
Core: Unify fromJson(String) parsing (#6425),14,114,2022-12-15 14:57:20-08:00,"['MetadataUpdateParser.java', 'PartitionSpecParser.java', 'SchemaParser.java', 'SingleValueParser.java', 'SnapshotParser.java', 'SnapshotRefParser.java', 'TableMetadataParser.java', 'TableIdentifierParser.java', 'NameMappingParser.java', 'FileMetadataParser.java', 'OAuth2Util.java', 'UpdateRequirementParser.java', 'ErrorResponseParser.java', 'OAuthErrorResponseParser.java']"
Docs: Update table snapshot retention property descriptions to explicitly mention that it is a default for all the table's branches. (#6152),1,4,2022-12-15 16:37:27-08:00,['configuration.md']
"Python: Add pyparsing (#6439)

This one was missing and was being pulled in transitively I presume",2,409,2022-12-15 17:13:18-08:00,"['poetry.lock', 'pyproject.toml']"
Docs: Add an example of Spark SQL to set identifier fields (#6444),1,26,2022-12-16 12:34:31-08:00,['spark-ddl.md']
Build: Run weekly JMH Benchmarks & visualize results (#6441),4,87,2022-12-16 12:35:27-08:00,"['recurring-jmh-benchmarks.yml', 'build.gradle', 'gradle.properties', 'jmh.gradle']"
Python: Mock home folder when running `test_missing_uri` (#6445),3,28,2022-12-17 09:35:18+01:00,"['test_console.py', 'conftest.py', 'test_config.py']"
Build: Rename jmh-bechmarks.yml to jmh-benchmarks.yml (#6447),1,0,2022-12-18 20:01:37+01:00,['jmh-benchmarks.yml']
Build: Rename jmh-bechmarks.yml to jmh-benchmarks.yml (#6447),0,0,2022-12-18 20:02:02+01:00,[]
Python: Support for UUID (#6446),7,167,2022-12-18 12:10:47-08:00,"['decoder.py', 'reader.py', 'resolver.py', 'schema.py', 'schema_conversion.py', 'test_decoder.py', 'test_reader.py']"
Python: Reduce the use of mock objects (#6438),15,862,2022-12-18 14:26:26-08:00,"['file.py', 'reader.py', 'manifest.py', 'typedef.py', 'test_reader.py', 'test_base.py', 'test_hive.py', 'conftest.py', 'test_evaluator.py', 'test_expressions.py', 'test_visitors.py', 'test_fsspec.py', 'test_io.py', 'test_metadata.py', 'test_manifest.py']"
Core: Allow configuring metrics reporter impl via Catalog property (#6404),6,155,2022-12-18 15:23:50-08:00,"['LoggingMetricsReporter.java', 'CatalogProperties.java', 'CatalogUtil.java', 'RESTSessionCatalog.java', 'TestCatalogUtil.java', 'TestRESTCatalog.java']"
Docs: Fix truncate argument order (#6419),1,4,2022-12-18 15:37:18-08:00,['spark-ddl.md']
"Core, ORC, Spark: Remove deprecated functionality (#6274)",25,549,2022-12-18 15:44:44-08:00,"['revapi.yml', 'BaseReplacePartitions.java', 'BaseRewriteManifests.java', 'BaseTableScan.java', 'FastAppend.java', 'GenericManifestEntry.java', 'InheritableMetadataFactory.java', 'ManifestEntry.java', 'ManifestReader.java', 'ManifestWriter.java', 'MergingSnapshotProducer.java', 'SnapshotProducer.java', 'TableProperties.java', 'V1Metadata.java', 'V2Metadata.java', 'Deletes.java', 'Util.java', 'HTTPClientFactory.java', 'PartitionUtil.java', 'TableTestBase.java', 'TestManifestWriter.java', 'TestManifestWriterVersions.java', 'TestRewriteManifests.java', 'ORC.java', 'TestSparkParquetReader.java']"
ORC: Add FileIO support for readers and writers (#6293),6,492,2022-12-18 15:55:13-08:00,"['HadoopStreams.java', 'FileIOFSUtil.java', 'ORC.java', 'OrcFileAppender.java', 'TestORCFileIOProxies.java', 'TestOrcDataWriter.java']"
"Spark 3.1, 3.2: Backport #5860 to support Java 8 time classes (#6190)",4,231,2022-12-18 15:59:16-08:00,"['TestRewriteManifestsProcedure.java', 'SparkValueConverter.java', 'TestRewriteManifestsProcedure.java', 'SparkValueConverter.java']"
Docs: Remove parent-version-id from the view spec example (#6234),1,3,2022-12-18 16:01:28-08:00,['view-spec.md']
Docs: Update spec about statistics file snapshot id (#6267),1,2,2022-12-18 16:08:27-08:00,['spec.md']
Docs: Set the default Spark catalog (#6239),1,1,2022-12-18 16:09:24-08:00,['aws.md']
"Python: Add adlfs support (Azure DataLake FileSystem) (#6392)

* Python: Initial code for ADLFS support

* Python: Initial code for ADLFS support

* Python: fix types and lint errors

* Python: fixing lint errors

* Python: address PR feedback

* Python: address PR feedback about credentials

* Python: add adlfs references into documentation

* Python: fix linting

* Python: rebase master

* Python: update test case

Co-authored-by: Ryan Blue <blue@apache.org>",14,2744,2022-12-19 13:17:44+01:00,"['python-ci.yml', 'Makefile', 'docker-compose-azurite.yml', 'run-azurite.sh', 'run-minio.sh', 'configuration.md', 'contributing.md', 'index.md', 'poetry.lock', '__init__.py', 'fsspec.py', 'pyproject.toml', 'conftest.py', 'test_fsspec.py']"
Spark-3.3: Use table sort order when RewriteProcedure called without a specified Sort Order (#6296),2,44,2022-12-19 08:14:15-06:00,"['TestRewriteDataFilesProcedure.java', 'RewriteDataFilesProcedure.java']"
Core: Create and report metrics about Snapshots (#6246),24,1638,2022-12-19 08:33:08-08:00,"['MetricsReporter.java', 'BaseTable.java', 'BaseTransaction.java', 'SnapshotProducer.java', 'TableScanContext.java', 'Transactions.java', 'CommitMetrics.java', 'CommitMetricsResult.java', 'CommitMetricsResultParser.java', 'CommitReport.java', 'CommitReportParser.java', 'ScanReportParser.java', 'RESTSessionCatalog.java', 'ReportMetricsRequest.java', 'ReportMetricsRequestParser.java', 'Tasks.java', 'TestCommitReporting.java', 'TestScanPlanningAndReporting.java', 'TestCommitMetricsResultParser.java', 'TestCommitReportParser.java', 'TestRESTCatalog.java', 'TestReportMetricsRequestParser.java', 'TestTasks.java', 'rest-catalog-open-api.yaml']"
Core: Add flag to control sending metric reports via REST (#6436),1,18,2022-12-19 08:34:05-08:00,['RESTSessionCatalog.java']
Spark 3.2: Use table sort order with sort strategy by default (#6454),2,44,2022-12-19 08:56:51-08:00,"['TestRewriteDataFilesProcedure.java', 'RewriteDataFilesProcedure.java']"
"Core: Do not produce a partition summary for unpartitioned writes (#6411)

Previously, having an unpartitioned table would produce a `""partitions.""` entry in
the snapshot summary when the partition summary limit was configured",3,37,2022-12-19 09:37:13-08:00,"['SnapshotSummary.java', 'TestFastAppend.java', 'TestRowDelta.java']"
AWS: Use provided glue catalog id in defaultWarehouseLocation (#6223),2,28,2022-12-19 09:47:54-08:00,"['GlueCatalog.java', 'TestGlueCatalog.java']"
Spec: Clean up sentence (#6457),1,2,2022-12-19 20:56:38+01:00,['spec.md']
Spec: Fix small typo (#6459),1,2,2022-12-20 08:30:56+01:00,['spec.md']
Spec: Typo - Column position is actually pos (#6458),1,4,2022-12-20 09:06:55-06:00,['spec.md']
Core: Refactor ManifestListReadTask to avoid extra S3 calls (#6460),1,53,2022-12-20 08:52:02-08:00,['AllManifestsTable.java']
"Python: Check for NaNs when creating literal (#6462)

* Check for nans when creating literal

* Implement Fokko's suggestions",2,22,2022-12-20 20:04:30+01:00,"['literals.py', 'test_literals.py']"
Flink: Improve IcebergFilesCommitter logging (#6452),3,56,2022-12-21 10:18:51+01:00,"['IcebergFilesCommitter.java', 'IcebergFilesCommitter.java', 'IcebergFilesCommitter.java']"
"AWS, Core, Nessie: Expose catalog properties (#6471)",4,25,2022-12-21 14:26:37-08:00,"['DynamoDbCatalog.java', 'JdbcCatalog.java', 'EcsCatalog.java', 'NessieCatalog.java']"
Python: Convert UUID to binary(16) in PyArrow (#6468),1,16,2022-12-21 14:29:45-08:00,['pyarrow.py']
Python: Read a date as an int (#6478),7,777,2022-12-21 15:47:05-08:00,"['decoder.py', 'reader.py', 'typedef.py', 'test_decoder.py', 'test_reader.py', 'conftest.py', 'test_manifest.py']"
Nessie: Bump Nessie to 0.46.0 (#6473),1,2,2022-12-22 15:19:16+01:00,['versions.props']
Hive: Merge identical catch branch (#6477),1,11,2022-12-22 16:35:57-08:00,['ScriptRunner.java']
Core: Have single 'working' constructor in BaseTable (#6472),1,4,2022-12-22 16:43:22-08:00,['BaseTable.java']
Core: Fix method description for SnapshotUtil::oldestAncestorAfter (#6479),1,3,2022-12-23 09:10:47-08:00,['SnapshotUtil.java']
Spark 3.3: Support storage-partitioned joins (#6371),23,1785,2022-12-24 10:37:28-08:00,"['Partitioning.java', 'TestPartitioning.java', 'TestAlterTablePartitionFields.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestStoragePartitionedJoinsInRowLevelOperations.java', 'Spark3Util.java', 'SparkReadConf.java', 'SparkSQLProperties.java', 'SparkBatch.java', 'SparkBatchQueryScan.java', 'SparkChangelogScan.java', 'SparkCopyOnWriteScan.java', 'SparkInputPartition.java', 'SparkMicroBatchStream.java', 'SparkPartitioningAwareScan.java', 'SparkScan.java', 'SparkScanBuilder.java', 'SparkWrite.java', 'StructInternalRow.java', 'SparkTestBase.java', 'TestStoragePartitionedJoins.java']"
"Build: Bump coverage from 6.5.0 to 7.0.1 in /python (#6493)

Bumps [coverage](https://github.com/nedbat/coveragepy) from 6.5.0 to 7.0.1.
- [Release notes](https://github.com/nedbat/coveragepy/releases)
- [Changelog](https://github.com/nedbat/coveragepy/blob/master/CHANGES.rst)
- [Commits](https://github.com/nedbat/coveragepy/compare/6.5.0...7.0.1)

---
updated-dependencies:
- dependency-name: coverage
  dependency-type: direct:development
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,2427,2022-12-26 21:07:04+01:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump actions/stale from 6.0.1 to 7.0.0 (#6491)

Bumps [actions/stale](https://github.com/actions/stale) from 6.0.1 to 7.0.0.
- [Release notes](https://github.com/actions/stale/releases)
- [Changelog](https://github.com/actions/stale/blob/main/CHANGELOG.md)
- [Commits](https://github.com/actions/stale/compare/v6.0.1...v7.0.0)

---
updated-dependencies:
- dependency-name: actions/stale
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2022-12-26 21:07:32+01:00,['stale.yml']
"Build: Bump adlfs from 2022.10.0 to 2022.11.2 in /python (#6492)

Bumps [adlfs](https://github.com/dask/adlfs) from 2022.10.0 to 2022.11.2.
- [Release notes](https://github.com/dask/adlfs/releases)
- [Changelog](https://github.com/fsspec/adlfs/blob/main/CHANGELOG.md)
- [Commits](https://github.com/dask/adlfs/compare/2022.10.0...2022.11.2)

---
updated-dependencies:
- dependency-name: adlfs
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,12,2022-12-26 21:25:58+01:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump moto from 4.0.11 to 4.0.12 in /python (#6494)

Bumps [moto](https://github.com/spulec/moto) from 4.0.11 to 4.0.12.
- [Release notes](https://github.com/spulec/moto/releases)
- [Changelog](https://github.com/spulec/moto/blob/master/CHANGELOG.md)
- [Commits](https://github.com/spulec/moto/compare/4.0.11...4.0.12)

---
updated-dependencies:
- dependency-name: moto
  dependency-type: direct:development
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,13,2022-12-26 21:36:58+01:00,"['poetry.lock', 'pyproject.toml']"
Python: Add more tests (#6504),4,78,2022-12-30 10:49:06-08:00,"['typedef.py', 'test_typedef.py', 'test_types.py', 'test_deprecated.py']"
Python: Move adlfs import inline (#6497),1,6,2022-12-30 10:54:01-08:00,['fsspec.py']
Python (legacy): Fix CI (#6495),2,3,2022-12-30 10:55:09-08:00,"['python-legacy-ci.yml', 'setup.py']"
"Python: Projection by Field ID (#6437)

* Python: Projection by Field ID

instead of name

* Comments

* Add tests

* WIP

* Support nested structures

* Cleanup

* Add support for filtering on a column that's not projected

* Python: Add SchemaWithPartnerVisitor, update pyarrow reads. (#339)

* Comments

* Fix nested list projection.

* Update based on comments

* Remove duplicate fixtures

* Cleanup

Co-authored-by: Ryan Blue <blue@apache.org>",9,1298,2022-12-30 23:07:24+01:00,"['resolver.py', 'exceptions.py', 'visitors.py', 'pyarrow.py', 'schema.py', '__init__.py', 'test_decoder.py', 'test_resolver.py', 'test_pyarrow.py']"
"Build: Bump pre-commit from 2.20.0 to 2.21.0 in /python (#6509)

Bumps [pre-commit](https://github.com/pre-commit/pre-commit) from 2.20.0 to 2.21.0.
- [Release notes](https://github.com/pre-commit/pre-commit/releases)
- [Changelog](https://github.com/pre-commit/pre-commit/blob/main/CHANGELOG.md)
- [Commits](https://github.com/pre-commit/pre-commit/compare/v2.20.0...v2.21.0)

---
updated-dependencies:
- dependency-name: pre-commit
  dependency-type: direct:development
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,13,2023-01-02 09:11:40+01:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump pydantic from 1.10.2 to 1.10.4 in /python (#6507)

Bumps [pydantic](https://github.com/pydantic/pydantic) from 1.10.2 to 1.10.4.
- [Release notes](https://github.com/pydantic/pydantic/releases)
- [Changelog](https://github.com/pydantic/pydantic/blob/v1.10.4/HISTORY.md)
- [Commits](https://github.com/pydantic/pydantic/compare/v1.10.2...v1.10.4)

---
updated-dependencies:
- dependency-name: pydantic
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,80,2023-01-02 09:27:58+01:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump rich from 12.6.0 to 13.0.0 in /python (#6508)

Bumps [rich](https://github.com/Textualize/rich) from 12.6.0 to 13.0.0.
- [Release notes](https://github.com/Textualize/rich/releases)
- [Changelog](https://github.com/Textualize/rich/blob/master/CHANGELOG.md)
- [Commits](https://github.com/Textualize/rich/compare/v12.6.0...v13.0.0)

---
updated-dependencies:
- dependency-name: rich
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,12,2023-01-02 09:42:41+01:00,"['poetry.lock', 'pyproject.toml']"
Python: Refactor Avro read path to use a partner visitor (#6506),9,575,2023-01-02 10:18:21-08:00,"['file.py', 'reader.py', 'resolver.py', 'pyarrow.py', 'schema.py', 'typedef.py', 'types.py', 'test_reader.py', 'test_resolver.py']"
Python: Update license-checker (#6348),2,16,2023-01-03 10:19:15-08:00,"['.rat-excludes', 'check-license']"
Parquet: Fix ParquetDictionaryRowGroupFilter evaluating NaN (#6431),2,41,2023-01-03 10:46:13-08:00,"['ParquetDictionaryRowGroupFilter.java', 'TestDictionaryRowGroupFilter.java']"
Core: Fix drop table without purge for REST session catalog (#6511),2,27,2023-01-05 07:29:11+01:00,"['CatalogHandlers.java', 'CatalogTests.java']"
Python: Use PyArrow to buffer Avro reads (#6501),6,73,2023-01-05 11:57:12-08:00,"['file.py', '__init__.py', 'fsspec.py', 'pyarrow.py', 'test_reader.py', 'test_pyarrow.py']"
Spark 3.3: Introduce a changelog iterator (#6344),5,558,2023-01-05 12:09:06-08:00,"['ChangelogOperation.java', 'ChangelogIterator.java', 'SparkTestBase.java', 'SparkTestHelperBase.java', 'TestChangelogIterator.java']"
Spark 3.3: Discard filters that can be pushed down completely (#6524),5,649,2023-01-05 15:52:07-08:00,"['Spark3Util.java', 'SparkScanBuilder.java', 'SparkExpressionConverter.scala', 'SparkTestBase.java', 'TestFilterPushDown.java']"
AWS: Update import in GlueTableOperations (#6500),1,3,2023-01-06 09:58:42+01:00,['GlueTableOperations.java']
Flink: add fixed field type for DataGenerators test util (#6426),1,9,2023-01-06 09:27:23-08:00,['DataGenerators.java']
Flink: Enable multiple flink sinks for the same table in the same job (#6528),2,272,2023-01-06 19:08:19+01:00,"['IcebergFilesCommitter.java', 'TestIcebergFilesCommitter.java']"
Spark 3.2: Introduce the changelog iterator (#6530),4,554,2023-01-06 11:35:33-08:00,"['ChangelogIterator.java', 'SparkTestBase.java', 'SparkTestHelperBase.java', 'TestChangelogIterator.java']"
Flink: Backport: Enable multiple flink sinks for the same table in the same job (#6536),4,544,2023-01-06 12:20:14-08:00,"['IcebergFilesCommitter.java', 'TestIcebergFilesCommitter.java', 'IcebergFilesCommitter.java', 'TestIcebergFilesCommitter.java']"
Spark 3.3: Use regular planning for applicable row-level operations (#6534),7,151,2023-01-06 13:52:29-08:00,"['RewriteMergeIntoTable.scala', 'RowLevelCommandScanRelationPushDown.scala', 'SparkRowLevelOperationsTestBase.java', 'TestMerge.java', 'SparkCopyOnWriteOperation.java', 'SparkWrite.java', 'SparkWriteBuilder.java']"
"Spark: Extend Timeout During Partial Progress Rewrites (#6378)

In order to avoid timing out when writing large manifest files, we increase
the timeout allowed for the commit phase of partial progress based rewrites",1,27,2023-01-06 17:07:22-05:00,['RewriteDataFilesCommitManager.java']
Python: Add Docker suggestion for testing (#6521),2,65,2023-01-06 15:01:07-08:00,"['verify-release.md', 'test_pyarrow.py']"
Python: Re-enable mdformat (#6529),2,34,2023-01-06 15:01:27-08:00,"['.pre-commit-config.yaml', 'README.md']"
Python: Bump version to 0.3.0 (#6526),2,4,2023-01-06 15:01:47-08:00,"['__init__.py', 'pyproject.toml']"
Python: Fix type cast in console CLI (#6533),1,3,2023-01-06 15:02:27-08:00,['__init__.py']
Python: Fix the mdformat issue (#6540),1,5,2023-01-07 13:36:27-08:00,['verify-release.md']
"Build: Bump spotless-plugin-gradle from 6.12.0 to 6.12.1 (#6542)

Bumps [spotless-plugin-gradle](https://github.com/diffplug/spotless) from 6.12.0 to 6.12.1.
- [Release notes](https://github.com/diffplug/spotless/releases)
- [Changelog](https://github.com/diffplug/spotless/blob/main/CHANGES.md)
- [Commits](https://github.com/diffplug/spotless/compare/gradle/6.12.0...gradle/6.12.1)

---
updated-dependencies:
- dependency-name: com.diffplug.spotless:spotless-plugin-gradle
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-01-08 19:33:15+01:00,['build.gradle']
Python: Add announcement template (#6535),1,18,2023-01-08 10:44:38-08:00,['how-to-release.md']
"Python: Add typing-extensions as a pylint depdency (#6546)

It is an issue in a downstream dependency, and is currently being
fixed in pylint: https://github.com/PyCQA/pylint/pull/8030

Has been fixed in Astroid in:
https://github.com/PyCQA/astroid/pull/1944",1,1,2023-01-08 11:49:39-08:00,['.pre-commit-config.yaml']
"Build: Bump coverage from 7.0.1 to 7.0.4 in /python (#6545)

Bumps [coverage](https://github.com/nedbat/coveragepy) from 7.0.1 to 7.0.4.
- [Release notes](https://github.com/nedbat/coveragepy/releases)
- [Changelog](https://github.com/nedbat/coveragepy/blob/master/CHANGES.rst)
- [Commits](https://github.com/nedbat/coveragepy/compare/7.0.1...7.0.4)

---
updated-dependencies:
- dependency-name: coverage
  dependency-type: direct:development
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,108,2023-01-08 23:13:55+01:00,"['poetry.lock', 'pyproject.toml']"
"Flink: make two test util methods public from SimpleDataUtil (#6537)

* Flink: make two test util methods public from SimpleDataUtil

* fix style",3,15,2023-01-08 20:27:22-08:00,"['SimpleDataUtil.java', 'SimpleDataUtil.java', 'SimpleDataUtil.java']"
Build: Bump rich from 13.0.0 to 13.0.1 in /python (#6544),2,10,2023-01-09 06:45:36+01:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump moto from 4.0.12 to 4.0.13 in /python (#6543),2,10,2023-01-09 08:40:09+01:00,"['poetry.lock', 'pyproject.toml']"
"Python: Fix reading 0-bytes binary (#6532)

* Python: Fix reading 0-bytes binary

When a binary field would be zero bytes, we would still read
the stream, causing a EOFErrors:

```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Users/fokkodriesprong/Desktop/iceberg/python/pyiceberg/manifest.py"", line 139, in read_manifest_entry
    for record in reader:
  File ""/Users/fokkodriesprong/Desktop/iceberg/python/pyiceberg/avro/file.py"", line 194, in __next__
    return self.__next__()
  File ""/Users/fokkodriesprong/Desktop/iceberg/python/pyiceberg/avro/file.py"", line 186, in __next__
    return next(self.block)
  File ""/Users/fokkodriesprong/Desktop/iceberg/python/pyiceberg/avro/file.py"", line 113, in __next__
    return self.reader.read(self.block_decoder)
  File ""/Users/fokkodriesprong/Desktop/iceberg/python/pyiceberg/avro/reader.py"", line 260, in read
    struct.set(pos, field.read(decoder))  # later: pass reuse in here
  File ""/Users/fokkodriesprong/Desktop/iceberg/python/pyiceberg/avro/reader.py"", line 260, in read
    struct.set(pos, field.read(decoder))  # later: pass reuse in here
  File ""/Users/fokkodriesprong/Desktop/iceberg/python/pyiceberg/avro/reader.py"", line 233, in read
    return self.option.read(decoder)
  File ""/Users/fokkodriesprong/Desktop/iceberg/python/pyiceberg/avro/reader.py"", line 313, in read
    read_items[key] = self.value.read(decoder)
  File ""/Users/fokkodriesprong/Desktop/iceberg/python/pyiceberg/avro/reader.py"", line 200, in read
    return decoder.read_bytes()
  File ""/Users/fokkodriesprong/Desktop/iceberg/python/pyiceberg/avro/decoder.py"", line 118, in read_bytes
    return self.read(self.read_int())
  File ""/Users/fokkodriesprong/Desktop/iceberg/python/pyiceberg/avro/decoder.py"", line 54, in read
    raise EOFError
EOFError
```

Fixes #6435

* Revert

* Read actual bytes

* Black

* Optimize the code

* Remove benchmark

* To a literal",2,39,2023-01-09 08:55:37+01:00,"['decoder.py', 'test_decoder.py']"
Nessie: Bump Nessie to 0.46.3 (#6547),1,2,2023-01-09 13:02:14+01:00,['versions.props']
"Add InMemoryFileIO as a test helper class (#6538)

* Add InMemoryFileIO alongside existing InMemoryOutputFile and
InMemoryInputFile as a test helper class stitching the two together
and maintaining an in-memory listing of files. Add a dedicated
unittest for the new test helper.

* Update variable naming for consistency, refactor to avoid using containsKey

* Use Maps.newConcurrentMap instead of Maps.newHashMap",3,209,2023-01-09 13:27:10-08:00,"['InMemoryFileIO.java', 'InMemoryOutputFile.java', 'TestInMemoryFileIO.java']"
Core: Minor renaming to avoid engine specific naming in core (#6496),1,12,2023-01-10 07:07:51+01:00,['TestCatalogUtil.java']
Spark: Perform nullability check on metastore and spark instances before invoking stop (#5952),4,50,2023-01-10 07:17:30+01:00,"['SparkTestBase.java', 'SparkTestBase.java', 'SparkTestBase.java', 'SparkTestBase.java']"
API: Fix comment in SQLViewRepresentation (#6556),1,4,2023-01-10 08:26:18-08:00,['SQLViewRepresentation.java']
Spark 3.3: Automatically set Arrow properties for read performance (#6550),5,110,2023-01-10 13:42:53-08:00,"['build.gradle', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'VectorizedSparkParquetReaders.java', 'BaseBatchReader.java']"
Hive: Lock hardening (#6451),15,611,2023-01-11 07:43:07+01:00,"['configuration.md', 'HiveSchemaUtil.java', 'HiveTableOperations.java', 'HiveVersion.java', 'MetastoreUtil.java', 'TestHiveCommitLocks.java', 'TestHiveCommits.java', 'HiveIcebergInputFormat.java', 'IcebergObjectInspector.java', 'IcebergInputFormat.java', 'TestDeserializer.java', 'TestHiveIcebergStorageHandlerNoScan.java', 'TestHiveIcebergStorageHandlerWithEngine.java', 'TestTables.java', 'TestIcebergObjectInspector.java']"
"Python: Expression to disjunctive normal form (#6555)

* Python: Expression to disjunctive normal form

Adds a visitor to rewrite an expression to the DNF.

This is required for filtering data in Dask.

* Run rewriteNot before

* Move to the tuple approach

* Raise an exception",3,97,2023-01-11 12:07:30+01:00,"['__init__.py', 'visitors.py', 'test_visitors.py']"
Add supporting only s3 bucket name for S3URI (#6352),2,29,2023-01-11 08:53:22-08:00,"['S3URI.java', 'TestS3URI.java']"
"Spark: Add ""Iceberg"" prefix to SparkTable name string for SparkUI (#5629)",2,12,2023-01-11 10:38:43-08:00,"['SparkTable.java', 'TestSparkTable.java']"
"API, Core, Flink, Parquet, Spark: Use enhanced for loop (#6476)",29,124,2023-01-11 10:45:10-08:00,"['FixedReservoirHistogram.java', 'JavaHashes.java', 'ZOrderByteUtilsBenchmark.java', 'ParallelIterable.java', 'DeltaManifestsSerializer.java', 'IcebergEnumeratorStateSerializer.java', 'TestRowDataPartitionKey.java', 'ReaderUtil.java', 'DeltaManifestsSerializer.java', 'IcebergEnumeratorStateSerializer.java', 'TestRowDataPartitionKey.java', 'ReaderUtil.java', 'DeltaManifestsSerializer.java', 'IcebergEnumeratorStateSerializer.java', 'TestRowDataPartitionKey.java', 'ReaderUtil.java', 'ParquetValueReaders.java', 'SparkOrcWriter.java', 'TestSparkParquetReader.java', 'SparkOrcWriter.java', 'TestSparkParquetReader.java', 'SparkOrcWriter.java', 'NumDeletes.java', 'NumSplits.java', 'TestSparkParquetReader.java', 'SparkOrcWriter.java', 'NumDeletes.java', 'NumSplits.java', 'TestSparkParquetReader.java']"
"Flink: add support of writing Avro GenericRecord DataStream to Iceberg (#6557)

Flink: add support of writing Avro GenericRecord DataStream to Iceberg",7,597,2023-01-12 08:14:22-08:00,"['flink-getting-started.md', 'build.gradle', 'AvroGenericRecordToRowDataMapper.java', 'AvroGenericRecordConverterBase.java', 'DataGenerator.java', 'DataGenerators.java', 'TestAvroGenericRecordToRowDataMapper.java']"
"Core: Create commit groups in commit service offer in RewriteDataFilesCommitManager (#6539)

Allows for concurrent commits during Partial Progress enabled RewriteDataFiles Actions",1,66,2023-01-12 16:49:13-06:00,['RewriteDataFilesCommitManager.java']
Doc: Fix example view JSON format for view spec (#6558),1,10,2023-01-12 15:49:40-08:00,['view-spec.md']
"Flink: backport PR #6337, PR #6426, PR #6557 to Flink 1.14 and 1.15 for DateGenerators test utils and support of writing Avro GenericRecord to Iceberg (#6572)",12,2696,2023-01-13 08:57:36-08:00,"['build.gradle', 'AvroGenericRecordToRowDataMapper.java', 'AvroGenericRecordConverterBase.java', 'DataGenerator.java', 'DataGenerators.java', 'TestAvroGenericRecordToRowDataMapper.java', 'build.gradle', 'AvroGenericRecordToRowDataMapper.java', 'AvroGenericRecordConverterBase.java', 'DataGenerator.java', 'DataGenerators.java', 'TestAvroGenericRecordToRowDataMapper.java']"
"Flink: Change to oldestAncestorAfter (#6401)

* Flink: Change to oldestAncestorAfter",9,84,2023-01-13 09:09:59-08:00,"['ContinuousSplitPlannerImpl.java', 'TestContinuousSplitPlannerImpl.java', 'TestContinuousSplitPlannerImplStartStrategy.java', 'ContinuousSplitPlannerImpl.java', 'TestContinuousSplitPlannerImpl.java', 'TestContinuousSplitPlannerImplStartStrategy.java', 'ContinuousSplitPlannerImpl.java', 'TestContinuousSplitPlannerImpl.java', 'TestContinuousSplitPlannerImplStartStrategy.java']"
Flink: Support inspecting metadata table (#6222),16,2238,2023-01-13 09:12:25-08:00,"['ReassignDoc.java', 'TypeUtil.java', 'BaseFilesTable.java', 'flink-getting-started.md', 'FlinkCatalog.java', 'FlinkSchemaUtil.java', 'StructRowData.java', 'DataTaskReader.java', 'FlinkInputFormat.java', 'IcebergSource.java', 'MetaDataReaderFunction.java', 'DataGenerators.java', 'TestHelpers.java', 'TestStructRowData.java', 'TestFlinkMetaDataTable.java', 'TestMetadataTableReadableMetrics.java']"
Parquet: Fix incorrect skipping of RowGroups with NaNs (#6517),3,163,2023-01-13 09:58:26-08:00,"['TestMetricsRowGroupFilter.java', 'ParquetMetricsRowGroupFilter.java', 'TestCDHParquetStatistics.java']"
"Core: View history entry core implementation (#6565)

Co-authored-by: John Zhuge <jzhuge@apache.org>",3,138,2023-01-13 17:22:06-08:00,"['ViewHistoryEntry.java', 'ViewHistoryEntryParser.java', 'TestViewHistoryEntryParser.java']"
Docs: Add information on how to read from branches and tags in Spark query docs (#6573),1,18,2023-01-13 17:33:14-08:00,['spark-queries.md']
"Add new SnowflakeCatalog implementation to enable directly using Snowflake-managed Iceberg tables (#6428)

* Initial read-only Snowflake Catalog implementation by @sfc-gh-mparmar (#1)

Initial read-only Snowflake Catalog implementation built on top of the Snowflake JDBC driver,
providing support for basic listing of namespaces, listing of tables, and loading/reads of tables.

Auth options are passthrough to the JDBC driver.

Co-authored-by: Maninder Parmar <maninder.parmar@snowflake.com>
Co-authored-by: Maninder Parmar <maninder.parmar+oss@snowflake.com>
Co-authored-by: Dennis Huo <dennis.huo+oss@snowflake.com>

* Add JdbcSnowflakeClientTest using mocks (#2)

Add JdbcSnowflakeClientTest using mocks; provides full coverage of JdbcSnowflakeClient
and entities' ResultSetHandler logic.

Also update target Spark runtime versions to be included.

* Add test { useJUnitPlatform() } tuple to iceberg-snowflake for
consistency and future interoperability with inheriting from abstact
unittest base classes.

* Extract versions into versions.props per PR review

* Misc test-related refactors per review suggestions
-Convert unittests to all use assertj/Assertions for ""fluent assertions""
-Refactor test injection into overloaded initialize() method
-Add test cases for close() propagation
-Use CloseableGroup.

* Fix unsupported behaviors of loadNamedpaceMetadata and defaultWarehouseLocation

* Move TableIdentifier checks out of newTableOps into the
SnowflakTableOperations class itself, add test case.

* Refactor out any Namespace-related business logic from the lower
SnowflakeClient/JdbcSnowflakeClient layers and merge SnowflakeTable
and SnowflakeSchema into a single SnowflakeIdentifier that also
encompasses ROOT and DATABASE level identifiers.

A SnowflakeIdentifier thus functions like a type-checked/constrained
Iceberg TableIdentifier, and eliminates any tight coupling between
a SnowflakeClient and Catalog business logic.

Parsing of Namespace numerical levels into a SnowflakeIdentifier
is now fully encapsulated in NamespaceHelpers so that callsites
don't duplicate namespace-handling/validation logic.

* Finish migrating JdbcSnowflakeClientTest off any usage of org.junit.Assert
in favor of assertj's Assertions.

* Style refactorings from review comments, expanded and moved InMemoryFileIO into core
with its own unittest.

* Fix behavior of getNamespaceMetadata to throw when the namespace doesn't
exist.

Refactor for naming conventions and consolidating identifier
handling into NamespaceHandlers.

Make FileIO instantiated fresh for each newTableOps call.

* Move private constructor to top, add assertion to test case.

* Define minimal ResultSetParser/QueryHarness classes to fully replace
any use of commons-dbutils; refactor ResultSet handling fully into
JdbcSnowflakeClient.java.

* Update snowflake/src/main/java/org/apache/iceberg/snowflake/SnowflakeTableOperations.java

Co-authored-by: Eduard Tudenhfner <etudenhoefner@gmail.com>

* Refactor style suggestions; remove debug-level logging, arguments in exceptions,
private members if not accessed outside, move precondition checks, add test for
NamespaceHelpers.

* Fix precondition messages, remove getConf()

* Clean up varargs.

* Make data members final, include rawJsonVal in toString for debuggability.

* Combine some small test cases into roundtrip test cases, misc cleanup

* Add comment for why a factory class is exposed for testing purposes.

Co-authored-by: Dennis Huo <dennis.huo@snowflake.com>
Co-authored-by: Maninder Parmar <maninder.parmar@snowflake.com>
Co-authored-by: Maninder Parmar <maninder.parmar+oss@snowflake.com>
Co-authored-by: Eduard Tudenhfner <etudenhoefner@gmail.com>",19,2419,2023-01-13 19:57:46-08:00,"['labeler.yml', 'build.gradle', 'JdbcClientPool.java', 'settings.gradle', 'JdbcSnowflakeClient.java', 'NamespaceHelpers.java', 'SnowflakeCatalog.java', 'SnowflakeClient.java', 'SnowflakeIdentifier.java', 'SnowflakeTableMetadata.java', 'SnowflakeTableOperations.java', 'FakeSnowflakeClient.java', 'JdbcSnowflakeClientTest.java', 'NamespaceHelpersTest.java', 'SnowflakeCatalogTest.java', 'build.gradle', 'build.gradle', 'build.gradle', 'versions.props']"
"Python: Refactor loading manifests (#6525)

* Add ManifestFile StructProtocol implementation.

* Python: Make it work

* Python: Refactor the reading of the manifest

* Comments

* Fix named record

* Revert some stuff

* Extend the test

* Always pass in the struct

* Refactor the Records into a single one

- And remove Pydantic as a base class

* Comments

* Cleanup

* Revert some changes and cleanup

* Make CI happy

* Fix passing in the struct

* Its easier to ask for forgiveness than permission

* Add some more tests

* Python: Minor changes to Record to support old test cases. (#351)

Co-authored-by: Ryan Blue <blue@apache.org>",29,2117,2023-01-14 13:01:48+01:00,"['file.py', 'reader.py', 'resolver.py', 'rest.py', 'output.py', 'manifest.py', 'partitioning.py', 'schema.py', '__init__.py', 'metadata.py', 'refs.py', 'snapshots.py', 'sorting.py', 'transforms.py', 'typedef.py', 'types.py', 'iceberg_base_model.py', 'test_file.py', 'test_reader.py', 'test_resolver.py', 'test_evaluator.py', 'test_expressions.py', 'test_visitors.py', 'test_snapshots.py', 'test_schema.py', 'test_transforms.py', 'test_typedef.py', 'test_types.py', 'test_manifest.py']"
Build: Update ORC to 1.8.2 (#6585),1,2,2023-01-14 13:24:42+01:00,['versions.props']
Python: Raise exception on deletes (#6574),2,45,2023-01-14 12:08:22-08:00,"['__init__.py', 'test_init.py']"
Flink: Refactor sink tests to use HadoopCatalogResource (#6583),4,167,2023-01-15 10:47:26+01:00,"['HadoopCatalogResource.java', 'HadoopTableResource.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkV2.java']"
Docs: Fix minor typo in time travel dataframe section (#6601),1,2,2023-01-16 08:35:05+01:00,['spark-queries.md']
Build: Bump requests from 2.28.1 to 2.28.2 in /python (#6597),2,2408,2023-01-16 08:38:02+01:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump coverage from 7.0.4 to 7.0.5 in /python (#6596),2,108,2023-01-16 09:16:20+01:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump spotless-plugin-gradle from 6.12.1 to 6.13.0 (#6592),1,2,2023-01-16 09:34:46+01:00,['build.gradle']
Build: Bump pytest from 7.2.0 to 7.2.1 in /python (#6595),2,10,2023-01-16 09:35:04+01:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump rich from 13.0.1 to 13.1.0 in /python (#6594),2,10,2023-01-16 11:40:37+01:00,"['poetry.lock', 'pyproject.toml']"
Core: Align commit metric name (#6563),3,6,2023-01-16 09:13:14-08:00,"['CommitMetricsResult.java', 'TestCommitMetricsResultParser.java', 'TestCommitReportParser.java']"
Flink: Backport: Improve unit tests for sink (#6603),5,58,2023-01-16 20:06:12+01:00,"['SimpleDataUtil.java', 'TestFlinkManifest.java', 'TestIcebergFilesCommitter.java', 'TestIcebergStreamWriter.java', 'TestTaskWriters.java']"
Core: Remove TableOperations from metadata tables. (#6357),37,1038,2023-01-16 13:34:04-08:00,"['revapi.yml', 'AllDataFilesTable.java', 'AllDeleteFilesTable.java', 'AllEntriesTable.java', 'AllFilesTable.java', 'AllManifestsTable.java', 'BaseAllMetadataTableScan.java', 'BaseEntriesTable.java', 'BaseFilesTable.java', 'BaseIncrementalAppendScan.java', 'BaseIncrementalChangelogScan.java', 'BaseIncrementalScan.java', 'BaseMetadataTable.java', 'BaseMetadataTableScan.java', 'BaseReadOnlyTable.java', 'BaseScan.java', 'BaseTable.java', 'BaseTableScan.java', 'DataFilesTable.java', 'DataTableScan.java', 'DeleteFilesTable.java', 'FilesTable.java', 'HistoryTable.java', 'IncrementalDataTableScan.java', 'ManifestEntriesTable.java', 'ManifestsTable.java', 'MetadataLogEntriesTable.java', 'MetadataTableUtils.java', 'PartitionsTable.java', 'RefsTable.java', 'SnapshotsTable.java', 'StaticTableScan.java', 'TestBatchScans.java', 'TestEntriesMetadataTable.java', 'TestMetadataTableFilters.java', 'TestMetadataTableScans.java', 'TestMetadataTableScansWithPartitionEvolution.java']"
Build: Bump moto from 4.0.13 to 4.1.0 in /python (#6593),2,24,2023-01-17 07:26:56+01:00,"['poetry.lock', 'pyproject.toml']"
Flink: Backport: Flink: Refactor sink tests to use HadoopCatalogResource (#6602),8,339,2023-01-17 07:39:33+01:00,"['HadoopCatalogResource.java', 'HadoopTableResource.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkV2.java', 'HadoopCatalogResource.java', 'HadoopTableResource.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkV2.java']"
"Core: Fix BaseMetastoreCatalog#registerTable to return full table name (#6589)

* Core: Fix BaseMetastoreCatalog#registerTable to return full table name

registerTable should return full table name, just like how loadTable and
create API returns

* Empty",2,7,2023-01-17 08:10:53-08:00,"['BaseMetastoreCatalog.java', 'TestJdbcCatalog.java']"
Core: Improve token exchange handling when token is expired (#6489),4,590,2023-01-17 08:47:11-08:00,"['RESTSessionCatalog.java', 'OAuth2Util.java', 'TestRESTCatalog.java', 'TestOAuth2Util.java']"
Spark: Add the query ID to file names (#6569),6,97,2023-01-17 08:49:24-08:00,"['OutputFileFactory.java', 'TestOutputFileFactory.java', 'SparkPositionDeltaWrite.java', 'SparkWrite.java', 'SparkPositionDeltaWrite.java', 'SparkWrite.java']"
Flink: Port Support inspecting metadata table to Flink 1.14 & 1.15 (#6610),24,3790,2023-01-17 08:54:35-08:00,"['FlinkCatalog.java', 'FlinkSchemaUtil.java', 'StructRowData.java', 'DataTaskReader.java', 'FlinkInputFormat.java', 'IcebergSource.java', 'MetaDataReaderFunction.java', 'DataGenerators.java', 'TestHelpers.java', 'TestStructRowData.java', 'TestFlinkMetaDataTable.java', 'TestMetadataTableReadableMetrics.java', 'FlinkCatalog.java', 'FlinkSchemaUtil.java', 'StructRowData.java', 'DataTaskReader.java', 'FlinkInputFormat.java', 'IcebergSource.java', 'MetaDataReaderFunction.java', 'DataGenerators.java', 'TestHelpers.java', 'TestStructRowData.java', 'TestFlinkMetaDataTable.java', 'TestMetadataTableReadableMetrics.java']"
Core: Support access to response headers from POST requests (#6578),3,87,2023-01-18 08:34:02-08:00,"['HTTPClient.java', 'RESTClient.java', 'TestHTTPClient.java']"
"Hive: Make UGI current user the owner of new Hive objects (#6324)

Co-authored-by: Haizhou Zhao <haizhou_zhao@apple.com>",4,105,2023-01-18 09:19:07-08:00,"['HiveCatalog.java', 'HiveHadoopUtil.java', 'HiveTableOperations.java', 'TestHiveCatalog.java']"
API: Rename query to sql on SQLViewRepresentation API (#6618),1,2,2023-01-18 13:55:32-08:00,['SQLViewRepresentation.java']
Spark 3.3: support version travel by reference name (#6575),2,100,2023-01-18 15:50:07-08:00,"['SparkCatalog.java', 'TestSelect.java']"
Core: Make it explicit that metrics reporter is required (#6474),1,2,2023-01-19 08:31:17-08:00,['BaseTable.java']
Core: Add test for token expiration during refresh (#6609),3,176,2023-01-19 08:47:50-08:00,"['OAuth2Util.java', 'TestRESTCatalog.java', 'AuthSessionUtil.java']"
Nessie: Bump to 0.47.0 (#6628),1,2,2023-01-20 15:07:40+01:00,['versions.props']
Flink: support reading as Avro GenericRecord for FLIP-27 IcebergSource (#6584),9,659,2023-01-20 08:29:15-08:00,"['flink-getting-started.md', 'AvroGenericRecordFileScanTaskReader.java', 'RowDataToAvroGenericRecordConverter.java', 'AvroGenericRecordReaderFunction.java', 'ListBatchRecords.java', 'ListDataIteratorBatcher.java', 'DataGenerators.java', 'TestRowDataToAvroGenericRecordConverter.java', 'TestIcebergSourceBoundedGenericRecord.java']"
Docs: Update spark SQL examples for time travel to branches and tags (#6627),1,20,2023-01-20 10:32:00-08:00,['spark-queries.md']
AWS: make warehouse path optional for read only catalog use cases (#6586),3,75,2023-01-20 10:33:13-08:00,"['TestGlueCatalogTable.java', 'GlueCatalog.java', 'TestGlueCatalog.java']"
Flink: backport PR #6584 to 1.14 and 1.15 for Avro GenericRecord in FLIP-27 source (#6631),17,1261,2023-01-20 14:06:01-08:00,"['AvroGenericRecordFileScanTaskReader.java', 'RowDataToAvroGenericRecordConverter.java', 'AvroGenericRecordReaderFunction.java', 'ListBatchRecords.java', 'ListDataIteratorBatcher.java', 'DataGenerators.java', 'TestIcebergSourceBoundedGenericRecord.java', 'TestRowDataToAvroGenericRecordConverter.java', 'AvroGenericRecordFileScanTaskReader.java', 'RowDataToAvroGenericRecordConverter.java', 'AvroGenericRecordReaderFunction.java', 'ListBatchRecords.java', 'ListDataIteratorBatcher.java', 'DataGenerators.java', 'TestIcebergSourceBoundedGenericRecord.java', 'TestRowDataToAvroGenericRecordConverter.java', 'TestRowDataToAvroGenericRecordConverter.java']"
"Spark: SQL Extensions for create branch (#6617)

Co-authored-by: Amogh Jahagirdar <jahamogh@amazon.com>
Co-authored-by: chidayong <247070443@qq.com>",7,391,2023-01-21 00:28:23-08:00,"['IcebergSqlExtensions.g4', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'CreateBranch.scala', 'CreateBranchExec.scala', 'ExtendedDataSourceV2Strategy.scala', 'TestCreateBranch.java']"
"Python: Fix `test_missing_uri` unit test (#6607)

* Fix test_missing_uri unit test

* Fix lint error",1,16,2023-01-21 20:53:20+01:00,['test_console.py']
"Build: Bump rich from 13.1.0 to 13.2.0 in /python (#6641)

Bumps [rich](https://github.com/Textualize/rich) from 13.1.0 to 13.2.0.
- [Release notes](https://github.com/Textualize/rich/releases)
- [Changelog](https://github.com/Textualize/rich/blob/master/CHANGELOG.md)
- [Commits](https://github.com/Textualize/rich/compare/v13.1.0...v13.2.0)

---
updated-dependencies:
- dependency-name: rich
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,64,2023-01-22 10:51:53+01:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump pandas from 1.5.2 to 1.5.3 in /python (#6639)

Bumps [pandas](https://github.com/pandas-dev/pandas) from 1.5.2 to 1.5.3.
- [Release notes](https://github.com/pandas-dev/pandas/releases)
- [Changelog](https://github.com/pandas-dev/pandas/blob/main/RELEASE.md)
- [Commits](https://github.com/pandas-dev/pandas/compare/v1.5.2...v1.5.3)

---
updated-dependencies:
- dependency-name: pandas
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,60,2023-01-22 11:09:50+01:00,"['poetry.lock', 'pyproject.toml']"
"Flink: add table setter to FLIP-27 IcebergSource#Builder. (#6635)

This is to avoid double loading if table is already loaded before the builder. This is also the same pattern as the pre FLIP-27 FlinkSource#Builder.",6,72,2023-01-22 21:15:50-08:00,"['IcebergSource.java', 'TestIcebergSourceBounded.java', 'IcebergSource.java', 'TestIcebergSourceBounded.java', 'IcebergSource.java', 'TestIcebergSourceBounded.java']"
"Build: Fix minor error-prone warnings (#6629)

* Build: Fix minor error-prone warnings

* Enforce StringSplitter to avoid future warnings",3,16,2023-01-23 11:35:57+01:00,"['baseline.gradle', 'OAuth2Util.java', 'HiveVersion.java']"
"Core, API: Support branch writes in more operations  (#5234)",13,2147,2023-01-23 07:48:25-08:00,"['revapi.yml', 'BaseOverwriteFiles.java', 'BaseReplacePartitions.java', 'BaseRewriteFiles.java', 'BaseRowDelta.java', 'MergingSnapshotProducer.java', 'SnapshotProducer.java', 'TableTestBase.java', 'TestOverwrite.java', 'TestOverwriteWithValidation.java', 'TestReplacePartitions.java', 'TestRewriteFiles.java', 'TestRowDelta.java']"
Core: Allow customizing OAuth scope (#6616),3,157,2023-01-23 09:48:48-08:00,"['RESTSessionCatalog.java', 'OAuth2Util.java', 'TestRESTCatalog.java']"
"API, Core: Allow using SnapshotManager in Transaction (#6074)

Currently, SnapshotManager encapsulates its own BaseTransaction object
and there is no way to expose it opposed to for example ExpireSnapshots
that can be created through the Transaction API. As a result the
operations in SnapshotManager can't run in the same transaction with
the operations in e.g. BaseTransaction.",5,116,2023-01-23 10:35:37-08:00,"['Transaction.java', 'BaseTransaction.java', 'CommitCallbackTransaction.java', 'SnapshotManager.java', 'TestSnapshotManager.java']"
Core: Fix for deleting files when commiting transactions with multiple branches (#6634),1,49,2023-01-23 11:23:21-08:00,['BaseTransaction.java']
Spark 3.3: Fix predicate pushdown for copy-on-write MERGE commands (#6633),4,135,2023-01-23 19:31:59-08:00,"['RewriteMergeIntoTable.scala', 'RowLevelCommandScanRelationPushDown.scala', 'SparkRowLevelOperationsTestBase.java', 'TestMerge.java']"
AWS: Print logs whether Glue optimistic locking is used or not (#6358),1,6,2023-01-24 07:39:22-08:00,['GlueCatalog.java']
"AWS, Docs: Add AWS Glue in Run Iceberg on AWS section (#6623)",1,7,2023-01-24 07:42:44-08:00,['aws.md']
Python: Check if optional file kv metadata is None before reading Iceberg Schema (#6654),1,4,2023-01-24 19:52:37+01:00,['pyarrow.py']
Python: Bump s3fs (#6643),2,2411,2023-01-24 12:27:36-08:00,"['poetry.lock', 'pyproject.toml']"
"Python: Bump pylint (#6580)

And remove the temporary hack",1,3,2023-01-24 12:28:14-08:00,['.pre-commit-config.yaml']
Core: Improvements around Token Refresh time expiration (#6562),2,118,2023-01-24 13:33:08-08:00,"['RESTSessionCatalog.java', 'OAuth2Util.java']"
"API, Core: Add position deletes metadata table (#6365)",20,1154,2023-01-24 13:54:52-08:00,"['revapi.yml', 'ContentScanTask.java', 'BaseMetadataTable.java', 'BasePositionDeletesScanTask.java', 'BaseScan.java', 'BaseTableScan.java', 'MetadataColumns.java', 'MetadataTableType.java', 'MetadataTableUtils.java', 'PositionDeletesScanTask.java', 'PositionDeletesTable.java', 'SerializableTable.java', 'SnapshotScan.java', 'SplitPositionDeletesScanTask.java', 'MetadataTableScanTestBase.java', 'TestMetadataTableScans.java', 'TestMetadataTableScansWithPartitionEvolution.java', 'TestSplitPlanning.java', 'TestStaticTable.java', 'TestTableSerialization.java']"
"Python: Parallelize IO (#6645)

* Python: Parallelize IO

Alternative for https://github.com/apache/iceberg/pull/6590

This uses the ThreadPool approach instead of ThreadPoolExecutor.

The ThreadPoolExecutor is more flexible and works well
with heterogeneous tasks. This allows the user to handle
exceptions per task and able to cancel individual tasks.
But the ThreadPoolExecutor also has some limitation
such as not able to forcefully terminate all the tasks.

For reading tasks I think the ThreadPool might be more appriopriate,
but for writing the ThreadPoolExecutor might be more applicable.

A very nice writeup of the differences is available in this blog:
https://superfastpython.com/threadpool-vs-threadpoolexecutor/

Before:
```
  python git:(fd-threadpool) time python3 /tmp/test.py
python3 /tmp/test.py  3.45s user 2.84s system 2% cpu 3:34.19 total
```

After:
```
  python git:(fd-threadpool)  time python3 /tmp/test.py
python3 /tmp/test.py  3.13s user 2.83s system 19% cpu 31.369 total
  python git:(fd-threadpool)  time python3 /tmp/test.py
python3 /tmp/test.py  2.94s user 3.08s system 18% cpu 32.538 total
  python git:(fd-threadpool)  time python3 /tmp/test.py
python3 /tmp/test.py  2.84s user 3.14s system 20% cpu 29.033 total
```

Longlining the requests from EU to the USA, so this might impact
the results a bit, but makes IO more dominant.

* Set read options",3,127,2023-01-24 23:31:48+01:00,"['literals.py', 'pyarrow.py', '__init__.py']"
"Fix OpenAPI types `CreateNamespaceRequest` + `GetNamespaceResponse` (#6663)

* Fix OpenAPI types `CreateNamespaceRequest` + `GetNamespaceResponse`

Both types define some map of string to string as their `properties` property. The current spec would generate Java code like `private @Valid Object properties = { };` for these fields (using the common OpenAPI Generators), which leads to compile errors.
I suspect, both are missing this:
```
          additionalProperties:
            type: string
```

* make ns updates maps actually maps",1,8,2023-01-25 08:52:45-08:00,['rest-catalog-open-api.yaml']
Spec: Fix OpenAPI types for CatalogConfig (ConfigResponse) (#6665),1,4,2023-01-25 09:12:02-08:00,['rest-catalog-open-api.yaml']
"Update REST Spec to include warehouse param (#6666)

* Update REST Spec to include warehouse param

* Reorder properties to match existing document",1,7,2023-01-25 09:52:28-08:00,['rest-catalog-open-api.yaml']
Core: Avoid creating new metadata file on registerTable (#6591),12,87,2023-01-25 11:11:09-08:00,"['TestDynamoDbCatalog.java', 'TestGlueCatalogTable.java', 'DynamoDbTableOperations.java', 'GlueTableOperations.java', 'BaseMetastoreTableOperations.java', 'JdbcTableOperations.java', 'TestJdbcCatalog.java', 'EcsTableOperations.java', 'TestEcsCatalog.java', 'HiveTableOperations.java', 'TestHiveCatalog.java', 'NessieTableOperations.java']"
Spark 3.2: Automatically set Arrow properties for read performance (#6671),5,110,2023-01-26 10:05:43+01:00,"['build.gradle', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'VectorizedSparkParquetReaders.java', 'BaseBatchReader.java']"
Core: Fix API breakages around scanMetrics() (#6664),2,36,2023-01-26 09:51:50-08:00,"['revapi.yml', 'SnapshotScan.java']"
Python: Add visitor to DNF expr into Dask/PyArrow format (#6566),2,100,2023-01-27 15:08:05-08:00,"['visitors.py', 'test_visitors.py']"
"Build: Bump pre-commit from 2.21.0 to 3.0.1 in /python (#6688)

Bumps [pre-commit](https://github.com/pre-commit/pre-commit) from 2.21.0 to 3.0.1.
- [Release notes](https://github.com/pre-commit/pre-commit/releases)
- [Changelog](https://github.com/pre-commit/pre-commit/blob/main/CHANGELOG.md)
- [Commits](https://github.com/pre-commit/pre-commit/compare/v2.21.0...v3.0.1)

---
updated-dependencies:
- dependency-name: pre-commit
  dependency-type: direct:development
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,2466,2023-01-30 05:49:35+01:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump fastavro from 1.7.0 to 1.7.1 in /python (#6689)

Bumps [fastavro](https://github.com/fastavro/fastavro) from 1.7.0 to 1.7.1.
- [Release notes](https://github.com/fastavro/fastavro/releases)
- [Changelog](https://github.com/fastavro/fastavro/blob/master/ChangeLog)
- [Commits](https://github.com/fastavro/fastavro/compare/1.7.0...1.7.1)

---
updated-dependencies:
- dependency-name: fastavro
  dependency-type: direct:development
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,48,2023-01-30 05:59:40+01:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump rich from 13.2.0 to 13.3.1 in /python (#6690),2,14,2023-01-30 07:31:24+01:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump coverage from 7.0.5 to 7.1.0 in /python (#6691),2,108,2023-01-30 07:42:52+01:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump pyarrow from 10.0.1 to 11.0.0 in /python (#6692)

Bumps [pyarrow](https://github.com/apache/arrow) from 10.0.1 to 11.0.0.
- [Release notes](https://github.com/apache/arrow/releases)
- [Commits](https://github.com/apache/arrow/compare/go/v10.0.1...apache-arrow-11.0.0)

---
updated-dependencies:
- dependency-name: pyarrow
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,56,2023-01-30 15:00:46+01:00,"['poetry.lock', 'pyproject.toml']"
"Nessie: Use default namespace location if exists (#6676)

In order to mimic HMS behavior, if the namespace of nessie have a
location then the table should be store into this location.",2,31,2023-01-30 15:09:07+01:00,"['NessieCatalog.java', 'TestNamespace.java']"
"Nessie: Update outdated javadoc (#6678)

* Nessie: Update the incorrect javadoc

Nessie catalog supports namespace properties. Test cases can be found [here](https://github.com/apache/iceberg/blob/038091f6b65bf63d028af175dbbbc7285815d6be/nessie/src/test/java/org/apache/iceberg/nessie/TestNamespace.java#L111-L146).

But the  javadoc of `loadNamespaceMetadata` is incorrect (maybe not updated when Nessie supported namespace properties)

* self review

* address comments",1,5,2023-01-30 15:11:12+01:00,['NessieCatalog.java']
"Nessie: Avoid usage of deprecated APIs in test (#6656)

* Nessie: Avoid usage of deprecated APIs in test

* Address comments",3,52,2023-01-30 15:13:19+01:00,"['BaseTestIceberg.java', 'TestNessieCatalog.java', 'TestNessieTable.java']"
"Core: DeleteWithFilter fails on HashCode Collision (#6680)

Failure to copy partition data structs when evaluating residuals caused hashcode collisions to incorrect delete or not delete files. To fix this PartitionData is copied before being place inside the Residual Evaluator map.",2,86,2023-01-30 10:13:49-06:00,"['ManifestFilterManager.java', 'TestDeleteFiles.java']"
Python: Update pyproject.toml to include dev folder (#6705),1,4,2023-01-31 09:36:02+01:00,['pyproject.toml']
"Docs: Add UPDATE and MERGE distribution mode table props (#6683)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",1,2,2023-01-31 11:32:47-08:00,['configuration.md']
Python: Optimize PyArrow reads (#6673),3,108,2023-01-31 11:33:58-08:00,"['visitors.py', 'pyarrow.py', 'schema.py']"
Core: Mark refreshed auth fields volatile (#6707),1,8,2023-01-31 11:35:18-08:00,['OAuth2Util.java']
Infra: Pin openapi-spec-validator version (#6722),1,2,2023-02-01 09:12:21-08:00,['open-api.yml']
API: Fix Transform backward compatibility in PartitionSpec (#6653),2,47,2023-02-02 08:45:34-08:00,"['BaseUpdatePartitionSpec.java', 'TestTableUpdatePartitionSpec.java']"
"Spark 3.3: REPLACE BRANCH SQL implementation (#6638)

Co-authored-by: liliwei hililiwei@gmail.com
Co-authored-by: xuwei xuwei132@huawei.com
Co-authored-by: chidayong chidayong2@h-partners.com",10,598,2023-02-02 15:08:36-08:00,"['IcebergSqlExtensions.g4', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'BranchOptions.scala', 'CreateOrReplaceBranch.scala', 'CreateBranchExec.scala', 'CreateOrReplaceBranchExec.scala', 'ExtendedDataSourceV2Strategy.scala', 'TestCreateBranch.java', 'TestReplaceBranch.java']"
Spark 3.3: Handle no-op for rewrite manifests procedure/action (#6695),3,50,2023-02-02 16:23:54-08:00,"['TestRewriteManifestsProcedure.java', 'RewriteManifestsSparkAction.java', 'TestRewriteManifestsAction.java']"
"Hive: Refactor commit lock mechanism from HiveTableOperations (#6648)

Co-authored-by: Adam Szita <40628386+szlta@users.noreply.github.com>
Co-authored-by: Peter Vary <peter_vary4@apple.com>",7,1091,2023-02-03 14:12:18+01:00,"['CommitFailedException.java', 'HiveLock.java', 'HiveTableOperations.java', 'LockException.java', 'MetastoreLock.java', 'TestHiveCommitLocks.java', 'TestHiveCommits.java']"
"AWS,Core: Add S3 REST Signer client + REST Spec (#6169)

* AWS,Core: Add S3 Signer client + REST Spec

This introduces an S3 REST signer client and defines a REST spec (`s3-signer-open-api.yml`) for a server implementation. Below is a high-level overview of the introduced changes:

* the main logic and functionality resides in the `S3V4RestSignerClient` class
  * it uses the same **credential/token** exchange flow as we have in `RESTSessionCatalog` and also uses the same token refresh mechanism. In order to achieve that, a few refactorings have been done in `RESTSessionCatalog` / `OAuth2Util`.
  * the default endpoint the signer connects to is `v1/aws/s3/sign` but can be customized.
  * The server decides which headers to sign and can indicate to the `S3V4RestSignerClient` whether a response with signed headers can be cached by sending a `Cache-Control: private` header
* `AwsProperties` introduce `s3.signer.class` that allows to dynamically load an S3 Signer implementation and apply it when creating an S3 client. This can be any Signer class that implements `software.amazon.awssdk.core.signer.Signer`.
* `S3SignRequest` and `S3SignResponse` classes define how the request and response looks like
* an `S3ObjectMapper` class has been introduced that is similar to `RESTObjectMapper` but only contains what's necessary for the S3 REST signer, which are the request/response classes with OAuth-related classes and error handling.
* Testing is done by using `MinioContainer` (`TestContainers` + `MinIO`) in `TestS3RestSigner`
  * The `S3SignerServlet` defines the minimum amount of work that a server-side implementation might have. It is by no means complete and only serves the purpose of testing

* make http client static

* review feedback

* change dynamic loading of signer",19,1907,2023-02-03 10:44:47-08:00,"['open-api.yml', 'AssumeRoleAwsClientFactory.java', 'AwsClientFactories.java', 'AwsProperties.java', 'S3ObjectMapper.java', 'S3SignRequest.java', 'S3SignRequestParser.java', 'S3SignResponse.java', 'S3SignResponseParser.java', 'S3V4RestSignerClient.java', 's3-signer-open-api.yaml', 'TestAwsProperties.java', 'MinioContainer.java', 'S3SignerServlet.java', 'TestS3RestSigner.java', 'TestS3SignRequestParser.java', 'TestS3SignResponseParser.java', 'build.gradle', 'versions.props']"
Spark 3.3: Fix isIcebergCommand check for replace branch and fix Scala style issues (#6728),4,29,2023-02-03 10:57:45-08:00,"['IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'TestCreateBranch.java', 'TestReplaceBranch.java']"
Spark 3.2: Handle no-op for rewrite manifests procedure/action (#6730),3,50,2023-02-03 15:27:05-08:00,"['TestRewriteManifestsProcedure.java', 'RewriteManifestsSparkAction.java', 'TestRewriteManifestsAction.java']"
Spark 3.1: Handle no-op for rewrite manifests procedure/action (#6731),3,50,2023-02-03 15:28:12-08:00,"['TestRewriteManifestsProcedure.java', 'BaseRewriteManifestsSparkAction.java', 'TestRewriteManifestsAction.java']"
Spark 2.4: Handle no-op for rewrite manifests procedure/action (#6733),2,55,2023-02-03 15:29:02-08:00,"['BaseRewriteManifestsSparkAction.java', 'TestRewriteManifestsAction.java']"
"Spark 3.3, Flink 1.16: Handle ResolvingFileIO while determining locality (#6655)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",4,101,2023-02-03 18:10:32-08:00,"['Util.java', 'ResolvingFileIO.java', 'SourceUtil.java', 'SparkReadConf.java']"
Build: Bump pre-commit from 3.0.1 to 3.0.4 in /python (#6748),2,10,2023-02-05 05:13:44+00:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump moto from 4.1.0 to 4.1.2 in /python (#6747),2,11,2023-02-05 06:21:55+00:00,"['poetry.lock', 'pyproject.toml']"
"Add support for special characters in snowflake identifiers for Snowflake Catalog (#6674)

* Handle special characters in database and schema name for snowflake catalog

* Fix mock exception messages

* Remove application identifier for jdbc client",2,184,2023-02-04 22:29:49-08:00,"['JdbcSnowflakeClient.java', 'JdbcSnowflakeClientTest.java']"
"Flink: Backport handling ResolvingFileIO in determining locality - PR 6655 (#6743)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",2,58,2023-02-05 18:39:45-08:00,"['SourceUtil.java', 'SourceUtil.java']"
Core: Prevent RESTCatalog AuthSession from expiring (#6749),1,15,2023-02-06 12:32:05-08:00,['RESTSessionCatalog.java']
Python: Bump pre-commit plugins to the latest version (#6738),6,29,2023-02-07 08:24:07-08:00,"['.pre-commit-config.yaml', 'reader.py', 'bin_packing.py', 'test_base.py', 'test_console.py', 'test_visitors.py']"
Python: Avoid local imports in test (#6737),5,373,2023-02-07 08:26:41-08:00,"['integration_test_glue.py', 'test_base.py', 'test_glue.py', 'test_console.py', 'conftest.py']"
"Python: Publish the docs by hand (#6719)

Currently everything that goes into master will directly be pushed
to Github Pages. This was fine for a while, but now we have PRs that
publish new functionality, but then it isn't available in the release
for example: https://github.com/apache/iceberg/pull/6644

I think we should now publish by hand, and move to multi version docs
once PyIceberg stabilizes a bit.",2,11,2023-02-07 08:27:19-08:00,"['python-ci-docs.yml', 'how-to-release.md']"
Python: Allow to pass in a string as filter (#6657),2,37,2023-02-07 08:28:56-08:00,"['api.md', '__init__.py']"
"Python: Remove the DNF conversion (#6721)

This was not needed after all. The Pythondoc was outdated, see:
https://github.com/apache/arrow/issues/33973",1,6,2023-02-07 18:14:35+01:00,['pyarrow.py']
"Delta: Support Snapshot Delta Lake Table to Iceberg Table (#6449)

Co-authored-by: ericlgoodman <erigood@amazon.com>",15,1936,2023-02-07 13:59:52-08:00,"['delta-conversion-ci.yml', 'build.gradle', 'DeltaLakeToIcebergMigrationSparkIntegration.java', 'SparkDeltaLakeSnapshotTestBase.java', 'TestSnapshotDeltaLakeTable.java', 'BaseSnapshotDeltaLakeTableAction.java', 'BaseSnapshotDeltaLakeTableActionResult.java', 'DeltaLakeDataTypeVisitor.java', 'DeltaLakeToIcebergMigrationActionsProvider.java', 'DeltaLakeTypeToType.java', 'SnapshotDeltaLakeTable.java', 'TestBaseSnapshotDeltaLakeTableAction.java', 'TestDeltaLakeTypeToType.java', 'settings.gradle', 'versions.props']"
Build: Bump cryptography from 39.0.0 to 39.0.1 in /python (#6767),1,54,2023-02-08 07:41:37+01:00,['poetry.lock']
Parquet: Improve Test Coverage of RowGroupFilter Code with Nans #6518 (#6554),1,29,2023-02-08 15:07:56-06:00,['TestMetricsRowGroupFilter.java']
Spark: Test register table procedure with all Spark catalogs (#6787),2,18,2023-02-09 08:27:24-06:00,"['TestRegisterTableProcedure.java', 'TestRegisterTableProcedure.java']"
Build: Update `httpclient5` for thread interrupt fix (#6782),1,2,2023-02-09 15:34:54+01:00,['versions.props']
Python: Loosen the version requirements for dependencies (#6745),2,22,2023-02-09 16:20:00+01:00,"['poetry.lock', 'pyproject.toml']"
"Flink: improve metrics (elapsedSecondsSinceLastSuccessfulCommit) and logging for IcebergFilesCommitter (#6764)

* Flink: improve metrics (elapsedSecondsSinceLastSuccessfulCommit) and logging for IcebergFilesCommitter",2,34,2023-02-09 07:56:00-08:00,"['IcebergFilesCommitter.java', 'IcebergFilesCommitterMetrics.java']"
AWS: Load HttpClientBuilder dynamically to avoid runtime deps of both urlconnection and apache client (#6746),6,821,2023-02-09 09:43:10-08:00,"['ApacheHttpClientConfigurations.java', 'AwsProperties.java', 'UrlConnectionHttpClientConfigurations.java', 'TestAwsProperties.java', 'TestHttpClientConfigurations.java', 'PropertyUtil.java']"
Spark 3.3: Improve log messages in scans (#6776),4,52,2023-02-09 10:16:32-08:00,"['SparkBatchQueryScan.java', 'SparkCopyOnWriteScan.java', 'SparkPartitioningAwareScan.java', 'SparkScan.java']"
"Spark: Backport handling ResolvingFileIO in determining locality (#6744)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",3,54,2023-02-09 11:34:46-08:00,"['SparkReadConf.java', 'SparkReadConf.java', 'SparkReadConf.java']"
Core: TableMetadata Always Strips Trailing Slash From Location (#6777),8,37,2023-02-09 11:42:10-08:00,"['TableMetadata.java', 'TestTableMetadata.java', 'TestSnapshotDeltaLakeTable.java', 'SnowflakeCatalogTest.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction.java']"
Build: Bump Nessie to 0.48.2 (#6790),2,4,2023-02-09 22:26:23+01:00,"['build.gradle', 'versions.props']"
Core: Allow configuring metrics reporter by catalog properties (#6410),3,65,2023-02-09 14:17:01-08:00,"['BaseMetastoreCatalog.java', 'JdbcCatalog.java', 'TestJdbcCatalog.java']"
"Core: View representation core implementation (#6598)

Co-authored-by: John Zhuge <jzhuge@apache.org>",9,423,2023-02-09 16:10:37-08:00,"['SQLViewRepresentation.java', 'ViewRepresentation.java', 'build.gradle', 'SQLViewRepresentationParser.java', 'UnknownViewRepresentation.java', 'ViewRepresentationParser.java', 'TestSQLViewRepresentationParser.java', 'TestViewRepresentationParser.java', 'versions.props']"
AWS: Remove unused validateTableIdentifier method in IcebergToGlueConverter (#6795),1,10,2023-02-09 16:13:45-08:00,['IcebergToGlueConverter.java']
Spark 3.3: Remove redundant vars in ChangelogRowReader (#6792),1,10,2023-02-10 13:47:51-08:00,['ChangelogRowReader.java']
Spark 3.3: Fix comment formatting (#6793),7,47,2023-02-10 13:50:52-08:00,"['SparkCatalog.java', 'SparkUtil.java', 'SparkBatchQueryScan.java', 'SparkCopyOnWriteScan.java', 'SparkFileWriterFactory.java', 'SparkMicroBatchStream.java', 'SparkPositionDeltaWrite.java']"
"Spark 3.3: SQL Extensions for CREATE TAG (#6637)

Co-authored-by: Amogh Jahagirdar <jahamogh@amazon.com>
Co-authored-by: chidayong <247070443@qq.com>",8,464,2023-02-10 14:00:04-08:00,"['IcebergSqlExtensions.g4', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'CreateOrReplaceTag.scala', 'TagOptions.scala', 'CreateOrReplaceTagExec.scala', 'ExtendedDataSourceV2Strategy.scala', 'TestTagDDL.java']"
"Spark 3.3: DROP BRANCH SQL implementation (#6752)

Co-authored-by: liliwei hililiwei@gmail.com
Co-authored-by: xuwei xuwei132@huawei.com
Co-authored-by: chidayong chidayong2@h-partners.com",8,202,2023-02-10 16:59:24-08:00,"['IcebergSqlExtensions.g4', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'CreateOrReplaceBranch.scala', 'DropBranch.scala', 'DropBranchExec.scala', 'ExtendedDataSourceV2Strategy.scala', 'TestBranchDDL.java']"
Doc: update Flink doc for sink metrics (#6765),1,44,2023-02-10 19:54:13-08:00,['flink-getting-started.md']
Core: Support lazy snapshot loading in TableMetadata (#6811),4,313,2023-02-12 13:08:56-08:00,"['TableMetadata.java', 'TableMetadataParser.java', 'TestSnapshotLoading.java', 'TestTableMetadata.java']"
Flink: Support branch writes in Flink sink (#6660),12,1215,2023-02-12 20:24:53-08:00,"['FlinkWriteConf.java', 'FlinkWriteOptions.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'SimpleDataUtil.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkBase.java', 'TestFlinkIcebergSinkBranch.java', 'TestFlinkIcebergSinkV2.java', 'TestFlinkIcebergSinkV2Base.java', 'TestFlinkIcebergSinkV2Branch.java', 'TestIcebergFilesCommitter.java']"
"Python: TypeVar for bounding TableScan (#6819)

* Properly use TypeVar for bounding TableScan return

* Fix isort and mypy error

* Update __init__.py

---------

Co-authored-by: Fokko Driesprong <fokko@apache.org>",1,21,2023-02-13 16:51:19+01:00,['__init__.py']
API: Revert to using stephenc findbugs dependency for Nullable (#6815),3,4,2023-02-13 10:26:48-08:00,"['SQLViewRepresentation.java', 'build.gradle', 'versions.props']"
API: Add new KeyManagementClient interface (#6485),4,136,2023-02-13 10:34:21-08:00,"['KmsClient.java', 'KeyManagementClient.java', 'KeyStoreKmsClient.java', 'MemoryMockKMS.java']"
"Python: Add support for static table (#6644)

* save some lines

* make metadata_location fixture

* Add StaticTable

* Fokko's feedback

* linterrrrrr

* Update __init__.py

---------

Co-authored-by: Fokko Driesprong <fokko@apache.org>",6,95,2023-02-13 21:02:14+01:00,"['api.md', 'rest.py', '__init__.py', 'test_hive.py', 'conftest.py', 'test_init.py']"
Core: Refactor validation in TableScanUtil (#6791),2,33,2023-02-13 12:40:59-08:00,"['TableScanUtil.java', 'TestSplitPlanning.java']"
Flink: use tag or branch to scan data (#5029),12,489,2023-02-14 07:45:07-08:00,"['GenericAppenderHelper.java', 'FlinkReadConf.java', 'FlinkReadOptions.java', 'FlinkSource.java', 'FlinkSplitPlanner.java', 'IcebergSource.java', 'ScanContext.java', 'StreamingMonitorFunction.java', 'TestFlinkScan.java', 'TestFlinkSource.java', 'TestStreamScanSql.java', 'TestStreamingMonitorFunction.java']"
Parquet: deprecate Decimal Metadata usage in favor of DecimalLogicalTypeAnnotation (#6735),12,60,2023-02-14 10:57:32-08:00,"['BaseParquetReaders.java', 'ParquetAvroValueReaders.java', 'ParquetAvroWriter.java', 'ParquetBloomRowGroupFilter.java', 'ParquetConversions.java', 'PigParquetReader.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java']"
"Spark 3.3: SQL Extensions for DROP TAG (#6807)

Co-authored-by: Amogh Jahagirdar <jahamogh@amazon.com>
Co-authored-by: chidayong <247070443@qq.com>",8,241,2023-02-14 14:06:41-08:00,"['IcebergSqlExtensions.g4', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'DropTag.scala', 'DropTagExec.scala', 'ExtendedDataSourceV2Strategy.scala', 'TestBranchDDL.java', 'TestTagDDL.java']"
"Spark 3.3: Return partition stats for AddFiles procedure (#6797)

Co-authored-by: Steve Zhang <hongyue_zhang@apple.com>",2,175,2023-02-14 17:30:27-06:00,"['TestAddFilesProcedure.java', 'AddFilesProcedure.java']"
"Build: Bump com.palantir.gradle.gitversion:gradle-git-version (#6812)

Bumps [com.palantir.gradle.gitversion:gradle-git-version](https://github.com/palantir/gradle-git-version) from 0.15.0 to 1.0.0.
- [Release notes](https://github.com/palantir/gradle-git-version/releases)
- [Changelog](https://github.com/palantir/gradle-git-version/blob/develop/.changelog.yml)
- [Commits](https://github.com/palantir/gradle-git-version/compare/0.15.0...1.0.0)

---
updated-dependencies:
- dependency-name: com.palantir.gradle.gitversion:gradle-git-version
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-02-15 10:25:13+01:00,['build.gradle']
Python: Inline the PyArrow import (#6827),1,3,2023-02-15 10:25:33+01:00,['__init__.py']
"Python: Set PyArrow as the default FileIO (#6822)

PyArrow is the most feature complete FileIO,
and it can be a bit confusing.",4,92,2023-02-15 10:25:59+01:00,"['configuration.md', '__init__.py', 'test_glue.py', 'test_io.py']"
"Python: Support for DynamoDB Catalog (#6646)

* Implement support for DynamoDB catalog

* Python: Support DynamoDB catalog #6541

* Fix licence

* Remove BaseAwsCatalog class

* Add custom DynamoDB table name

* Remove __init__.py from tests/catalog/

* Apply comments from PR

* Rebase and fix tests

* Return empty list for hierarchical namespace

* Return empty list for hierarchical namespace

* Apply comments from PR

* Rebase and fix circular import

* Fix linter issue

* Fix integ tests",15,2112,2023-02-15 10:32:10+01:00,"['configuration.md', 'index.md', '__init__.py', 'dynamodb.py', 'glue.py', 'hive.py', 'exceptions.py', '__init__.py', 'pyproject.toml', 'integration_test_dynamodb.py', 'integration_test_glue.py', 'test_dynamodb.py', 'test_glue.py', 'test_hive.py', 'conftest.py']"
"Python: Fix the CI (#6842)

Changing the default FileIO from Arrow to Fsspec broke
the dynamodb tests.",1,38,2023-02-15 17:58:07+01:00,['test_dynamodb.py']
"API,Core,Spark: Add rewritten bytes to rewrite data files procedure results (#6801)

Co-authored-by: Alex Reid <areid@tabular.io>",9,227,2023-02-15 15:46:53-06:00,"['RewriteDataFiles.java', 'BaseFileGroupRewriteResult.java', 'RewriteFileGroup.java', 'TestRewriteDataFilesProcedure.java', 'RewriteDataFilesProcedure.java', 'SparkCatalogConfig.java', 'SparkTestHelperBase.java', 'TestRewriteDataFilesAction.java', 'TestRefreshTable.java']"
"Add application identifier for Snowflake JDBC driver (#6740)

* Add application identifier for Jdbc driver

* Rename app identifier and add doc link",1,8,2023-02-15 19:06:08-08:00,['SnowflakeCatalog.java']
Spark 3.3: Make manifest file names unique during imports (#6818),2,40,2023-02-15 21:04:53-08:00,"['TestAddFilesProcedure.java', 'SparkTableUtil.java']"
"Spark 3.2: Make manifest file names unique during imports (#6845)

Backports PR #6818 to Spark 3.2.",2,40,2023-02-15 21:07:09-08:00,"['TestAddFilesProcedure.java', 'SparkTableUtil.java']"
Spark 3.3: Change default distribution modes (#6828),7,276,2023-02-15 21:10:02-08:00,"['TestRewriteDataFilesProcedure.java', 'SparkWriteConf.java', 'TestSparkDistributionAndOrderingUtil.java', 'TestRewriteManifestsAction.java', 'TestIcebergSourceTablesBase.java', 'TestPartitionValues.java', 'TestSparkDataWrite.java']"
"Data: Add a select collections for IcebergGenerics (#6834)

* feat(iceberg-data): add override method

The IcebergGenerics class only has String ... method for select, should add Collection for select
will be better!

feat #6833

* feat(data): format code

foramt code

* feat(data): format **select** code

they need not to copy of the collection again, because of the underlying interface has a conversion
logic.

* feat(data): remove ImmutableList",1,9,2023-02-16 08:35:12+01:00,['IcebergGenerics.java']
"Build: Bump werkzeug from 2.2.2 to 2.2.3 in /python (#6854)

Bumps [werkzeug](https://github.com/pallets/werkzeug) from 2.2.2 to 2.2.3.
- [Release notes](https://github.com/pallets/werkzeug/releases)
- [Changelog](https://github.com/pallets/werkzeug/blob/main/CHANGES.rst)
- [Commits](https://github.com/pallets/werkzeug/compare/2.2.2...2.2.3)

---
updated-dependencies:
- dependency-name: werkzeug
  dependency-type: indirect
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,11,2023-02-16 08:45:52+01:00,['poetry.lock']
"Python: Add String to Boolean literal conversion (#6851)

* Convert string to boolean if the binding variable is Boolean

* Update python/pyiceberg/expressions/literals.py

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* addressed review comments

* corrected lint failure

* corrected test failure

---------

Co-authored-by: pritampan <pritampan@pinterest.com>
Co-authored-by: Fokko Driesprong <fokko@apache.org>",2,24,2023-02-16 09:05:04+01:00,"['literals.py', 'test_literals.py']"
Build: Bump Arrow from 10.0.1 to 11.0.0 (#6696),1,4,2023-02-16 11:57:18+01:00,['versions.props']
Build: Bump jackson-annotations from 2.14.1 to 2.14.2 (#6687),2,4,2023-02-16 12:00:37+01:00,"['build.gradle', 'build.gradle']"
[Python Legacy] Convert string to boolean if the binding variable is Boolean (#6843),2,13,2023-02-16 12:01:15+01:00,"['literals.py', 'test_string_literal_conversions.py']"
Spark 3.1: Add rewritten bytes to rewrite data files procedure results (#6856),6,133,2023-02-16 07:50:18-06:00,"['TestRewriteDataFilesProcedure.java', 'RewriteDataFilesProcedure.java', 'SparkCatalogConfig.java', 'SparkTestBase.java', 'TestRewriteDataFilesAction.java', 'TestRefreshTable.java']"
Spark 3.2: Add rewritten bytes to rewrite data files procedure results (#6855),6,197,2023-02-16 07:51:34-06:00,"['TestRewriteDataFilesProcedure.java', 'RewriteDataFilesProcedure.java', 'SparkCatalogConfig.java', 'SparkTestHelperBase.java', 'TestRewriteDataFilesAction.java', 'TestRefreshTable.java']"
AWS: set lastEvaluatedKey for listTables in DynamoDb Catalog (#6823),1,3,2023-02-16 11:00:22-08:00,['DynamoDbCatalog.java']
Flink: backport PR #6764 to 1.14 and 1.15 for elapsedSecondsSinceLastSuccessfulCommit sink metric (#6808),4,68,2023-02-16 12:57:42-08:00,"['IcebergFilesCommitter.java', 'IcebergFilesCommitterMetrics.java', 'IcebergFilesCommitter.java', 'IcebergFilesCommitterMetrics.java']"
"Python: Add `default-catalog` option to the config (#6864)

If you set `default-catalog` it will default to that catalog.",3,26,2023-02-16 14:00:37-08:00,"['__init__.py', 'console.py', 'config.py']"
Docs: Note partitions metadata table might show 'old' partitions (#6771),1,4,2023-02-16 18:18:06-08:00,['spark-queries.md']
"AWS: Fix warning in S3V4RestSignerClient (#6859)

This should fix the following warning:

```
> Task :iceberg-aws:compileJava
/home/nastra/Development/workspace/iceberg/aws/src/main/java/org/apache/iceberg/aws/s3/signer/S3V4RestSignerClient.java:75: warning: (immutables:incompat) Avoid introduction of fields (except constants) in abstract value types
  private static RESTClient httpClient;
                            ^
```",1,12,2023-02-16 20:55:16-08:00,['S3V4RestSignerClient.java']
"Spark 3.3: Add SQL property to control distribution mode (#6838)

Co-authored-by: Steve Zhang <hongyue_zhang@apple.com>",3,205,2023-02-17 12:32:07-08:00,"['SparkSQLProperties.java', 'SparkWriteConf.java', 'TestSparkWriteConf.java']"
"Spark 3.1: Make manifest file names unique during imports (#6846)

Backports PR #6818 to Spark 3.1.

Co-authored-by: Abid Mohammed <abid_mohammed@apple.com>",2,47,2023-02-17 12:55:41-08:00,"['TestAddFilesProcedure.java', 'SparkTableUtil.java']"
"Spark 3.3: Support reading position deletes table (#6716)

Co-authored-by: Ryan Blue <blue@apache.org>",7,1066,2023-02-17 13:03:33-08:00,"['ExpressionUtil.java', 'BaseMetadataTable.java', 'PositionDeletesTable.java', 'FileHelpers.java', 'PositionDeletesRowReader.java', 'SparkRowReaderFactory.java', 'TestPositionDeletesTable.java']"
Spark 3.3: Delete orphan files JMH benchmark (#5615),1,179,2023-02-17 15:44:39-08:00,['DeleteOrphanFilesBenchmark.java']
"Python: Bump DuckDB to 0.7.0 (#6848)

New release:

https://github.com/duckdb/duckdb/releases/tag/v0.7.0

That has some nice Python API improvements:

https://duckdb.org/2023/02/13/announcing-duckdb-070.html#python-api-improvements",2,2539,2023-02-19 22:02:48+01:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump pydantic from 1.10.4 to 1.10.5 in /python (#6881)

Bumps [pydantic](https://github.com/pydantic/pydantic) from 1.10.4 to 1.10.5.
- [Release notes](https://github.com/pydantic/pydantic/releases)
- [Changelog](https://github.com/pydantic/pydantic/blob/v1.10.5/HISTORY.md)
- [Commits](https://github.com/pydantic/pydantic/compare/v1.10.4...v1.10.5)

---
updated-dependencies:
- dependency-name: pydantic
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,2583,2023-02-19 22:11:32+01:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump typing-extensions from 4.4.0 to 4.5.0 in /python (#6883)

Bumps [typing-extensions](https://github.com/python/typing_extensions) from 4.4.0 to 4.5.0.
- [Release notes](https://github.com/python/typing_extensions/releases)
- [Changelog](https://github.com/python/typing_extensions/blob/main/CHANGELOG.md)
- [Commits](https://github.com/python/typing_extensions/compare/4.4.0...4.5.0)

---
updated-dependencies:
- dependency-name: typing-extensions
  dependency-type: direct:development
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,10,2023-02-19 22:20:10+01:00,"['poetry.lock', 'pyproject.toml']"
Python: Add more pyiceberg docs (#6874),1,6,2023-02-20 12:17:47+01:00,['api.md']
Core: Add REST support for lazy snapshot loading (#6850),3,174,2023-02-20 09:25:52-08:00,"['RESTSessionCatalog.java', 'TestRESTCatalog.java', 'rest-catalog-open-api.yaml']"
AWS: OSS S3 Signer Updates (#6835),2,30,2023-02-20 10:22:20-08:00,"['S3ObjectMapper.java', 'S3V4RestSignerClient.java']"
Build: Fix compile warning with Immutables subtype (#6869),1,3,2023-02-21 19:21:50+01:00,['ViewRepresentation.java']
Spark 3.2: Change default distribution modes (#6877),7,276,2023-02-21 14:22:55-08:00,"['TestRewriteDataFilesProcedure.java', 'SparkWriteConf.java', 'TestSparkDistributionAndOrderingUtil.java', 'TestRewriteManifestsAction.java', 'TestIcebergSourceTablesBase.java', 'TestPartitionValues.java', 'TestSparkDataWrite.java']"
"Spark 3.2: Add SQL property to control distribution mode (#6878)

Backports PR #6838 to Spark 3.2.

Co-authored-by: Steve Zhang <hongyue_zhang@apple.com>",3,205,2023-02-21 16:12:03-08:00,"['SparkSQLProperties.java', 'SparkWriteConf.java', 'TestSparkWriteConf.java']"
Build: Bump Gradle to 8.0.1 (#6826),13,62,2023-02-22 09:54:15+01:00,"['build.gradle', 'deploy.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'gradle-wrapper.properties', 'gradlew', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle']"
Core: Make Iceberg version in EnvironmentContext by default (#6831),2,39,2023-02-22 14:18:28+01:00,"['EnvironmentContext.java', 'TestEnvironmentContext.java']"
Core: Handle statistics file clean up from expireSnapshots (#6090),5,164,2023-02-22 10:18:54-08:00,"['FileCleanupStrategy.java', 'IncrementalFileCleanup.java', 'ReachableFileCleanup.java', 'TableMetadata.java', 'TestRemoveSnapshots.java']"
"Spark 3.3: Minor updates to ChangelogIterator (#6898)

This PR is a follow-up change to PR #6344.",2,102,2023-02-22 13:10:39-08:00,"['ChangelogIterator.java', 'TestChangelogIterator.java']"
Spark 3.3: Optimize DELETEs handled using metadata (#6899),7,95,2023-02-22 14:27:42-08:00,"['ExpressionUtil.java', 'TestDelete.java', 'SparkReadConf.java', 'SparkUtil.java', 'SparkZOrderStrategy.java', 'SparkScanBuilder.java', 'SparkTable.java']"
"Spark 3.2: Minor updates to ChangelogIterator (#6909)

This PR backports PR #6898 to Spark 3.2.",2,102,2023-02-22 15:11:47-08:00,"['ChangelogIterator.java', 'TestChangelogIterator.java']"
Spark 3.3: Support reading tag or branch via identifiers (#6717),6,215,2023-02-22 15:24:29-08:00,"['SparkCachedTableCatalog.java', 'SparkCatalog.java', 'IcebergSource.java', 'SparkTable.java', 'TestSnapshotSelection.java', 'TestSelect.java']"
"Spark 3.2: Optimize DELETEs handled using metadata (#6912)

This change backports PR #6899 into Spark 3.2.",5,71,2023-02-22 16:59:53-08:00,"['TestDelete.java', 'SparkReadConf.java', 'SparkUtil.java', 'SparkZOrderStrategy.java', 'SparkTable.java']"
"Spark 3.2, 3.3: Use table partition spec explicitly in add_files for path based tables (#6779)",6,182,2023-02-22 18:47:28-08:00,"['TestAddFilesProcedure.java', 'Spark3Util.java', 'AddFilesProcedure.java', 'TestAddFilesProcedure.java', 'Spark3Util.java', 'AddFilesProcedure.java']"
AWS: Change default glue skip archive to true (#6916),4,44,2023-02-23 10:08:00-08:00,"['GlueTestBase.java', 'TestGlueCatalogTable.java', 'AwsProperties.java', 'aws.md']"
"Core, Spark: Push down min, max, and count aggregations (#6622)",22,1955,2023-02-23 11:23:28-08:00,"['TableScan.java', 'AggregateEvaluator.java', 'BoundAggregate.java', 'CountAggregate.java', 'CountNonNull.java', 'CountStar.java', 'ExpressionUtil.java', 'MaxAggregate.java', 'MinAggregate.java', 'UnboundAggregate.java', 'ValueAggregate.java', 'TestAggregateEvaluator.java', 'BaseTableScan.java', 'TableScanContext.java', 'TestMergeOnReadDelete.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkSQLProperties.java', 'SparkAggregates.java', 'SparkLocalScan.java', 'SparkScanBuilder.java', 'TestAggregatePushDown.java']"
"Build: Bump markdown-it-py from 2.1.0 to 2.2.0 in /python (#6922)

Bumps [markdown-it-py](https://github.com/executablebooks/markdown-it-py) from 2.1.0 to 2.2.0.
- [Release notes](https://github.com/executablebooks/markdown-it-py/releases)
- [Changelog](https://github.com/executablebooks/markdown-it-py/blob/master/CHANGELOG.md)
- [Commits](https://github.com/executablebooks/markdown-it-py/compare/v2.1.0...v2.2.0)

---
updated-dependencies:
- dependency-name: markdown-it-py
  dependency-type: indirect
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,14,2023-02-23 21:50:05+01:00,['poetry.lock']
Spark 3.3: Improve task and job abort handling (#6876),4,456,2023-02-23 13:55:06-08:00,"['TestWriteAborts.java', 'SparkCleanupUtil.java', 'SparkPositionDeltaWrite.java', 'SparkWrite.java']"
"API: Allow spaces in string type definitions (#6917)

* Fix Types from string, allow spaces

* Use Assertj",2,52,2023-02-24 09:12:20+01:00,"['Types.java', 'TestTypes.java']"
"REST: Correct snapshot id and time ms int format (#6921)

* [Rest Catalog Spec] Correct snapshot id and time ms int format

* Another int format fix

---------

Co-authored-by: Haizhou Zhao <haizhou_zhao@apple.com>",1,9,2023-02-24 09:14:16+01:00,['rest-catalog-open-api.yaml']
Spark 3.2: Improve task and job abort handling (#6926),4,457,2023-02-24 13:37:40-08:00,"['TestWriteAborts.java', 'SparkCleanupUtil.java', 'SparkPositionDeltaWrite.java', 'SparkWrite.java']"
Build: Bump coverage from 7.1.0 to 7.2.0 in /python (#6944),2,108,2023-02-26 07:39:23+01:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump zstandard from 0.19.0 to 0.20.0 in /python (#6943),2,108,2023-02-26 10:27:22+01:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump fastavro from 1.7.1 to 1.7.2 in /python (#6942),2,48,2023-02-26 11:34:24+01:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump pre-commit from 3.0.4 to 3.1.0 in /python (#6941),2,10,2023-02-26 12:07:37+01:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump moto from 4.1.2 to 4.1.3 in /python (#6940),2,10,2023-02-26 13:07:06+01:00,"['poetry.lock', 'pyproject.toml']"
Spark: Aggregate push down followup (#6923),10,322,2023-02-26 11:49:42-08:00,"['TableScan.java', 'BaseTableScan.java', 'TableScanContext.java', 'TestMergeOnReadDelete.java', 'SparkAggregates.java', 'SparkSQLProperties.java', 'SparkAggregates.java', 'SparkLocalScan.java', 'SparkScanBuilder.java', 'TestAggregatePushDown.java']"
"Core: use random port for rest catalog (#6895)

* Core: use random port for rest catalog unit tests

* spotless

* use jetty's random port instead

---------

Co-authored-by: Abid Mohammed <abid_mohammed@apple.com>",1,15,2023-02-27 09:55:30+01:00,['TestRESTCatalog.java']
Flink 1.15: Port use tag or branch to scan data to Flink 1.15,11,468,2023-02-27 12:18:52-08:00,"['FlinkReadConf.java', 'FlinkReadOptions.java', 'FlinkSource.java', 'FlinkSplitPlanner.java', 'IcebergSource.java', 'ScanContext.java', 'StreamingMonitorFunction.java', 'TestFlinkScan.java', 'TestFlinkSource.java', 'TestStreamScanSql.java', 'TestStreamingMonitorFunction.java']"
Flink 1.14: Port use tag or branch to scan data to Flink 1.14,11,468,2023-02-27 12:18:52-08:00,"['FlinkReadConf.java', 'FlinkReadOptions.java', 'FlinkSource.java', 'FlinkSplitPlanner.java', 'IcebergSource.java', 'ScanContext.java', 'StreamingMonitorFunction.java', 'TestFlinkScan.java', 'TestFlinkSource.java', 'TestStreamScanSql.java', 'TestStreamingMonitorFunction.java']"
Python: Filter on Datafile metrics (#6714),6,1110,2023-02-27 14:02:49-08:00,"['conversions.py', 'literals.py', 'visitors.py', 'pyarrow.py', '__init__.py', 'test_evaluator.py']"
Flink: Add branch to successful commit logs,1,3,2023-02-27 14:55:59-08:00,['IcebergFilesCommitter.java']
Flink: fix wrong projection when delete records in upsert mode (#6753),2,24,2023-02-27 18:18:56-08:00,"['BaseDeltaTaskWriter.java', 'TestFlinkIcebergSinkV2.java']"
Flink: fix compiling error from PR #6753 (#6953),1,5,2023-02-27 20:13:40-08:00,['TestFlinkIcebergSinkV2.java']
Core: Use server URI from REST server instead of manually constructing it (#6947),1,13,2023-02-28 09:06:00-08:00,['TestRESTCatalog.java']
"Python: Fix timezone concat issue (#6946)

Resolves #6945",2,29,2023-02-28 18:17:10+01:00,"['pyarrow.py', 'test_pyarrow.py']"
Spark 3.3: Skip duplicate check for deleted files on adding files to iceberg table (#6889),2,63,2023-02-28 11:09:46-08:00,"['TestAddFilesProcedure.java', 'SparkTableUtil.java']"
Docs: Creating a table using DataFrameWriterV2 with a table location (#6729),1,8,2023-02-28 11:11:07-08:00,['spark-writes.md']
Build: Bump Apache Spark to 3.3.2 (#6852),1,2,2023-02-28 21:33:06+01:00,['build.gradle']
Python-legacy: Remove python_legacy (#6960),203,19740,2023-02-28 13:47:22-08:00,"['labeler.yml', 'delta-conversion-ci.yml', 'flink-ci.yml', 'hive-ci.yml', 'java-ci.yml', 'python-legacy-ci.yml', 'spark-ci.yml', '.gitignore', 'CHANGELOG.md', 'README.md', '__init__.py', '__init__.py', 'append_files.py', 'combined_scan_task.py', 'data_file.py', 'data_operations.py', 'delete_files.py', 'expire_snapshots.py', '__init__.py', 'binder.py', 'evaluator.py', 'expression.py', 'expression_parser.py', 'expressions.py', 'inclusive_manifest_evaluator.py', 'inclusive_metrics_evaluator.py', '__init__.py', 'literals.py', 'predicate.py', 'projections.py', 'reference.py', 'residual_evaluator.py', 'strict_metrics_evaluator.py', 'term.py', 'transform.py', 'file_format.py', 'file_scan_task.py', 'files.py', 'filterable.py', 'filtered_snapshot.py', '__init__.py', 'closeable_group.py', 'closeable_iterable.py', 'delegating_input_stream.py', 'delegating_output_stream.py', 'file_appender.py', 'input_file.py', 'output_file.py', 'position_output_stream.py', 'seekable_input_stream.py', 'manifest_file.py', 'metrics.py', 'overwrite_files.py', 'partition_field.py', 'partition_spec.py', 'pending_update.py', 'replace_partitions.py', 'rewrite_files.py', 'rollback.py', 'scan_task.py', 'schema.py', 'snapshot.py', 'snapshot_iterable.py', 'struct_like.py', 'table.py', 'table_scan.py', 'tables.py', 'transaction.py', '__init__.py', 'bucket.py', 'dates.py', 'identity.py', 'projection_util.py', 'timestamps.py', 'transform.py', 'transform_util.py', 'transforms.py', 'truncate.py', 'unknown_transform.py', 'void_transform.py', '__init__.py', 'conversions.py', 'type.py', 'type_util.py', 'types.py', 'update_properties.py', 'update_schema.py', '__init__.py', '__init__.py', 'avro_schema_util.py', 'avro_to_iceberg.py', 'iceberg_to_avro.py', 'base_combined_scan_task.py', 'base_file_scan_task.py', 'base_metastore_table_operations.py', 'base_metastore_tables.py', 'base_snapshot.py', 'base_table.py', 'base_table_scan.py', 'base_transaction.py', 'config_properties.py', 'data_files.py', 'data_table_scan.py', '__init__.py', 'file_status.py', 'file_system.py', 'filesystem_table_operations.py', 'filesystem_tables.py', 'local_filesystem.py', 's3_filesystem.py', 'util.py', 'filtered_manifest.py', 'generic_data_file.py', 'generic_manifest_file.py', 'generic_partition_field_summary.py', 'manifest_entry.py', 'manifest_list_writer.py', 'manifest_reader.py', 'partition_data.py', 'partition_spec_parser.py', 'partition_summary.py', 'scan_summary.py', 'schema_parser.py', 'schema_update.py', 'snapshot_parser.py', 'table_metadata.py', 'table_metadata_parser.py', 'table_operations.py', 'table_properties.py', '__init__.py', 'atomic_integer.py', 'bin_packing.py', 'profile.py', '__init__.py', 'exceptions.py', '__init__.py', 'hive_table_operations.py', 'hive_tables.py', 'hive_types.py', '__init__.py', 'dataset_utils.py', 'parquet_reader.py', 'parquet_schema_utils.py', 'parquet_to_iceberg.py', 'setup.py', '__init__.py', '__init__.py', '__init__.py', 'conftest.py', 'test_evaluator.py', 'test_expression_binding.py', 'test_expression_helpers.py', 'test_expression_serializations.py', 'test_inclusive_manifest_evaluator.py', 'test_inclusive_metrics_evaluator.py', 'test_literal_serialization.py', 'test_misc_literal_conversions.py', 'test_numeric_literal_conversions.py', 'test_predicate_binding.py', 'test_str_to_expr.py', 'test_strict_metrics_evaluator.py', 'test_string_literal_conversions.py', 'test_conversions.py', 'test_file_format.py', 'test_helpers.py', 'test_partition_spec.py', '__init__.py', 'test_bucket.py', 'test_bucketing.py', 'test_dates.py', 'test_identity.py', 'test_timestamps.py', 'test_truncate.py', '__init__.py', 'test_binary_comparator.py', 'test_char_seq_comparator.py', 'test_comparable_comparator.py', 'test_readabilty_checks.py', 'test_type_util.py', '__init__.py', '__init__.py', 'conftest.py', 'test_avro.py', 'test_read_projection.py', 'conftest.py', 'test_base_table_scan.py', 'test_filesystem_tables.py', 'test_partition_spec.py', 'test_partition_spec_parser.py', 'test_snapshot_json.py', 'test_table_metadata_json.py', 'test_table_metadata_parser.py', '__init__.py', 'test_bin_packing.py', '__init__.py', 'conftest.py', 'test_hive_tables.py', '__init__.py', 'conftest.py', 'test_dataset_utils.py', 'test_parquet_reader.py', 'test_parquet_to_iceberg.py', 'tox.ini']"
Flink 1.14/1.15: backport projection fix from #6753 (#6954),4,48,2023-02-28 15:28:31-08:00,"['BaseDeltaTaskWriter.java', 'TestFlinkIcebergSinkV2.java', 'BaseDeltaTaskWriter.java', 'TestFlinkIcebergSinkV2.java']"
fix missing genericity (#6958),3,6,2023-02-28 15:30:09-08:00,"['IcebergSource.java', 'IcebergSource.java', 'IcebergSource.java']"
Flink: Backport PR #6660 to Flink 1.14 and 1.15 (#6949),24,2445,2023-02-28 15:43:44-08:00,"['FlinkWriteConf.java', 'FlinkWriteOptions.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'SimpleDataUtil.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkBase.java', 'TestFlinkIcebergSinkBranch.java', 'TestFlinkIcebergSinkV2.java', 'TestFlinkIcebergSinkV2Base.java', 'TestFlinkIcebergSinkV2Branch.java', 'TestIcebergFilesCommitter.java', 'FlinkWriteConf.java', 'FlinkWriteOptions.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'SimpleDataUtil.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkBase.java', 'TestFlinkIcebergSinkBranch.java', 'TestFlinkIcebergSinkV2.java', 'TestFlinkIcebergSinkV2Base.java', 'TestFlinkIcebergSinkV2Branch.java', 'TestIcebergFilesCommitter.java']"
Flink: fix compiling error from PR #6954 (#6963),2,40,2023-02-28 20:43:38-08:00,"['TestFlinkIcebergSinkV2.java', 'TestFlinkIcebergSinkV2.java']"
Spark: Port Branch DDL to Spark 3.2 & 3.1 (#6929),20,1739,2023-02-28 21:12:06-08:00,"['IcebergSqlExtensions.g4', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'BranchOptions.scala', 'CreateOrReplaceBranch.scala', 'DropBranch.scala', 'CreateOrReplaceBranchExec.scala', 'DropBranchExec.scala', 'ExtendedDataSourceV2Strategy.scala', 'TestBranchDDL.java', 'IcebergSqlExtensions.g4', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'BranchOptions.scala', 'CreateOrReplaceBranch.scala', 'DropBranch.scala', 'CreateOrReplaceBranchExec.scala', 'DropBranchExec.scala', 'ExtendedDataSourceV2Strategy.scala', 'TestBranchDDL.java']"
Delta: Handle delta lake's automatic log clean and VACUUM (#6880),4,445,2023-02-28 21:13:05-08:00,"['SparkDeltaLakeSnapshotTestBase.java', 'TestSnapshotDeltaLakeTable.java', 'BaseSnapshotDeltaLakeTableAction.java', 'TestBaseSnapshotDeltaLakeTableAction.java']"
"Core, API: BaseReplacePartitions to branch test Refactoring (#6650)",12,476,2023-02-28 22:39:37-08:00,"['BaseOverwriteFiles.java', 'BaseReplacePartitions.java', 'BaseRewriteFiles.java', 'SnapshotUtil.java', 'TableTestBase.java', 'TestDeleteFiles.java', 'TestMergeAppend.java', 'TestOverwrite.java', 'TestOverwriteWithValidation.java', 'TestReplacePartitions.java', 'TestRewriteFiles.java', 'TestRowDelta.java']"
"AWS: Use random port for HTTP server (#6959)

This is mainly so that we don't conflict with other tests that might run in parallel",1,6,2023-03-01 08:47:52+01:00,['TestS3RestSigner.java']
"Build: Bump me.champeau.jmh:jmh-gradle-plugin from 0.6.8 to 0.7.0 (#6938)

Bumps me.champeau.jmh:jmh-gradle-plugin from 0.6.8 to 0.7.0.

---
updated-dependencies:
- dependency-name: me.champeau.jmh:jmh-gradle-plugin
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-03-01 08:48:37+01:00,['build.gradle']
"API: Add try catch on `ExpressionUtils.sanitizeString` (#6920)

* add try catch on ExpressionUtils.sanitizeString

* add unit test

* use assertThat to print more error info",2,46,2023-03-01 08:49:51+01:00,"['ExpressionUtil.java', 'TestExpressionUtil.java']"
"Docs: Fix incorrect link (#6957)

* Fixed a incorrect link

* Modified as suggested",1,6,2023-03-01 14:05:57+01:00,['spark-getting-started.md']
"API, Core: Use Google findbugs dependency but as CompileOnly (#6976)",5,11,2023-03-01 10:55:54-08:00,"['SQLViewRepresentation.java', 'build.gradle', 'CommitMetricsResult.java', 'ScanMetricsResult.java', 'versions.props']"
Build: Fix minor errorprone warnings during compile (#6983),3,4,2023-03-02 10:23:17+01:00,"['AggregateEvaluator.java', 'ValueAggregate.java', 'baseline.gradle']"
Build: Update sqlite-jdbc from 3.34.0 to 3.41.0.0 (#6931),1,2,2023-03-02 13:08:43+01:00,['versions.props']
"Python: `starts_with` and `not_starts_with` expressions (#6892)

* Add new expressions

* Add test for new expressions

* Fix tests and test visitors

* Add py arrow tests

* Fix visitors, fix mypy

* Fix problem on ManifestEvalVisitor

* Update python/pyiceberg/expressions/visitors.py

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* Update python/tests/expressions/test_parser.py

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* Fix test_parser tests and add more test_evaluator tests for new python operators

* Fix ManifestEvalVisitor logic, add more tests

* Fixes and minors from review

* Add MetricsEvaluator starts_with logic and fix tests

* Apply suggestions from code review

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* Apply suggestions from code review

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* Fix mypy error

---------

Co-authored-by: Luigi Cerone <luigi.cerone@facile.it>
Co-authored-by: Fokko Driesprong <fokko@apache.org>",10,537,2023-03-02 13:32:52+01:00,"['__init__.py', 'parser.py', 'visitors.py', 'pyarrow.py', 'transforms.py', 'test_evaluator.py', 'test_parser.py', 'test_visitors.py', 'test_pyarrow.py', 'test_transforms.py']"
"Build: Upgrade Java test dependencies (#6985)

- upgrade junit5 to 5.9.2
- upgrade mockito to 4.11.0
- upgrade assertj to 3.24.2
- upgrade testcontainers to 1.17.6

Co-authored-by: Fokko Driesprong <fokko@apache.org>",1,10,2023-03-02 15:33:25+01:00,['versions.props']
"API, Core, Spark 3.3: Bulk delete (#6682)

Previously deletes were handled by a per Action execution service that would be used
to parallelize single deletes. In this PR we move the responsibility of performing the
deletes and the parallelization of those deletes to the FileIO via SupportsBulkOperations.",11,324,2023-03-02 11:27:25-06:00,"['DeleteOrphanFiles.java', 'DeleteReachableFiles.java', 'ExpireSnapshots.java', 'HadoopFileIO.java', 'HadoopFileIOTest.java', 'BaseSparkAction.java', 'DeleteOrphanFilesSparkAction.java', 'DeleteReachableFilesSparkAction.java', 'ExpireSnapshotsSparkAction.java', 'ExpireSnapshotsProcedure.java', 'RemoveOrphanFilesProcedure.java']"
Build: Upgrade Github Actions to `ubuntu-22.04` (#6272),15,48,2023-03-02 19:24:27+01:00,"['api-binary-compatibility.yml', 'delta-conversion-ci.yml', 'flink-ci.yml', 'hive-ci.yml', 'java-ci.yml', 'jmh-benchmarks.yml', 'labeler.yml', 'license_check.yml', 'open-api.yml', 'publish-snapshot.yml', 'python-ci-docs.yml', 'python-ci.yml', 'recurring-jmh-benchmarks.yml', 'spark-ci.yml', 'stale.yml']"
Core: Use Awaitility instead of Thread.sleep() for async testing (#6990),3,471,2023-03-02 12:29:19-08:00,"['build.gradle', 'TestRESTCatalog.java', 'versions.props']"
Docs: Update documentation for Spark AddFiles procedure (#6849),1,21,2023-03-02 13:58:41-08:00,['spark-procedures.md']
"Python: Config loading on windows (#7002)

* Python: fix config loading on windows

* Python: add backticks to docs

* Python: remove HOME env variable and us os.path.expanduser()

* Python: remove HOME env variable and use os.path.expanduser()

* Update config.py

---------

Co-authored-by: Isa.Inalcik <isa.inalcik@bestsecret.com>
Co-authored-by: Fokko Driesprong <fokko@apache.org>",2,7,2023-03-03 21:41:33+01:00,"['api.md', 'config.py']"
Build: Show API deprecation rules on RevAPI failure (#6999),1,20,2023-03-03 13:53:40-08:00,['build.gradle']
Flink: Set up EnvironmentContext for Flink(Both JM and TM) (#6936),9,116,2023-03-03 18:54:19-08:00,"['FlinkCatalog.java', 'FlinkEnvironmentContext.java', 'TableLoader.java', 'FlinkCatalog.java', 'FlinkEnvironmentContext.java', 'TableLoader.java', 'FlinkCatalog.java', 'FlinkEnvironmentContext.java', 'TableLoader.java']"
Spark 3.3: Add a procedure to create changelog view (#6012),5,733,2023-03-03 21:58:18-08:00,"['IcebergSqlExtensions.g4', 'TestCreateChangelogViewProcedure.java', 'BaseProcedure.java', 'CreateChangelogViewProcedure.java', 'SparkProcedures.java']"
"Python: Wrap FsspecFileIO in PyArrowFileIO (#6972)

* Python: Wrap FsspecFileIO in PyArrowFileIO

This allows us to read PyArrow tables using FsspecFileIO.
For ADLS users this allows them to pull data from ADLS.

* Add test

* Make CI happy",4,81,2023-03-04 10:19:58+01:00,"['fsspec.py', 'pyarrow.py', 'conftest.py', 'test_pyarrow.py']"
"Python: Pass location when recreating the FileIO (#6971)

We need to pass in the metadata location when we recreate
the file io for the table. We re-create the table because
there can be new configuration, but we don't supply the location.

This can cause issues when you have both PyArrow and FSspec
installed, you don't have the FileIO set explicitly in your config:

```yaml
catalog:
    default:
...
        py-io-impl: pyiceberg.io.fsspec.FsspecFileIO
```

When you fetch the metadata from ADLS using FSSpec,
but then the re-created FileIO is PyArrow.
When we pass in the url, the schema gets taken into
account and PyArrow won't be considered for ADLS.",5,18,2023-03-04 10:26:01+01:00,"['__init__.py', 'dynamodb.py', 'glue.py', 'hive.py', 'rest.py']"
"Python: Fix ADLS configuration (#6970)

The configuration keys weren't extracted according
to the documentation.",3,29,2023-03-04 10:28:33+01:00,"['configuration.md', 'fsspec.py', 'conftest.py']"
"Build: Bump pytest from 7.2.1 to 7.2.2 in /python (#7019)

Bumps [pytest](https://github.com/pytest-dev/pytest) from 7.2.1 to 7.2.2.
- [Release notes](https://github.com/pytest-dev/pytest/releases)
- [Changelog](https://github.com/pytest-dev/pytest/blob/main/CHANGELOG.rst)
- [Commits](https://github.com/pytest-dev/pytest/compare/7.2.1...7.2.2)

---
updated-dependencies:
- dependency-name: pytest
  dependency-type: direct:development
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,10,2023-03-05 17:50:06+01:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump duckdb from 0.7.0 to 0.7.1 in /python (#7018)

Bumps [duckdb](https://github.com/duckdb/duckdb) from 0.7.0 to 0.7.1.
- [Release notes](https://github.com/duckdb/duckdb/releases)
- [Changelog](https://github.com/duckdb/duckdb/blob/master/tools/release-pip.py)
- [Commits](https://github.com/duckdb/duckdb/compare/v0.7.0...v0.7.1)

---
updated-dependencies:
- dependency-name: duckdb
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,100,2023-03-05 18:50:38+01:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump pre-commit from 3.1.0 to 3.1.1 in /python (#7015),2,10,2023-03-05 19:20:51+01:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump rich from 13.3.1 to 13.3.2 in /python (#7016),2,14,2023-03-05 19:38:06+01:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump coverage from 7.2.0 to 7.2.1 in /python (#7017)

Bumps [coverage](https://github.com/nedbat/coveragepy) from 7.2.0 to 7.2.1.
- [Release notes](https://github.com/nedbat/coveragepy/releases)
- [Changelog](https://github.com/nedbat/coveragepy/blob/master/CHANGES.rst)
- [Commits](https://github.com/nedbat/coveragepy/compare/7.2.0...7.2.1)

---
updated-dependencies:
- dependency-name: coverage
  dependency-type: direct:development
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,108,2023-03-05 20:36:42+01:00,"['poetry.lock', 'pyproject.toml']"
Spark: Support snapshot_ids in expire snapshots procedure (#6992),8,204,2023-03-05 15:35:59-08:00,"['IcebergSqlExtensions.g4', 'TestExpireSnapshotsProcedure.java', 'ExpireSnapshotsProcedure.java', 'IcebergSqlExtensions.g4', 'TestExpireSnapshotsProcedure.java', 'ExpireSnapshotsProcedure.java', 'TestExpireSnapshotsProcedure.java', 'ExpireSnapshotsProcedure.java']"
"Build: Bump Gradle to 8.0.2 (#7006)

See https://docs.gradle.org/8.0.2/release-notes.html",2,12,2023-03-05 15:36:58-08:00,"['gradle-wrapper.properties', 'gradlew']"
Spark 3.3: Bug Fix for Metadata table Time Travel with Schema Evolution (#6980),2,76,2023-03-05 17:00:03-08:00,"['TestMetadataTables.java', 'SparkTable.java']"
Spark 3.2:  Bug Fix for Metadata table Time Travel with Schema Evolution (#6994),2,76,2023-03-05 17:01:33-08:00,"['TestMetadataTables.java', 'SparkTable.java']"
Spark 3.1: Bug Fix for Metadata table Time Travel with Schema Evolution (#6993),3,206,2023-03-05 17:02:26-08:00,"['TestMetadataTables.java', 'SparkTable.java', 'TestHelpers.java']"
"Python: Don't warn on an identifier (#6844)

When we pass in a warehouse identifier, we don't
want to emit a warning. Also, the help message won't
be helpful:

```
No preferred file implementation for scheme:
```

Since there is no scheme.",2,31,2023-03-06 08:47:13+01:00,"['__init__.py', 'test_io.py']"
Build: Fix flaky checkstyle issue (#7024),1,4,2023-03-06 08:42:12-08:00,['build.gradle']
Docs: Add expire_snapshots parameter snapshot_ids (#7028),1,7,2023-03-06 09:07:29-08:00,['spark-procedures.md']
Nessie: Upgrade nessie dependencies to 0.50.0 (#6875),1,2,2023-03-06 21:14:55+01:00,['versions.props']
Add support for SigV4 request signing to REST Catalog requests (#6951),8,503,2023-03-06 15:22:57-08:00,"['AwsProperties.java', 'RESTSigV4Signer.java', 'TestRESTSigV4Signer.java', 'build.gradle', 'HTTPClient.java', 'RESTCatalog.java', 'RESTSessionCatalog.java', 'TestHTTPClient.java']"
Build: Bump Nessie to 0.51.1 (#7031),2,10,2023-03-07 19:20:18+01:00,"['build.gradle', 'versions.props']"
Use UGI shortUserName as the default owner of Hive objects (#6955),2,31,2023-03-07 10:24:57-08:00,"['HiveHadoopUtil.java', 'TestHiveCatalog.java']"
Python: Allow setting the AWS Region (#6847),4,47,2023-03-07 10:43:26-08:00,"['configuration.md', '__init__.py', 'fsspec.py', 'pyarrow.py']"
Core: Allow dropping columns referenced in old sort orders (#6984),3,15,2023-03-07 12:56:31-08:00,"['SortOrderParser.java', 'TableMetadataParser.java', 'TestSortOrder.java']"
Core: Use token after config route for initial REST auth (#7035),1,5,2023-03-07 16:15:41-08:00,['RESTSessionCatalog.java']
Core: Add initialize method for MetricsReporter. (#7014),5,56,2023-03-07 16:59:15-08:00,"['MetricsReporter.java', 'BaseMetastoreCatalog.java', 'CatalogUtil.java', 'RESTSessionCatalog.java', 'TestCatalogUtil.java']"
"Spark 3.2: Add a procedure to create changelog view (#7036)

This change backports PR #6012 to Spark 3.2.",4,727,2023-03-07 20:51:54-08:00,"['TestCreateChangelogViewProcedure.java', 'BaseProcedure.java', 'CreateChangelogViewProcedure.java', 'SparkProcedures.java']"
"Update slack invite link (#7042)

follow up of https://github.com/apache/iceberg-docs/pull/200",1,2,2023-03-08 15:19:41+01:00,['iceberg_question.yml']
AWS: bump aws sdk version to 2.20.18 (#7003),9,79,2023-03-08 07:59:10-08:00,"['TestS3FileIO.java', 'TestS3InputStream.java', 'TestS3OutputStream.java', 'TestS3RestSigner.java', 'TestS3SignRequestParser.java', 'TestS3SignResponseParser.java', 'build.gradle', 'aws.md', 'versions.props']"
"Core, AWS: Allow disabling token refresh (#6837)

Deprecate AUTH_DEFAULT_REFRESH_ENABLED / Introduce TOKEN_REFRESH_ENABLED property",6,166,2023-03-08 08:34:10-08:00,"['S3V4RestSignerClient.java', 'CatalogProperties.java', 'RESTSessionCatalog.java', 'OAuth2Properties.java', 'OAuth2Util.java', 'TestRESTCatalog.java']"
"Core: Add InMemoryCatalog (#6927)

Co-authored-by: mayursrivastava <mayur.srivastava@twosigma.com>",2,388,2023-03-08 08:42:04-08:00,"['InMemoryCatalog.java', 'TestInMemoryCatalog.java']"
Core: ReachableFileUtil.versionHintLocation() should not fail for table location with just bucket name (#6913),2,15,2023-03-08 15:08:39-06:00,"['ReachableFileUtil.java', 'TestReachableFileUtil.java']"
"Flink: Add REST catalog shorthand (#7044)

* Flink: Add REST catalog shorthand

Currently I'm using the REST Catalog using a `catalog-impl`:

```sql
CREATE CATALOG my_catalog WITH (
  'type'='iceberg',
  'catalog-impl'='org.apache.iceberg.rest.RESTCatalog',
  'uri'='http://localhost:8181',
  's3.access-key-id'='admin',
  's3.secret-access-key'='password',
  's3.endpoint'='http://localhost:9000'
);
```

But it would be nicer to have the `catalog-type` shorthand:

```sql
CREATE CATALOG my_catalog WITH (
  'type'='iceberg',
  'catalog-type'='rest',
  'uri'='http://localhost:8181',
  's3.access-key-id'='admin',
  's3.secret-access-key'='password',
  's3.endpoint'='http://localhost:9000'
);
```

This PR adds this

* Cleanup

* Make the tests happy",5,209,2023-03-08 23:07:07+01:00,"['flink-getting-started.md', 'CatalogLoader.java', 'FlinkCatalogFactory.java', 'TestCatalogLoader.java', 'TestCatalogTableLoader.java']"
REST: Set metadata location for lazy load snapshot (#7051),1,1,2023-03-08 20:51:00-08:00,['RESTSessionCatalog.java']
Docs: `write.metadata.metrics.max-inferred-column-defaults` (#6870),1,89,2023-03-09 13:04:41-06:00,['configuration.md']
"Core: Remove compile-time Hadoop dependency for catalogs (#7049)

Using Configurable<Configuration> in catalog implementations requires
downstream users to have Hadoop on the classpath for compilation.",4,67,2023-03-09 15:13:58-08:00,"['revapi.yml', 'JdbcCatalog.java', 'RESTCatalog.java', 'RESTSessionCatalog.java']"
"Spark 3.2: Bulk delete support for actions (#7048)

This change backports PR #6682 to Spark 3.2.",6,200,2023-03-09 18:03:54-08:00,"['BaseSparkAction.java', 'DeleteOrphanFilesSparkAction.java', 'DeleteReachableFilesSparkAction.java', 'ExpireSnapshotsSparkAction.java', 'ExpireSnapshotsProcedure.java', 'RemoveOrphanFilesProcedure.java']"
Spark 3.3: Add ProcedureInput to simplify procedures (#7038),2,313,2023-03-09 19:28:33-08:00,"['CreateChangelogViewProcedure.java', 'ProcedureInput.java']"
Spark-3.3: Handle statistics files while expiring snapshots (#6091),7,231,2023-03-10 11:03:36-08:00,"['ExpireSnapshots.java', 'ReachableFileUtil.java', 'BaseExpireSnapshotsActionResult.java', 'TestExpireSnapshotsProcedure.java', 'BaseSparkAction.java', 'ExpireSnapshotsSparkAction.java', 'ExpireSnapshotsProcedure.java']"
Core: Allow customizing FileIO in REST catalog (#7064),2,46,2023-03-10 12:01:58-08:00,"['JdbcCatalog.java', 'RESTSessionCatalog.java']"
Spark 3.3: Remove deprecated methods in ExpireSnapshotsSparkAction (#7069),2,33,2023-03-10 12:34:30-08:00,"['ExpireSnapshotsSparkAction.java', 'TestExpireSnapshotsAction.java']"
Flink: Add REST catalog shorthand (#7053),4,189,2023-03-10 13:50:10-08:00,"['CatalogLoader.java', 'FlinkCatalogFactory.java', 'TestCatalogLoader.java', 'TestCatalogTableLoader.java']"
Flink 1.14: Add REST catalog shorthand (#7056),4,186,2023-03-10 13:50:41-08:00,"['CatalogLoader.java', 'FlinkCatalogFactory.java', 'TestCatalogLoader.java', 'TestCatalogTableLoader.java']"
Spark 3.3: Use ProcedureInput in AddFilesProcedure (#7068),2,67,2023-03-10 14:29:00-08:00,"['AddFilesProcedure.java', 'ProcedureInput.java']"
Spark: Minor fixes for CreateChangelogViewProcedure (#7072),4,56,2023-03-10 15:29:38-08:00,"['BaseProcedure.java', 'CreateChangelogViewProcedure.java', 'BaseProcedure.java', 'CreateChangelogViewProcedure.java']"
"Spark 3.3: Support write to branch through table identifier (#6965)

Co-authored-by: Namratha Mysore Keshavaprakash <nmk344@gmail.com>
Co-authored-by: Amogh Jahagirdar <jahamogh@amazon.com>",53,2528,2023-03-10 21:23:23-08:00,"['MergingSnapshotProducer.java', 'SnapshotProducer.java', 'SnapshotScan.java', 'SnapshotUtil.java', 'SparkRowLevelOperationsTestBase.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestDelete.java', 'TestMerge.java', 'TestMergeOnReadDelete.java', 'TestMergeOnReadMerge.java', 'TestMergeOnReadUpdate.java', 'TestUpdate.java', 'SparkCatalog.java', 'SparkReadConf.java', 'SparkWriteConf.java', 'BaseBatchReader.java', 'BaseReader.java', 'BaseRowReader.java', 'BatchDataReader.java', 'ChangelogRowReader.java', 'EqualityDeleteRowReader.java', 'PositionDeletesRowReader.java', 'RowDataReader.java', 'SparkBatch.java', 'SparkBatchQueryScan.java', 'SparkCopyOnWriteOperation.java', 'SparkCopyOnWriteScan.java', 'SparkInputPartition.java', 'SparkMicroBatchStream.java', 'SparkPartitioningAwareScan.java', 'SparkPositionDeltaOperation.java', 'SparkPositionDeltaWrite.java', 'SparkPositionDeltaWriteBuilder.java', 'SparkRowLevelOperationBuilder.java', 'SparkScan.java', 'SparkScanBuilder.java', 'SparkTable.java', 'SparkWrite.java', 'SparkWriteBuilder.java', 'SparkTestBaseWithCatalog.java', 'TestHelpers.java', 'TestBaseReader.java', 'TestChangelogReader.java', 'TestSparkDataWrite.java', 'TestSparkReaderDeletes.java', 'PartitionedWritesTestBase.java', 'TestPartitionedWrites.java', 'TestPartitionedWritesToBranch.java', 'TestUnpartitionedWrites.java', 'TestUnpartitionedWritesToBranch.java', 'UnpartitionedWritesTestBase.java']"
Spark 3.3: Add SparkStagedScan to replace SparkFilesScan (#6924),12,314,2023-03-10 21:26:34-08:00,"['TableScanUtil.java', 'FileScanTaskSetManager.java', 'ScanTaskSetManager.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkFilesScan.java', 'SparkFilesScanBuilder.java', 'SparkStagedScan.java', 'SparkStagedScanBuilder.java', 'SparkTable.java', 'TestPositionDeletesTable.java', 'TestSparkStagedScan.java']"
"Spark 3.2: Handle statistics files while expiring snapshots (#7074)

This change backports PR #6091 to Spark 3.2.",4,198,2023-03-10 21:32:10-08:00,"['TestExpireSnapshotsProcedure.java', 'BaseSparkAction.java', 'ExpireSnapshotsSparkAction.java', 'ExpireSnapshotsProcedure.java']"
Spark 3.2: Remove deprecated methods in ExpireSnapshotsSparkAction (#7078),2,33,2023-03-10 21:49:54-08:00,"['ExpireSnapshotsSparkAction.java', 'TestExpireSnapshotsAction.java']"
Spark 3.2: Add ProcedureInput to simplify procedures (#7076),2,313,2023-03-10 21:51:22-08:00,"['CreateChangelogViewProcedure.java', 'ProcedureInput.java']"
AWS: Simplify enabling S3 remote signing (#7080),2,106,2023-03-11 12:51:19-08:00,"['AwsProperties.java', 'TestAwsProperties.java']"
Flink: Update the docs (#7070),1,239,2023-03-11 16:36:33-08:00,['flink-getting-started.md']
"Build: Bump moto from 4.1.3 to 4.1.4 in /python (#7082)

Bumps [moto](https://github.com/getmoto/moto) from 4.1.3 to 4.1.4.
- [Release notes](https://github.com/getmoto/moto/releases)
- [Changelog](https://github.com/getmoto/moto/blob/master/CHANGELOG.md)
- [Commits](https://github.com/getmoto/moto/compare/4.1.3...4.1.4)

---
updated-dependencies:
- dependency-name: moto
  dependency-type: direct:development
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,10,2023-03-12 18:01:41+01:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump pydantic from 1.10.5 to 1.10.6 in /python (#7083)

Bumps [pydantic](https://github.com/pydantic/pydantic) from 1.10.5 to 1.10.6.
- [Release notes](https://github.com/pydantic/pydantic/releases)
- [Changelog](https://github.com/pydantic/pydantic/blob/v1.10.6/HISTORY.md)
- [Commits](https://github.com/pydantic/pydantic/compare/v1.10.5...v1.10.6)

---
updated-dependencies:
- dependency-name: pydantic
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,78,2023-03-12 19:31:32+01:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump fastavro from 1.7.2 to 1.7.3 in /python (#7084)

Bumps [fastavro](https://github.com/fastavro/fastavro) from 1.7.2 to 1.7.3.
- [Release notes](https://github.com/fastavro/fastavro/releases)
- [Changelog](https://github.com/fastavro/fastavro/blob/master/ChangeLog)
- [Commits](https://github.com/fastavro/fastavro/compare/1.7.2...1.7.3)

---
updated-dependencies:
- dependency-name: fastavro
  dependency-type: direct:development
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,58,2023-03-12 20:50:56+01:00,"['poetry.lock', 'pyproject.toml']"
Docs: Update nessie docs (#7060),1,5,2023-03-13 13:44:54+01:00,['nessie.md']
Core: Allow injecting client pool in JDBC catalog (#7087),1,37,2023-03-13 10:27:07-07:00,['JdbcCatalog.java']
"Tests: Deprecate AssertHelpers (#6977)

Point people to use `Assertions#assertThatThrownBy(..)` as it provides a more fluent way of asserting exceptions",1,44,2023-03-13 16:04:33-07:00,['AssertHelpers.java']
AWS: Do not create signer refresh executor when refresh is disabled (#7046),1,54,2023-03-13 16:08:01-07:00,['S3V4RestSignerClient.java']
Spark 3.3: Support write to WAP branch (#7050),9,377,2023-03-13 16:20:13-07:00,"['TestDelete.java', 'TestMerge.java', 'TestUpdate.java', 'SparkReadConf.java', 'SparkSQLProperties.java', 'SparkWriteConf.java', 'TestRemoveOrphanFilesAction.java', 'TestIcebergSourceTablesBase.java', 'TestPartitionedWritesToWapBranch.java']"
Core: Allow passing identity object through RESTSessionCatalog (#7088),3,58,2023-03-13 16:44:51-07:00,"['SessionCatalog.java', 'RESTCatalog.java', 'RESTSessionCatalog.java']"
Nessie: Remove compile-time Hadoop dependency (#7054),1,23,2023-03-14 09:37:55+01:00,['NessieCatalog.java']
"Core: Fix deprecation message (#7104)

This was supposed to be removed in the next minor release (rather than the next major release)",1,2,2023-03-14 13:47:21-07:00,['BaseMetadataTable.java']
"Python: Integration tests (#6398)

* Integration tests

* First version

* Add caching

* Add caching

* Restore pyproject

* WIP

* NaN seems to be broken

* WIP

* Coming along

* Cleanup

* Install duckdb

* Cleanup

* Revert changes to poetry

* Make it even nicer

* Revert unneeded change

* Update Spark version

* Make test passing

* comments",11,504,2023-03-15 20:04:53+01:00,"['python-integration.yml', 'Makefile', 'Dockerfile', 'docker-compose-integration.yml', 'entrypoint.sh', 'provision.py', 'spark-defaults.conf', 'pyarrow.py', '__init__.py', 'pyproject.toml', 'test_integration.py']"
Build: Update ORC to 1.8.3 (#7124),1,2,2023-03-16 00:56:38-05:00,['versions.props']
AWS: Use Apache HTTP client as default AWS HTTP client (#7119),2,13,2023-03-16 09:43:21-07:00,"['AwsProperties.java', 'aws.md']"
AWS: Enable virtual-host-style requests for MinioContainer (#7125),2,7,2023-03-16 09:45:44-07:00,"['MinioContainer.java', 'TestS3RestSigner.java']"
Flink: fix usage of lambda function with class not annotated with @FunctionalInterface,1,28,2023-03-16 11:00:34-07:00,['IcebergTableSink.java']
Flink: Bump to Flink 1.16.1 (#7057),2,4,2023-03-16 11:02:00-07:00,"['build.gradle', 'TestFlinkPackage.java']"
Build: Bump pre-commit from 3.1.1 to 3.2.0 in /python (#7141),2,10,2023-03-19 12:00:00+01:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump coverage from 7.2.1 to 7.2.2 in /python (#7142)

Bumps [coverage](https://github.com/nedbat/coveragepy) from 7.2.1 to 7.2.2.
- [Release notes](https://github.com/nedbat/coveragepy/releases)
- [Changelog](https://github.com/nedbat/coveragepy/blob/master/CHANGES.rst)
- [Commits](https://github.com/nedbat/coveragepy/compare/7.2.1...7.2.2)

---
updated-dependencies:
- dependency-name: coverage
  dependency-type: direct:development
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,108,2023-03-19 16:03:56+01:00,"['poetry.lock', 'pyproject.toml']"
Core: Use unknown report type for forward-compatibility (#7145),3,54,2023-03-20 08:36:44-07:00,"['ReportMetricsRequest.java', 'ReportMetricsRequestParser.java', 'TestReportMetricsRequestParser.java']"
Aliyun: Remove AssertHelpers (#7116),4,96,2023-03-20 11:09:04-07:00,"['TestOSSInputFile.java', 'TestOSSInputStream.java', 'TestOSSOutputFile.java', 'TestOSSURI.java']"
Dell: remove usage of AssertHelpers (#7143),4,81,2023-03-20 13:26:39-07:00,"['TestEcsCatalog.java', 'TestEcsOutputFile.java', 'TestEcsTableOperations.java', 'TestEcsURI.java']"
Core: Minor refactoring of PartitionsTable (#6975),6,43,2023-03-20 19:49:44-07:00,"['PartitionsTable.java', 'TestMetadataTableScans.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java']"
Build: Let RevAPI compare against 1.2.0 (#7155),1,2,2023-03-21 08:11:49-07:00,['build.gradle']
MR: Remove deprecated AssertHelpers (#7159),3,353,2023-03-21 09:34:43-07:00,"['TestCatalogs.java', 'TestIcebergInputFormats.java', 'TestHiveIcebergStorageHandlerNoScan.java']"
Core: Remove deprecated validation APIs (#7150),2,312,2023-03-21 11:42:27-07:00,"['revapi.yml', 'MergingSnapshotProducer.java']"
Data: Remove AssertHelpers usage (#7134),3,101,2023-03-21 11:43:32-07:00,"['TestGenericRecord.java', 'TestLocalScan.java', 'TestPartitioningWriters.java']"
Flink: implement clone methods for TableLoader and CatalogLoader to handle Closeable catalog like JDBC properly.,6,91,2023-03-21 13:11:40-07:00,"['CatalogLoader.java', 'TableLoader.java', 'IcebergSource.java', 'ContinuousSplitPlannerImpl.java', 'TestTableLoader.java', 'TestContinuousSplitPlannerImpl.java']"
Spark 3.3: Remove use of deprecated SparkFilesScan (#7106),10,210,2023-03-21 13:17:46-07:00,"['SparkReadConf.java', 'SparkReadOptions.java', 'SparkBinPackStrategy.java', 'SparkSortStrategy.java', 'SparkZOrderStrategy.java', 'SparkFilesScan.java', 'SparkFilesScanBuilder.java', 'SparkTable.java', 'TestFileRewriteCoordinator.java', 'TestRewriteDataFilesAction.java']"
Docs: Add `rest` to the catalog configuration (#7126),1,2,2023-03-21 13:59:00-07:00,['spark-configuration.md']
Contributing: Add section for testing code (#7131),1,80,2023-03-21 14:25:58-07:00,['CONTRIBUTING.md']
Python: Make Python CI collect most of the unit tests and Fix CI name conflict (#7136),5,44,2023-03-21 14:47:15-07:00,"['python-ci.yml', 'python-integration.yml', 'Makefile', 'conftest.py', 'test_pyarrow.py']"
"Core: Implement view version and parser (#6861)

Co-authored-by: John Zhuge <jzhuge@apache.org>",4,265,2023-03-21 17:30:00-07:00,"['revapi.yml', 'ViewVersion.java', 'ViewVersionParser.java', 'TestViewVersionParser.java']"
"API, Spark: Update defaults of max-concurrent-file-group-rewrites to 5 (#6907)",5,25,2023-03-22 12:00:03-05:00,"['revapi.yml', 'RewriteDataFiles.java', 'TestRewriteDataFilesAction.java', 'TestRewriteDataFilesAction.java', 'TestRewriteDataFilesAction.java']"
Flink: Fixed Cloneable not implemented on CatalogLoader (#7168),1,2,2023-03-22 11:04:08-07:00,['CatalogLoader.java']
Core: Refactor actions results (#7089),22,151,2023-03-22 15:06:38-07:00,"['DeleteOrphanFiles.java', 'DeleteReachableFiles.java', 'MigrateTable.java', 'RewriteDataFiles.java', 'RewriteManifests.java', 'SnapshotTable.java', 'BaseDeleteOrphanFilesActionResult.java', 'BaseDeleteReachableFilesActionResult.java', 'BaseExpireSnapshotsActionResult.java', 'BaseFileGroupRewriteResult.java', 'BaseMigrateTableActionResult.java', 'BaseRewriteDataFilesFileGroupInfo.java', 'BaseRewriteDataFilesResult.java', 'BaseRewriteManifestsActionResult.java', 'BaseSnapshotTableActionResult.java', 'RewriteFileGroup.java', 'DeleteOrphanFilesSparkAction.java', 'DeleteReachableFilesSparkAction.java', 'MigrateTableSparkAction.java', 'RewriteDataFilesSparkAction.java', 'RewriteManifestsSparkAction.java', 'SnapshotTableSparkAction.java']"
Docs: improve description of Glue catalog optimistic locking mechanism (#7167),1,2,2023-03-22 15:07:24-07:00,['aws.md']
Python: Update docker file (#7164),5,39,2023-03-22 15:32:08-07:00,"['iceberg_bug_report.yml', 'Dockerfile', 'docker-compose-integration.yml', 'docker-compose.yml', 'verify-release.md']"
API: Fix retainAll and removeAll in CharSequenceSet (#7133),2,58,2023-03-22 15:52:46-07:00,"['CharSequenceSet.java', 'TestCharSequenceSet.java']"
Spark 3.3: Support metadata column in the changelog table (#7152),2,39,2023-03-22 16:38:14-07:00,"['TestChangelogTable.java', 'SparkChangelogTable.java']"
"Spark 3.2: Support metadata column in the changelog table (#7178)

This change backports PR #7152 to Spark 3.2.",2,39,2023-03-22 19:58:15-07:00,"['TestChangelogTable.java', 'SparkChangelogTable.java']"
Flink: backport  #6614 to 1.15 (#7165),6,93,2023-03-22 20:54:32-07:00,"['CatalogLoader.java', 'TableLoader.java', 'IcebergSource.java', 'ContinuousSplitPlannerImpl.java', 'TestTableLoader.java', 'TestContinuousSplitPlannerImpl.java']"
Core: Remove deprecated code from 1.2.0 (#7156),18,391,2023-03-23 07:58:03-07:00,"['revapi.yml', 'S3V4RestSignerClient.java', 'BaseMetadataTable.java', 'BaseScan.java', 'CatalogProperties.java', 'DataTableScan.java', 'Partitioning.java', 'TableProperties.java', 'BaseExpireSnapshotsActionResult.java', 'JdbcCatalog.java', 'HTTPClient.java', 'RESTCatalog.java', 'RESTSessionCatalog.java', 'OAuth2Util.java', 'TestHTTPClient.java', 'TestRESTCatalog.java', 'BaseExpireSnapshotsSparkAction.java', 'BaseExpireSnapshotsSparkAction.java']"
Python: Add conversion from iceberg table scan to Ray dataset (#7148),8,528,2023-03-23 09:38:56-07:00,"['Makefile', 'provision.py', 'api.md', 'index.md', 'poetry.lock', '__init__.py', 'pyproject.toml', 'test_integration.py']"
"AWS: Support S3 Credentials provider with DefaultAwsClientFactory #7063 (#7066)

Allows dynamically loading a Credential Provider with the DefaultAwsClientFactory.

Co-authored-by: pani <ddhakshnamurthy@apple.com>",3,300,2023-03-23 13:13:48-05:00,"['AwsClientFactories.java', 'AwsProperties.java', 'TestAwsClientFactories.java']"
Core: Move InMemoryCatalog from test to core (#7185),17,53,2023-03-23 12:35:34-07:00,"['InMemoryCatalog.java', 'InMemoryFileIO.java', 'InMemoryInputFile.java', 'InMemoryOutputFile.java', 'TestManifestListVersions.java', 'TestManifestWriterVersions.java', 'TestScansAndSchemaEvolution.java', 'TestAvroDeleteWriters.java', 'TestGenericAvro.java', 'TestInMemoryFileIO.java', 'TestInMemoryInputFile.java', 'TestInMemoryOutputFile.java', 'TestIOUtil.java', 'TestPuffinReader.java', 'TestPuffinWriter.java', 'TestRESTCatalog.java', 'SnowflakeCatalogTest.java']"
"Docs: Reorganize Flink docs (#7099)

* Doc: Typeset Flink Doc

* Update docs/flink-actions.md

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* Update docs/flink-actions.md

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* Update docs/flink-queries.md

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* Update docs/flink-writes.md

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* Update docs/flink-writes.md

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* Update docs/flink-writes.md

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* Doc: Typeset Flink Doc

---------

Co-authored-by: Fokko Driesprong <fokko@apache.org>",6,1978,2023-03-23 21:25:17+01:00,"['flink-actions.md', 'flink-configuration.md', 'flink-ddl.md', 'flink-getting-started.md', 'flink-queries.md', 'flink-writes.md']"
Core: Store split offset for delete files (#7011),8,107,2023-03-23 18:26:49-07:00,"['DataFiles.java', 'FileMetadata.java', 'GenericDeleteFile.java', 'EqualityDeleteWriter.java', 'PositionDeleteWriter.java', 'TestManifestWriterVersions.java', 'TestSplitPlanning.java', 'TestPositionDeletesTable.java']"
Flink: Backport #6614 to Flink 1.14 (#7166),6,93,2023-03-23 20:28:37-07:00,"['CatalogLoader.java', 'TableLoader.java', 'IcebergSource.java', 'ContinuousSplitPlannerImpl.java', 'TestTableLoader.java', 'TestContinuousSplitPlannerImpl.java']"
"Python: Add limit to table scan (#7163)

* Python: Add support for ORC

Creates fragments based on the FileFormat.

Blocked by: https://github.com/apache/iceberg/pull/6997

* Revert

* TableScan add limit

* pyarrow limit number of rows fetched from files if limit is set

* add tests for scan limit

* python ci rebuild container if changes on python/dev/

* remove support for ORC

* remove unused imports

* increase sleep before running tests

* update python docs to include limit in table query

* docs fix format

---------

Co-authored-by: Fokko Driesprong <fokko@apache.org>
Co-authored-by: Daniel Rckert Garca <daniel@betterplaceapp.com>",8,146,2023-03-24 09:30:53+01:00,"['python-integration.yml', 'provision.py', 'api.md', 'files.py', 'pyarrow.py', 'manifest.py', '__init__.py', 'test_integration.py']"
Hive: Support customizable ClientPool (#6698),6,336,2023-03-24 09:55:32-07:00,"['build.gradle', 'CatalogProperties.java', 'CachedClientPool.java', 'HiveCatalog.java', 'TestCachedClientPool.java', 'TestLoadHiveCatalog.java']"
AWS: Remove deprecated AssertHelpers (#7195),7,219,2023-03-24 10:17:50-07:00,"['TestAwsClientFactories.java', 'TestAwsProperties.java', 'TestGlueCatalog.java', 'TestGlueToIcebergConverter.java', 'TestIcebergToGlueConverter.java', 'TestS3FileIO.java', 'TestS3URI.java']"
"Spark 3.2, 3.3: SparkSessionCatalog should delegate load function if Iceberg function is not found (#7153)",5,110,2023-03-25 20:15:58-05:00,"['SparkSessionCatalog.java', 'TestSparkSessionCatalog.java', 'SparkSessionCatalog.java', 'TestSparkSessionCatalog.java', 'TestSparkCatalog.java']"
Build: Bump moto from 4.1.4 to 4.1.5 in /python (#7203),2,28,2023-03-26 07:57:04+02:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump pre-commit from 3.2.0 to 3.2.1 in /python (#7204),2,10,2023-03-26 08:27:51+02:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump pydantic from 1.10.6 to 1.10.7 in /python (#7205),2,78,2023-03-26 11:51:38+02:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump ray from 2.3.0 to 2.3.1 in /python (#7206),2,56,2023-03-26 12:37:50+02:00,"['poetry.lock', 'pyproject.toml']"
Flink: Implement data statistics operator to collect traffic distribution for guiding smart shuffling (#6382),7,554,2023-03-27 21:09:39-07:00,"['DataStatisticsOperator.java', 'DataStatisticsOrRecord.java', 'DataStatistics.java', 'DataStatisticsFactory.java', 'MapDataStatistics.java', 'MapDataStatisticsFactory.java', 'TestDataStatisticsOperator.java']"
Build: Move RevApi breakage to correct version (#7223),1,10,2023-03-28 15:45:26-05:00,['revapi.yml']
"API, Core: Ability to add multiple metrics reporters to scans (#6919)",6,102,2023-03-29 12:17:48-07:00,"['BatchScanAdapter.java', 'Scan.java', 'BaseScan.java', 'SnapshotScan.java', 'TableScanContext.java', 'TestScanPlanningAndReporting.java']"
Spark 3.3: Use ProcedureInput in AncestorsOfProcedure (#7177),5,65,2023-03-29 12:19:02-07:00,"['TestAncestorsOfProcedure.java', 'AddFilesProcedure.java', 'AncestorsOfProcedure.java', 'CreateChangelogViewProcedure.java', 'ProcedureInput.java']"
Core: Parse snapshot-id as long in remove-statistics update (#7235),2,24,2023-03-30 08:10:54-07:00,"['MetadataUpdateParser.java', 'TestMetadataUpdateParser.java']"
Bump Nessie to 0.54.0 (#7146),8,323,2023-03-31 06:42:05+02:00,"['CatalogTests.java', 'NessieIcebergClient.java', 'BaseTestIceberg.java', 'TestBranchVisibility.java', 'TestNamespace.java', 'TestNessieCatalog.java', 'TestNessieTable.java', 'versions.props']"
"Arrow: Optimize vectorized read for Parquet decimal (#3249)

Co-authored-by: Xianyang Liu <xianyangliu@tencent.com>",7,385,2023-03-30 23:17:43-07:00,"['ArrowSchemaUtil.java', 'GenericArrowVectorAccessorFactory.java', 'VectorizedArrowReader.java', 'VectorizedColumnIterator.java', 'VectorizedPageIterator.java', 'ArrowSchemaUtilTest.java', 'VectorizedReadParquetDecimalBenchmark.java']"
Python: Relax the pin for `fsspec` implementations (#7242),2,699,2023-03-31 13:49:34+02:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump rich from 13.3.2 to 13.3.3 in /python (#7266),2,14,2023-04-02 13:26:17+02:00,"['poetry.lock', 'pyproject.toml']"
"Core: Improve bit density in object storage layout (#7128)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>
Co-authored-by: Ryan Blue <blue@apache.org>",1,26,2023-04-03 10:12:52-07:00,['LocationProviders.java']
AWS: Prevent token refresh scheduling on every sign request (#7270),3,114,2023-04-03 10:42:10-07:00,"['S3V4RestSignerClient.java', 'S3SignerServlet.java', 'TestS3RestSigner.java']"
AWS: Disable local credentials if remote signing is enabled (#7230),1,5,2023-04-03 12:06:36-07:00,['AwsProperties.java']
"Revert ""Spark: Add ""Iceberg"" prefix to SparkTable name string for SparkUI (#5629)"" (#7273)",2,12,2023-04-03 15:02:47-07:00,"['SparkTable.java', 'TestSparkTable.java']"
Spark: broadcast table instead of file IO in rewrite manifests (#7263),1,32,2023-04-03 20:38:42-07:00,['RewriteManifestsSparkAction.java']
"AWS: abort S3 input stream on close if not EOS (#7262)

* AWS: abort S3 input stream on close if not EOS

* Close the stream for backwards compatibility

* undo unrelated change

* add trace log

* comment update

* logger updates

* handle connection closed exception",1,25,2023-04-04 08:31:51-07:00,['S3InputStream.java']
Spark 3.2: Use ProcedureInput in AncestorsOfProcedure and AddFilesProcedure (#7260),5,126,2023-04-04 13:49:21-07:00,"['TestAncestorsOfProcedure.java', 'AddFilesProcedure.java', 'AncestorsOfProcedure.java', 'CreateChangelogViewProcedure.java', 'ProcedureInput.java']"
Spark 3.3: Dataset writes for position deletes (#7029),9,1428,2023-04-05 10:27:26-07:00,"['PositionDeletesTable.java', 'BaseFileRewriteCoordinator.java', 'FileRewriteCoordinator.java', 'PositionDeletesRewriteCoordinator.java', 'SparkPositionDeletesRewrite.java', 'SparkPositionDeletesRewriteBuilder.java', 'SparkTable.java', 'TestRewriteDataFilesAction.java', 'TestPositionDeletesTable.java']"
REST: fix previous locations for refs-only load (#7284),1,1,2023-04-05 15:51:40-07:00,['RESTSessionCatalog.java']
"Core: Fix flakiness in HadoopFileIOTest (#7253)

* Core: Fix flakiness in HadoopFileIOTest

Replaces non-thread-safe arraylist with thread-safe vector",1,5,2023-04-05 20:33:23-05:00,['HadoopFileIOTest.java']
Flink: Data statistics operator sends local data statistics to coordinator and receive aggregated data statistics from coordinator for smart shuffling (#7269),3,161,2023-04-06 08:11:45-07:00,"['DataStatisticsEvent.java', 'DataStatisticsOperator.java', 'TestDataStatisticsOperator.java']"
"AWS: Make AuthSession cache static (#7289)

Signer instances can be fairly short-lived, meaning that the
`AuthSession` cache doesn't get a chance to remove an `AuthSession` from
the cache and thus call `AuthSession#stopRefreshing()`.",1,48,2023-04-06 11:20:26-07:00,['S3V4RestSignerClient.java']
Core: Require namespace when creating table using InMemoryCatalog (#7252),2,23,2023-04-06 12:09:44-07:00,"['InMemoryCatalog.java', 'TestInMemoryCatalog.java']"
Core: Refactor PartitionsTable planning (#7190),5,284,2023-04-07 11:31:23-07:00,"['BaseScan.java', 'PartitionsTable.java', 'MetadataTableScanTestBase.java', 'TestMetadataTableScans.java', 'TestMetadataTableScansWithPartitionEvolution.java']"
"Python: Use Prettier to format TOML (#7248)

* Python: Use Prettier to format TOML and more files

* Python: Make Prettier skip the mkdocs admonoitions",12,188,2023-04-08 09:28:59+02:00,"['.pre-commit-config.yaml', 'docker-compose-azurite.yml', 'docker-compose-integration.yml', 'docker-compose.yml', 'api.md', 'configuration.md', 'contributing.md', 'feature-support.md', 'index.md', 'verify-release.md', 'mkdocs.yml', 'pyproject.toml']"
Flink: Remove Flink 1.14,238,41889,2023-04-08 08:05:34-07:00,"['flink-ci.yml', 'stage-binaries.sh', 'build.gradle', 'build.gradle', 'LICENSE', 'NOTICE', 'IcebergConnectorSmokeTest.java', 'CatalogLoader.java', 'FlinkCatalog.java', 'FlinkCatalogFactory.java', 'FlinkConfParser.java', 'FlinkConfigOptions.java', 'FlinkDynamicTableFactory.java', 'FlinkEnvironmentContext.java', 'FlinkFilters.java', 'FlinkFixupTypes.java', 'FlinkReadConf.java', 'FlinkReadOptions.java', 'FlinkSchemaUtil.java', 'FlinkTypeToType.java', 'FlinkTypeVisitor.java', 'FlinkWriteConf.java', 'FlinkWriteOptions.java', 'IcebergTableSink.java', 'IcebergTableSource.java', 'RowDataWrapper.java', 'TableLoader.java', 'TypeToFlinkType.java', 'Actions.java', 'RewriteDataFilesAction.java', 'AvroWithFlinkSchemaVisitor.java', 'FlinkAvroReader.java', 'FlinkAvroWriter.java', 'FlinkOrcReader.java', 'FlinkOrcReaders.java', 'FlinkOrcWriter.java', 'FlinkOrcWriters.java', 'FlinkParquetReaders.java', 'FlinkParquetWriters.java', 'FlinkSchemaVisitor.java', 'FlinkValueReaders.java', 'FlinkValueWriters.java', 'ParquetWithFlinkSchemaVisitor.java', 'RowDataProjection.java', 'RowDataUtil.java', 'StructRowData.java', 'AvroGenericRecordToRowDataMapper.java', 'BaseDeltaTaskWriter.java', 'CommitSummary.java', 'DeltaManifests.java', 'DeltaManifestsSerializer.java', 'EqualityFieldKeySelector.java', 'FlinkAppenderFactory.java', 'FlinkFileWriterFactory.java', 'FlinkManifestUtil.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'IcebergFilesCommitterMetrics.java', 'IcebergStreamWriter.java', 'IcebergStreamWriterMetrics.java', 'ManifestOutputFileFactory.java', 'PartitionKeySelector.java', 'PartitionedDeltaWriter.java', 'RowDataTaskWriterFactory.java', 'TaskWriterFactory.java', 'UnpartitionedDeltaWriter.java', 'AvroGenericRecordFileScanTaskReader.java', 'DataIterator.java', 'DataTaskReader.java', 'FileScanTaskReader.java', 'FlinkInputFormat.java', 'FlinkInputSplit.java', 'FlinkSource.java', 'FlinkSplitPlanner.java', 'IcebergSource.java', 'IcebergTableSource.java', 'RowDataFileScanTaskReader.java', 'RowDataRewriter.java', 'RowDataToAvroGenericRecordConverter.java', 'ScanContext.java', 'SourceUtil.java', 'StreamingMonitorFunction.java', 'StreamingReaderOperator.java', 'StreamingStartingStrategy.java', 'GetSplitResult.java', 'SimpleSplitAssigner.java', 'SimpleSplitAssignerFactory.java', 'SplitAssigner.java', 'SplitAssignerFactory.java', 'SplitAssignerType.java', 'AbstractIcebergEnumerator.java', 'ContinuousEnumerationResult.java', 'ContinuousIcebergEnumerator.java', 'ContinuousSplitPlanner.java', 'ContinuousSplitPlannerImpl.java', 'EnumerationHistory.java', 'IcebergEnumeratorPosition.java', 'IcebergEnumeratorPositionSerializer.java', 'IcebergEnumeratorState.java', 'IcebergEnumeratorStateSerializer.java', 'StaticIcebergEnumerator.java', 'ArrayBatchRecords.java', 'ArrayPoolDataIteratorBatcher.java', 'AvroGenericRecordReaderFunction.java', 'DataIteratorBatcher.java', 'DataIteratorReaderFunction.java', 'IcebergSourceReader.java', 'IcebergSourceReaderMetrics.java', 'IcebergSourceRecordEmitter.java', 'IcebergSourceSplitReader.java', 'ListBatchRecords.java', 'ListDataIteratorBatcher.java', 'MetaDataReaderFunction.java', 'ReaderFunction.java', 'RecordAndPosition.java', 'RecordFactory.java', 'RowDataReaderFunction.java', 'RowDataRecordFactory.java', 'IcebergSourceSplit.java', 'IcebergSourceSplitSerializer.java', 'IcebergSourceSplitState.java', 'IcebergSourceSplitStatus.java', 'SplitRequestEvent.java', 'FlinkCompatibilityUtil.java', 'FlinkPackage.java', 'org.apache.flink.table.factories.Factory', 'org.apache.flink.table.factories.TableFactory', 'AvroGenericRecordConverterBase.java', 'DataGenerator.java', 'DataGenerators.java', 'FlinkCatalogTestBase.java', 'FlinkTestBase.java', 'HadoopCatalogResource.java', 'HadoopTableResource.java', 'MiniClusterResource.java', 'RowDataConverter.java', 'SimpleDataUtil.java', 'TestCatalogLoader.java', 'TestCatalogTableLoader.java', 'TestChangeLogTable.java', 'TestDataFileSerialization.java', 'TestFixtures.java', 'TestFlinkCatalogDatabase.java', 'TestFlinkCatalogFactory.java', 'TestFlinkCatalogTable.java', 'TestFlinkCatalogTablePartitions.java', 'TestFlinkFilters.java', 'TestFlinkHiveCatalog.java', 'TestFlinkSchemaUtil.java', 'TestFlinkTableSink.java', 'TestFlinkUpsert.java', 'TestHelpers.java', 'TestIcebergConnector.java', 'TestManifestFileSerialization.java', 'TestRowDataWrapper.java', 'TestTableLoader.java', 'TestTableSerialization.java', 'TestRewriteDataFilesAction.java', 'RandomRowData.java', 'RowDataToRowMapper.java', 'TestFlinkAvroReaderWriter.java', 'TestFlinkOrcReaderWriter.java', 'TestFlinkParquetReader.java', 'TestFlinkParquetWriter.java', 'TestRowDataProjection.java', 'TestRowProjection.java', 'TestStructRowData.java', 'TestAvroGenericRecordToRowDataMapper.java', 'TestCompressionSettings.java', 'TestDeltaTaskWriter.java', 'TestFlinkAppenderFactory.java', 'TestFlinkFileWriterFactory.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkBase.java', 'TestFlinkIcebergSinkBranch.java', 'TestFlinkIcebergSinkV2.java', 'TestFlinkIcebergSinkV2Base.java', 'TestFlinkIcebergSinkV2Branch.java', 'TestFlinkManifest.java', 'TestFlinkPartitioningWriters.java', 'TestFlinkPositionDeltaWriters.java', 'TestFlinkRollingFileWriters.java', 'TestFlinkWriterMetrics.java', 'TestIcebergFilesCommitter.java', 'TestIcebergStreamWriter.java', 'TestRowDataPartitionKey.java', 'TestTaskWriters.java', 'BoundedTableFactory.java', 'BoundedTestSource.java', 'ChangeLogTableTestBase.java', 'SplitHelpers.java', 'SqlHelpers.java', 'TestBoundedTableFactory.java', 'TestFlinkInputFormat.java', 'TestFlinkInputFormatReaderDeletes.java', 'TestFlinkMergingMetrics.java', 'TestFlinkMetaDataTable.java', 'TestFlinkReaderDeletesBase.java', 'TestFlinkScan.java', 'TestFlinkScanSql.java', 'TestFlinkSource.java', 'TestFlinkSourceConfig.java', 'TestFlinkSourceSql.java', 'TestFlinkTableSource.java', 'TestIcebergSourceBounded.java', 'TestIcebergSourceBoundedGenericRecord.java', 'TestIcebergSourceBoundedSql.java', 'TestIcebergSourceContinuous.java', 'TestIcebergSourceFailover.java', 'TestIcebergSourceReaderDeletes.java', 'TestIcebergSourceSql.java', 'TestMetadataTableReadableMetrics.java', 'TestProjectMetaColumn.java', 'TestRowDataToAvroGenericRecordConverter.java', 'TestSourceUtil.java', 'TestSqlBase.java', 'TestStreamScanSql.java', 'TestStreamingMonitorFunction.java', 'TestStreamingReaderOperator.java', 'TestSimpleSplitAssigner.java', 'ManualContinuousSplitPlanner.java', 'TestContinuousIcebergEnumerator.java', 'TestContinuousSplitPlannerImpl.java', 'TestContinuousSplitPlannerImplStartStrategy.java', 'TestEnumerationHistory.java', 'TestIcebergEnumeratorStateSerializer.java', 'ReaderFunctionTestBase.java', 'ReaderUtil.java', 'TestArrayBatchRecords.java', 'TestArrayPoolDataIteratorBatcherRowData.java', 'TestIcebergSourceReader.java', 'TestRowDataReaderFunction.java', 'TestingMetricGroup.java', 'TestIcebergSourceSplitSerializer.java', 'TestFlinkPackage.java', 'org.apache.flink.table.factories.Factory', 'gradle.properties', 'settings.gradle']"
Flink: Move flink/v1.16 to flink/v1.17,240,0,2023-04-08 08:05:34-07:00,"['build.gradle', 'LICENSE', 'NOTICE', 'IcebergConnectorSmokeTest.java', 'CatalogLoader.java', 'FlinkCatalog.java', 'FlinkCatalogFactory.java', 'FlinkConfParser.java', 'FlinkConfigOptions.java', 'FlinkDynamicTableFactory.java', 'FlinkEnvironmentContext.java', 'FlinkFilters.java', 'FlinkFixupTypes.java', 'FlinkReadConf.java', 'FlinkReadOptions.java', 'FlinkSchemaUtil.java', 'FlinkTypeToType.java', 'FlinkTypeVisitor.java', 'FlinkWriteConf.java', 'FlinkWriteOptions.java', 'IcebergTableSink.java', 'RowDataWrapper.java', 'TableLoader.java', 'TypeToFlinkType.java', 'Actions.java', 'RewriteDataFilesAction.java', 'AvroWithFlinkSchemaVisitor.java', 'FlinkAvroReader.java', 'FlinkAvroWriter.java', 'FlinkOrcReader.java', 'FlinkOrcReaders.java', 'FlinkOrcWriter.java', 'FlinkOrcWriters.java', 'FlinkParquetReaders.java', 'FlinkParquetWriters.java', 'FlinkSchemaVisitor.java', 'FlinkValueReaders.java', 'FlinkValueWriters.java', 'ParquetWithFlinkSchemaVisitor.java', 'RowDataProjection.java', 'RowDataUtil.java', 'StructRowData.java', 'AvroGenericRecordToRowDataMapper.java', 'BaseDeltaTaskWriter.java', 'CommitSummary.java', 'DeltaManifests.java', 'DeltaManifestsSerializer.java', 'EqualityFieldKeySelector.java', 'FlinkAppenderFactory.java', 'FlinkFileWriterFactory.java', 'FlinkManifestUtil.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'IcebergFilesCommitterMetrics.java', 'IcebergStreamWriter.java', 'IcebergStreamWriterMetrics.java', 'ManifestOutputFileFactory.java', 'PartitionKeySelector.java', 'PartitionedDeltaWriter.java', 'RowDataTaskWriterFactory.java', 'TaskWriterFactory.java', 'UnpartitionedDeltaWriter.java', 'DataStatisticsEvent.java', 'DataStatisticsOperator.java', 'DataStatisticsOrRecord.java', 'DataStatistics.java', 'DataStatisticsFactory.java', 'MapDataStatistics.java', 'MapDataStatisticsFactory.java', 'AvroGenericRecordFileScanTaskReader.java', 'DataIterator.java', 'DataTaskReader.java', 'FileScanTaskReader.java', 'FlinkInputFormat.java', 'FlinkInputSplit.java', 'FlinkSource.java', 'FlinkSplitPlanner.java', 'IcebergSource.java', 'IcebergTableSource.java', 'RowDataFileScanTaskReader.java', 'RowDataRewriter.java', 'RowDataToAvroGenericRecordConverter.java', 'ScanContext.java', 'SourceUtil.java', 'StreamingMonitorFunction.java', 'StreamingReaderOperator.java', 'StreamingStartingStrategy.java', 'GetSplitResult.java', 'SimpleSplitAssigner.java', 'SimpleSplitAssignerFactory.java', 'SplitAssigner.java', 'SplitAssignerFactory.java', 'SplitAssignerType.java', 'AbstractIcebergEnumerator.java', 'ContinuousEnumerationResult.java', 'ContinuousIcebergEnumerator.java', 'ContinuousSplitPlanner.java', 'ContinuousSplitPlannerImpl.java', 'EnumerationHistory.java', 'IcebergEnumeratorPosition.java', 'IcebergEnumeratorPositionSerializer.java', 'IcebergEnumeratorState.java', 'IcebergEnumeratorStateSerializer.java', 'StaticIcebergEnumerator.java', 'ArrayBatchRecords.java', 'ArrayPoolDataIteratorBatcher.java', 'AvroGenericRecordReaderFunction.java', 'DataIteratorBatcher.java', 'DataIteratorReaderFunction.java', 'IcebergSourceReader.java', 'IcebergSourceReaderMetrics.java', 'IcebergSourceRecordEmitter.java', 'IcebergSourceSplitReader.java', 'ListBatchRecords.java', 'ListDataIteratorBatcher.java', 'MetaDataReaderFunction.java', 'ReaderFunction.java', 'RecordAndPosition.java', 'RecordFactory.java', 'RowDataReaderFunction.java', 'RowDataRecordFactory.java', 'IcebergSourceSplit.java', 'IcebergSourceSplitSerializer.java', 'IcebergSourceSplitState.java', 'IcebergSourceSplitStatus.java', 'SplitRequestEvent.java', 'FlinkCompatibilityUtil.java', 'FlinkPackage.java', 'org.apache.flink.table.factories.Factory', 'org.apache.flink.table.factories.TableFactory', 'AvroGenericRecordConverterBase.java', 'DataGenerator.java', 'DataGenerators.java', 'FlinkCatalogTestBase.java', 'FlinkTestBase.java', 'HadoopCatalogResource.java', 'HadoopTableResource.java', 'MiniClusterResource.java', 'RowDataConverter.java', 'SimpleDataUtil.java', 'TestCatalogLoader.java', 'TestCatalogTableLoader.java', 'TestChangeLogTable.java', 'TestDataFileSerialization.java', 'TestFixtures.java', 'TestFlinkCatalogDatabase.java', 'TestFlinkCatalogFactory.java', 'TestFlinkCatalogTable.java', 'TestFlinkCatalogTablePartitions.java', 'TestFlinkFilters.java', 'TestFlinkHiveCatalog.java', 'TestFlinkSchemaUtil.java', 'TestFlinkTableSink.java', 'TestFlinkUpsert.java', 'TestHelpers.java', 'TestIcebergConnector.java', 'TestManifestFileSerialization.java', 'TestRowDataWrapper.java', 'TestTableLoader.java', 'TestTableSerialization.java', 'TestRewriteDataFilesAction.java', 'RandomRowData.java', 'RowDataToRowMapper.java', 'TestFlinkAvroReaderWriter.java', 'TestFlinkOrcReaderWriter.java', 'TestFlinkParquetReader.java', 'TestFlinkParquetWriter.java', 'TestRowDataProjection.java', 'TestRowProjection.java', 'TestStructRowData.java', 'TestAvroGenericRecordToRowDataMapper.java', 'TestCompressionSettings.java', 'TestDeltaTaskWriter.java', 'TestFlinkAppenderFactory.java', 'TestFlinkFileWriterFactory.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkBase.java', 'TestFlinkIcebergSinkBranch.java', 'TestFlinkIcebergSinkV2.java', 'TestFlinkIcebergSinkV2Base.java', 'TestFlinkIcebergSinkV2Branch.java', 'TestFlinkManifest.java', 'TestFlinkPartitioningWriters.java', 'TestFlinkPositionDeltaWriters.java', 'TestFlinkRollingFileWriters.java', 'TestFlinkWriterMetrics.java', 'TestIcebergFilesCommitter.java', 'TestIcebergStreamWriter.java', 'TestRowDataPartitionKey.java', 'TestTaskWriters.java', 'TestDataStatisticsOperator.java', 'BoundedTableFactory.java', 'BoundedTestSource.java', 'ChangeLogTableTestBase.java', 'SplitHelpers.java', 'SqlHelpers.java', 'TestBoundedTableFactory.java', 'TestFlinkInputFormat.java', 'TestFlinkInputFormatReaderDeletes.java', 'TestFlinkMergingMetrics.java', 'TestFlinkMetaDataTable.java', 'TestFlinkReaderDeletesBase.java', 'TestFlinkScan.java', 'TestFlinkScanSql.java', 'TestFlinkSource.java', 'TestFlinkSourceConfig.java', 'TestFlinkSourceSql.java', 'TestFlinkTableSource.java', 'TestIcebergSourceBounded.java', 'TestIcebergSourceBoundedGenericRecord.java', 'TestIcebergSourceBoundedSql.java', 'TestIcebergSourceContinuous.java', 'TestIcebergSourceFailover.java', 'TestIcebergSourceReaderDeletes.java', 'TestIcebergSourceSql.java', 'TestMetadataTableReadableMetrics.java', 'TestProjectMetaColumn.java', 'TestRowDataToAvroGenericRecordConverter.java', 'TestSourceUtil.java', 'TestSqlBase.java', 'TestStreamScanSql.java', 'TestStreamingMonitorFunction.java', 'TestStreamingReaderOperator.java', 'TestSimpleSplitAssigner.java', 'ManualContinuousSplitPlanner.java', 'TestContinuousIcebergEnumerator.java', 'TestContinuousSplitPlannerImpl.java', 'TestContinuousSplitPlannerImplStartStrategy.java', 'TestEnumerationHistory.java', 'TestIcebergEnumeratorStateSerializer.java', 'ReaderFunctionTestBase.java', 'ReaderUtil.java', 'TestArrayBatchRecords.java', 'TestArrayPoolDataIteratorBatcherRowData.java', 'TestIcebergSourceReader.java', 'TestRowDataReaderFunction.java', 'TestingMetricGroup.java', 'TestIcebergSourceSplitSerializer.java', 'TestFlinkPackage.java', 'org.apache.flink.table.factories.Factory']"
Flink: Copy flink/1.16 files from flink/1.17,240,42307,2023-04-08 08:05:34-07:00,"['build.gradle', 'LICENSE', 'NOTICE', 'IcebergConnectorSmokeTest.java', 'CatalogLoader.java', 'FlinkCatalog.java', 'FlinkCatalogFactory.java', 'FlinkConfParser.java', 'FlinkConfigOptions.java', 'FlinkDynamicTableFactory.java', 'FlinkEnvironmentContext.java', 'FlinkFilters.java', 'FlinkFixupTypes.java', 'FlinkReadConf.java', 'FlinkReadOptions.java', 'FlinkSchemaUtil.java', 'FlinkTypeToType.java', 'FlinkTypeVisitor.java', 'FlinkWriteConf.java', 'FlinkWriteOptions.java', 'IcebergTableSink.java', 'RowDataWrapper.java', 'TableLoader.java', 'TypeToFlinkType.java', 'Actions.java', 'RewriteDataFilesAction.java', 'AvroWithFlinkSchemaVisitor.java', 'FlinkAvroReader.java', 'FlinkAvroWriter.java', 'FlinkOrcReader.java', 'FlinkOrcReaders.java', 'FlinkOrcWriter.java', 'FlinkOrcWriters.java', 'FlinkParquetReaders.java', 'FlinkParquetWriters.java', 'FlinkSchemaVisitor.java', 'FlinkValueReaders.java', 'FlinkValueWriters.java', 'ParquetWithFlinkSchemaVisitor.java', 'RowDataProjection.java', 'RowDataUtil.java', 'StructRowData.java', 'AvroGenericRecordToRowDataMapper.java', 'BaseDeltaTaskWriter.java', 'CommitSummary.java', 'DeltaManifests.java', 'DeltaManifestsSerializer.java', 'EqualityFieldKeySelector.java', 'FlinkAppenderFactory.java', 'FlinkFileWriterFactory.java', 'FlinkManifestUtil.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'IcebergFilesCommitterMetrics.java', 'IcebergStreamWriter.java', 'IcebergStreamWriterMetrics.java', 'ManifestOutputFileFactory.java', 'PartitionKeySelector.java', 'PartitionedDeltaWriter.java', 'RowDataTaskWriterFactory.java', 'TaskWriterFactory.java', 'UnpartitionedDeltaWriter.java', 'DataStatisticsEvent.java', 'DataStatisticsOperator.java', 'DataStatisticsOrRecord.java', 'DataStatistics.java', 'DataStatisticsFactory.java', 'MapDataStatistics.java', 'MapDataStatisticsFactory.java', 'AvroGenericRecordFileScanTaskReader.java', 'DataIterator.java', 'DataTaskReader.java', 'FileScanTaskReader.java', 'FlinkInputFormat.java', 'FlinkInputSplit.java', 'FlinkSource.java', 'FlinkSplitPlanner.java', 'IcebergSource.java', 'IcebergTableSource.java', 'RowDataFileScanTaskReader.java', 'RowDataRewriter.java', 'RowDataToAvroGenericRecordConverter.java', 'ScanContext.java', 'SourceUtil.java', 'StreamingMonitorFunction.java', 'StreamingReaderOperator.java', 'StreamingStartingStrategy.java', 'GetSplitResult.java', 'SimpleSplitAssigner.java', 'SimpleSplitAssignerFactory.java', 'SplitAssigner.java', 'SplitAssignerFactory.java', 'SplitAssignerType.java', 'AbstractIcebergEnumerator.java', 'ContinuousEnumerationResult.java', 'ContinuousIcebergEnumerator.java', 'ContinuousSplitPlanner.java', 'ContinuousSplitPlannerImpl.java', 'EnumerationHistory.java', 'IcebergEnumeratorPosition.java', 'IcebergEnumeratorPositionSerializer.java', 'IcebergEnumeratorState.java', 'IcebergEnumeratorStateSerializer.java', 'StaticIcebergEnumerator.java', 'ArrayBatchRecords.java', 'ArrayPoolDataIteratorBatcher.java', 'AvroGenericRecordReaderFunction.java', 'DataIteratorBatcher.java', 'DataIteratorReaderFunction.java', 'IcebergSourceReader.java', 'IcebergSourceReaderMetrics.java', 'IcebergSourceRecordEmitter.java', 'IcebergSourceSplitReader.java', 'ListBatchRecords.java', 'ListDataIteratorBatcher.java', 'MetaDataReaderFunction.java', 'ReaderFunction.java', 'RecordAndPosition.java', 'RecordFactory.java', 'RowDataReaderFunction.java', 'RowDataRecordFactory.java', 'IcebergSourceSplit.java', 'IcebergSourceSplitSerializer.java', 'IcebergSourceSplitState.java', 'IcebergSourceSplitStatus.java', 'SplitRequestEvent.java', 'FlinkCompatibilityUtil.java', 'FlinkPackage.java', 'org.apache.flink.table.factories.Factory', 'org.apache.flink.table.factories.TableFactory', 'AvroGenericRecordConverterBase.java', 'DataGenerator.java', 'DataGenerators.java', 'FlinkCatalogTestBase.java', 'FlinkTestBase.java', 'HadoopCatalogResource.java', 'HadoopTableResource.java', 'MiniClusterResource.java', 'RowDataConverter.java', 'SimpleDataUtil.java', 'TestCatalogLoader.java', 'TestCatalogTableLoader.java', 'TestChangeLogTable.java', 'TestDataFileSerialization.java', 'TestFixtures.java', 'TestFlinkCatalogDatabase.java', 'TestFlinkCatalogFactory.java', 'TestFlinkCatalogTable.java', 'TestFlinkCatalogTablePartitions.java', 'TestFlinkFilters.java', 'TestFlinkHiveCatalog.java', 'TestFlinkSchemaUtil.java', 'TestFlinkTableSink.java', 'TestFlinkUpsert.java', 'TestHelpers.java', 'TestIcebergConnector.java', 'TestManifestFileSerialization.java', 'TestRowDataWrapper.java', 'TestTableLoader.java', 'TestTableSerialization.java', 'TestRewriteDataFilesAction.java', 'RandomRowData.java', 'RowDataToRowMapper.java', 'TestFlinkAvroReaderWriter.java', 'TestFlinkOrcReaderWriter.java', 'TestFlinkParquetReader.java', 'TestFlinkParquetWriter.java', 'TestRowDataProjection.java', 'TestRowProjection.java', 'TestStructRowData.java', 'TestAvroGenericRecordToRowDataMapper.java', 'TestCompressionSettings.java', 'TestDeltaTaskWriter.java', 'TestFlinkAppenderFactory.java', 'TestFlinkFileWriterFactory.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkBase.java', 'TestFlinkIcebergSinkBranch.java', 'TestFlinkIcebergSinkV2.java', 'TestFlinkIcebergSinkV2Base.java', 'TestFlinkIcebergSinkV2Branch.java', 'TestFlinkManifest.java', 'TestFlinkPartitioningWriters.java', 'TestFlinkPositionDeltaWriters.java', 'TestFlinkRollingFileWriters.java', 'TestFlinkWriterMetrics.java', 'TestIcebergFilesCommitter.java', 'TestIcebergStreamWriter.java', 'TestRowDataPartitionKey.java', 'TestTaskWriters.java', 'TestDataStatisticsOperator.java', 'BoundedTableFactory.java', 'BoundedTestSource.java', 'ChangeLogTableTestBase.java', 'SplitHelpers.java', 'SqlHelpers.java', 'TestBoundedTableFactory.java', 'TestFlinkInputFormat.java', 'TestFlinkInputFormatReaderDeletes.java', 'TestFlinkMergingMetrics.java', 'TestFlinkMetaDataTable.java', 'TestFlinkReaderDeletesBase.java', 'TestFlinkScan.java', 'TestFlinkScanSql.java', 'TestFlinkSource.java', 'TestFlinkSourceConfig.java', 'TestFlinkSourceSql.java', 'TestFlinkTableSource.java', 'TestIcebergSourceBounded.java', 'TestIcebergSourceBoundedGenericRecord.java', 'TestIcebergSourceBoundedSql.java', 'TestIcebergSourceContinuous.java', 'TestIcebergSourceFailover.java', 'TestIcebergSourceReaderDeletes.java', 'TestIcebergSourceSql.java', 'TestMetadataTableReadableMetrics.java', 'TestProjectMetaColumn.java', 'TestRowDataToAvroGenericRecordConverter.java', 'TestSourceUtil.java', 'TestSqlBase.java', 'TestStreamScanSql.java', 'TestStreamingMonitorFunction.java', 'TestStreamingReaderOperator.java', 'TestSimpleSplitAssigner.java', 'ManualContinuousSplitPlanner.java', 'TestContinuousIcebergEnumerator.java', 'TestContinuousSplitPlannerImpl.java', 'TestContinuousSplitPlannerImplStartStrategy.java', 'TestEnumerationHistory.java', 'TestIcebergEnumeratorStateSerializer.java', 'ReaderFunctionTestBase.java', 'ReaderUtil.java', 'TestArrayBatchRecords.java', 'TestArrayPoolDataIteratorBatcherRowData.java', 'TestIcebergSourceReader.java', 'TestRowDataReaderFunction.java', 'TestingMetricGroup.java', 'TestIcebergSourceSplitSerializer.java', 'TestFlinkPackage.java', 'org.apache.flink.table.factories.Factory']"
Flink: Make flink 1.17 work,8,60,2023-04-08 08:05:34-07:00,"['flink-ci.yml', 'stage-binaries.sh', 'build.gradle', 'build.gradle', 'TestFlinkTableSource.java', 'TestFlinkPackage.java', 'gradle.properties', 'settings.gradle']"
Build: Bump coverage from 7.2.2 to 7.2.3 in /python (#7308),2,108,2023-04-09 08:05:09+02:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump pytest from 7.2.2 to 7.3.0 in /python (#7306),2,15,2023-04-09 08:19:27+02:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump pre-commit from 3.2.1 to 3.2.2 in /python (#7307),2,10,2023-04-09 08:38:46+02:00,"['poetry.lock', 'pyproject.toml']"
AWS: Check commit status after failed commit if AWS client performed retries (#7198),6,433,2023-04-10 14:04:11-07:00,"['GlueTestBase.java', 'TestGlueCatalogCommitFailure.java', 'DynamoDbTableOperations.java', 'GlueTableOperations.java', 'RetryDetector.java', 'TestRetryDetector.java']"
Core: Fix errorprone warning (#7286),2,3,2023-04-10 23:50:54+02:00,"['baseline.gradle', 'InMemoryInputFile.java']"
Build: Bump Nessie to 0.56.0 (#7283),2,46,2023-04-10 23:53:12+02:00,"['NessieTableOperations.java', 'versions.props']"
"Build: Bump actions/stale from 7.0.0 to 8.0.0 (#7200)

Bumps [actions/stale](https://github.com/actions/stale) from 7.0.0 to 8.0.0.
- [Release notes](https://github.com/actions/stale/releases)
- [Changelog](https://github.com/actions/stale/blob/main/CHANGELOG.md)
- [Commits](https://github.com/actions/stale/compare/v7.0.0...v8.0.0)

---
updated-dependencies:
- dependency-name: actions/stale
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-04-10 23:59:32+02:00,['stale.yml']
"Build: Bump org.apache.hadoop:hadoop-client from 3.3.4 to 3.3.5 (#7201)

Bumps org.apache.hadoop:hadoop-client from 3.3.4 to 3.3.5.

---
updated-dependencies:
- dependency-name: org.apache.hadoop:hadoop-client
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-04-11 00:01:51+02:00,['build.gradle']
"Spark 3.1, 3.2: Broadcast Table instead of FileIO in rewrite manifests (#7263) (#7296)

This change backports PR #7263 to Spark 3.1 and 3.2",5,115,2023-04-10 17:45:54-07:00,"['SparkUtil.java', 'BaseRewriteManifestsSparkAction.java', 'SparkUtil.java', 'RewriteManifestsSparkAction.java', 'SparkUtil.java']"
Build: `iceberg-delta-lake` Spark version to 3.3.2 (#7199),1,2,2023-04-11 09:25:44+02:00,['build.gradle']
"Nessie: Use latest hash for catalog APIs (#6789)

* Nessie: Handle refresh for catalog APIs that doesn't use table operations

* Add commit testcase

* Another test case

* Address comments

* Avoid hash roundtrip

* Address new comments

* refactor",3,250,2023-04-11 13:04:39+02:00,"['NessieIcebergClient.java', 'UpdateableReference.java', 'TestMultipleClients.java']"
Arrow: Support vectorized read of INT96 timestamp in imported data (#6962),14,429,2023-04-11 07:33:16-07:00,"['GenericArrowVectorAccessorFactory.java', 'VectorizedArrowReader.java', 'VectorizedColumnIterator.java', 'VectorizedDictionaryEncodedParquetValuesReader.java', 'VectorizedPageIterator.java', 'VectorizedParquetDefinitionLevelReader.java', 'ParquetUtil.java', 'SparkParquetReaders.java', 'SparkParquetReaders.java', 'SparkParquetReaders.java', 'SparkParquetReaders.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java']"
"Flink: Expose write-parallelism in SQL Hints (#7039)

Co-authored-by: chidayong <247070443@qq.com>",5,57,2023-04-11 08:45:35-07:00,"['flink-configuration.md', 'FlinkWriteConf.java', 'FlinkWriteOptions.java', 'FlinkSink.java', 'TestFlinkTableSink.java']"
Nessie: Fix testcase failures (#7320),1,6,2023-04-11 09:19:52-07:00,['TestMultipleClients.java']
Flink: move the classes from flink.sink.shuffle.statistics pkg to one level up as flink.sink.shuffle pkg (#7322),16,52,2023-04-11 11:16:50-07:00,"['DataStatistics.java', 'DataStatisticsEvent.java', 'DataStatisticsFactory.java', 'DataStatisticsOperator.java', 'DataStatisticsOrRecord.java', 'MapDataStatistics.java', 'MapDataStatisticsFactory.java', 'TestDataStatisticsOperator.java', 'DataStatistics.java', 'DataStatisticsEvent.java', 'DataStatisticsFactory.java', 'DataStatisticsOperator.java', 'DataStatisticsOrRecord.java', 'MapDataStatistics.java', 'MapDataStatisticsFactory.java', 'TestDataStatisticsOperator.java']"
Spark 3.3: Add doc for the changelog view procedure. (#7147),1,116,2023-04-11 13:39:01-07:00,['spark-procedures.md']
Build: Bump Nessie from 0.56.0 to 0.57.0 (#7323),1,2,2023-04-12 17:04:03+02:00,['versions.props']
Flink 1.15: Port Expose write-parallelism in SQL Hints to 1.15,4,56,2023-04-12 09:00:53-07:00,"['FlinkWriteConf.java', 'FlinkWriteOptions.java', 'FlinkSink.java', 'TestFlinkTableSink.java']"
Flink 1.17: Port Expose write-parallelism in SQL Hints to 1.17,4,56,2023-04-12 09:00:53-07:00,"['FlinkWriteConf.java', 'FlinkWriteOptions.java', 'FlinkSink.java', 'TestFlinkTableSink.java']"
Update issue template for 1.2.1 release (#7331),1,3,2023-04-12 12:14:12-07:00,['iceberg_bug_report.yml']
Core: Fix SnapshotProducer#targetBranch exception message (#7315),2,24,2023-04-12 15:01:03-07:00,"['SnapshotProducer.java', 'TestFastAppend.java']"
Build: Bump Gradle from 8.0.2 to 8.1 (#7333),1,4,2023-04-13 08:33:02-07:00,['gradle-wrapper.properties']
Build: Fix flaky checkstyle issue (#7321),10,41,2023-04-13 09:34:42-07:00,"['TestCloseableIterable.java', 'baseline.gradle', 'build.gradle', 'TestMetrics.java', 'DataGenerators.java', 'DataGenerators.java', 'DataGenerators.java', 'TestBloomRowGroupFilter.java', 'TestSparkReaderWithBloomFilter.java', 'TestSparkReaderWithBloomFilter.java']"
Infra: Update vote mail sample in source-release.sh (#7330),1,6,2023-04-13 10:31:25-07:00,['source-release.sh']
Core: Add missing metrics reporters when creating BaseTable (#7341),2,7,2023-04-13 10:38:08-07:00,"['BaseMetastoreCatalog.java', 'RESTSessionCatalog.java']"
"Core, Spark 3.3: Add FileRewriter API (#7175)",18,1528,2023-04-13 11:16:25-07:00,"['BinPackStrategy.java', 'FileRewriter.java', 'RewriteStrategy.java', 'SizeBasedDataRewriter.java', 'SizeBasedFileRewriter.java', 'SortStrategy.java', 'TestRewriteDataFilesProcedure.java', 'RewriteDataFilesSparkAction.java', 'SparkBinPackDataRewriter.java', 'SparkBinPackStrategy.java', 'SparkShufflingDataRewriter.java', 'SparkSizeBasedDataRewriter.java', 'SparkSortDataRewriter.java', 'SparkSortStrategy.java', 'SparkZOrderDataRewriter.java', 'SparkZOrderStrategy.java', 'TestRewriteDataFilesAction.java', 'TestSparkFileRewriter.java']"
Spark: Accept an `output-spec-id` to write to a desired partition spec (#7120),13,371,2023-04-13 12:00:55-07:00,"['SparkWriteConf.java', 'SparkWriteOptions.java', 'SparkWrite.java', 'TestPartitionedWrites.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'SparkWrite.java', 'TestPartitionedWrites.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'SparkWrite.java', 'PartitionedWritesTestBase.java', 'TestPartitionedWritesToWapBranch.java']"
"ORC, Spark 3.3: Support selected vector with ORC row and batch readers (#7197)",5,433,2023-04-14 18:16:37-07:00,"['OrcIterable.java', 'TestOrcDataReader.java', 'build.gradle', 'VectorizedSparkOrcReaders.java', 'TestVectorizedOrcDataReader.java']"
Flink: use correct scan mode when in TABLE_SCAN_THEN_INCREMENTAL mode (#7338),3,65,2023-04-15 20:58:29-07:00,"['FlinkSplitPlanner.java', 'ContinuousSplitPlannerImpl.java', 'TestIcebergSourceContinuous.java']"
"Build: Bump rich from 13.3.3 to 13.3.4 in /python (#7354)

Bumps [rich](https://github.com/Textualize/rich) from 13.3.3 to 13.3.4.
- [Release notes](https://github.com/Textualize/rich/releases)
- [Changelog](https://github.com/Textualize/rich/blob/master/CHANGELOG.md)
- [Commits](https://github.com/Textualize/rich/compare/v13.3.3...v13.3.4)

---
updated-dependencies:
- dependency-name: rich
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,10,2023-04-16 20:34:23+02:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump pytest from 7.3.0 to 7.3.1 in /python (#7355)

Bumps [pytest](https://github.com/pytest-dev/pytest) from 7.3.0 to 7.3.1.
- [Release notes](https://github.com/pytest-dev/pytest/releases)
- [Changelog](https://github.com/pytest-dev/pytest/blob/main/CHANGELOG.rst)
- [Commits](https://github.com/pytest-dev/pytest/compare/7.3.0...7.3.1)

---
updated-dependencies:
- dependency-name: pytest
  dependency-type: direct:development
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,10,2023-04-16 21:18:40+02:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump moto from 4.1.6 to 4.1.7 in /python (#7356)

Bumps [moto](https://github.com/getmoto/moto) from 4.1.6 to 4.1.7.
- [Release notes](https://github.com/getmoto/moto/releases)
- [Changelog](https://github.com/getmoto/moto/blob/master/CHANGELOG.md)
- [Commits](https://github.com/getmoto/moto/compare/4.1.6...4.1.7)

---
updated-dependencies:
- dependency-name: moto
  dependency-type: direct:development
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,10,2023-04-16 21:30:24+02:00,"['poetry.lock', 'pyproject.toml']"
AWS: Fix Glue catalog integration with SparkSessionCatalog (#7277),3,59,2023-04-17 12:01:50-07:00,"['GlueTableOperations.java', 'GlueToIcebergConverter.java', 'TestGlueToIcebergConverter.java']"
"Build: Bump Airlift from 0.21 to 0.24 (#7347)

They removed unnecessary links to the Hadoop codebase: https://github.com/airlift/aircompressor/commits/master",1,2,2023-04-17 13:36:18-07:00,['versions.props']
Docs: clarify Hive on Tez configuration (#7282),1,4,2023-04-18 06:36:37+02:00,['hive.md']
Spark: Simplify checks of output-spec-id in SparkWriteConf (#7348),3,29,2023-04-17 22:02:24-07:00,"['SparkWriteConf.java', 'SparkWriteConf.java', 'SparkWriteConf.java']"
"Core: Fix variable name in SetDefaultPartitionSpec (#7350)

Co-authored-by: Steve Zhang <hongyue_zhang@apple.com>",1,4,2023-04-17 23:22:26-07:00,['MetadataUpdate.java']
"Core, Spark: Make ObjectStoreLocationProvider serializable (#7353)",2,21,2023-04-18 11:30:50-07:00,"['LocationProviders.java', 'TestTableSerialization.java']"
Core: Parameterize RewriteDataFile's CommitService (#7343),3,388,2023-04-18 11:56:41-07:00,"['revapi.yml', 'BaseCommitService.java', 'RewriteDataFilesCommitManager.java']"
Core: Fix flaky TestParallelIterable test (#7372),1,18,2023-04-18 20:45:25-07:00,['TestParallelIterable.java']
"Flink: Apply row level filtering (#7109)

* Flink: Apply row level filtering

* Fix the tests

* Add test for case-sensitive

* Reduce duplication using a private method",15,187,2023-04-19 09:29:33+02:00,"['GenericAppenderHelper.java', 'FlinkSourceFilter.java', 'FlinkInputFormat.java', 'IcebergSource.java', 'RowDataFileScanTaskReader.java', 'RowDataRewriter.java', 'AvroGenericRecordReaderFunction.java', 'RowDataReaderFunction.java', 'TestFlinkScan.java', 'TestFlinkSource.java', 'TestIcebergSourceBounded.java', 'TestIcebergSourceBoundedGenericRecord.java', 'ReaderUtil.java', 'TestIcebergSourceReader.java', 'TestRowDataReaderFunction.java']"
Spark: Surface better error message during streaming planning when checkpoint snapshot not found (#6480),2,53,2023-04-19 12:53:52-07:00,"['SparkMicroBatchStream.java', 'TestStructuredStreamingRead3.java']"
Flink: backport #7338 to 1.16 and 1.15 (#7373),6,130,2023-04-19 13:15:33-07:00,"['FlinkSplitPlanner.java', 'ContinuousSplitPlannerImpl.java', 'TestIcebergSourceContinuous.java', 'FlinkSplitPlanner.java', 'ContinuousSplitPlannerImpl.java', 'TestIcebergSourceContinuous.java']"
Spark 3.4: Move 3.3 classes to 3.4 folder,482,0,2023-04-19 14:59:41-07:00,"['build.gradle', 'IcebergSqlExtensions.g4', 'IcebergSparkSessionExtensions.scala', 'ProjectingInternalRow.scala', 'AlignRowLevelCommandAssignments.scala', 'AlignedRowLevelIcebergCommandCheck.scala', 'AssignmentAlignmentSupport.scala', 'CheckMergeIntoTableConditions.scala', 'MergeIntoIcebergTableResolutionCheck.scala', 'ProcedureArgumentCoercion.scala', 'ResolveMergeIntoTableReferences.scala', 'ResolveProcedures.scala', 'RewriteDeleteFromIcebergTable.scala', 'RewriteMergeIntoTable.scala', 'RewriteRowLevelIcebergCommand.scala', 'RewriteUpdateTable.scala', 'AssignmentUtils.scala', 'ExtendedV2ExpressionUtils.scala', 'ExtendedReplaceNullWithFalseInPredicate.scala', 'ExtendedSimplifyConditionalsInPredicate.scala', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'RewrittenRowLevelCommand.scala', 'AddPartitionField.scala', 'BranchOptions.scala', 'Call.scala', 'CreateOrReplaceBranch.scala', 'CreateOrReplaceTag.scala', 'DeleteFromIcebergTable.scala', 'DropBranch.scala', 'DropIdentifierFields.scala', 'DropPartitionField.scala', 'DropTag.scala', 'MergeIntoIcebergTable.scala', 'MergeRows.scala', 'NoStatsUnaryNode.scala', 'ReplaceIcebergData.scala', 'ReplacePartitionField.scala', 'RowLevelCommand.scala', 'SetIdentifierFields.scala', 'TagOptions.scala', 'UnresolvedMergeIntoIcebergTable.scala', 'UpdateIcebergTable.scala', 'V2WriteCommandLike.scala', 'WriteDelta.scala', 'statements.scala', 'RowDeltaUtils.scala', 'WriteDeltaProjections.scala', 'TruncateTransform.scala', 'ExtendedLogicalWriteInfoImpl.scala', 'AddPartitionFieldExec.scala', 'CallExec.scala', 'CreateOrReplaceBranchExec.scala', 'CreateOrReplaceTagExec.scala', 'DropBranchExec.scala', 'DropIdentifierFieldsExec.scala', 'DropPartitionFieldExec.scala', 'DropTagExec.scala', 'ExtendedDataSourceV2Implicits.scala', 'ExtendedDataSourceV2Strategy.scala', 'ExtendedDistributionAndOrderingUtils.scala', 'ExtendedV2Writes.scala', 'MergeRowsExec.scala', 'OptimizeMetadataOnlyDeleteFromIcebergTable.scala', 'ReplaceDataExec.scala', 'ReplacePartitionFieldExec.scala', 'ReplaceRewrittenRowLevelCommand.scala', 'RowLevelCommandScanRelationPushDown.scala', 'SetIdentifierFieldsExec.scala', 'SetWriteDistributionAndOrderingExec.scala', 'WriteDeltaExec.scala', 'RowLevelCommandDynamicPruning.scala', 'Employee.java', 'SparkExtensionsTestBase.java', 'SparkRowLevelOperationsTestBase.java', 'TestAddFilesProcedure.java', 'TestAlterTablePartitionFields.java', 'TestAlterTableSchema.java', 'TestAncestorsOfProcedure.java', 'TestBranchDDL.java', 'TestCallStatementParser.java', 'TestChangelogTable.java', 'TestCherrypickSnapshotProcedure.java', 'TestConflictValidation.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestCreateChangelogViewProcedure.java', 'TestDelete.java', 'TestExpireSnapshotsProcedure.java', 'TestIcebergExpressions.java', 'TestMerge.java', 'TestMergeOnReadDelete.java', 'TestMergeOnReadMerge.java', 'TestMergeOnReadUpdate.java', 'TestMetadataTables.java', 'TestMigrateTableProcedure.java', 'TestPublishChangesProcedure.java', 'TestRegisterTableProcedure.java', 'TestRemoveOrphanFilesProcedure.java', 'TestReplaceBranch.java', 'TestRequiredDistributionAndOrdering.java', 'TestRewriteDataFilesProcedure.java', 'TestRewriteManifestsProcedure.java', 'TestRollbackToSnapshotProcedure.java', 'TestRollbackToTimestampProcedure.java', 'TestSetCurrentSnapshotProcedure.java', 'TestSetWriteDistributionAndOrdering.java', 'TestSnapshotTableProcedure.java', 'TestStoragePartitionedJoinsInRowLevelOperations.java', 'TestTagDDL.java', 'TestUpdate.java', 'TestWriteAborts.java', 'LICENSE', 'NOTICE', 'SmokeTest.java', 'SparkBenchmarkUtil.java', 'DeleteOrphanFilesBenchmark.java', 'IcebergSortCompactionBenchmark.java', 'RandomGeneratingUDF.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'Action.java', 'IcebergSourceBenchmark.java', 'IcebergSourceDeleteBenchmark.java', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'IcebergSourceNestedListDataBenchmark.java', 'WritersBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'IcebergSourceParquetEqDeleteBenchmark.java', 'IcebergSourceParquetMultiDeleteFileBenchmark.java', 'IcebergSourceParquetPosDeleteBenchmark.java', 'IcebergSourceParquetWithUnrelatedDeleteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'VectorizedReadParquetDecimalBenchmark.java', 'BaseCatalog.java', 'BaseFileRewriteCoordinator.java', 'ChangelogIterator.java', 'CommitMetadata.java', 'ExtendedParser.java', 'FileRewriteCoordinator.java', 'FileScanTaskSetManager.java', 'IcebergSpark.java', 'JobGroupInfo.java', 'JobGroupUtils.java', 'PathIdentifier.java', 'PositionDeletesRewriteCoordinator.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'RollbackStagedTable.java', 'ScanTaskSetManager.java', 'SortOrderToSpark.java', 'Spark3Util.java', 'SparkAggregates.java', 'SparkCachedTableCatalog.java', 'SparkCatalog.java', 'SparkConfParser.java', 'SparkDataFile.java', 'SparkDistributionAndOrderingUtil.java', 'SparkExceptionUtil.java', 'SparkFilters.java', 'SparkFixupTimestampType.java', 'SparkFixupTypes.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkSQLProperties.java', 'SparkSchemaUtil.java', 'SparkSessionCatalog.java', 'SparkStructLike.java', 'SparkTableCache.java', 'SparkTableUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'SparkUtil.java', 'SparkV2Filters.java', 'SparkValueConverter.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'TypeToSparkType.java', 'BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java', 'BaseTableCreationSparkAction.java', 'DeleteOrphanFilesSparkAction.java', 'DeleteReachableFilesSparkAction.java', 'ExpireSnapshotsSparkAction.java', 'FileInfo.java', 'ManifestFileBean.java', 'MigrateTableSparkAction.java', 'RewriteDataFilesSparkAction.java', 'RewriteManifestsSparkAction.java', 'SetAccumulator.java', 'SnapshotTableSparkAction.java', 'SparkActions.java', 'SparkBinPackDataRewriter.java', 'SparkBinPackStrategy.java', 'SparkShufflingDataRewriter.java', 'SparkSizeBasedDataRewriter.java', 'SparkSortDataRewriter.java', 'SparkSortStrategy.java', 'SparkZOrderDataRewriter.java', 'SparkZOrderStrategy.java', 'SparkZOrderUDF.java', 'AvroWithSparkSchemaVisitor.java', 'ParquetWithSparkSchemaVisitor.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'ArrowVectorAccessorFactory.java', 'ArrowVectorAccessors.java', 'ColumnVectorBuilder.java', 'ColumnVectorWithFilter.java', 'ColumnarBatchReader.java', 'ConstantColumnVector.java', 'DeletedColumnVector.java', 'IcebergArrowColumnVector.java', 'RowPositionColumnVector.java', 'VectorizedSparkOrcReaders.java', 'VectorizedSparkParquetReaders.java', 'BucketFunction.java', 'DaysFunction.java', 'HoursFunction.java', 'IcebergVersionFunction.java', 'MonthsFunction.java', 'SparkFunctions.java', 'TruncateFunction.java', 'UnaryUnboundFunction.java', 'YearsFunction.java', 'AddFilesProcedure.java', 'AncestorsOfProcedure.java', 'BaseProcedure.java', 'CherrypickSnapshotProcedure.java', 'CreateChangelogViewProcedure.java', 'ExpireSnapshotsProcedure.java', 'MigrateTableProcedure.java', 'ProcedureInput.java', 'PublishChangesProcedure.java', 'RegisterTableProcedure.java', 'RemoveOrphanFilesProcedure.java', 'RewriteDataFilesProcedure.java', 'RewriteManifestsProcedure.java', 'RollbackToSnapshotProcedure.java', 'RollbackToTimestampProcedure.java', 'SetCurrentSnapshotProcedure.java', 'SnapshotTableProcedure.java', 'SparkProcedures.java', 'BaseBatchReader.java', 'BaseReader.java', 'BaseRowReader.java', 'BatchDataReader.java', 'ChangelogRowReader.java', 'EqualityDeleteRowReader.java', 'HasIcebergCatalog.java', 'IcebergSource.java', 'InternalRowWrapper.java', 'PositionDeletesRowReader.java', 'RowDataReader.java', 'SerializableTableWithSize.java', 'SparkAppenderFactory.java', 'SparkBatch.java', 'SparkBatchQueryScan.java', 'SparkChangelogScan.java', 'SparkChangelogTable.java', 'SparkCleanupUtil.java', 'SparkColumnarReaderFactory.java', 'SparkCopyOnWriteOperation.java', 'SparkCopyOnWriteScan.java', 'SparkFileWriterFactory.java', 'SparkInputPartition.java', 'SparkLocalScan.java', 'SparkMetadataColumn.java', 'SparkMicroBatchStream.java', 'SparkPartitionedFanoutWriter.java', 'SparkPartitionedWriter.java', 'SparkPartitioningAwareScan.java', 'SparkPositionDeletesRewrite.java', 'SparkPositionDeletesRewriteBuilder.java', 'SparkPositionDeltaOperation.java', 'SparkPositionDeltaWrite.java', 'SparkPositionDeltaWriteBuilder.java', 'SparkRowLevelOperationBuilder.java', 'SparkRowReaderFactory.java', 'SparkScan.java', 'SparkScanBuilder.java', 'SparkStagedScan.java', 'SparkStagedScanBuilder.java', 'SparkTable.java', 'SparkWrite.java', 'SparkWriteBuilder.java', 'StagedSparkTable.java', 'Stats.java', 'StreamingOffset.java', 'StructInternalRow.java', 'NumDeletes.java', 'NumSplits.java', 'TaskNumDeletes.java', 'TaskNumSplits.java', 'NoSuchProcedureException.java', 'Procedure.java', 'ProcedureCatalog.java', 'ProcedureParameter.java', 'ProcedureParameterImpl.java', 'DeltaBatchWrite.java', 'DeltaWrite.java', 'DeltaWriteBuilder.java', 'DeltaWriter.java', 'DeltaWriterFactory.java', 'ExtendedLogicalWriteInfo.java', 'SupportsDelta.java', 'org.apache.spark.sql.sources.DataSourceRegister', 'TransformExpressions.scala', 'SetWriteDistributionAndOrdering.scala', 'SortOrderParserUtil.scala', 'DistributionAndOrderingUtils.scala', 'PlanUtils.scala', 'SparkExpressionConverter.scala', 'KryoHelpers.java', 'TaskCheckHelper.java', 'TestDataFileSerialization.java', 'TestFileIOSerialization.java', 'TestHadoopMetricsContextSerialization.java', 'TestManifestFileSerialization.java', 'TestScanTaskSerialization.java', 'TestTableSerialization.java', 'ValidationHelpers.java', 'SparkCatalogConfig.java', 'SparkCatalogTestBase.java', 'SparkTestBase.java', 'SparkTestBaseWithCatalog.java', 'SparkTestHelperBase.java', 'TestChangelogIterator.java', 'TestFileRewriteCoordinator.java', 'TestFunctionCatalog.java', 'TestSpark3Util.java', 'TestSparkCachedTableCatalog.java', 'TestSparkCatalogOperations.java', 'TestSparkDistributionAndOrderingUtil.java', 'TestSparkFilters.java', 'TestSparkSchemaUtil.java', 'TestSparkSessionCatalog.java', 'TestSparkTableUtil.java', 'TestSparkV2Filters.java', 'TestSparkValueConverter.java', 'TestSparkWriteConf.java', 'TestCreateActions.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction3.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'TestSparkFileRewriter.java', 'AvroDataTest.java', 'GenericsHelpers.java', 'RandomData.java', 'TestHelpers.java', 'TestOrcWrite.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkAvroEnums.java', 'TestSparkAvroReader.java', 'TestSparkDateTimes.java', 'TestSparkOrcReadMetadataColumns.java', 'TestSparkOrcReader.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkParquetReader.java', 'TestSparkParquetWriter.java', 'TestSparkRecordOrcReaderWriter.java', 'TestVectorizedOrcDataReader.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryFallbackToPlainEncodingVectorizedReads.java', 'TestParquetVectorizedReads.java', 'ComplexRecord.java', 'FilePathLastModifiedRecord.java', 'LogMessage.java', 'ManualSource.java', 'NestedRecord.java', 'SimpleRecord.java', 'SparkSQLExecutionHelper.java', 'TestAvroScan.java', 'TestBaseReader.java', 'TestChangelogReader.java', 'TestDataFrameWriterV2.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestFilteredScan.java', 'TestForwardCompatibility.java', 'TestIcebergSource.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSpark.java', 'TestIdentityPartitionData.java', 'TestInternalRowWrapper.java', 'TestMetadataTableReadableMetrics.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestParquetScan.java', 'TestPartitionPruning.java', 'TestPartitionValues.java', 'TestPathIdentifier.java', 'TestPositionDeletesTable.java', 'TestReadProjection.java', 'TestRequiredDistributionAndOrdering.java', 'TestRuntimeFiltering.java', 'TestSnapshotSelection.java', 'TestSparkAggregates.java', 'TestSparkAppenderFactory.java', 'TestSparkCatalog.java', 'TestSparkCatalogCacheExpiration.java', 'TestSparkCatalogHadoopOverrides.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestSparkFileWriterFactory.java', 'TestSparkMergingMetrics.java', 'TestSparkMetadataColumns.java', 'TestSparkPartitioningWriters.java', 'TestSparkPositionDeltaWriters.java', 'TestSparkReadProjection.java', 'TestSparkReaderDeletes.java', 'TestSparkReaderWithBloomFilter.java', 'TestSparkRollingFileWriters.java', 'TestSparkScan.java', 'TestSparkStagedScan.java', 'TestSparkTable.java', 'TestSparkWriterMetrics.java', 'TestStreamingOffset.java', 'TestStructuredStreaming.java', 'TestStructuredStreamingRead3.java', 'TestTables.java', 'TestTimestampWithoutZone.java', 'TestWriteMetricsConfig.java', 'ThreeColumnRecord.java', 'PartitionedWritesTestBase.java', 'TestAggregatePushDown.java', 'TestAlterTable.java', 'TestCreateTable.java', 'TestCreateTableAsSelect.java', 'TestDeleteFrom.java', 'TestDropTable.java', 'TestFilterPushDown.java', 'TestNamespaceSQL.java', 'TestPartitionedWrites.java', 'TestPartitionedWritesAsSelect.java', 'TestPartitionedWritesToBranch.java', 'TestPartitionedWritesToWapBranch.java', 'TestRefreshTable.java', 'TestSelect.java', 'TestSparkBucketFunction.java', 'TestSparkDaysFunction.java', 'TestSparkHoursFunction.java', 'TestSparkMonthsFunction.java', 'TestSparkTruncateFunction.java', 'TestSparkYearsFunction.java', 'TestStoragePartitionedJoins.java', 'TestTimestampWithoutZone.java', 'TestUnpartitionedWrites.java', 'TestUnpartitionedWritesToBranch.java', 'UnpartitionedWritesTestBase.java']"
Spark 3.3: Copy 3.3 classes back,482,103746,2023-04-19 14:59:41-07:00,"['build.gradle', 'IcebergSqlExtensions.g4', 'IcebergSparkSessionExtensions.scala', 'ProjectingInternalRow.scala', 'AlignRowLevelCommandAssignments.scala', 'AlignedRowLevelIcebergCommandCheck.scala', 'AssignmentAlignmentSupport.scala', 'CheckMergeIntoTableConditions.scala', 'MergeIntoIcebergTableResolutionCheck.scala', 'ProcedureArgumentCoercion.scala', 'ResolveMergeIntoTableReferences.scala', 'ResolveProcedures.scala', 'RewriteDeleteFromIcebergTable.scala', 'RewriteMergeIntoTable.scala', 'RewriteRowLevelIcebergCommand.scala', 'RewriteUpdateTable.scala', 'AssignmentUtils.scala', 'ExtendedV2ExpressionUtils.scala', 'ExtendedReplaceNullWithFalseInPredicate.scala', 'ExtendedSimplifyConditionalsInPredicate.scala', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'RewrittenRowLevelCommand.scala', 'AddPartitionField.scala', 'BranchOptions.scala', 'Call.scala', 'CreateOrReplaceBranch.scala', 'CreateOrReplaceTag.scala', 'DeleteFromIcebergTable.scala', 'DropBranch.scala', 'DropIdentifierFields.scala', 'DropPartitionField.scala', 'DropTag.scala', 'MergeIntoIcebergTable.scala', 'MergeRows.scala', 'NoStatsUnaryNode.scala', 'ReplaceIcebergData.scala', 'ReplacePartitionField.scala', 'RowLevelCommand.scala', 'SetIdentifierFields.scala', 'TagOptions.scala', 'UnresolvedMergeIntoIcebergTable.scala', 'UpdateIcebergTable.scala', 'V2WriteCommandLike.scala', 'WriteDelta.scala', 'statements.scala', 'RowDeltaUtils.scala', 'WriteDeltaProjections.scala', 'TruncateTransform.scala', 'ExtendedLogicalWriteInfoImpl.scala', 'AddPartitionFieldExec.scala', 'CallExec.scala', 'CreateOrReplaceBranchExec.scala', 'CreateOrReplaceTagExec.scala', 'DropBranchExec.scala', 'DropIdentifierFieldsExec.scala', 'DropPartitionFieldExec.scala', 'DropTagExec.scala', 'ExtendedDataSourceV2Implicits.scala', 'ExtendedDataSourceV2Strategy.scala', 'ExtendedDistributionAndOrderingUtils.scala', 'ExtendedV2Writes.scala', 'MergeRowsExec.scala', 'OptimizeMetadataOnlyDeleteFromIcebergTable.scala', 'ReplaceDataExec.scala', 'ReplacePartitionFieldExec.scala', 'ReplaceRewrittenRowLevelCommand.scala', 'RowLevelCommandScanRelationPushDown.scala', 'SetIdentifierFieldsExec.scala', 'SetWriteDistributionAndOrderingExec.scala', 'WriteDeltaExec.scala', 'RowLevelCommandDynamicPruning.scala', 'Employee.java', 'SparkExtensionsTestBase.java', 'SparkRowLevelOperationsTestBase.java', 'TestAddFilesProcedure.java', 'TestAlterTablePartitionFields.java', 'TestAlterTableSchema.java', 'TestAncestorsOfProcedure.java', 'TestBranchDDL.java', 'TestCallStatementParser.java', 'TestChangelogTable.java', 'TestCherrypickSnapshotProcedure.java', 'TestConflictValidation.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestCreateChangelogViewProcedure.java', 'TestDelete.java', 'TestExpireSnapshotsProcedure.java', 'TestIcebergExpressions.java', 'TestMerge.java', 'TestMergeOnReadDelete.java', 'TestMergeOnReadMerge.java', 'TestMergeOnReadUpdate.java', 'TestMetadataTables.java', 'TestMigrateTableProcedure.java', 'TestPublishChangesProcedure.java', 'TestRegisterTableProcedure.java', 'TestRemoveOrphanFilesProcedure.java', 'TestReplaceBranch.java', 'TestRequiredDistributionAndOrdering.java', 'TestRewriteDataFilesProcedure.java', 'TestRewriteManifestsProcedure.java', 'TestRollbackToSnapshotProcedure.java', 'TestRollbackToTimestampProcedure.java', 'TestSetCurrentSnapshotProcedure.java', 'TestSetWriteDistributionAndOrdering.java', 'TestSnapshotTableProcedure.java', 'TestStoragePartitionedJoinsInRowLevelOperations.java', 'TestTagDDL.java', 'TestUpdate.java', 'TestWriteAborts.java', 'LICENSE', 'NOTICE', 'SmokeTest.java', 'SparkBenchmarkUtil.java', 'DeleteOrphanFilesBenchmark.java', 'IcebergSortCompactionBenchmark.java', 'RandomGeneratingUDF.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'Action.java', 'IcebergSourceBenchmark.java', 'IcebergSourceDeleteBenchmark.java', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'IcebergSourceNestedListDataBenchmark.java', 'WritersBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'IcebergSourceParquetEqDeleteBenchmark.java', 'IcebergSourceParquetMultiDeleteFileBenchmark.java', 'IcebergSourceParquetPosDeleteBenchmark.java', 'IcebergSourceParquetWithUnrelatedDeleteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'VectorizedReadParquetDecimalBenchmark.java', 'BaseCatalog.java', 'BaseFileRewriteCoordinator.java', 'ChangelogIterator.java', 'CommitMetadata.java', 'ExtendedParser.java', 'FileRewriteCoordinator.java', 'FileScanTaskSetManager.java', 'IcebergSpark.java', 'JobGroupInfo.java', 'JobGroupUtils.java', 'PathIdentifier.java', 'PositionDeletesRewriteCoordinator.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'RollbackStagedTable.java', 'ScanTaskSetManager.java', 'SortOrderToSpark.java', 'Spark3Util.java', 'SparkAggregates.java', 'SparkCachedTableCatalog.java', 'SparkCatalog.java', 'SparkConfParser.java', 'SparkDataFile.java', 'SparkDistributionAndOrderingUtil.java', 'SparkExceptionUtil.java', 'SparkFilters.java', 'SparkFixupTimestampType.java', 'SparkFixupTypes.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkSQLProperties.java', 'SparkSchemaUtil.java', 'SparkSessionCatalog.java', 'SparkStructLike.java', 'SparkTableCache.java', 'SparkTableUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'SparkUtil.java', 'SparkV2Filters.java', 'SparkValueConverter.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'TypeToSparkType.java', 'BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java', 'BaseTableCreationSparkAction.java', 'DeleteOrphanFilesSparkAction.java', 'DeleteReachableFilesSparkAction.java', 'ExpireSnapshotsSparkAction.java', 'FileInfo.java', 'ManifestFileBean.java', 'MigrateTableSparkAction.java', 'RewriteDataFilesSparkAction.java', 'RewriteManifestsSparkAction.java', 'SetAccumulator.java', 'SnapshotTableSparkAction.java', 'SparkActions.java', 'SparkBinPackDataRewriter.java', 'SparkBinPackStrategy.java', 'SparkShufflingDataRewriter.java', 'SparkSizeBasedDataRewriter.java', 'SparkSortDataRewriter.java', 'SparkSortStrategy.java', 'SparkZOrderDataRewriter.java', 'SparkZOrderStrategy.java', 'SparkZOrderUDF.java', 'AvroWithSparkSchemaVisitor.java', 'ParquetWithSparkSchemaVisitor.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'ArrowVectorAccessorFactory.java', 'ArrowVectorAccessors.java', 'ColumnVectorBuilder.java', 'ColumnVectorWithFilter.java', 'ColumnarBatchReader.java', 'ConstantColumnVector.java', 'DeletedColumnVector.java', 'IcebergArrowColumnVector.java', 'RowPositionColumnVector.java', 'VectorizedSparkOrcReaders.java', 'VectorizedSparkParquetReaders.java', 'BucketFunction.java', 'DaysFunction.java', 'HoursFunction.java', 'IcebergVersionFunction.java', 'MonthsFunction.java', 'SparkFunctions.java', 'TruncateFunction.java', 'UnaryUnboundFunction.java', 'YearsFunction.java', 'AddFilesProcedure.java', 'AncestorsOfProcedure.java', 'BaseProcedure.java', 'CherrypickSnapshotProcedure.java', 'CreateChangelogViewProcedure.java', 'ExpireSnapshotsProcedure.java', 'MigrateTableProcedure.java', 'ProcedureInput.java', 'PublishChangesProcedure.java', 'RegisterTableProcedure.java', 'RemoveOrphanFilesProcedure.java', 'RewriteDataFilesProcedure.java', 'RewriteManifestsProcedure.java', 'RollbackToSnapshotProcedure.java', 'RollbackToTimestampProcedure.java', 'SetCurrentSnapshotProcedure.java', 'SnapshotTableProcedure.java', 'SparkProcedures.java', 'BaseBatchReader.java', 'BaseReader.java', 'BaseRowReader.java', 'BatchDataReader.java', 'ChangelogRowReader.java', 'EqualityDeleteRowReader.java', 'HasIcebergCatalog.java', 'IcebergSource.java', 'InternalRowWrapper.java', 'PositionDeletesRowReader.java', 'RowDataReader.java', 'SerializableTableWithSize.java', 'SparkAppenderFactory.java', 'SparkBatch.java', 'SparkBatchQueryScan.java', 'SparkChangelogScan.java', 'SparkChangelogTable.java', 'SparkCleanupUtil.java', 'SparkColumnarReaderFactory.java', 'SparkCopyOnWriteOperation.java', 'SparkCopyOnWriteScan.java', 'SparkFileWriterFactory.java', 'SparkInputPartition.java', 'SparkLocalScan.java', 'SparkMetadataColumn.java', 'SparkMicroBatchStream.java', 'SparkPartitionedFanoutWriter.java', 'SparkPartitionedWriter.java', 'SparkPartitioningAwareScan.java', 'SparkPositionDeletesRewrite.java', 'SparkPositionDeletesRewriteBuilder.java', 'SparkPositionDeltaOperation.java', 'SparkPositionDeltaWrite.java', 'SparkPositionDeltaWriteBuilder.java', 'SparkRowLevelOperationBuilder.java', 'SparkRowReaderFactory.java', 'SparkScan.java', 'SparkScanBuilder.java', 'SparkStagedScan.java', 'SparkStagedScanBuilder.java', 'SparkTable.java', 'SparkWrite.java', 'SparkWriteBuilder.java', 'StagedSparkTable.java', 'Stats.java', 'StreamingOffset.java', 'StructInternalRow.java', 'NumDeletes.java', 'NumSplits.java', 'TaskNumDeletes.java', 'TaskNumSplits.java', 'NoSuchProcedureException.java', 'Procedure.java', 'ProcedureCatalog.java', 'ProcedureParameter.java', 'ProcedureParameterImpl.java', 'DeltaBatchWrite.java', 'DeltaWrite.java', 'DeltaWriteBuilder.java', 'DeltaWriter.java', 'DeltaWriterFactory.java', 'ExtendedLogicalWriteInfo.java', 'SupportsDelta.java', 'org.apache.spark.sql.sources.DataSourceRegister', 'TransformExpressions.scala', 'SetWriteDistributionAndOrdering.scala', 'SortOrderParserUtil.scala', 'DistributionAndOrderingUtils.scala', 'PlanUtils.scala', 'SparkExpressionConverter.scala', 'KryoHelpers.java', 'TaskCheckHelper.java', 'TestDataFileSerialization.java', 'TestFileIOSerialization.java', 'TestHadoopMetricsContextSerialization.java', 'TestManifestFileSerialization.java', 'TestScanTaskSerialization.java', 'TestTableSerialization.java', 'ValidationHelpers.java', 'SparkCatalogConfig.java', 'SparkCatalogTestBase.java', 'SparkTestBase.java', 'SparkTestBaseWithCatalog.java', 'SparkTestHelperBase.java', 'TestChangelogIterator.java', 'TestFileRewriteCoordinator.java', 'TestFunctionCatalog.java', 'TestSpark3Util.java', 'TestSparkCachedTableCatalog.java', 'TestSparkCatalogOperations.java', 'TestSparkDistributionAndOrderingUtil.java', 'TestSparkFilters.java', 'TestSparkSchemaUtil.java', 'TestSparkSessionCatalog.java', 'TestSparkTableUtil.java', 'TestSparkV2Filters.java', 'TestSparkValueConverter.java', 'TestSparkWriteConf.java', 'TestCreateActions.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction3.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'TestSparkFileRewriter.java', 'AvroDataTest.java', 'GenericsHelpers.java', 'RandomData.java', 'TestHelpers.java', 'TestOrcWrite.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkAvroEnums.java', 'TestSparkAvroReader.java', 'TestSparkDateTimes.java', 'TestSparkOrcReadMetadataColumns.java', 'TestSparkOrcReader.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkParquetReader.java', 'TestSparkParquetWriter.java', 'TestSparkRecordOrcReaderWriter.java', 'TestVectorizedOrcDataReader.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryFallbackToPlainEncodingVectorizedReads.java', 'TestParquetVectorizedReads.java', 'ComplexRecord.java', 'FilePathLastModifiedRecord.java', 'LogMessage.java', 'ManualSource.java', 'NestedRecord.java', 'SimpleRecord.java', 'SparkSQLExecutionHelper.java', 'TestAvroScan.java', 'TestBaseReader.java', 'TestChangelogReader.java', 'TestDataFrameWriterV2.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestFilteredScan.java', 'TestForwardCompatibility.java', 'TestIcebergSource.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSpark.java', 'TestIdentityPartitionData.java', 'TestInternalRowWrapper.java', 'TestMetadataTableReadableMetrics.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestParquetScan.java', 'TestPartitionPruning.java', 'TestPartitionValues.java', 'TestPathIdentifier.java', 'TestPositionDeletesTable.java', 'TestReadProjection.java', 'TestRequiredDistributionAndOrdering.java', 'TestRuntimeFiltering.java', 'TestSnapshotSelection.java', 'TestSparkAggregates.java', 'TestSparkAppenderFactory.java', 'TestSparkCatalog.java', 'TestSparkCatalogCacheExpiration.java', 'TestSparkCatalogHadoopOverrides.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestSparkFileWriterFactory.java', 'TestSparkMergingMetrics.java', 'TestSparkMetadataColumns.java', 'TestSparkPartitioningWriters.java', 'TestSparkPositionDeltaWriters.java', 'TestSparkReadProjection.java', 'TestSparkReaderDeletes.java', 'TestSparkReaderWithBloomFilter.java', 'TestSparkRollingFileWriters.java', 'TestSparkScan.java', 'TestSparkStagedScan.java', 'TestSparkTable.java', 'TestSparkWriterMetrics.java', 'TestStreamingOffset.java', 'TestStructuredStreaming.java', 'TestStructuredStreamingRead3.java', 'TestTables.java', 'TestTimestampWithoutZone.java', 'TestWriteMetricsConfig.java', 'ThreeColumnRecord.java', 'PartitionedWritesTestBase.java', 'TestAggregatePushDown.java', 'TestAlterTable.java', 'TestCreateTable.java', 'TestCreateTableAsSelect.java', 'TestDeleteFrom.java', 'TestDropTable.java', 'TestFilterPushDown.java', 'TestNamespaceSQL.java', 'TestPartitionedWrites.java', 'TestPartitionedWritesAsSelect.java', 'TestPartitionedWritesToBranch.java', 'TestPartitionedWritesToWapBranch.java', 'TestRefreshTable.java', 'TestSelect.java', 'TestSparkBucketFunction.java', 'TestSparkDaysFunction.java', 'TestSparkHoursFunction.java', 'TestSparkMonthsFunction.java', 'TestSparkTruncateFunction.java', 'TestSparkYearsFunction.java', 'TestStoragePartitionedJoins.java', 'TestTimestampWithoutZone.java', 'TestUnpartitionedWrites.java', 'TestUnpartitionedWritesToBranch.java', 'UnpartitionedWritesTestBase.java']"
Spark 3.4: Initial support,54,1062,2023-04-19 14:59:41-07:00,"['jmh-benchmarks.yml', 'publish-snapshot.yml', 'recurring-jmh-benchmarks.yml', 'spark-ci.yml', '.gitignore', 'stage-binaries.sh', 'gradle.properties', 'jmh.gradle', 'settings.gradle', 'build.gradle', 'build.gradle', 'ProjectingInternalRow.scala', 'AlignRowLevelCommandAssignments.scala', 'AssignmentAlignmentSupport.scala', 'ResolveMergeIntoTableReferences.scala', 'RewriteDeleteFromIcebergTable.scala', 'RewriteMergeIntoTable.scala', 'RewriteRowLevelIcebergCommand.scala', 'RewriteUpdateTable.scala', 'IcebergSparkSqlExtensionsParser.scala', 'RewrittenRowLevelCommand.scala', 'WriteIcebergDelta.scala', 'RowDeltaUtils.scala', 'WriteDeltaProjections.scala', 'ExtendedLogicalWriteInfoImpl.scala', 'ExtendedDataSourceV2Strategy.scala', 'ExtendedV2Writes.scala', 'RowLevelCommandScanRelationPushDown.scala', 'WriteDeltaExec.scala', 'RowLevelCommandDynamicPruning.scala', 'TestConflictValidation.java', 'TestDelete.java', 'TestMerge.java', 'TestMergeOnReadDelete.java', 'TestRemoveOrphanFilesProcedure.java', 'TestRequiredDistributionAndOrdering.java', 'TestSnapshotTableProcedure.java', 'TestUpdate.java', 'TestWriteAborts.java', 'SparkPositionDeltaOperation.java', 'SparkPositionDeltaWrite.java', 'SparkPositionDeltaWriteBuilder.java', 'NoSuchProcedureException.java', 'DeltaBatchWrite.java', 'DeltaWrite.java', 'DeltaWriteBuilder.java', 'DeltaWriter.java', 'DeltaWriterFactory.java', 'ExtendedLogicalWriteInfo.java', 'SupportsDelta.java', 'TestFunctionCatalog.java', 'TestRequiredDistributionAndOrdering.java', 'TestSparkDataWrite.java', 'TestDropTable.java']"
Spark 3.3: Honor Spark case sensitivity in ALTER TABLE ... WRITE ORDERED (#7324),6,73,2023-04-19 15:04:04-07:00,"['SortOrder.java', 'SortOrderBuilder.java', 'BaseReplaceSortOrder.java', 'TestSortOrder.java', 'SetWriteDistributionAndOrderingExec.scala', 'TestSetWriteDistributionAndOrdering.java']"
"Spark 3.3: Surface better error message during streaming planning when checkpoint snapshot not found (#7381)

This change backports PR #6480 to 3.3.

Co-authored-by: Amogh Jahagirdar <jahamogh@amazon.com>",2,53,2023-04-20 08:31:04-07:00,"['SparkMicroBatchStream.java', 'TestStructuredStreamingRead3.java']"
Spark 2.4: Remove module (#7385),208,40477,2023-04-20 11:19:10-07:00,"['spark-ci.yml', '.gitignore', 'stage-binaries.sh', 'spark-configuration.md', 'spark-ddl.md', 'spark-queries.md', 'spark-structured-streaming.md', 'spark-writes.md', 'gradle.properties', 'jmh.gradle', 'settings.gradle', 'build.gradle', 'build.gradle', 'LICENSE', 'NOTICE', 'SparkBenchmarkUtil.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'Action.java', 'IcebergSourceBenchmark.java', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'IcebergSourceNestedListDataBenchmark.java', 'WritersBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'Actions.java', 'RewriteDataFilesAction.java', 'SparkActions.java', 'IcebergSpark.java', 'JobGroupInfo.java', 'JobGroupUtils.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'SparkConfParser.java', 'SparkDataFile.java', 'SparkExceptionUtil.java', 'SparkFilters.java', 'SparkFixupTimestampType.java', 'SparkFixupTypes.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkSQLProperties.java', 'SparkSchemaUtil.java', 'SparkStructLike.java', 'SparkTableUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'SparkUtil.java', 'SparkValueConverter.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'TypeToSparkType.java', 'BaseDeleteOrphanFilesSparkAction.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseExpireSnapshotsSparkAction.java', 'BaseRewriteManifestsSparkAction.java', 'BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java', 'BaseSparkActions.java', 'ManifestFileBean.java', 'SparkActions.java', 'AvroWithSparkSchemaVisitor.java', 'ParquetWithSparkSchemaVisitor.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'ArrowVectorAccessorFactory.java', 'ArrowVectorAccessors.java', 'ColumnarBatchReader.java', 'ConstantColumnVector.java', 'IcebergArrowColumnVector.java', 'RowPositionColumnVector.java', 'VectorizedSparkOrcReaders.java', 'VectorizedSparkParquetReaders.java', 'BaseDataReader.java', 'BatchDataReader.java', 'CustomCatalogs.java', 'EqualityDeleteRowReader.java', 'IcebergSource.java', 'InternalRowWrapper.java', 'Reader.java', 'RowDataReader.java', 'RowDataRewriter.java', 'SparkAppenderFactory.java', 'SparkFileWriterFactory.java', 'SparkPartitionedFanoutWriter.java', 'SparkPartitionedWriter.java', 'Stats.java', 'StreamingOffset.java', 'StreamingWriter.java', 'StructInternalRow.java', 'Writer.java', 'org.apache.spark.sql.sources.DataSourceRegister', 'KryoHelpers.java', 'TaskCheckHelper.java', 'TestDataFileSerialization.java', 'TestFileIOSerialization.java', 'TestManifestFileSerialization.java', 'TestScanTaskSerialization.java', 'TestTableSerialization.java', 'ValidationHelpers.java', 'TestRewriteDataFilesAction.java', 'ConcurrencyTest.java', 'README.md', 'ReadAndWriteTablesTest.java', 'SchemaEvolutionTest.java', 'SimpleRecord.java', 'SnapshotFunctionalityTest.java', 'SparkTestBase.java', 'TestSparkSchemaUtil.java', 'TestSparkValueConverter.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRewriteManifestsAction.java', 'AvroDataTest.java', 'GenericsHelpers.java', 'RandomData.java', 'TestHelpers.java', 'TestOrcWrite.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkAvroEnums.java', 'TestSparkAvroReader.java', 'TestSparkDateTimes.java', 'TestSparkOrcReadMetadataColumns.java', 'TestSparkOrcReader.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkParquetReader.java', 'TestSparkParquetWriter.java', 'TestSparkRecordOrcReaderWriter.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryFallbackToPlainEncodingVectorizedReads.java', 'TestParquetVectorizedReads.java', 'ComplexRecord.java', 'LogMessage.java', 'ManualSource.java', 'NestedRecord.java', 'SimpleRecord.java', 'TestAvroScan.java', 'TestCatalog.java', 'TestCustomCatalog.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestFilteredScan.java', 'TestForwardCompatibility.java', 'TestIcebergSource.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSpark.java', 'TestIdentityPartitionData.java', 'TestInternalRowWrapper.java', 'TestNameMappingProjection.java', 'TestParquetScan.java', 'TestPartitionPruning.java', 'TestPartitionValues.java', 'TestReadProjection.java', 'TestSelect.java', 'TestSnapshotSelection.java', 'TestSparkAppenderFactory.java', 'TestSparkBaseDataReader.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestSparkFileWriterFactory.java', 'TestSparkMergingMetrics.java', 'TestSparkPartitioningWriters.java', 'TestSparkPositionDeltaWriters.java', 'TestSparkReadProjection.java', 'TestSparkReaderDeletes.java', 'TestSparkRollingFileWriters.java', 'TestSparkSchema.java', 'TestSparkTableUtil.java', 'TestSparkTableUtilWithInMemoryCatalog.java', 'TestSparkWriterMetrics.java', 'TestStreamingOffset.java', 'TestStructuredStreaming.java', 'TestTables.java', 'TestTimestampWithoutZone.java', 'TestWriteMetricsConfig.java', 'ThreeColumnRecord.java', 'books.json', 'new-books.json']"
"Build: Bump Hive to 2.3.9 (#7374)

Some small bug fixes, but also removes the `commons-httpclient` dependency, which is nice.

https://issues.apache.org/jira/secure/ReleaseNote.jspa?version=12350009&styleName=Text&projectId=12310843",1,2,2023-04-20 16:29:40-07:00,['versions.props']
"Core: Introduce CompositeMetricsReporter (#7337)

This also switches from a collection of reporters to the
`CompositeMetricsReporter` in `TableScanContext` to fix an issue where
duplicate reporters were not handled.",6,284,2023-04-21 08:40:27-07:00,"['LoggingMetricsReporter.java', 'SnapshotScan.java', 'TableScanContext.java', 'MetricsReporters.java', 'TestScanPlanningAndReporting.java', 'TestMetricsReporters.java']"
"Flink: Use starting sequence number by default when rewriting data files (#7218)

Co-authored-by: linyanghao <linyanghao.data@bytedance.com>",2,141,2023-04-21 10:17:16-07:00,"['BaseRewriteDataFilesAction.java', 'TestRewriteDataFilesAction.java']"
"Backport to Flink 1.15: Implement DataStatisticsOperator operator to collect and send traffic distribution for guiding smart shuffling (#7400)

Co-authored-by: gang_ye <gang_ye@apple.com>",8,685,2023-04-21 10:37:00-07:00,"['DataStatistics.java', 'DataStatisticsEvent.java', 'DataStatisticsFactory.java', 'DataStatisticsOperator.java', 'DataStatisticsOrRecord.java', 'MapDataStatistics.java', 'MapDataStatisticsFactory.java', 'TestDataStatisticsOperator.java']"
Flink: Backport row filter into 1.15 and 1.16 (#7397),20,419,2023-04-21 16:45:09-07:00,"['FlinkSourceFilter.java', 'FlinkInputFormat.java', 'IcebergSource.java', 'RowDataFileScanTaskReader.java', 'AvroGenericRecordReaderFunction.java', 'RowDataReaderFunction.java', 'TestFlinkScan.java', 'TestFlinkSource.java', 'TestIcebergSourceBounded.java', 'TestIcebergSourceBoundedGenericRecord.java', 'FlinkSourceFilter.java', 'FlinkInputFormat.java', 'IcebergSource.java', 'RowDataFileScanTaskReader.java', 'AvroGenericRecordReaderFunction.java', 'RowDataReaderFunction.java', 'TestFlinkScan.java', 'TestFlinkSource.java', 'TestIcebergSourceBounded.java', 'TestIcebergSourceBoundedGenericRecord.java']"
Spark 3.3: support rate limit in Spark Streaming (#4479),6,497,2023-04-22 10:24:49-07:00,"['MicroBatches.java', 'TestMicroBatchBuilder.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkMicroBatchStream.java', 'TestStructuredStreamingRead3.java']"
Spec: Add S3 configuration to REST table load (#7401),1,18,2023-04-22 12:19:57-07:00,['rest-catalog-open-api.yaml']
Doc: Add a page explaining migration from other table formats to iceberg (#6600),3,261,2023-04-22 16:05:06-07:00,"['delta-lake-migration.md', 'hive-migration.md', 'table-migration.md']"
Doc: Fix typo in hive_migration.md (#7407),1,2,2023-04-22 22:02:17-07:00,['hive-migration.md']
"Spark: Fix failing unit test (#7414)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",1,18,2023-04-23 07:32:59-07:00,['SparkMicroBatchStream.java']
"Backport #7218 (#7404)

Co-authored-by: linyanghao <linyanghao.data@bytedance.com>",2,220,2023-04-23 09:54:19-07:00,"['TestRewriteDataFilesAction.java', 'TestRewriteDataFilesAction.java']"
"Build: Bump zstandard from 0.20.0 to 0.21.0 in /python (#7411)

Bumps [zstandard](https://github.com/indygreg/python-zstandard) from 0.20.0 to 0.21.0.
- [Release notes](https://github.com/indygreg/python-zstandard/releases)
- [Changelog](https://github.com/indygreg/python-zstandard/blob/main/docs/news.rst)
- [Commits](https://github.com/indygreg/python-zstandard/compare/0.20.0...0.21.0)

---
updated-dependencies:
- dependency-name: zstandard
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,103,2023-04-23 20:14:06+02:00,"['poetry.lock', 'pyproject.toml']"
MR: Skip filter translation if there are no leaves (#7123),2,83,2023-04-24 09:12:37+02:00,"['HiveIcebergFilterFactory.java', 'TestHiveIcebergFilterFactory.java']"
"Python: Add mkdocstrings (#7108)

* Add mkdocstrings

* Add mkdocs theme

* Add theme to mkdocs and fix pages gen

* Fix missing license

* Fix prettier",12,174,2023-04-24 10:03:09+02:00,"['.pre-commit-config.yaml', 'SUMMARY.md', 'api.md', 'iceberg-logo-icon.png', 'cli.md', 'configuration.md', 'contributing.md', 'feature-support.md', 'index.md', 'gen_doc_stubs.py', 'mkdocs.yml', 'requirements.txt']"
AWS: Fix default warehouse path in Dynamodb catalog (#7358),3,122,2023-04-24 11:25:13-07:00,"['TestDynamoDbCatalog.java', 'DynamoDbCatalog.java', 'TestDynamoDbCatalog.java']"
Flink: sync 1.16 with 1.17 for backports missed or not ported identically (#7403),7,68,2023-04-24 11:42:18-07:00,"['RowDataFileScanTaskReader.java', 'RowDataRewriter.java', 'AvroGenericRecordReaderFunction.java', 'RowDataReaderFunction.java', 'ReaderUtil.java', 'TestIcebergSourceReader.java', 'TestRowDataReaderFunction.java']"
Flink: sync 1.15 with 1.17 for missed backports previously (#7402),16,127,2023-04-24 11:42:48-07:00,"['CatalogLoader.java', 'FlinkEnvironmentContext.java', 'TableLoader.java', 'IcebergFilesCommitter.java', 'RowDataFileScanTaskReader.java', 'RowDataRewriter.java', 'AvroGenericRecordReaderFunction.java', 'RowDataReaderFunction.java', 'FlinkCatalogTestBase.java', 'FlinkTestBase.java', 'TestChangeLogTable.java', 'TestFlinkHiveCatalog.java', 'TestFlinkMergingMetrics.java', 'ReaderUtil.java', 'TestIcebergSourceReader.java', 'TestRowDataReaderFunction.java']"
Views: Clean up and clarify the view spec (#7416),1,323,2023-04-24 16:21:15-07:00,['view-spec.md']
Docs: Separate page for Branching and Tagging (#6723),8,410,2023-04-24 21:34:35-07:00,"['branching-and-tagging.md', 'flink-configuration.md', 'flink-getting-started.md', 'flink-queries.md', 'flink-writes.md', 'java-api-quickstart.md', 'spark-ddl.md', 'spark-writes.md']"
Views: Fix SQL view representation field name (#7417),6,56,2023-04-24 21:38:52-07:00,"['ViewVersion.java', 'SQLViewRepresentationParser.java', 'ViewRepresentationParser.java', 'ViewVersionParser.java', 'TestViewRepresentationParser.java', 'TestViewVersionParser.java']"
Hive: Use EnvironmentContext instead of Hive Locks to provide transactional commits after HIVE-26882 (#6570),8,263,2023-04-25 09:13:20+02:00,"['TableProperties.java', 'ConfigProperties.java', 'configuration.md', 'HiveTableOperations.java', 'MetastoreUtil.java', 'NoLock.java', 'TestHiveCommitLocks.java', 'TestHiveCommits.java']"
"Python: Provide version ranges for each dependency (#7376)

* Python: Provide version ranges for each dependency

* Python: ""Fix"" the range specification for `duckdb`

* Python: Add support for Pandas 2 and PyArrow 7.0.0

* Python: Remove extraneous versioning justification

* Python: Define explicit upper bound for Dependabot

* Python: Update PyArrow lower bound from 7.0 to 9.0

Co-authored-by: Fokko Driesprong <fokko@apache.org>

---------

Co-authored-by: Fokko Driesprong <fokko@apache.org>",2,740,2023-04-25 09:44:05+02:00,"['poetry.lock', 'pyproject.toml']"
Spark: Backport #6480 to Spark 3.2 and Spark 3.1 (#7425),4,102,2023-04-25 10:01:53+02:00,"['SparkMicroBatchStream.java', 'TestStructuredStreamingRead3.java', 'SparkMicroBatchStream.java', 'TestStructuredStreamingRead3.java']"
"API, Core: Move schemaID from ViewRepresentation to ViewVersion and make it required (#7421)",7,56,2023-04-25 10:22:11-07:00,"['revapi.yml', 'SQLViewRepresentation.java', 'ViewVersion.java', 'SQLViewRepresentationParser.java', 'ViewVersionParser.java', 'TestSQLViewRepresentationParser.java', 'TestViewVersionParser.java']"
Spark 3.4: Relax constraints in SparkPartitioningAwareScan (#7423),1,35,2023-04-25 10:32:54-07:00,['SparkPartitioningAwareScan.java']
Core: Extract REST metrics reporter into its own class (#7339),2,97,2023-04-25 10:50:49-07:00,"['RESTMetricsReporter.java', 'RESTSessionCatalog.java']"
Spark 3.4: Add tests for SPJ when partition keys mismatch (#7424),2,81,2023-04-25 12:09:00-07:00,"['TestStoragePartitionedJoinsInRowLevelOperations.java', 'TestStoragePartitionedJoins.java']"
Spark 3.4: Cherry pick case sensitivity backport (#7324),2,29,2023-04-25 15:22:05-05:00,"['SetWriteDistributionAndOrderingExec.scala', 'TestSetWriteDistributionAndOrdering.java']"
Build: Run Iceberg with JDK 17 (#7391),12,238,2023-04-25 15:26:09-07:00,"['delta-conversion-ci.yml', 'hive-ci.yml', 'java-ci.yml', 'spark-ci.yml', 'ExpressionUtil.java', 'TestExpressionUtil.java', 'build.gradle', 'jmh.gradle', 'build.gradle', 'TestMetadataTableReadableMetrics.java', 'build.gradle', 'TestMetadataTableReadableMetrics.java']"
"Python: Use fsspec implementation of LocalFileSystem (#7432)

instead of pyarrow implementation of LocalFileSystem",1,2,2023-04-26 08:15:28+02:00,['fsspec.py']
Views: Move 'operation' check to ViewVersion (#7428),3,34,2023-04-25 23:46:32-07:00,"['ViewVersion.java', 'ViewVersionParser.java', 'TestViewVersionParser.java']"
"Docs: Add Java 17 to README.md (#7434)

* Updated README.md

#7391 
It's just a simple change in my thinking.

* Reduce writing

I like that it's shorter.

Co-authored-by: Fokko Driesprong <fokko@apache.org>

---------

Co-authored-by: Fokko Driesprong <fokko@apache.org>",1,2,2023-04-26 13:37:12+02:00,['README.md']
Hive: Clean up expired metastore clients (#7310),3,15,2023-04-26 17:18:10+02:00,"['ClientPoolImpl.java', 'CachedClientPool.java', 'TestCachedClientPool.java']"
"Core: Make TableScanContext immutable (#5985)

Co-authored-by: Liwei Li <hililiwei@gmail.com>",6,395,2023-04-26 20:44:20-07:00,"['BaseIncrementalChangelogScan.java', 'BaseMetadataTableScan.java', 'BaseTable.java', 'PositionDeletesTable.java', 'TableScanContext.java', 'TestScanPlanningAndReporting.java']"
Core: Move table-creation-without-namespace-test to CatalogTests (#7349),3,43,2023-04-27 07:32:13-07:00,"['InMemoryCatalog.java', 'CatalogTests.java', 'TestInMemoryCatalog.java']"
"Spark: Refactor SparkReadConf to use primitive type (#7429)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",8,48,2023-04-27 09:49:58-07:00,"['SparkReadConf.java', 'SparkMicroBatchStream.java', 'SparkReadConf.java', 'SparkMicroBatchStream.java', 'SparkReadConf.java', 'SparkMicroBatchStream.java', 'SparkReadConf.java', 'SparkMicroBatchStream.java']"
Spark 3.4: Remove deprecated classes (#7448),12,779,2023-04-27 10:14:56-07:00,"['FileRewriteCoordinator.java', 'FileScanTaskSetManager.java', 'Spark3Util.java', 'SparkTableUtil.java', 'SparkUtil.java', 'SparkBinPackStrategy.java', 'SparkSizeBasedDataRewriter.java', 'SparkSortStrategy.java', 'SparkZOrderStrategy.java', 'VectorizedSparkParquetReaders.java', 'TestFileRewriteCoordinator.java', 'TestSparkParquetReadMetadataColumns.java']"
Arrow: Convert dict encoded vectors to their expected Arrow vector types (#3024),8,422,2023-04-27 11:13:07-07:00,"['DictEncodedArrowConverter.java', 'ArrowReader.java', 'ArrowVectorAccessors.java', 'ColumnVector.java', 'ColumnarBatch.java', 'VectorHolder.java', 'VectorizedArrowReader.java', 'ArrowReaderTest.java']"
Spark: Fixed Typo in Spark Read Option Vectorization Javadoc (#7439),4,8,2023-04-27 15:11:37-05:00,"['SparkReadOptions.java', 'SparkReadOptions.java', 'SparkReadOptions.java', 'SparkReadOptions.java']"
Spark 3.4: Remove no longer needed write extensions (#7443),23,999,2023-04-27 14:00:43-07:00,"['RewriteMergeIntoTable.scala', 'RewriteRowLevelIcebergCommand.scala', 'ExtendedV2ExpressionUtils.scala', 'WriteIcebergDelta.scala', 'ExtendedDistributionAndOrderingUtils.scala', 'ExtendedV2Writes.scala', 'RowLevelCommandDynamicPruning.scala', 'TestIcebergExpressions.java', 'TestRewriteDataFilesProcedure.java', 'BaseCatalog.java', 'SortOrderToSpark.java', 'SparkCachedTableCatalog.java', 'SparkFunctionCatalog.java', 'SupportsFunctions.java', 'SparkShufflingDataRewriter.java', 'SparkSortDataRewriter.java', 'SparkZOrderDataRewriter.java', 'SparkWriteBuilder.java', 'TransformExpressions.scala', 'DistributionAndOrderingUtils.scala', 'TestRemoveOrphanFilesAction.java', 'TestRewriteDataFilesAction.java', 'TestRequiredDistributionAndOrdering.java']"
Delta: Add version and timestamp tags for each Delta Lake transaction (#7450),2,69,2023-04-27 17:33:36-07:00,"['TestSnapshotDeltaLakeTable.java', 'BaseSnapshotDeltaLakeTableAction.java']"
Delta: Fix snapshotDataFilesCount and use Immutable for result (#7454),5,134,2023-04-28 08:42:58-07:00,"['build.gradle', 'TestSnapshotDeltaLakeTable.java', 'BaseSnapshotDeltaLakeTableAction.java', 'BaseSnapshotDeltaLakeTableActionResult.java', 'SnapshotDeltaLakeTable.java']"
"Python: fix `mkdocs` warnings from `conversions.py` (#7462)

* updates to remove mkdocs warnings from_bytes()

* updated comments for mkdocs WARNINGS to be removed",1,10,2023-04-28 19:50:36+02:00,['conversions.py']
Spark 3.4: Support rate limit in Spark Streaming (#7422),4,286,2023-04-28 11:03:14-07:00,"['SparkReadConf.java', 'SparkReadOptions.java', 'SparkMicroBatchStream.java', 'TestStructuredStreamingRead3.java']"
"Python: fix mkdocs warnings from visitors.py (#7464)

* updates to remove mkdocs warnings from_bytes()

* updated comments for mkdocs WARNINGS to be removed

* removal of warnings from mkdocs serve --strict",1,4,2023-04-28 20:46:05+02:00,['visitors.py']
"Python: fix mkdocs warnings from sorting.py (#7467)

* updates to remove mkdocs warnings from_bytes()

* updated comments for mkdocs WARNINGS to be removed

* removal of warnings from mkdocs serve --strict

* changes to SortOrder init() added order_id arg

* reverted...

* updated for keyword args vs args order_id

* removed blank line 123 fom sorting.py

* finalizing comments

* Remove spaces

---------

Co-authored-by: Fokko Driesprong <fokko@apache.org>",1,4,2023-04-28 23:30:09+02:00,['sorting.py']
"Spark: Fix failing Spark streaming rate limit unit test (#7470)

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",1,8,2023-04-29 07:29:13-07:00,['TestStructuredStreamingRead3.java']
Build: Bump ray from 2.3.1 to 2.4.0 in /python (#7479),1,136,2023-04-30 08:35:06+02:00,['poetry.lock']
Build: Bump mkdocs-gen-files from 0.4.0 to 0.5.0 in /python (#7478),1,2,2023-04-30 08:35:43+02:00,['requirements.txt']
Build: Bump mkdocstrings-python from 0.8.3 to 0.9.0 in /python (#7475),1,2,2023-04-30 08:36:04+02:00,['requirements.txt']
"Build: Bump pyyaml from 5.4.1 to 6.0 in /python (#7477)

Bumps [pyyaml](https://github.com/yaml/pyyaml) from 5.4.1 to 6.0.
- [Release notes](https://github.com/yaml/pyyaml/releases)
- [Changelog](https://github.com/yaml/pyyaml/blob/master/CHANGES)
- [Commits](https://github.com/yaml/pyyaml/compare/5.4.1...6.0)

---
updated-dependencies:
- dependency-name: pyyaml
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,77,2023-04-30 17:05:01+02:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump mkdocs-material from 9.1.5 to 9.1.8 in /python (#7476)

Bumps [mkdocs-material](https://github.com/squidfunk/mkdocs-material) from 9.1.5 to 9.1.8.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/CHANGELOG)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/9.1.5...9.1.8)

---
updated-dependencies:
- dependency-name: mkdocs-material
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-04-30 17:05:18+02:00,['requirements.txt']
"Python: Fix warnings in documentation (#7472)

* updates to remove mkdocs warnings from_bytes()

* updated comments for mkdocs WARNINGS to be removed

* removal of warnings from mkdocs serve --strict

* changes to SortOrder init() added order_id arg

* reverted...

* updated for keyword args vs args order_id

* removed blank line 123 fom sorting.py

* finalizing comments

* Remove spaces

* fixed all mkdocs serve --strict warnings

* fixed trailing whitespace

* updates to comments for mkdocs serve --strict mode

* updates to io/__init__.py for mkdocs warns removal

* updates to remove mkdocs warns from types.py

* updates for schema.py to remove mkdocs warns

* updates to remove mkdoc warns from literals.py

* final mkdocs fixed transforms.py

* request PR changes from code review

* reuest format changes for comments

---------

Co-authored-by: Fokko Driesprong <fokko@apache.org>",8,107,2023-04-30 22:17:28+02:00,"['python-ci-docs.yml', 'literals.py', '__init__.py', 'fsspec.py', 'pyarrow.py', 'schema.py', 'transforms.py', 'types.py']"
Spark 3.4: Switch to built-in DELETE implementation (#7453),10,296,2023-04-30 20:55:11-07:00,"['IcebergSparkSessionExtensions.scala', 'RewriteDeleteFromIcebergTable.scala', 'ExtendedReplaceNullWithFalseInPredicate.scala', 'ExtendedSimplifyConditionalsInPredicate.scala', 'IcebergSparkSqlExtensionsParser.scala', 'DeleteFromIcebergTable.scala', 'ExtendedDataSourceV2Strategy.scala', 'OptimizeMetadataOnlyDeleteFromIcebergTable.scala', 'RowLevelCommandDynamicPruning.scala', 'TestDelete.java']"
"Python: Fix code highlighting in docs (#7484)

* updates to remove mkdocs warnings from_bytes()

* updated comments for mkdocs WARNINGS to be removed

* removal of warnings from mkdocs serve --strict

* changes to SortOrder init() added order_id arg

* reverted...

* updated for keyword args vs args order_id

* removed blank line 123 fom sorting.py

* finalizing comments

* Remove spaces

* fixed all mkdocs serve --strict warnings

* fixed trailing whitespace

* updates to comments for mkdocs serve --strict mode

* updates to io/__init__.py for mkdocs warns removal

* updates to remove mkdocs warns from types.py

* updates for schema.py to remove mkdocs warns

* updates to remove mkdoc warns from literals.py

* final mkdocs fixed transforms.py

* request PR changes from code review

* reuest format changes for comments

* fix pymdownx markdown_ext for code hihglights

---------

Co-authored-by: Fokko Driesprong <fokko@apache.org>",1,3,2023-05-01 08:45:20+02:00,['mkdocs.yml']
Spark: Remove Usage of deprecated AssertHelpers in spark-sql (#7486),14,717,2023-05-01 11:51:45+02:00,"['TestAlterTable.java', 'TestCreateTable.java', 'TestDeleteFrom.java', 'TestDropTable.java', 'TestNamespaceSQL.java', 'TestSelect.java', 'TestSparkBucketFunction.java', 'TestSparkDaysFunction.java', 'TestSparkHoursFunction.java', 'TestSparkMonthsFunction.java', 'TestSparkTruncateFunction.java', 'TestSparkYearsFunction.java', 'TestTimestampWithoutZone.java', 'UnpartitionedWritesTestBase.java']"
Spark 3.3: Remove deprecated FileScanTaskSetManager (#7489),1,79,2023-05-01 14:04:12-07:00,['FileScanTaskSetManager.java']
"Python: Update pre-commit to the latest version (#7436)

Removed some ignores and removed some list materialization",10,88,2023-05-01 23:38:50+02:00,"['.pre-commit-config.yaml', 'conversions.py', '__init__.py', 'literals.py', 'visitors.py', 'schema.py', 'typedef.py', 'decimal.py', 'test_transforms.py', 'test_bin_packing.py']"
Hive: Support connecting to multiple HMS-Catalog on same HMS URL (#7441),3,62,2023-05-01 15:28:28-07:00,"['CachedClientPool.java', 'HiveCatalog.java', 'TestCachedClientPool.java']"
Spark 3.4: Add read and write support for UUIDs (#7399),15,165,2023-05-01 16:51:48-07:00,"['UUIDUtil.java', 'RandomUtil.java', 'GenericArrowVectorAccessorFactory.java', 'SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'ArrowVectorAccessorFactory.java', 'VectorizedSparkOrcReaders.java', 'AvroDataTest.java', 'RandomData.java', 'TestSparkParquetWriter.java']"
Python: Infer Iceberg schema from the Parquet file (#6997),4,618,2023-05-01 17:06:16-07:00,"['pyarrow.py', 'test_pyarrow.py', 'test_pyarrow_visitor.py', 'test_integration.py']"
Hive: Remove deprecated AssertHelpers (#7482),9,560,2023-05-02 09:22:47+02:00,"['HiveCreateReplaceTableTest.java', 'HiveTableTest.java', 'TestHiveCatalog.java', 'TestHiveClientPool.java', 'TestHiveCommitLocks.java', 'TestHiveCommits.java', 'TestHiveSchemaUtil.java', 'TestHiveIcebergFilterFactory.java', 'TestORCSchemaUtil.java']"
Flink: Remove deprecated AssertHelpers (#7481),17,477,2023-05-02 09:25:08+02:00,"['TestFlinkCatalogDatabase.java', 'TestFlinkCatalogFactory.java', 'TestFlinkCatalogTable.java', 'TestFlinkCatalogTablePartitions.java', 'TestFlinkSchemaUtil.java', 'TestIcebergConnector.java', 'TestRowDataProjection.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkV2.java', 'TestFlinkIcebergSinkV2Base.java', 'TestFlinkScan.java', 'TestFlinkSourceConfig.java', 'TestFlinkTableSource.java', 'TestStreamScanSql.java', 'TestStreamingMonitorFunction.java', 'TestContinuousSplitPlannerImpl.java', 'TestContinuousSplitPlannerImplStartStrategy.java']"
Spark: Remove deprecated AssertHelpers usage (#7483),18,643,2023-05-02 14:43:05+02:00,"['TestFunctionCatalog.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'TestParquetVectorizedReads.java', 'TestDataFrameWriterV2.java', 'TestDataSourceOptions.java', 'TestForwardCompatibility.java', 'TestIcebergSourceTablesBase.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestRequiredDistributionAndOrdering.java', 'TestSparkDataWrite.java', 'TestSparkMetadataColumns.java', 'TestStructuredStreamingRead3.java', 'TestTimestampWithoutZone.java', 'TestWriteMetricsConfig.java']"
Core: Remove compile-time dependency to ResolvingFileIO (#7488),1,5,2023-05-02 10:39:53-07:00,['RESTSessionCatalog.java']
Docs: Update new catalog features (#7433),3,44,2023-05-02 17:39:19-07:00,"['spark-configuration.md', 'SparkCatalog.java', 'SparkCatalog.java']"
Spark 3.3: Add read and write support for UUIDs (#7496),13,128,2023-05-03 08:35:18-07:00,"['SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'ArrowVectorAccessorFactory.java', 'VectorizedSparkOrcReaders.java', 'AvroDataTest.java', 'RandomData.java', 'TestSparkParquetWriter.java', 'SparkOrcValueWriters.java']"
Spark 3.2: Add read and write support for UUIDs (#7497),12,125,2023-05-03 08:36:02-07:00,"['SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'ArrowVectorAccessorFactory.java', 'VectorizedSparkOrcReaders.java', 'AvroDataTest.java', 'RandomData.java', 'TestSparkParquetWriter.java']"
Spark 3.1: Add read and write support for UUIDs (#7508),12,125,2023-05-03 08:36:26-07:00,"['SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'ArrowVectorAccessorFactory.java', 'VectorizedSparkOrcReaders.java', 'AvroDataTest.java', 'RandomData.java', 'TestSparkParquetWriter.java']"
API: Remove deprecated AssertHelpers usage (#7468),14,752,2023-05-03 09:25:40-07:00,"['TestPartitionSpecValidation.java', 'TestSnapshotRef.java', 'TestNamespace.java', 'TestEvaluator.java', 'TestExpressionHelpers.java', 'TestInclusiveManifestEvaluator.java', 'TestInclusiveMetricsEvaluator.java', 'TestPredicateBinding.java', 'TestStrictMetricsEvaluator.java', 'TestCloseableIterable.java', 'TestBucketing.java', 'TestProjection.java', 'TestTruncate.java', 'TestTypeUtil.java']"
API: Update Javadoc for listTables and listViews (#7336),2,8,2023-05-04 14:22:55+02:00,"['Catalog.java', 'ViewCatalog.java']"
Core: Simplify partition coercion code in PartitionsTable (#7503),2,109,2023-05-04 07:37:06-07:00,"['PartitionsTable.java', 'PartitionUtil.java']"
"Python: Support Iceberg UUIDType from Parquet (#7523)

* add cast if needed in the visitor

* Revert ""add cast if needed in the visitor""

This reverts commit fa86862cb68399059fb40a10f96a97745c7102a0.

* add promotion from Fixed16 to UUID

* add a comment explaining why the promotion is needed",1,9,2023-05-04 18:27:53+02:00,['schema.py']
"Core, Spark: Add case-sensitivity configuration to CachingCatalog (#7469)",6,55,2023-05-04 10:56:24-07:00,"['CatalogProperties.java', 'SparkCatalog.java', 'SparkUtil.java', 'SparkCatalog.java', 'SparkCatalog.java', 'SparkCatalog.java']"
AWS: Add finalizer to S3FileIO (#7513),2,31,2023-05-04 12:21:42-07:00,"['S3FileIO.java', 'TestS3FileIO.java']"
AWS: Move all S3FileIO related properties into a separate class S3FileIOProperties (#7505),4,1484,2023-05-04 14:13:07-07:00,"['AwsProperties.java', 'S3FileIOProperties.java', 'TestS3FileIOProperties.java', 'build.gradle']"
Spark 3.4: Handle skew in writes (#7520),5,224,2023-05-04 14:25:12-07:00,"['TestDelete.java', 'TestMerge.java', 'TestUpdate.java', 'SparkPositionDeltaWrite.java', 'SparkWrite.java']"
Spec: Update View spec to reflect that schema is defined at the version level  and is required (#7485),1,22,2023-05-04 15:18:36-07:00,['view-spec.md']
Spark 3.4: Action for rewriting position deletes (#7389),17,1944,2023-05-04 16:23:43-07:00,"['revapi.yml', 'ActionsProvider.java', 'RewritePositionDeleteFiles.java', 'CatalogUtil.java', 'RewritePositionDeleteStrategy.java', 'RewritePositionDeletesCommitManager.java', 'RewritePositionDeletesGroup.java', 'SizeBasedFileRewriter.java', 'SizeBasedPositionDeletesRewriter.java', 'SparkBinPackDataRewriter.java', 'RewritePositionDeleteSparkAction.java', 'SparkActions.java', 'SparkBinPackDataRewriter.java', 'SparkBinPackPositionDeletesRewriter.java', 'SparkPositionDeletesRewrite.java', 'TestRewritePositionDeleteFilesAction.java', 'FourColumnRecord.java']"
Spark 3.4: Tests for coalescing small writing tasks (#7532),3,193,2023-05-04 16:27:29-07:00,"['TestDelete.java', 'TestMerge.java', 'TestUpdate.java']"
Core: Support delete file stats in partitions metadata table (#6661),8,1019,2023-05-05 11:23:51-07:00,"['PartitionsTable.java', 'MetadataTableScanTestBase.java', 'TestMetadataTableScans.java', 'TestMetadataTableScansWithPartitionEvolution.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java']"
"Core, Spark: Revert SparkCatalog case sensitive CachingCatalog default (#7535)",5,26,2023-05-05 11:26:28-07:00,"['CatalogProperties.java', 'SparkCatalog.java', 'SparkCatalog.java', 'SparkCatalog.java', 'SparkCatalog.java']"
Core: Remove duplicate check for ManifestEntry.dataSequenceNumber() (#7538),1,8,2023-05-05 12:36:19-07:00,['TableTestBase.java']
"Remove usages of S3 fields from AwsProperties within s3 package (#7534)

Remove usages of S3 fields from AwsProperties within s3 package",12,347,2023-05-05 14:05:52-07:00,"['TestS3FileIOIntegration.java', 'TestS3MultipartUpload.java', 'BaseS3File.java', 'S3FileIO.java', 'S3InputFile.java', 'S3InputStream.java', 'S3OutputFile.java', 'S3OutputStream.java', 'S3RequestUtil.java', 'TestAwsClientFactories.java', 'TestS3OutputStream.java', 'TestS3RequestUtil.java']"
"Build: Bump mkdocstrings from 0.20.0 to 0.21.2 in /python (#7547)

Bumps [mkdocstrings](https://github.com/mkdocstrings/mkdocstrings) from 0.20.0 to 0.21.2.
- [Release notes](https://github.com/mkdocstrings/mkdocstrings/releases)
- [Changelog](https://github.com/mkdocstrings/mkdocstrings/blob/master/CHANGELOG.md)
- [Commits](https://github.com/mkdocstrings/mkdocstrings/compare/0.20.0...0.21.2)

---
updated-dependencies:
- dependency-name: mkdocstrings
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-05-07 20:42:20+02:00,['requirements.txt']
"Build: Bump griffe from 0.26.0 to 0.27.3 in /python (#7546)

Bumps [griffe](https://github.com/mkdocstrings/griffe) from 0.26.0 to 0.27.3.
- [Changelog](https://github.com/mkdocstrings/griffe/blob/master/CHANGELOG.md)
- [Commits](https://github.com/mkdocstrings/griffe/compare/0.26.0...0.27.3)

---
updated-dependencies:
- dependency-name: griffe
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-05-07 20:42:42+02:00,['requirements.txt']
"Build: Bump rich from 13.3.4 to 13.3.5 in /python (#7545)

Bumps [rich](https://github.com/Textualize/rich) from 13.3.4 to 13.3.5.
- [Release notes](https://github.com/Textualize/rich/releases)
- [Changelog](https://github.com/Textualize/rich/blob/master/CHANGELOG.md)
- [Commits](https://github.com/Textualize/rich/compare/v13.3.4...v13.3.5)

---
updated-dependencies:
- dependency-name: rich
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,6,2023-05-07 20:42:54+02:00,['poetry.lock']
"Build: Bump requests from 2.28.2 to 2.30.0 in /python (#7544)

Bumps [requests](https://github.com/psf/requests) from 2.28.2 to 2.30.0.
- [Release notes](https://github.com/psf/requests/releases)
- [Changelog](https://github.com/psf/requests/blob/main/HISTORY.md)
- [Commits](https://github.com/psf/requests/compare/v2.28.2...v2.30.0)

---
updated-dependencies:
- dependency-name: requests
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,10,2023-05-07 20:43:02+02:00,['poetry.lock']
"Build: Bump mkdocs-material from 9.1.8 to 9.1.9 in /python (#7542)

Bumps [mkdocs-material](https://github.com/squidfunk/mkdocs-material) from 9.1.8 to 9.1.9.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/CHANGELOG)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/9.1.8...9.1.9)

---
updated-dependencies:
- dependency-name: mkdocs-material
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-05-07 20:43:15+02:00,['requirements.txt']
"Python: Add REST support for SigV4 (#7519)

* Add REST support for SigV4 signed requests

* Add comment for second session create

* lint

* Address comments

* Fix typing issues

* Add docks

* Lint

* remove lint ignore",3,150,2023-05-07 21:34:50+02:00,"['configuration.md', 'rest.py', 'test_rest.py']"
Flink: fix typo in namespace (#7527),6,24,2023-05-07 20:32:03-07:00,"['TestFlinkCatalogDatabase.java', 'TestFlinkCatalogTable.java', 'TestFlinkCatalogDatabase.java', 'TestFlinkCatalogTable.java', 'TestFlinkCatalogDatabase.java', 'TestFlinkCatalogTable.java']"
Arrow: Fix errorprone warnings (#7498),3,25,2023-05-08 08:13:39+02:00,"['ColumnVector.java', 'baseline.gradle', 'OrcSplit.java']"
Spark: Use UUIDUtil.convertToByteBuffer to avoid rewinding buffer (#7525),5,41,2023-05-08 08:49:47+02:00,"['ValueWriters.java', 'SparkValueWriters.java', 'SparkValueWriters.java', 'SparkValueWriters.java', 'SparkValueWriters.java']"
"Build: Bump me.champeau.jmh:jmh-gradle-plugin from 0.7.0 to 0.7.1 (#7408)

Bumps me.champeau.jmh:jmh-gradle-plugin from 0.7.0 to 0.7.1.

---
updated-dependencies:
- dependency-name: me.champeau.jmh:jmh-gradle-plugin
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-05-08 12:12:34+02:00,['build.gradle']
"Build: Bump adlfs from 2023.1.0 to 2023.4.0 in /python (#7543)

Bumps [adlfs](https://github.com/dask/adlfs) from 2023.1.0 to 2023.4.0.
- [Changelog](https://github.com/fsspec/adlfs/blob/main/CHANGELOG.md)
- [Commits](https://github.com/dask/adlfs/compare/2023.1.0...2023.4.0)

---
updated-dependencies:
- dependency-name: adlfs
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,6,2023-05-08 15:45:08+02:00,['poetry.lock']
"API, Core: Make RewriteFiles flexible (#7501)",7,247,2023-05-08 12:33:18-07:00,"['RewriteFiles.java', 'BaseRewriteFiles.java', 'ManifestFilterManager.java', 'MergingSnapshotProducer.java', 'BaseRewriteDataFilesAction.java', 'RewritePositionDeletesCommitManager.java', 'TestRewriteFiles.java']"
"API, Core: Make RewriteFiles flexible (#7501)",0,0,2023-05-08 12:33:41-07:00,[]
"API, Core: Make RewriteFiles flexible (#7501)",0,0,2023-05-08 12:34:08-07:00,[]
"API, Core: Make RewriteFiles flexible (#7501)",0,0,2023-05-08 12:34:47-07:00,[]
AWS: add missing line to assign param S3FileIOProperties inside constructor (#7559),1,1,2023-05-08 13:48:02-07:00,['S3FileIO.java']
Build: Update RoaringBitmap to 0.9.44 (#7563),1,2,2023-05-09 09:06:59+02:00,['versions.props']
"Python: Move to strictyaml (#7529)

To avoid the Norway problem",4,379,2023-05-09 09:41:03+02:00,"['poetry.lock', 'config.py', 'pyproject.toml', 'test_config.py']"
Core: Refactor naming in MergingSnapshotProducer (#7564),2,62,2023-05-09 08:56:51-07:00,"['BaseOverwriteFiles.java', 'MergingSnapshotProducer.java']"
Fix typos and improve wording in aws.md (#7548),1,71,2023-05-09 18:11:21+02:00,['aws.md']
Spark 3.3: Uniquess validation when computing updates of changelogs (#7388),5,654,2023-05-09 15:36:25-07:00,"['ChangelogIterator.java', 'ComputeUpdateIterator.java', 'RemoveCarryoverIterator.java', 'CreateChangelogViewProcedure.java', 'TestChangelogIterator.java']"
Core: Add finalizer to ResolvingFileIO (#7536),1,41,2023-05-09 16:24:59-07:00,['ResolvingFileIO.java']
"Core, AWS: Add flag to suppress duplicate FileIO stack trace (#7552)

When `S3FileIO` gets created through `ResolvingFileIO` then the creation stack
trace is being kept in `ResolvingFileIO`. `ResolvingFileIO` will then
close the underlying `S3FileIO` when `ResolvingFileIO#finalize()` gets
called. Therefore we don't want to issue a `WARN` in `S3FileIO` in case
`S3FileIO#finalize()` gets called before `ResolvingFileIO#finalize()`.",2,17,2023-05-09 16:27:50-07:00,"['S3FileIO.java', 'ResolvingFileIO.java']"
"Spark 3.2, 3.4: Uniqueness validation when computing updates of changelogs (#7573)",10,1308,2023-05-10 10:12:49-07:00,"['ChangelogIterator.java', 'ComputeUpdateIterator.java', 'RemoveCarryoverIterator.java', 'CreateChangelogViewProcedure.java', 'TestChangelogIterator.java', 'ChangelogIterator.java', 'ComputeUpdateIterator.java', 'RemoveCarryoverIterator.java', 'CreateChangelogViewProcedure.java', 'TestChangelogIterator.java']"
"AWS: create HttpClientProperties, move s3 related methods into S3FileIOProperties (#7562)

* AWS: create separate class for HttpClientProperties, move s3 helper methods into S3FileIOProperties",7,863,2023-05-10 10:24:27-07:00,"['AwsClientProperties.java', 'AwsProperties.java', 'HttpClientProperties.java', 'S3FileIOProperties.java', 'AwsClientPropertiesTest.java', 'HttpClientPropertiesTest.java', 'TestS3FileIOProperties.java']"
Doc: Updates Writing to Partitioned Table Spark Docs (#7499),1,127,2023-05-10 15:57:59-05:00,['spark-writes.md']
Update slack invite link (#7583),1,2,2023-05-11 10:36:34+02:00,['iceberg_question.yml']
Nessie: Bump Nessie dependencies from 0.57.0 to 0.58.1 (#7579),1,2,2023-05-11 16:07:40+02:00,['versions.props']
Docs: Add identifier to each Markdown file under docs (#7575),32,32,2023-05-12 09:06:14+02:00,"['aws.md', 'branching-and-tagging.md', 'configuration.md', 'dell.md', 'delta-lake-migration.md', 'evolution.md', 'flink-actions.md', 'flink-configuration.md', 'flink-connector.md', 'flink-ddl.md', 'flink-getting-started.md', 'flink-queries.md', 'flink-writes.md', 'hive-migration.md', 'java-api-quickstart.md', 'java-api.md', 'java-custom-catalog.md', 'jdbc.md', 'maintenance.md', 'nessie.md', 'partitioning.md', 'performance.md', 'reliability.md', 'schemas.md', 'spark-configuration.md', 'spark-ddl.md', 'spark-getting-started.md', 'spark-procedures.md', 'spark-queries.md', 'spark-structured-streaming.md', 'spark-writes.md', 'table-migration.md']"
"Python: Bump PyArrow to 12.0.0 (#7588)

This includes the fix https://github.com/apache/arrow/pull/34015

Now:

```
[root@fa7688db87e9 /]# mc admin trace --call s3 minio
2023-05-11T20:06:32.268 [206 Partial Content] s3.GetObject warehouse.minio:9000/nyc/taxis/metadata/00004-5eeae12f-6f3b-4c36-9413-2fbef26a94b7.metadata.json 172.22.0.2        2.791ms       148 B  9.6 KiB
2023-05-11T20:06:32.558 [200 OK] s3.HeadObject 127.0.0.1:9000/warehouse/nyc/taxis/metadata/snap-3831732930279655857-1-9f7fb22f-eb4a-42d2-9657-87cc8039004d.avro 172.22.0.1        2.379ms       153 B  0 B
2023-05-11T20:06:32.566 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/metadata/snap-3831732930279655857-1-9f7fb22f-eb4a-42d2-9657-87cc8039004d.avro 172.22.0.1        1.925ms       159 B  3.9 KiB
2023-05-11T20:06:32.583 [200 OK] s3.HeadObject 127.0.0.1:9000/warehouse/nyc/taxis/metadata/8e396fa9-dc45-4998-8d37-38665bf45724-m0.avro 172.22.0.1        528s        153 B  0 B
2023-05-11T20:06:32.584 [200 OK] s3.HeadObject 127.0.0.1:9000/warehouse/nyc/taxis/metadata/9f7fb22f-eb4a-42d2-9657-87cc8039004d-m0.avro 172.22.0.1        347s        153 B  0 B
2023-05-11T20:06:32.584 [200 OK] s3.HeadObject 127.0.0.1:9000/warehouse/nyc/taxis/metadata/273e2d75-5d3a-4c2c-bebd-a6ef37cadbe2-m0.avro 172.22.0.1        684s        153 B  0 B
2023-05-11T20:06:32.584 [200 OK] s3.HeadObject 127.0.0.1:9000/warehouse/nyc/taxis/metadata/5f6429bd-1ae4-4a54-820e-f53387e04e2b-m0.avro 172.22.0.1        502s        153 B  0 B
2023-05-11T20:06:32.584 [200 OK] s3.HeadObject 127.0.0.1:9000/warehouse/nyc/taxis/metadata/8f666929-42ff-4198-a203-af5c85cfb233-m0.avro 172.22.0.1        962s        153 B  0 B
2023-05-11T20:06:32.589 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/metadata/5f6429bd-1ae4-4a54-820e-f53387e04e2b-m0.avro 172.22.0.1        1.805ms       159 B  7.1 KiB
2023-05-11T20:06:32.589 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/metadata/8e396fa9-dc45-4998-8d37-38665bf45724-m0.avro 172.22.0.1        1.54ms        159 B  7.1 KiB
2023-05-11T20:06:32.588 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/metadata/9f7fb22f-eb4a-42d2-9657-87cc8039004d-m0.avro 172.22.0.1        2.27ms        159 B  7.1 KiB
2023-05-11T20:06:32.589 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/metadata/273e2d75-5d3a-4c2c-bebd-a6ef37cadbe2-m0.avro 172.22.0.1        1.239ms       159 B  7.1 KiB
2023-05-11T20:06:32.589 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/metadata/8f666929-42ff-4198-a203-af5c85cfb233-m0.avro 172.22.0.1        2.783ms       159 B  7.1 KiB
2023-05-11T20:06:32.618 [200 OK] s3.HeadObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1272-519910f9-3e1b-4a64-8745-3c34d879233d-00001.parquet 172.22.0.1        445s        153 B  0 B
2023-05-11T20:06:32.618 [200 OK] s3.HeadObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1290-df4bb385-1e5f-4841-960f-85600d3708e5-00001.parquet 172.22.0.1        319s        153 B  0 B
2023-05-11T20:06:32.618 [200 OK] s3.HeadObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1254-03dd06d8-f2da-4b9b-89ba-a2421e3f60fd-00001.parquet 172.22.0.1        263s        153 B  0 B
2023-05-11T20:06:32.618 [200 OK] s3.HeadObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1263-f568eb3b-a4d6-4a93-bcae-2b22f8baa1e7-00001.parquet 172.22.0.1        929s        153 B  0 B
2023-05-11T20:06:32.618 [200 OK] s3.HeadObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1281-d941a1d6-d041-4cf3-9e44-778191ae68fb-00001.parquet 172.22.0.1        275s        153 B  0 B
2023-05-11T20:06:32.622 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1290-df4bb385-1e5f-4841-960f-85600d3708e5-00001.parquet 172.22.0.1        2.981ms       159 B  64 KiB
2023-05-11T20:06:32.622 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1272-519910f9-3e1b-4a64-8745-3c34d879233d-00001.parquet 172.22.0.1        6.991ms       159 B  64 KiB
2023-05-11T20:06:32.624 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1263-f568eb3b-a4d6-4a93-bcae-2b22f8baa1e7-00001.parquet 172.22.0.1        4.944ms       159 B  64 KiB
2023-05-11T20:06:32.624 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1281-d941a1d6-d041-4cf3-9e44-778191ae68fb-00001.parquet 172.22.0.1        6.287ms       159 B  64 KiB
2023-05-11T20:06:32.622 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1254-03dd06d8-f2da-4b9b-89ba-a2421e3f60fd-00001.parquet 172.22.0.1        9.967ms       159 B  64 KiB
2023-05-11T20:06:32.641 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1281-d941a1d6-d041-4cf3-9e44-778191ae68fb-00001.parquet 172.22.0.1        95.637ms      159 B  6.6 MiB
2023-05-11T20:06:32.638 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1272-519910f9-3e1b-4a64-8745-3c34d879233d-00001.parquet 172.22.0.1        711.24ms      159 B  15 MiB
2023-05-11T20:06:32.638 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1290-df4bb385-1e5f-4841-960f-85600d3708e5-00001.parquet 172.22.0.1        767.182ms     159 B  16 MiB
2023-05-11T20:06:32.640 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1263-f568eb3b-a4d6-4a93-bcae-2b22f8baa1e7-00001.parquet 172.22.0.1        1.694288s     159 B  27 MiB
2023-05-11T20:06:32.640 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1263-f568eb3b-a4d6-4a93-bcae-2b22f8baa1e7-00001.parquet 172.22.0.1        1.748438s     159 B  27 MiB
2023-05-11T20:06:32.640 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1272-519910f9-3e1b-4a64-8745-3c34d879233d-00001.parquet 172.22.0.1        1.895823s     159 B  29 MiB
2023-05-11T20:06:32.638 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1290-df4bb385-1e5f-4841-960f-85600d3708e5-00001.parquet 172.22.0.1        1.925349s     159 B  32 MiB
2023-05-11T20:06:32.644 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1281-d941a1d6-d041-4cf3-9e44-778191ae68fb-00001.parquet 172.22.0.1        1.944678s     159 B  30 MiB
2023-05-11T20:06:33.200 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1254-03dd06d8-f2da-4b9b-89ba-a2421e3f60fd-00001.parquet 172.22.0.1        1.510093s     159 B  27 MiB
2023-05-11T20:06:33.972 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1254-03dd06d8-f2da-4b9b-89ba-a2421e3f60fd-00001.parquet 172.22.0.1        1.326988s     159 B  26 MiB
```

Before:
```
^C[root@fa7688db87e9 /]# mc admin trace --call s3 minio
2023-05-11T20:19:09.894 [206 Partial Content] s3.GetObject warehouse.minio:9000/nyc/taxis/metadata/00004-5eeae12f-6f3b-4c36-9413-2fbef26a94b7.metadata.json 172.22.0.2        897s        148 B  9.6 KiB
2023-05-11T20:19:11.092 [200 OK] s3.HeadObject 127.0.0.1:9000/warehouse/nyc/taxis/metadata/snap-3831732930279655857-1-9f7fb22f-eb4a-42d2-9657-87cc8039004d.avro 172.22.0.1        2.395ms       153 B  0 B
2023-05-11T20:19:11.113 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/metadata/snap-3831732930279655857-1-9f7fb22f-eb4a-42d2-9657-87cc8039004d.avro 172.22.0.1        1.439ms       159 B  3.9 KiB
2023-05-11T20:19:11.135 [200 OK] s3.HeadObject 127.0.0.1:9000/warehouse/nyc/taxis/metadata/5f6429bd-1ae4-4a54-820e-f53387e04e2b-m0.avro 172.22.0.1        1.135ms       153 B  0 B
2023-05-11T20:19:11.136 [200 OK] s3.HeadObject 127.0.0.1:9000/warehouse/nyc/taxis/metadata/273e2d75-5d3a-4c2c-bebd-a6ef37cadbe2-m0.avro 172.22.0.1        376s        153 B  0 B
2023-05-11T20:19:11.136 [200 OK] s3.HeadObject 127.0.0.1:9000/warehouse/nyc/taxis/metadata/8f666929-42ff-4198-a203-af5c85cfb233-m0.avro 172.22.0.1        465s        153 B  0 B
2023-05-11T20:19:11.136 [200 OK] s3.HeadObject 127.0.0.1:9000/warehouse/nyc/taxis/metadata/8e396fa9-dc45-4998-8d37-38665bf45724-m0.avro 172.22.0.1        841s        153 B  0 B
2023-05-11T20:19:11.135 [200 OK] s3.HeadObject 127.0.0.1:9000/warehouse/nyc/taxis/metadata/9f7fb22f-eb4a-42d2-9657-87cc8039004d-m0.avro 172.22.0.1        2.065ms       153 B  0 B
2023-05-11T20:19:11.143 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/metadata/9f7fb22f-eb4a-42d2-9657-87cc8039004d-m0.avro 172.22.0.1        1.153ms       159 B  7.1 KiB
2023-05-11T20:19:11.144 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/metadata/8e396fa9-dc45-4998-8d37-38665bf45724-m0.avro 172.22.0.1        1.105ms       159 B  7.1 KiB
2023-05-11T20:19:11.143 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/metadata/8f666929-42ff-4198-a203-af5c85cfb233-m0.avro 172.22.0.1        2.29ms        159 B  7.1 KiB
2023-05-11T20:19:11.143 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/metadata/5f6429bd-1ae4-4a54-820e-f53387e04e2b-m0.avro 172.22.0.1        2.646ms       159 B  7.1 KiB
2023-05-11T20:19:11.144 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/metadata/273e2d75-5d3a-4c2c-bebd-a6ef37cadbe2-m0.avro 172.22.0.1        1.914ms       159 B  7.1 KiB
2023-05-11T20:19:11.176 [200 OK] s3.HeadObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1281-d941a1d6-d041-4cf3-9e44-778191ae68fb-00001.parquet 172.22.0.1        368s        153 B  0 B
2023-05-11T20:19:11.176 [200 OK] s3.HeadObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1290-df4bb385-1e5f-4841-960f-85600d3708e5-00001.parquet 172.22.0.1        380s        153 B  0 B
2023-05-11T20:19:11.176 [200 OK] s3.HeadObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1272-519910f9-3e1b-4a64-8745-3c34d879233d-00001.parquet 172.22.0.1        280s        153 B  0 B
2023-05-11T20:19:11.177 [200 OK] s3.HeadObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1254-03dd06d8-f2da-4b9b-89ba-a2421e3f60fd-00001.parquet 172.22.0.1        255s        153 B  0 B
2023-05-11T20:19:11.177 [200 OK] s3.HeadObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1263-f568eb3b-a4d6-4a93-bcae-2b22f8baa1e7-00001.parquet 172.22.0.1        433s        153 B  0 B
2023-05-11T20:19:11.180 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1281-d941a1d6-d041-4cf3-9e44-778191ae68fb-00001.parquet 172.22.0.1        4.36ms        159 B  64 KiB
2023-05-11T20:19:11.182 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1263-f568eb3b-a4d6-4a93-bcae-2b22f8baa1e7-00001.parquet 172.22.0.1        3.465ms       159 B  64 KiB
2023-05-11T20:19:11.180 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1290-df4bb385-1e5f-4841-960f-85600d3708e5-00001.parquet 172.22.0.1        6.57ms        159 B  64 KiB
2023-05-11T20:19:11.180 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1272-519910f9-3e1b-4a64-8745-3c34d879233d-00001.parquet 172.22.0.1        7.434ms       159 B  64 KiB
2023-05-11T20:19:11.182 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1254-03dd06d8-f2da-4b9b-89ba-a2421e3f60fd-00001.parquet 172.22.0.1        6.438ms       159 B  64 KiB
2023-05-11T20:19:11.196 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1290-df4bb385-1e5f-4841-960f-85600d3708e5-00001.parquet 172.22.0.1        3.827ms       159 B  64 KiB
2023-05-11T20:19:11.196 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1263-f568eb3b-a4d6-4a93-bcae-2b22f8baa1e7-00001.parquet 172.22.0.1        3.971ms       159 B  64 KiB
2023-05-11T20:19:11.194 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1281-d941a1d6-d041-4cf3-9e44-778191ae68fb-00001.parquet 172.22.0.1        5.977ms       159 B  64 KiB
2023-05-11T20:19:11.198 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1254-03dd06d8-f2da-4b9b-89ba-a2421e3f60fd-00001.parquet 172.22.0.1        7.024ms       159 B  64 KiB
2023-05-11T20:19:11.196 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1272-519910f9-3e1b-4a64-8745-3c34d879233d-00001.parquet 172.22.0.1        9.302ms       159 B  64 KiB
2023-05-11T20:19:11.213 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1281-d941a1d6-d041-4cf3-9e44-778191ae68fb-00001.parquet 172.22.0.1        69.011ms      159 B  6.6 MiB
2023-05-11T20:19:11.211 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1272-519910f9-3e1b-4a64-8745-3c34d879233d-00001.parquet 172.22.0.1        685.555ms     159 B  15 MiB
2023-05-11T20:19:11.213 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1290-df4bb385-1e5f-4841-960f-85600d3708e5-00001.parquet 172.22.0.1        886.157ms     159 B  16 MiB
2023-05-11T20:19:11.211 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1263-f568eb3b-a4d6-4a93-bcae-2b22f8baa1e7-00001.parquet 172.22.0.1        1.711973s     159 B  27 MiB
2023-05-11T20:19:11.213 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1263-f568eb3b-a4d6-4a93-bcae-2b22f8baa1e7-00001.parquet 172.22.0.1        1.740533s     159 B  27 MiB
2023-05-11T20:19:11.211 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1272-519910f9-3e1b-4a64-8745-3c34d879233d-00001.parquet 172.22.0.1        1.754817s     159 B  29 MiB
2023-05-11T20:19:11.209 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1281-d941a1d6-d041-4cf3-9e44-778191ae68fb-00001.parquet 172.22.0.1        1.960224s     159 B  30 MiB
2023-05-11T20:19:11.211 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1290-df4bb385-1e5f-4841-960f-85600d3708e5-00001.parquet 172.22.0.1        2.066043s     159 B  32 MiB
2023-05-11T20:19:11.784 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1254-03dd06d8-f2da-4b9b-89ba-a2421e3f60fd-00001.parquet 172.22.0.1        1.618623s     159 B  27 MiB
2023-05-11T20:19:12.526 [206 Partial Content] s3.GetObject 127.0.0.1:9000/warehouse/nyc/taxis/data/00003-1254-03dd06d8-f2da-4b9b-89ba-a2421e3f60fd-00001.parquet 172.22.0.1        1.407968s     159 B  26 MiB
```",2,176,2023-05-12 14:26:31+02:00,"['poetry.lock', 'pyproject.toml']"
Core: Check all specs to determine schema of partitions table (#7551),2,41,2023-05-12 09:37:56-07:00,"['PartitionsTable.java', 'TestMetadataTableScansWithPartitionEvolution.java']"
"API, Flink: StructProjection returns null projection object for null nested struct value (#7517)",4,36,2023-05-12 12:28:54-07:00,"['StructProjection.java', 'RowDataProjection.java', 'RowDataProjection.java', 'RowDataProjection.java']"
"Build: Bump mkdocstrings-python from 0.9.0 to 1.0.0 in /python (#7606)

Bumps [mkdocstrings-python](https://github.com/mkdocstrings/python) from 0.9.0 to 1.0.0.
- [Changelog](https://github.com/mkdocstrings/python/blob/master/CHANGELOG.md)
- [Commits](https://github.com/mkdocstrings/python/compare/0.9.0...1.0.0)

---
updated-dependencies:
- dependency-name: mkdocstrings-python
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-05-14 20:02:29+02:00,['requirements.txt']
"Build: Bump pre-commit from 3.2.2 to 3.3.1 in /python (#7605)

Bumps [pre-commit](https://github.com/pre-commit/pre-commit) from 3.2.2 to 3.3.1.
- [Release notes](https://github.com/pre-commit/pre-commit/releases)
- [Changelog](https://github.com/pre-commit/pre-commit/blob/main/CHANGELOG.md)
- [Commits](https://github.com/pre-commit/pre-commit/compare/v3.2.2...v3.3.1)

---
updated-dependencies:
- dependency-name: pre-commit
  dependency-type: direct:development
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,14,2023-05-14 20:03:51+02:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump griffe from 0.27.3 to 0.27.5 in /python (#7604)

Bumps [griffe](https://github.com/mkdocstrings/griffe) from 0.27.3 to 0.27.5.
- [Changelog](https://github.com/mkdocstrings/griffe/blob/master/CHANGELOG.md)
- [Commits](https://github.com/mkdocstrings/griffe/compare/0.27.3...0.27.5)

---
updated-dependencies:
- dependency-name: griffe
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-05-14 20:05:28+02:00,['requirements.txt']
"Build: Bump mkdocs-material from 9.1.9 to 9.1.12 in /python (#7603)

Bumps [mkdocs-material](https://github.com/squidfunk/mkdocs-material) from 9.1.9 to 9.1.12.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/CHANGELOG)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/9.1.9...9.1.12)

---
updated-dependencies:
- dependency-name: mkdocs-material
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-05-14 20:05:43+02:00,['requirements.txt']
"Build: Bump mkdocs from 1.4.2 to 1.4.3 in /python (#7602)

Bumps [mkdocs](https://github.com/mkdocs/mkdocs) from 1.4.2 to 1.4.3.
- [Release notes](https://github.com/mkdocs/mkdocs/releases)
- [Commits](https://github.com/mkdocs/mkdocs/compare/1.4.2...1.4.3)

---
updated-dependencies:
- dependency-name: mkdocs
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-05-14 20:20:52+02:00,['requirements.txt']
"Build: Upgrade Gradle to 8.1.1 (#7610)

see https://docs.gradle.org/8.1.1/release-notes.html

Upgraded by running the following command twice and manually
re-applying iceberg customizations:

./gradlew wrapper --gradle-version 8.1.1 --gradle-distribution-sha256-sum e111cb9948407e26351227dabce49822fb88c37ee72f1d1582a69c68af2e702",2,13,2023-05-15 09:13:06+02:00,"['gradle-wrapper.properties', 'gradlew']"
"Core: Remove deprecated AssertHelpers usage in catalog (#7596)

* Core: Remove deprecated AssertHelpers usage in catalog

* fix test",2,206,2023-05-15 09:25:40+02:00,"['CatalogTests.java', 'TestTableIdentifierParser.java']"
Build: Bump Arrow from 11.0.0 to 12.0.0 (#7595),1,4,2023-05-15 09:27:36+02:00,['versions.props']
Core: Remove deprecated AssertHelpers usage (#7597),11,390,2023-05-15 09:34:24+02:00,"['TestBinPackStrategy.java', 'TestSortStrategy.java', 'TestByteBufferInputStreams.java', 'TestIOUtil.java', 'TestJdbcCatalog.java', 'TestNameMapping.java', 'TestHTTPClient.java', 'TestRESTCatalog.java', 'TestInMemoryLockManager.java', 'TestLocationUtil.java', 'TestTableScanUtil.java']"
Spark: Fix Parquet read benchmarks for Spark 3.3 + 3.4 (#7587),4,12,2023-05-15 15:21:35+02:00,"['SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java']"
"Docs: Improve readability on page Branching and Tagging (#7592)

* Improve the description",1,2,2023-05-15 08:04:30-07:00,['branching-and-tagging.md']
"Flink: change sink shuffle to use RowData as data type and statistics key type (#7494)

Flink: change sink shuffle to use RowData as data type and statistics key type, because FlinkSink normalize the data type to RowData before coming to writer. Also added custom type serializers for MapDataStatistics and /DataStatisticsOrRecord.",10,812,2023-05-15 08:43:49-07:00,"['DataStatistics.java', 'DataStatisticsEvent.java', 'DataStatisticsFactory.java', 'DataStatisticsOperator.java', 'DataStatisticsOrRecord.java', 'DataStatisticsOrRecordSerializer.java', 'MapDataStatistics.java', 'MapDataStatisticsFactory.java', 'MapDataStatisticsSerializer.java', 'TestDataStatisticsOperator.java']"
"Flink: add toString, equals, hashCode overrides for RowDataProjection. (#7493)

* Flink: add toString, equals, hashCode overrides for RowDataProjection.

Flink RowData implementation classes (like GenericRowData) all implement proper overrides for those methods. We also intend to use RowDataProjection as map key for MapDataStatistics from sink shuffling work. Hence this change is also required.",4,772,2023-05-15 08:44:17-07:00,"['RowDataProjection.java', 'DataGenerator.java', 'DataGenerators.java', 'TestRowDataProjection.java']"
Core: Add ReadableMetrics in Entries table (#7539),8,397,2023-05-15 10:22:26-07:00,"['BaseEntriesTable.java', 'TestEntriesMetadataTable.java', 'TestMetadataTableScans.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestMetadataTableReadableMetrics.java']"
"Add unique JDBC application identifier and user agent header (#7580)

* Add user agent headers to Snowflake catalog

* Suggested fixes

* Restrict length of unique id",2,18,2023-05-15 14:09:17-07:00,"['SnowflakeCatalog.java', 'versions.props']"
Spark: Remove deprecated methods in VectorizedSparkParquetReaders (#7591),15,366,2023-05-15 17:02:18-07:00,"['VectorizedSparkParquetReaders.java', 'TestHelpers.java', 'TestSparkParquetReadMetadataColumns.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetVectorizedReads.java', 'VectorizedSparkParquetReaders.java', 'TestHelpers.java', 'TestSparkParquetReadMetadataColumns.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetVectorizedReads.java', 'VectorizedSparkParquetReaders.java', 'TestHelpers.java', 'TestSparkParquetReadMetadataColumns.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetVectorizedReads.java']"
"Views: Update spec with expectations on versions, representations, and dialects (#7500)",1,4,2023-05-15 19:06:45-07:00,['view-spec.md']
"Core: Allow deleting old partition spec columns in V1 (#7398)

Resolves #7386",2,36,2023-05-15 19:08:38-07:00,"['TableMetadata.java', 'TestPartitioning.java']"
"API, Core, Spark: Add file groups failure in rewrite result (#7361)",5,82,2023-05-16 07:27:26+02:00,"['RewriteDataFiles.java', 'TestRewriteDataFilesProcedure.java', 'RewriteDataFilesSparkAction.java', 'RewriteDataFilesProcedure.java', 'TestRewriteDataFilesAction.java']"
Docs: Update link to contributing section (#7117),1,2,2023-05-16 10:15:43+02:00,['CONTRIBUTING.md']
AWS: Add S3FileIOAwsClientFactory for S3FileIO (#7590),9,283,2023-05-16 08:28:04-07:00,"['TestS3FileIOIntegration.java', 'AwsClientProperties.java', 'HttpClientProperties.java', 'S3FileIOAwsClientFactories.java', 'DefaultS3FileIOAwsClientFactory.java', 'S3FileIO.java', 'S3FileIOAwsClientFactory.java', 'S3FileIOProperties.java', 'TestS3FileIOAwsClientFactories.java']"
Core: Add FileIO tracker/closer to REST catalog (#7487),1,55,2023-05-16 08:56:37-07:00,['RESTSessionCatalog.java']
"API, Core: Expose file and data sequence numbers through ContentFile (#7555)

API, Core: Expose file and data sequence numbers through ContentFile 
Co-authored-by: chenjunjiedada <jimmyjchen@tencent.com>",10,378,2023-05-16 09:03:37-07:00,"['ContentFile.java', 'Snapshot.java', 'BaseFile.java', 'InheritableMetadataFactory.java', 'V1Metadata.java', 'V2Metadata.java', 'TableTestBase.java', 'TestDataTableScan.java', 'TestSequenceNumberForV2Table.java', 'TestSnapshot.java']"
Spark 3.4: Avoid local sort for MERGE cardinality check (#7558),8,297,2023-05-16 13:56:26-07:00,"['.gitignore', 'jmh.gradle', 'build.gradle', 'MergeCardinalityCheckBenchmark.java', 'RewriteMergeIntoTable.scala', 'MergeRows.scala', 'ExtendedDataSourceV2Strategy.scala', 'MergeRowsExec.scala']"
Spark 3.4: Fixup for RewritePositionDeleteFilesSparkAction (#7389) (#7565),3,177,2023-05-16 16:17:03-07:00,"['StructLikeMap.java', 'RewritePositionDeleteFilesSparkAction.java', 'SparkActions.java']"
Flink: Add config for max allowed consecutive planning failures in IcebergSource before failing the job (#7571),8,225,2023-05-16 19:52:37-07:00,"['flink-configuration.md', 'FlinkReadConf.java', 'FlinkReadOptions.java', 'IcebergSource.java', 'ScanContext.java', 'ContinuousIcebergEnumerator.java', 'ManualContinuousSplitPlanner.java', 'TestContinuousIcebergEnumerator.java']"
"Build: Bump com.fasterxml.jackson.core:jackson-annotations (#7601)

Bumps [com.fasterxml.jackson.core:jackson-annotations](https://github.com/FasterXML/jackson) from 2.14.2 to 2.15.0.
- [Commits](https://github.com/FasterXML/jackson/commits)

---
updated-dependencies:
- dependency-name: com.fasterxml.jackson.core:jackson-annotations
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,4,2023-05-17 07:39:53+02:00,"['build.gradle', 'build.gradle']"
Spark: Disable aggregate pushdown for incremental scan (#7626),4,30,2023-05-17 08:44:51-07:00,"['SparkScanBuilder.java', 'TestDataSourceOptions.java', 'SparkScanBuilder.java', 'TestDataSourceOptions.java']"
Spark 3.4: Add RewritePositionDeleteFilesProcedure (#7572),3,262,2023-05-17 08:50:55-07:00,"['TestRewritePositionDeleteFilesProcedure.java', 'RewritePositionDeleteFilesProcedure.java', 'SparkProcedures.java']"
Build: Remove Kyle and add bitsondatadev to collaborators .asf.yaml (#7634),1,3,2023-05-17 12:35:14-07:00,['.asf.yaml']
"Improve Error Handling to map Snowflake Exceptions into Iceberg Exceptions (#6952)

* Improve Error Handling to map Snowflake Exceptions into Iceberg Exceptions

* Fix code style

* Stray character

* Address code review comments

* Style cop

* Refactor and cleanup helper method

* Refactor helper method

* Change Set declaration

* Address review feedback to refactor tests to be clearer

* Refactor Exception conversion method

---------

Co-authored-by: Anubhav Sudhakar <anubhav.sudhakar+oss+oss@snowflake.com>",3,422,2023-05-17 15:45:43-07:00,"['JdbcSnowflakeClient.java', 'SnowflakeCatalog.java', 'JdbcSnowflakeClientTest.java']"
Flink: backport Add config for max allowed consecutive planning failures in IcebergSource before failing the job (#7571) to 1.16 and 1.15 (#7629),14,360,2023-05-18 10:55:02+02:00,"['FlinkReadConf.java', 'FlinkReadOptions.java', 'IcebergSource.java', 'ScanContext.java', 'ContinuousIcebergEnumerator.java', 'ManualContinuousSplitPlanner.java', 'TestContinuousIcebergEnumerator.java', 'FlinkReadConf.java', 'FlinkReadOptions.java', 'IcebergSource.java', 'ScanContext.java', 'ContinuousIcebergEnumerator.java', 'ManualContinuousSplitPlanner.java', 'TestContinuousIcebergEnumerator.java']"
Flink: backport PR #7494. change sink shuffle to use RowData as data type and statistics key type (#7632),20,1624,2023-05-18 06:44:10-07:00,"['DataStatistics.java', 'DataStatisticsEvent.java', 'DataStatisticsFactory.java', 'DataStatisticsOperator.java', 'DataStatisticsOrRecord.java', 'DataStatisticsOrRecordSerializer.java', 'MapDataStatistics.java', 'MapDataStatisticsFactory.java', 'MapDataStatisticsSerializer.java', 'TestDataStatisticsOperator.java', 'DataStatistics.java', 'DataStatisticsEvent.java', 'DataStatisticsFactory.java', 'DataStatisticsOperator.java', 'DataStatisticsOrRecord.java', 'DataStatisticsOrRecordSerializer.java', 'MapDataStatistics.java', 'MapDataStatisticsFactory.java', 'MapDataStatisticsSerializer.java', 'TestDataStatisticsOperator.java']"
"Flink: backport PR #7493. add toString, equals, hashCode overrides for RowDataProjection (#7631)",8,1582,2023-05-18 08:09:57-07:00,"['RowDataProjection.java', 'DataGenerator.java', 'DataGenerators.java', 'TestRowDataProjection.java', 'RowDataProjection.java', 'DataGenerator.java', 'DataGenerators.java', 'TestRowDataProjection.java']"
"Flink: sink support of spec evaluation (#7171)

Use the same spec as writer operator for writing manifest file. Use the specs map from table when reading a manifest file.",6,224,2023-05-18 10:44:43-07:00,"['FlinkManifestUtil.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'SimpleDataUtil.java', 'TestFlinkManifest.java', 'TestIcebergFilesCommitter.java']"
Core: Allow one data writer in BasePositionDeltaWriter (#7648),2,51,2023-05-18 15:16:58-07:00,"['BasePositionDeltaWriter.java', 'TestPositionDeltaWriters.java']"
Spark 3.4: Minor refactoring for SparkPositionDeltaWrite (#7650),1,55,2023-05-18 20:05:27-07:00,['SparkPositionDeltaWrite.java']
Spark-3.4: Fix errorprone warning (#7654),3,7,2023-05-19 11:49:54+02:00,"['baseline.gradle', 'build.gradle', 'MergeCardinalityCheckBenchmark.java']"
"GCP, Pig: Switch tests to JUnit5 (#7647)",5,68,2023-05-19 14:20:13+02:00,"['build.gradle', 'GCSFileIOTest.java', 'GCSInputStreamTest.java', 'GCSOutputStreamTest.java', 'SchemaUtilTest.java']"
"Spark 3.4: Fix NPE when create branch and tag on table without snapshot (#7652)

* Spark 3.4: Fix NPE when create branch and tag on table without snapshot

---------

Co-authored-by: Steve Zhang <hongyue_zhang@apple.com>",4,48,2023-05-19 11:40:52-07:00,"['CreateOrReplaceBranchExec.scala', 'CreateOrReplaceTagExec.scala', 'TestBranchDDL.java', 'TestTagDDL.java']"
Spark 3.4: Split update into delete and insert for position deltas (#7646),12,1016,2023-05-19 13:34:35-07:00,"['UpdateProjectionBenchmark.java', 'RewriteMergeIntoTable.scala', 'RewriteRowLevelIcebergCommand.scala', 'RewriteUpdateTable.scala', 'MergeRows.scala', 'UpdateRows.scala', 'ExtendedDataSourceV2Strategy.scala', 'MergeRowsExec.scala', 'UpdateRowsExec.scala', 'TestMerge.java', 'SparkDistributionAndOrderingUtil.java', 'TestSparkDistributionAndOrderingUtil.java']"
"Parquet: Update parquet to 1.13.1 (#7301)

* Parquet: Update parquet to 1.13.0

* fix aliyun failures

* Disable dictionary encoding to make sure BF always gets created

* Update the doc

* point to 1.13.1 using staging repo until officially released

* revert staging remote repo

* remove apache commons dep

* address review feedback

---------

Co-authored-by: Prashant Singh <psinghvk@amazon.com>",5,118,2023-05-19 23:05:27+02:00,"['TableProperties.java', 'configuration.md', 'Parquet.java', 'TestBloomRowGroupFilter.java', 'versions.props']"
Spark 3.4: Harmonize RewriteDataFilesSparkAction code with RewritePositionDeleteFilesSparkAction (#7630),3,183,2023-05-19 16:09:39-07:00,"['RewriteFileGroup.java', 'RewriteDataFilesSparkAction.java', 'TestRewriteDataFilesAction.java']"
"Spark 3.3, 3.4: Fix always true/false condition in rewrite_data_files procedure (#6760)",4,94,2023-05-19 17:29:21-07:00,"['TestRewriteDataFilesProcedure.java', 'SparkExpressionConverter.scala', 'TestRewriteDataFilesProcedure.java', 'SparkExpressionConverter.scala']"
"Spark 3.2: backport Spark SQL extension on create/update/drop tags (#7662)

* Spark 3.2: backport Spark SQL extension on create/update/drop tags
---------

Co-authored-by: Steve Zhang <hongyue_zhang@apple.com>",10,677,2023-05-20 11:30:46-07:00,"['IcebergSqlExtensions.g4', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'CreateOrReplaceTag.scala', 'DropTag.scala', 'TagOptions.scala', 'CreateOrReplaceTagExec.scala', 'DropTagExec.scala', 'ExtendedDataSourceV2Strategy.scala', 'TestTagDDL.java']"
"Spark: Backport fix NPE when create branch and tag on table without snapshot (#7659)

Co-authored-by: Steve Zhang <hongyue_zhang@apple.com>",8,96,2023-05-20 12:05:47-07:00,"['CreateOrReplaceBranchExec.scala', 'TestBranchDDL.java', 'CreateOrReplaceBranchExec.scala', 'TestBranchDDL.java', 'CreateOrReplaceBranchExec.scala', 'CreateOrReplaceTagExec.scala', 'TestBranchDDL.java', 'TestTagDDL.java']"
Core: Compacted position delete files should use the max data sequence number of source files (#7651),6,247,2023-05-20 22:06:37-07:00,"['RewriteFiles.java', 'BaseRewriteFiles.java', 'MergingSnapshotProducer.java', 'RewritePositionDeletesCommitManager.java', 'RewritePositionDeletesGroup.java', 'TestRewritePositionDeleteFilesAction.java']"
Docs: RewritePositionDeleteFiles procedure (#7589),1,45,2023-05-20 22:08:17-07:00,['spark-procedures.md']
"Build: Bump mkdocs-material from 9.1.12 to 9.1.14 in /python (#7670)

Bumps [mkdocs-material](https://github.com/squidfunk/mkdocs-material) from 9.1.12 to 9.1.14.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/CHANGELOG)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/9.1.12...9.1.14)

---
updated-dependencies:
- dependency-name: mkdocs-material
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-05-21 08:51:40+02:00,['requirements.txt']
"Build: Bump fastavro from 1.7.3 to 1.7.4 in /python (#7671)

Bumps [fastavro](https://github.com/fastavro/fastavro) from 1.7.3 to 1.7.4.
- [Release notes](https://github.com/fastavro/fastavro/releases)
- [Changelog](https://github.com/fastavro/fastavro/blob/master/ChangeLog)
- [Commits](https://github.com/fastavro/fastavro/compare/1.7.3...1.7.4)

---
updated-dependencies:
- dependency-name: fastavro
  dependency-type: direct:development
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,68,2023-05-21 08:52:17+02:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump duckdb from 0.7.1 to 0.8.0 in /python (#7673)

Bumps [duckdb](https://github.com/duckdb/duckdb) from 0.7.1 to 0.8.0.
- [Release notes](https://github.com/duckdb/duckdb/releases)
- [Changelog](https://github.com/duckdb/duckdb/blob/master/tools/release-pip.py)
- [Commits](https://github.com/duckdb/duckdb/compare/v0.7.1...v0.8.0)

---
updated-dependencies:
- dependency-name: duckdb
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,96,2023-05-21 08:52:35+02:00,['poetry.lock']
"Build: Bump griffe from 0.27.5 to 0.28.0 in /python (#7674)

Bumps [griffe](https://github.com/mkdocstrings/griffe) from 0.27.5 to 0.28.0.
- [Changelog](https://github.com/mkdocstrings/griffe/blob/master/CHANGELOG.md)
- [Commits](https://github.com/mkdocstrings/griffe/compare/0.27.5...0.28.0)

---
updated-dependencies:
- dependency-name: griffe
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-05-21 08:52:45+02:00,['requirements.txt']
"Spec: OpenAPI responses should reference schemas (#6699)

The common _OpenAPI Tools_ generators do not properly recognize non-200 responses and generate the necessary objects for the non-200 response types.
This change moves the schema definitions from `responses` to `schemas`.

Having code generated from the spec helps a lot, at least as a good start.",1,291,2023-05-21 13:09:38-07:00,['rest-catalog-open-api.yaml']
"Core, Parquet: Remove Parquet dictionary encoding table property (#7665)

Co-authored-by: Fokko Driesprong <fokko@apache.org>",4,49,2023-05-21 15:22:32-07:00,"['TableProperties.java', 'configuration.md', 'Parquet.java', 'TestBloomRowGroupFilter.java']"
"Build: Bump pre-commit from 3.3.1 to 3.3.2 in /python (#7672)

Bumps [pre-commit](https://github.com/pre-commit/pre-commit) from 3.3.1 to 3.3.2.
- [Release notes](https://github.com/pre-commit/pre-commit/releases)
- [Changelog](https://github.com/pre-commit/pre-commit/blob/main/CHANGELOG.md)
- [Commits](https://github.com/pre-commit/pre-commit/compare/v3.3.1...v3.3.2)

---
updated-dependencies:
- dependency-name: pre-commit
  dependency-type: direct:development
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,10,2023-05-22 09:03:34-05:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump com.esotericsoftware:kryo-shaded from 4.0.2 to 4.0.3 (#7669)

Bumps com.esotericsoftware:kryo-shaded from 4.0.2 to 4.0.3.

---
updated-dependencies:
- dependency-name: com.esotericsoftware:kryo-shaded
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,4,2023-05-22 12:16:19-05:00,"['build.gradle', 'build.gradle']"
"Infra: Use the standard shadow plugin (#7681)

thanks for fixing this @ajantha-bhat",1,2,2023-05-22 20:48:55+02:00,['build.gradle']
Spark 3.4: Add TimestampNTZ (#7553),41,1047,2023-05-22 15:50:16-07:00,"['PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'SparkCatalog.java', 'SparkFilters.java', 'SparkFixupTimestampType.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkSQLProperties.java', 'SparkSchemaUtil.java', 'SparkTypeToType.java', 'SparkUtil.java', 'SparkValueConverter.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'TypeToSparkType.java', 'BucketFunction.java', 'DaysFunction.java', 'HoursFunction.java', 'MonthsFunction.java', 'YearsFunction.java', 'SparkChangelogScan.java', 'SparkPositionDeletesRewriteBuilder.java', 'SparkPositionDeltaWriteBuilder.java', 'SparkScan.java', 'SparkWriteBuilder.java', 'SparkTestBaseWithCatalog.java', 'TestSparkFilters.java', 'AvroDataTest.java', 'GenericsHelpers.java', 'TestHelpers.java', 'TestSparkOrcReader.java', 'TestParquetVectorizedReads.java', 'TestSparkDataFile.java', 'TestTimestampWithoutZone.java', 'TestSparkBucketFunction.java', 'TestSparkDaysFunction.java', 'TestSparkHoursFunction.java', 'TestSparkMonthsFunction.java', 'TestSparkYearsFunction.java', 'TestStoragePartitionedJoins.java', 'TestTimestampWithoutZone.java']"
"Spark 3.3: Add RewritePositionDeleteFilesSparkAction (#7684)

This change backports #7389 to Spark 3.3.",5,1541,2023-05-22 16:59:16-07:00,"['RewritePositionDeleteFilesSparkAction.java', 'SparkActions.java', 'SparkBinPackPositionDeletesRewriter.java', 'TestRewritePositionDeleteFilesAction.java', 'FourColumnRecord.java']"
Spark 3.4: Distribution and ordering enhancements (#7637),13,1921,2023-05-22 17:09:22-07:00,"['Spark3Util.java', 'SparkConfParser.java', 'SparkDistributionAndOrderingUtil.java', 'SparkWriteConf.java', 'SparkWriteRequirements.java', 'SparkWriteUtil.java', 'SparkShufflingDataRewriter.java', 'SparkPositionDeltaWrite.java', 'SparkPositionDeltaWriteBuilder.java', 'SparkWrite.java', 'SparkWriteBuilder.java', 'TestSparkDistributionAndOrderingUtil.java', 'TestSparkWriteConf.java']"
"Flink: Port #7171 to flink 1.17 

Co-authored-by: xianyangliu <xianyangliu@tencent.com>",6,224,2023-05-22 20:32:12-07:00,"['FlinkManifestUtil.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'SimpleDataUtil.java', 'TestFlinkManifest.java', 'TestIcebergFilesCommitter.java']"
"Flink: Port #7171 to 1.15 (#7679)

Co-authored-by: xianyangliu <xianyangliu@tencent.com>",6,224,2023-05-22 20:33:20-07:00,"['FlinkManifestUtil.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'SimpleDataUtil.java', 'TestFlinkManifest.java', 'TestIcebergFilesCommitter.java']"
Spark 3.3: Avoid local sort for MERGE cardinality check (#7686),8,301,2023-05-22 22:19:37-07:00,"['.gitignore', 'jmh.gradle', 'build.gradle', 'MergeCardinalityCheckBenchmark.java', 'RewriteMergeIntoTable.scala', 'MergeRows.scala', 'ExtendedDataSourceV2Strategy.scala', 'MergeRowsExec.scala']"
"Spark 3.3: Add RewritePositionDeleteFilesProcedure (#7687)

This commit backports PR #7572 to Spark 3.3.",3,262,2023-05-22 22:21:07-07:00,"['TestRewritePositionDeleteFilesProcedure.java', 'RewritePositionDeleteFilesProcedure.java', 'SparkProcedures.java']"
"Build: Bump requests from 2.30.0 to 2.31.0 in /python (#7689)

Bumps [requests](https://github.com/psf/requests) from 2.30.0 to 2.31.0.
- [Release notes](https://github.com/psf/requests/releases)
- [Changelog](https://github.com/psf/requests/blob/main/HISTORY.md)
- [Commits](https://github.com/psf/requests/compare/v2.30.0...v2.31.0)

---
updated-dependencies:
- dependency-name: requests
  dependency-type: direct:production
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,6,2023-05-23 07:18:42-05:00,['poetry.lock']
Nessie: Bump Nessie version from 0.58.1 to 0.59.0 (#7642),2,4,2023-05-23 14:59:54+02:00,"['NessieTableOperations.java', 'versions.props']"
"Spark 3.3: Harmonize RewriteDataFilesSparkAction (#7676)

This commit backports PR #7630 to Spark 3.3.",2,166,2023-05-23 11:13:06-07:00,"['RewriteDataFilesSparkAction.java', 'TestRewriteDataFilesAction.java']"
Core: Metadata table code harmonization for readable_metrics (#7613),3,267,2023-05-23 11:23:48-07:00,"['BaseEntriesTable.java', 'BaseFilesTable.java', 'MetricsUtil.java']"
Nessie: Disable table metadata files cleanup during commits (#7641),2,70,2023-05-24 06:01:23-05:00,"['NessieTableOperations.java', 'TestNessieTable.java']"
Core: Support set system level properties with environmental variables (#5659),7,179,2023-05-24 11:11:59-07:00,"['revapi.yml', 'BaseScan.java', 'ManifestFiles.java', 'SystemConfigs.java', 'SystemProperties.java', 'ThreadPools.java', 'TestManifestCaching.java']"
"Core: Fix docstring (#7697)

```
/Users/fokkodriesprong/Desktop/iceberg/core/src/main/java/org/apache/iceberg/BaseFilesTable.java:188: warning: [InvalidBlockTag] @file is not a valid tag, but is a parameter
name. Use {@code %s} to refer to parameter names inline.
     * @file content file metadata
```",1,2,2023-05-24 15:11:45-05:00,['BaseFilesTable.java']
Core: Add writer for unordered position deletes (#7692),5,378,2023-05-25 08:05:50-07:00,"['PositionDeleteWriter.java', 'SortingPositionOnlyDeleteWriter.java', 'FanoutPositionOnlyDeleteWriter.java', 'TestPartitioningWriters.java', 'WritersBenchmark.java']"
"Python: Refactor integration tests (#7698)

* Python: Refactor integration tests

This splits out running and building the integration tests that
enables quick development iterations. I've also added ipython
that will give a more meaningful error when something goes wrong
with the provisioning of the tests.

* Simplify SQL",5,174,2023-05-25 13:45:09-05:00,"['Makefile', 'Dockerfile', 'entrypoint.sh', 'provision.py', 'contributing.md']"
"Spec: TableRequirement definition and parser mismatch (#7700)

* [RestCatalogSpec] AddSchemaUpdate definition & parser mismatch

* Remove unneeded changes

---------

Co-authored-by: Haizhou Zhao <haizhou_zhao@apple.com>",1,4,2023-05-25 13:51:00-05:00,['rest-catalog-open-api.yaml']
Parquet: Add encryption config to read and write builders (#2639),8,565,2023-05-25 16:02:06-07:00,"['TestParquetEncryptionWithWriteSupport.java', 'Parquet.java', 'ParquetWriter.java', 'ReadConf.java', 'TestParquetEncryption.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryFallbackToPlainEncodingVectorizedReads.java', 'TestParquetVectorizedReads.java']"
Core: Make all of the BaseFile stat maps immutable (#7643),3,72,2023-05-26 11:24:46+02:00,"['BaseFile.java', 'SerializableByteBufferMap.java', 'TestManifestReaderStats.java']"
Enable extra commit properties with metadata delete (#7649),6,193,2023-05-26 10:30:32-07:00,"['SparkTable.java', 'TestDataSourceOptions.java', 'SparkTable.java', 'TestDataSourceOptions.java', 'SparkTable.java', 'TestDataSourceOptions.java']"
Spark 3.4: Support fanout writers in SparkPositionDeltaWrite (#7703),15,372,2023-05-26 11:22:31-07:00,"['SparkRowLevelOperationsTestBase.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestDelete.java', 'TestMerge.java', 'TestMergeOnReadDelete.java', 'TestMergeOnReadMerge.java', 'TestMergeOnReadUpdate.java', 'TestUpdate.java', 'SparkWriteConf.java', 'SparkWriteRequirements.java', 'SparkWriteUtil.java', 'SparkPositionDeltaWrite.java', 'TestSparkDistributionAndOrderingUtil.java']"
"Spark 3.3: Fix bucket expressions on binary columns (#7693)

Co-authored-by: xianyangliu <xianyangliu@tencent.com>",3,51,2023-05-26 11:52:51-07:00,"['TestIcebergExpressions.java', 'TestRequiredDistributionAndOrdering.java', 'TransformExpressions.scala']"
Core: Remove deprecated AssertHelpers (#7711),5,398,2023-05-30 07:26:12+02:00,"['TestCreateNamespaceRequest.java', 'TestCreateTableRequest.java', 'TestRenameTableRequest.java', 'TestUpdateNamespacePropertiesRequest.java', 'TestUpdateRequirementParser.java']"
Nessie: Bump Nessie to 0.60.1 (#7701),1,4,2023-05-30 18:06:47+02:00,['versions.props']
"Build: Add openapi label (#7712)

Co-authored-by: Steve Zhang <hongyue_zhang@apple.com>",1,2,2023-05-30 18:14:33+02:00,['labeler.yml']
"Revert ""Python: Refactor integration tests (#7698)"" (#7729)

This reverts commit 3a584a28352e5f13ca128599f4d331aa5eeaa374.",5,174,2023-05-30 18:57:27+02:00,"['Makefile', 'Dockerfile', 'entrypoint.sh', 'provision.py', 'contributing.md']"
Parquet: skip writing bloom filters for deletes (#7617),1,13,2023-05-30 13:19:13-07:00,['Parquet.java']
AWS: Fix Tests3RestSigner on OSX (#7742),1,1,2023-05-30 14:48:10-07:00,['TestS3RestSigner.java']
API: Improve Javadoc of listNamespaces() (#7196),3,64,2023-05-31 13:10:02+02:00,"['SessionCatalog.java', 'SupportsNamespaces.java', 'rest-catalog-open-api.yaml']"
"Python: Loosen dependency on typing-extensions (#7747)

In the CI we pin the `typing-extensions` dependency on `4.5.0`,
but it looks like some bug has been introduced in `4.6.1`.

By loosening this requirement, we install the same version as when
someone would when they don't install the dev requirements.

Resolves #7746",2,375,2023-06-01 12:23:27+02:00,"['poetry.lock', 'pyproject.toml']"
Flink: Bump version to 1.16.2 and 1.17.1 (#7745),5,16,2023-06-01 12:32:08+02:00,"['flink-getting-started.md', 'build.gradle', 'TestFlinkPackage.java', 'build.gradle', 'TestFlinkPackage.java']"
Core: Switch tests to Junit5 in avro package (#7655),10,348,2023-06-01 12:32:20+02:00,"['AvroDataTest.java', 'TestAvroDataWriter.java', 'TestAvroDeleteWriters.java', 'TestAvroEncoderUtil.java', 'TestAvroEnums.java', 'TestAvroFileSplit.java', 'TestAvroOptionsWithNonNullDefaults.java', 'TestAvroSchemaProjection.java', 'TestHasIds.java', 'TestSchemaConversions.java']"
"Build: Bump griffe from 0.28.0 to 0.29.0 in /python (#7728)

Bumps [griffe](https://github.com/mkdocstrings/griffe) from 0.28.0 to 0.29.0.
- [Changelog](https://github.com/mkdocstrings/griffe/blob/master/CHANGELOG.md)
- [Commits](https://github.com/mkdocstrings/griffe/compare/0.28.0...0.29.0)

---
updated-dependencies:
- dependency-name: griffe
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-06-01 12:44:24+02:00,['requirements.txt']
"Build: Bump mkdocstrings from 0.21.2 to 0.22.0 in /python (#7727)

Bumps [mkdocstrings](https://github.com/mkdocstrings/mkdocstrings) from 0.21.2 to 0.22.0.
- [Release notes](https://github.com/mkdocstrings/mkdocstrings/releases)
- [Changelog](https://github.com/mkdocstrings/mkdocstrings/blob/master/CHANGELOG.md)
- [Commits](https://github.com/mkdocstrings/mkdocstrings/compare/0.21.2...0.22.0)

---
updated-dependencies:
- dependency-name: mkdocstrings
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-06-01 12:44:34+02:00,['requirements.txt']
"Build: Bump mkdocstrings-python from 1.0.0 to 1.1.0 in /python (#7724)

Bumps [mkdocstrings-python](https://github.com/mkdocstrings/python) from 1.0.0 to 1.1.0.
- [Changelog](https://github.com/mkdocstrings/python/blob/master/CHANGELOG.md)
- [Commits](https://github.com/mkdocstrings/python/compare/1.0.0...1.1.0)

---
updated-dependencies:
- dependency-name: mkdocstrings-python
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-06-01 12:53:30+02:00,['requirements.txt']
Python: Fix integration-test path (#7705),1,2,2023-06-01 14:11:39+02:00,['python-integration.yml']
"Core: Switch tests to JUnit5 in deletes,expressions,auth packages (#7755)",4,210,2023-06-02 14:06:27+02:00,"['TestEqualityFilter.java', 'TestPositionFilter.java', 'TestExpressionParser.java', 'TestOAuth2Util.java']"
Python: Add support for initial default (#7699),9,305,2023-06-02 15:54:28-07:00,"['file.py', 'reader.py', 'resolver.py', 'manifest.py', 'types.py', 'test_resolver.py', 'conftest.py', 'test_manifest.py', 'test_schema_conversion.py']"
API: Switch tests to JUnit5 (#7730),21,3453,2023-06-03 15:06:40+02:00,"['TestHelpers.java', 'TestNamespace.java', 'TestTableIdentifier.java', 'TestListeners.java', 'TestAggregateBinding.java', 'TestAggregateEvaluator.java', 'TestEvaluator.java', 'TestExpressionBinding.java', 'TestExpressionHelpers.java', 'TestExpressionSerialization.java', 'TestExpressionUtil.java', 'TestInclusiveManifestEvaluator.java', 'TestInclusiveMetricsEvaluator.java', 'TestLiteralSerialization.java', 'TestMetricsEvaluatorsNaNHandling.java', 'TestMiscLiteralConversions.java', 'TestNumericLiteralConversions.java', 'TestPredicateBinding.java', 'TestStrictMetricsEvaluator.java', 'TestStringLiteralConversions.java', 'build.gradle']"
"API: Switch tests to JUnit5 (io,metrics,transforms packages) (#7757)",22,1362,2023-06-03 16:36:44+02:00,"['TestCloseableGroup.java', 'TestCloseableIterable.java', 'TestClosingIterator.java', 'TestDefaultCounter.java', 'TestDefaultMetricsContext.java', 'TestDefaultTimer.java', 'TestFixedReservoirHistogram.java', 'TestBucketing.java', 'TestBucketingProjection.java', 'TestDates.java', 'TestDatesProjection.java', 'TestIdentity.java', 'TestNotStartsWith.java', 'TestProjection.java', 'TestResiduals.java', 'TestStartsWith.java', 'TestTimestamps.java', 'TestTimestampsProjection.java', 'TestTransformSerialization.java', 'TestTruncate.java', 'TestTruncatesProjection.java', 'TestTruncatesResiduals.java']"
"Build: Bump typing-extensions from 4.6.2 to 4.6.3 in /python (#7765)

Bumps [typing-extensions](https://github.com/python/typing_extensions) from 4.6.2 to 4.6.3.
- [Changelog](https://github.com/python/typing_extensions/blob/main/CHANGELOG.md)
- [Commits](https://github.com/python/typing_extensions/compare/4.6.2...4.6.3)

---
updated-dependencies:
- dependency-name: typing-extensions
  dependency-type: direct:development
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,14,2023-06-04 08:30:52+02:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump mkdocs-material from 9.1.14 to 9.1.15 in /python (#7764)

Bumps [mkdocs-material](https://github.com/squidfunk/mkdocs-material) from 9.1.14 to 9.1.15.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/CHANGELOG)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/9.1.14...9.1.15)

---
updated-dependencies:
- dependency-name: mkdocs-material
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-06-04 08:31:06+02:00,['requirements.txt']
Python: Remove integration-test caching (#7704),1,38,2023-06-04 11:39:56-07:00,['python-integration.yml']
"Python: Refactor integration tests (#7698) (#7768)

* Python: Refactor integration tests (#7698)

* Python: Refactor integration tests

This splits out running and building the integration tests that
enables quick development iterations. I've also added ipython
that will give a more meaningful error when something goes wrong
with the provisioning of the tests.

* Simplify SQL

* Bump to Iceberg 1.3.0",5,174,2023-06-05 21:33:40+02:00,"['Makefile', 'Dockerfile', 'entrypoint.sh', 'provision.py', 'contributing.md']"
"Spec: Add missing `last-column-id` (#7445)

* Spec: Add missing last-column-id to open-api spec

* Add description",3,21,2023-06-05 23:54:00+02:00,"['MetadataUpdateParser.java', 'TestMetadataUpdateParser.java', 'rest-catalog-open-api.yaml']"
"Python: Add support for pydocstyle (#7772)

This will make sure that our docstrings are properly formatted.

This is getting important since we also generate docs from the doc
strings. This PR is about adding the framework, and then we can follow
up in new PRs for each of the error codes.",1,10,2023-06-05 16:52:42-07:00,['.pre-commit-config.yaml']
"API: Switch tests to JUnit5 (types, util packages) (#7758)",19,774,2023-06-06 10:02:04+02:00,"['TestAccessors.java', 'TestIcebergBuild.java', 'TestMetricsSerialization.java', 'TestPartitionPaths.java', 'TestPartitionSpecValidation.java', 'TestSnapshotRef.java', 'TestTransformSerialization.java', 'TestBinaryComparator.java', 'TestCharSeqComparator.java', 'TestComparableComparator.java', 'TestComparators.java', 'TestConversions.java', 'TestReadabilityChecks.java', 'TestSerializableTypes.java', 'TestTypeUtil.java', 'TestTypes.java', 'TestCharSequenceSet.java', 'TestDateTimeUtil.java', 'TestExceptionUtil.java']"
Core: Remove deprecated AssertHelpers in hadoop package (#7722),5,210,2023-06-06 10:14:48+02:00,"['TestCachingCatalog.java', 'TestHadoopCatalog.java', 'TestHadoopCommits.java', 'TestHadoopTables.java', 'TestStaticTable.java']"
"Build: Bump com.fasterxml.jackson.core:jackson-annotations (#7763)

Bumps [com.fasterxml.jackson.core:jackson-annotations](https://github.com/FasterXML/jackson) from 2.15.0 to 2.15.2.
- [Commits](https://github.com/FasterXML/jackson/commits)

---
updated-dependencies:
- dependency-name: com.fasterxml.jackson.core:jackson-annotations
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,4,2023-06-06 10:15:44+02:00,"['build.gradle', 'build.gradle']"
"Open-API: Add Python code as an example (#7751)

* Open-API: Add Python code as an example

This make it easier (at least for me), to see the impact on the
code that's being generated. Polymorphism and Inheritance is not
always clear to me from the spec, but it is from the Python code.

* Add licenses

* Thanks Eduard :)

* Update CI

* Update requirements

* Remove ||

* Make the CI happy",6,923,2023-06-06 11:44:01+02:00,"['open-api.yml', 'Makefile', 'README.md', 'header.txt', 'requirements.txt', 'rest-catalog-open-api.py']"
"Python: Pin `mkdocs-admon` (#7779)

A new version has been released 9 hours ago, and broke the build:

https://pypi.org/project/mdformat_admon/1.0.2/

Let's pin the versions.",1,18,2023-06-06 13:35:36+02:00,['.pre-commit-config.yaml']
"Python: Fix TypeError when partition tuples have nulls (#7783)

Resolves #7736",2,33,2023-06-06 10:27:57-07:00,"['visitors.py', 'test_visitors.py']"
"Spark 3.4: Add a bucket binary unit test (#7720)

Co-authored-by: xianyangliu <xianyangliu@tencent.com>",1,17,2023-06-06 20:00:54+02:00,['TestRequiredDistributionAndOrdering.java']
Tests: More permissive error message assertion in catalog tests (#7784),1,12,2023-06-06 21:51:34+02:00,['CatalogTests.java']
"Python: Add support for sequence number inheritance (#7778)

* Python: Add support for sequence number inheritance

* Refactor",6,148,2023-06-06 23:24:31+02:00,"['__init__.py', 'output.py', 'manifest.py', '__init__.py', 'conftest.py', 'test_manifest.py']"
Core: Fix paths for unpartitioned specs in writers (#7685),3,18,2023-06-06 15:13:09-07:00,"['ClusteredWriter.java', 'FanoutWriter.java', 'RollingFileWriter.java']"
"Tests: Update catalog test assertion to be more permissive (#7789)

* Tests: Update catalog test assertion to be more permissive

* another assertion update",1,4,2023-06-07 08:14:42+02:00,['CatalogTests.java']
"Core: Deprecate `newOutputFile` from `{ClusteredWriter,FanoutWriter}` (#7788)

* Core: Deprecate `newOutputFile` from `{ClusteredWriter,FanoutWriter}

They are not used anymore

* Update core/src/main/java/org/apache/iceberg/io/ClusteredWriter.java

* Update core/src/main/java/org/apache/iceberg/io/FanoutWriter.java",2,4,2023-06-07 20:26:42+02:00,"['ClusteredWriter.java', 'FanoutWriter.java']"
"Python: Fix optionality of Manifest fields (#7796)

Without these changes the Avro files that were generated couldn't be
parsed by the iceberg rest catalog service.",1,6,2023-06-07 22:29:41+02:00,['manifest.py']
Fix D403 pydocstyle issues (#7801),5,28,2023-06-09 19:16:29+03:00,"['.pre-commit-config.yaml', 'decoder.py', 'pyarrow.py', 'transforms.py', 'config.py']"
Core: Key metadata in Avro format (#6450),9,499,2023-06-09 14:43:12-07:00,"['GenericAvroReader.java', 'GenericAvroWriter.java', 'IcebergDecoder.java', 'RawDecoder.java', 'KeyMetadata.java', 'KeyMetadataDecoder.java', 'KeyMetadataEncoder.java', 'TestKeyMetadataParser.java', 'TestSingleMessageEncoding.java']"
Core: Add REST spec and request for commits to multiple tables (#7741),7,522,2023-06-09 15:03:35-07:00,"['RESTSerializers.java', 'ResourcePaths.java', 'CommitTransactionRequest.java', 'CommitTransactionRequestParser.java', 'UpdateTableRequest.java', 'TestCommitTransactionRequestParser.java', 'rest-catalog-open-api.yaml']"
"Python: D414 and D200 docstring issues (#7806)

Co-authored-by: Michael DeRoy <mkderoy@ibm.com>",9,38,2023-06-10 10:15:26+03:00,"['.pre-commit-config.yaml', 'decoder.py', 'file.py', 'console.py', 'partitioning.py', 'datetime.py', 'decimal.py', 'schema_conversion.py', 'conftest.py']"
"Python: Resolve pydocstring D202 violations (#7805)

Co-authored-by: Michael DeRoy <mkderoy@ibm.com>
Co-authored-by: Fokko Driesprong <fokko@apache.org>",10,17,2023-06-10 10:36:13+03:00,"['.pre-commit-config.yaml', '__init__.py', 'dynamodb.py', 'glue.py', 'hive.py', 'rest.py', 'visitors.py', 'pyarrow.py', 'schema.py', 'deprecated.py']"
Open-API: Update code (#7807),1,8,2023-06-10 09:46:36+02:00,['rest-catalog-open-api.py']
Build: Bump pytest from 7.3.1 to 7.3.2 in /python (#7817),2,114,2023-06-11 09:02:35+03:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump mkdocstrings-python from 1.1.0 to 1.1.2 in /python (#7816),1,2,2023-06-11 09:02:49+03:00,['requirements.txt']
Build: Bump ray from 2.4.0 to 2.5.0 in /python (#7814),1,66,2023-06-11 09:04:16+03:00,['poetry.lock']
Build: Bump requests-mock from 1.10.0 to 1.11.0 in /python (#7815),2,12,2023-06-11 10:24:55+03:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump moto from 4.1.10 to 4.1.11 in /python (#7813),2,22,2023-06-11 10:37:34+03:00,"['poetry.lock', 'pyproject.toml']"
Build: skip scheduled workflows on forks (#7818),2,2,2023-06-12 08:03:22+02:00,"['recurring-jmh-benchmarks.yml', 'stale.yml']"
"Core: Switch tests to JUnit5 in metrics,puffin,rest packages (#7803)",27,1028,2023-06-12 17:38:25+02:00,"['TestCommitMetricsResultParser.java', 'TestCommitReportParser.java', 'TestCounterResultParser.java', 'TestScanMetricsResultParser.java', 'TestScanReport.java', 'TestScanReportParser.java', 'TestTimerResultParser.java', 'TestFileMetadataParser.java', 'TestPuffinFormat.java', 'TestPuffinReader.java', 'TestPuffinWriter.java', 'TestCreateNamespaceRequest.java', 'TestCreateTableRequest.java', 'TestRenameTableRequest.java', 'TestReportMetricsRequestParser.java', 'TestUpdateNamespacePropertiesRequest.java', 'TestUpdateRequirementParser.java', 'TestCatalogErrorResponseParser.java', 'TestConfigResponse.java', 'TestCreateNamespaceResponse.java', 'TestGetNamespaceResponse.java', 'TestListNamespacesResponse.java', 'TestListTablesResponse.java', 'TestLoadTableResponse.java', 'TestOAuthErrorResponseParser.java', 'TestOAuthTokenResponse.java', 'TestUpdateNamespacePropertiesResponse.java']"
Core: Fix NPE in SnapshotUtil.ancestorsOf (#7718),2,114,2023-06-13 09:18:44+02:00,"['SnapshotUtil.java', 'TestSnapshotUtil.java']"
Spark: Update antlr4 to match Spark 3.4 (#7824),1,4,2023-06-13 09:53:57+02:00,['build.gradle']
Spark: Use constants instead of plain strings (#7825),3,18,2023-06-13 11:18:37+02:00,"['SparkSessionCatalog.java', 'SparkSessionCatalog.java', 'SparkSessionCatalog.java']"
Docs: Update Nessie docs (#7826),1,5,2023-06-13 15:11:07+02:00,['nessie.md']
"Python: Make Glue catalog configurable (#7781)

* Make boto3 session for Glue catalog configurable.

(cherry picked from commit aecc33bda59da974f6dfaa6cba97206f320d67a9)

* Fix linting issues.",3,44,2023-06-13 18:14:47+02:00,"['configuration.md', 'glue.py', 'test_glue.py']"
Docs: Fix SQL formatting in Flink docs (#7761),1,8,2023-06-13 18:30:40+02:00,['flink-ddl.md']
"Build: Bump com.github.alisiikh:gradle-scalastyle-plugin (#7811)

Bumps com.github.alisiikh:gradle-scalastyle-plugin from 3.4.1 to 3.5.0.

---
updated-dependencies:
- dependency-name: com.github.alisiikh:gradle-scalastyle-plugin
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-06-13 18:36:47+02:00,['build.gradle']
Parquet: Revert workaround for resource usage with zstd (#7834),2,10,2023-06-14 08:10:04+02:00,"['Parquet.java', 'ParquetCodecFactory.java']"
"Python: Fix D400 Docstring voilations (#7829)

* Update decoder.py

* Update file.py

D400: First line should end with a period

* Update reader.py

D400: First line should end with a period

* Update resolver.py

* Update __init__.py

D400: First line should end with a period

* Update dynamodb.py

* Update glue.py

D400: First line should end with a period

* Update hive.py

D400: First line should end with a period

* Update rest.py

D400: First line should end with a period

* Update console.py

D400: First line should end with a period

* Update output.py

D400: First line should end with a period

* Update output.py

D400: First line should end with a period

* Update __init__.py

D400: First line should end with a period

* Update literals.py

D400: First line should end with a period

* Update visitors.py

D400: First line should end with a period

* Update __init__.py

D400: First line should end with a period

* Update fsspec.py

D400: First line should end with a period

* Update memory.py

D400: First line should end with a period

* Update pyarrow.py

D400: First line should end with a period

* Update __init__.py

D400: First line should end with a period

* Update metadata.py

D400: First line should end with a period

* Update snapshots.py

D400: First line should end with a period

* Update sorting.py

D400: First line should end with a period

* Update config.py

D400: First line should end with a period

* Update datetime.py

D400: First line should end with a period

* Update decimal.py

D400: First line should end with a period

* Update parsing.py

D400: First line should end with a period

* Update schema_conversion.py

D400: First line should end with a period

* Update singleton.py

D400: First line should end with a period

* Update conversions.py

D400: First line should end with a period

* Update exceptions.py

D400: First line should end with a period

* Update files.py

D400: First line should end with a period

* Update manifest.py

D400: First line should end with a period

* Update partitioning.py

D400: First line should end with a period

* Update schema.py

D400: First line should end with a period

* Update serializers.py

D400: First line should end with a period

* Update transforms.py

D400: First line should end with a period

* Update typedef.py

D400: First line should end with a period

* Update types.py

D400: First line should end with a period

* Removed D400 code from .pre-commit-config.yaml

* Update dynamodb.py

fixed D400 compliance

* Update python/pyiceberg/catalog/__init__.py

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* Update conversions.py

D400 fix

* Update metadata.py

d400 fix

* Update console.py

d400 fix

* Update visitors.py

D400 fix

* Update types.py

D400 compliance

* Update partitioning.py

D400 fix

* Update config.py

D400 fix

* Update decoder.py

D400

* Update file.py

D400 fix

* Update schema_conversion.py

D400 fixes and added small definitions for compliance purposes.

* Update fsspec.py

D400 fix

* Update snapshots.py

D400 fix

* Update integration_test_glue.py

D400 fix

* Update integration_test_dynamodb.py

D400 fix

* Update conftest.py

D400 fix

* Update deprecated.py

D400 fix

* Update snappy_codec.py

D400 fix

* Update parser.py

D400 fix

* Update types.py

fix D400

* Update conftest.py

fix D400

* Update decoder.py

fix D200

* Update snapshots.py

fix D200

* Fixed trailing whitespaces

* Fixed trailing whitespaces

* Fixed trailing whitespaces

* Fixed trailing whitespaces

* Fixed trailing whitespaces

* Fixed trailing whitespaces

* Fixed trailing whitespaces

* Fixed trailing whitespaces

* Fixed trailing whitespaces

* Update python/pyiceberg/catalog/__init__.py

* Update python/pyiceberg/io/pyarrow.py

* Update python/pyiceberg/io/pyarrow.py

* Update python/pyiceberg/serializers.py

---------

Co-authored-by: Fokko Driesprong <fokko@apache.org>",45,1740,2023-06-14 09:08:40+02:00,"['.pre-commit-config.yaml', 'snappy_codec.py', 'decoder.py', 'file.py', 'reader.py', 'resolver.py', '__init__.py', 'dynamodb.py', 'glue.py', 'hive.py', 'rest.py', 'console.py', 'output.py', 'conversions.py', 'exceptions.py', '__init__.py', 'literals.py', 'parser.py', 'visitors.py', 'files.py', '__init__.py', 'fsspec.py', 'memory.py', 'pyarrow.py', 'manifest.py', 'partitioning.py', 'schema.py', 'serializers.py', '__init__.py', 'metadata.py', 'snapshots.py', 'sorting.py', 'transforms.py', 'typedef.py', 'types.py', 'config.py', 'datetime.py', 'decimal.py', 'deprecated.py', 'parsing.py', 'schema_conversion.py', 'singleton.py', 'integration_test_dynamodb.py', 'integration_test_glue.py', 'conftest.py']"
"Python: Add pickle support (#7645)

* Python: Add pickle support

* Fix test

* Fix type annotation

* Update python/pyiceberg/types.py

* Update python/pyiceberg/types.py

* Update python/pyiceberg/types.py

---------

Co-authored-by: Georg Grob <g.grob@winton.com>
Co-authored-by: Fokko Driesprong <fokko@apache.org>",4,83,2023-06-14 16:01:00+02:00,"['__init__.py', 'types.py', 'test_expressions.py', 'test_types.py']"
"Python: Fixes for D205 issues (#7823)

* Fixes for D205 issues

fix one comment

* Update python/pyiceberg/utils/deprecated.py

* Update python/pyiceberg/utils/deprecated.py

---------

Co-authored-by: Michael DeRoy <mkderoy@ibm.com>
Co-authored-by: Fokko Driesprong <fokko@apache.org>",17,162,2023-06-14 17:05:25+02:00,"['.pre-commit-config.yaml', 'decoder.py', 'file.py', 'dynamodb.py', 'conversions.py', 'visitors.py', '__init__.py', 'partitioning.py', 'metadata.py', 'snapshots.py', 'transforms.py', 'types.py', 'config.py', 'decimal.py', 'deprecated.py', 'schema_conversion.py', 'conftest.py']"
Build: Update ORC to 1.8.4 (#7839),1,2,2023-06-14 18:00:10+02:00,['versions.props']
Docs: Add docs for CommitMetadata (#7743),1,15,2023-06-14 23:02:22-07:00,['spark-configuration.md']
"Core: Switch tests to JUnit5 in catalog,encryption,inmemory,io,view packages (#7767)",15,1835,2023-06-15 12:19:41+02:00,"['CatalogTests.java', 'TestTableIdentifierParser.java', 'TestCiphers.java', 'TestInMemoryFileIO.java', 'TestInMemoryInputFile.java', 'TestInMemoryOutputFile.java', 'TestByteBufferInputStreams.java', 'TestIOUtil.java', 'TestMultiBufferInputStream.java', 'TestResolvingIO.java', 'TestSingleBufferInputStream.java', 'TestSQLViewRepresentationParser.java', 'TestViewHistoryEntryParser.java', 'TestViewRepresentationParser.java', 'TestViewVersionParser.java']"
Nessie: Support ApiV2 for Nessie client (#6712),6,68,2023-06-15 13:28:23+02:00,"['NessieCatalog.java', 'NessieUtil.java', 'BaseTestIceberg.java', 'TestCustomNessieClient.java', 'TestNessieCatalog.java', 'TestNessieIcebergClient.java']"
Add 1.3.0 to Bug Template (#7845),1,3,2023-06-15 15:38:16+02:00,['iceberg_bug_report.yml']
Build: Let Rev API compare against 1.3.0 (#7848),1,2,2023-06-15 16:50:56+02:00,['build.gradle']
Core: Move UpdateRequirement out of rest package (#7750),16,1757,2023-06-16 11:00:29-07:00,"['revapi.yml', 'UpdateRequirement.java', 'UpdateRequirementParser.java', 'UpdateRequirements.java', 'CatalogHandlers.java', 'RESTSerializers.java', 'RESTTableOperations.java', 'CommitTransactionRequest.java', 'CommitTransactionRequestParser.java', 'UpdateRequirementParser.java', 'UpdateTableRequest.java', 'UpdateTableRequestParser.java', 'TestUpdateRequirementParser.java', 'TestUpdateRequirements.java', 'TestCommitTransactionRequestParser.java', 'TestUpdateTableRequestParser.java']"
"Core: View metadata implementation (#7759)

Co-authored-by: Amogh Jahagirdar <jahamogh@amazon.com>
Co-authored-by: John Zhuge <jzhuge@apache.org>",12,1367,2023-06-16 11:02:18-07:00,"['ViewMetadata.java', 'ViewMetadataParser.java', 'ViewProperties.java', 'TestViewMetadata.java', 'TestViewMetadataParser.java', 'ValidViewMetadata.json', 'ViewMetadataInvalidCurrentSchema.json', 'ViewMetadataInvalidCurrentVersion.json', 'ViewMetadataLimitedVersions.json', 'ViewMetadataMissingCurrentSchema.json', 'ViewMetadataMissingCurrentVersion.json', 'ViewMetadataMissingLocation.json']"
Flink: Add possibilit of ordering the splits based on the file sequence number (#7661),14,471,2023-06-16 13:29:47-07:00,"['IcebergSource.java', 'DefaultSplitAssigner.java', 'OrderedSplitAssignerFactory.java', 'SimpleSplitAssignerFactory.java', 'IcebergSourceReader.java', 'IcebergSourceSplitReader.java', 'SerializableComparator.java', 'SplitComparators.java', 'SplitHelpers.java', 'SplitAssignerTestBase.java', 'TestDefaultSplitAssigner.java', 'TestFileSequenceNumberBasedSplitAssigner.java', 'TestContinuousIcebergEnumerator.java', 'TestIcebergSourceReader.java']"
Build: Bump pre-commit from 3.3.2 to 3.3.3 in /python (#7855),2,10,2023-06-18 07:11:43+02:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump pyarrow from 12.0.0 to 12.0.1 in /python (#7856),1,52,2023-06-18 07:12:12+02:00,['poetry.lock']
Build: Bump pydantic from 1.10.8 to 1.10.9 in /python (#7857),1,74,2023-06-18 07:18:10+02:00,['poetry.lock']
Build: Bump rich from 13.4.1 to 13.4.2 in /python (#7858),1,8,2023-06-18 07:18:22+02:00,['poetry.lock']
Build: Bump duckdb from 0.8.0 to 0.8.1 in /python (#7859),1,101,2023-06-18 07:18:37+02:00,['poetry.lock']
Build: Bump mkdocs-material from 9.1.15 to 9.1.16 in /python (#7860),1,2,2023-06-18 07:18:52+02:00,['requirements.txt']
Core: Remove usage of AssertHelpers (#7862),14,480,2023-06-19 15:46:46+02:00,"['ScanSummary.java', 'TestMetricsTruncation.java', 'TestOverwrite.java', 'TestPartitioning.java', 'TestScanSummary.java', 'TestSchemaAndMappingUpdate.java', 'TestSequenceNumberForV2Table.java', 'TestSortOrder.java', 'TestSplitPlanning.java', 'TestTransaction.java', 'TestWapWorkflow.java', 'TestAvroNameMapping.java', 'TestReadProjection.java', 'TestKeyMetadataParser.java']"
Core: Include all reachable snapshots with v1 format and REF snapshot mode (#7621),3,140,2023-06-19 08:28:43-07:00,"['TableMetadata.java', 'TestSnapshotLoading.java', 'TestRESTCatalog.java']"
Core: Add REST API for committing changes against multiple tables (#7569),8,272,2023-06-19 08:58:09-07:00,"['BaseTransaction.java', 'TableCommit.java', 'CatalogHandlers.java', 'RESTCatalog.java', 'RESTSessionCatalog.java', 'UpdateTableRequest.java', 'RESTCatalogAdapter.java', 'TestRESTCatalog.java']"
Flink: Improve naming of Tests (#7864),3,24,2023-06-20 16:05:30+02:00,"['TestFlinkCatalogFactory.java', 'TestFlinkCatalogFactory.java', 'TestFlinkCatalogFactory.java']"
Python: Add positional deletes (#6775),8,903,2023-06-20 21:18:34+02:00,"['poetry.lock', 'pyarrow.py', 'manifest.py', '__init__.py', 'pyproject.toml', 'test_pyarrow.py', 'test_init.py', 'test_integration.py']"
Core: Remove usage of AssertHelpers (#7868),16,456,2023-06-21 08:53:46+02:00,"['ScanTestBase.java', 'TestBaseIncrementalAppendScan.java', 'TestBaseIncrementalChangelogScan.java', 'TestCatalogUtil.java', 'TestCreateTransaction.java', 'TestDataTableScan.java', 'TestDeleteFiles.java', 'TestFastAppend.java', 'TestFormatVersions.java', 'TestIncrementalDataTableScan.java', 'TestLocationProvider.java', 'TestManifestListVersions.java', 'TestManifestReader.java', 'TestManifestReaderStats.java', 'TestManifestWriterVersions.java', 'TestMetadataUpdateParser.java']"
"Python: Alter table plumbing and REST support (#6323)

* Alter table

* Make the CI happy

* Comments

* Thanks Ryan!

* Python: Bump dependencies to the latest version

* Remove from docs

* WIP

* Comments

* Make CI happy

* Update docstrings

* Do some renaming

* Add a context manager

* Rename commit to commit_transaction()

* Update docs

* Refresh in place

* Remove redudant call

* Load a fresh copy instead

* Fix the docstrings

* Restore CommitTableResponse

* Conflicts",16,861,2023-06-22 08:56:00+02:00,"['api.md', 'poetry.lock', '__init__.py', 'dynamodb.py', 'glue.py', 'hive.py', 'noop.py', 'rest.py', 'exceptions.py', '__init__.py', 'test_base.py', 'test_rest.py', 'test_console.py', 'test_pyarrow.py', 'test_init.py', 'test_integration.py']"
"Python: Fix D105 docstring violations (#7852)

Co-authored-by: Michael DeRoy <mkderoy@ibm.com>",19,183,2023-06-22 09:04:54+02:00,"['.pre-commit-config.yaml', 'file.py', 'reader.py', '__init__.py', 'literals.py', '__init__.py', 'memory.py', 'manifest.py', 'partitioning.py', 'schema.py', '__init__.py', 'refs.py', 'snapshots.py', 'sorting.py', 'transforms.py', 'typedef.py', 'types.py', 'bin_packing.py', 'conftest.py']"
Python: Fix docstrings (#7877),2,7,2023-06-22 09:59:20+02:00,"['manifest.py', '__init__.py']"
Core: Switch tests to JUnit5 in rest/hadoop pakages (#7861),14,944,2023-06-23 07:34:11+02:00,"['HadoopFileIOTest.java', 'HadoopTableTestBase.java', 'TestCachingCatalog.java', 'TestCatalogUtilDropTable.java', 'TestHadoopCatalog.java', 'TestHadoopCommits.java', 'TestHadoopTables.java', 'TestStaticTable.java', 'TestTableSerialization.java', 'RequestResponseTestBase.java', 'TestHTTPClient.java', 'TestRESTCatalog.java', 'TestRESTUtil.java', 'TestResourcePaths.java']"
Python: Remove future annotations (#7878),1,24,2023-06-23 09:32:19-07:00,['schema_conversion.py']
"Python: Log to logging instead of warn (#7876)

* Python: Log to logging instead of warn

I was doing some final testing befor the release, and noticed
that when you don't have PyArrow installed (only s3fs), and
you try to describe a table, you'll get a warning:

```
root@0d64c149ba01:/vo# pyiceberg describe dbt_tabular.rides
/vo/pyiceberg/io/__init__.py:283: UserWarning: Could not initialize FileIO: pyiceberg.io.pyarrow.PyArrowFileIO
  warnings.warn(f""Could not initialize FileIO: {io_impl}"")
Table format version  1

Metadata location
s3://tabular-wh-us-east-1/6efbcaf4-21ae-499d-b340-3bc1a7003f52/f59f662e-878f-42e4-8b66-04b076c8ee23/metadata/00037-c9977e9d-64d7-45fc-a93a-7e10efdfecc9.gz.metadat
Table UUID            f59f662e-878f-42e4-8b66-04b076c8ee23

Last Updated          1684818900590

Partition spec        []

Sort order            []

Current schema        Schema, id=13

                       1: vendor: optional string (TPEP provider that provided the record)

                       2: pickup_time: optional timestamptz (The date and time when the meter was engaged.)

                       3: pickup_zone_name: optional string (Taxi Zone in which the taximeter was engaged.)

                       4: pickup_borough: optional string (Borough in which the taximeter was engaged.)

                       5: dropoff_time: optional timestamptz (The date and time when the meter was disengaged.)

                       6: dropoff_zone_name: optional string (Taxi Zone in which the taximeter was disengaged)

                       7: dropoff_borough: optional string (Borough in which the taximeter was disengaged)

                       8: passenger_count: optional int (The number of passengers in the vehicle (This is a driver-entered value).)
```

I think it makes more sense to send this to logging so you
don't see it in the console.

* Oops",1,2,2023-06-23 18:45:36+02:00,['__init__.py']
Core: Register JSON Parser for UpdateTableRequest (#7891),1,5,2023-06-23 13:30:37-07:00,['RESTSerializers.java']
Core: Add last updated timestamp and snapshotId for Partitions table (#7581),8,1001,2023-06-23 14:32:13-07:00,"['PartitionsTable.java', 'MetadataTableScanTestBase.java', 'TestMetadataTableScans.java', 'TestMetadataTableScansWithPartitionEvolution.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java']"
ORC: Fix to avoid test failure on Hadoop 2.7.3 (#7894),1,8,2023-06-23 15:26:32-07:00,['TestOrcDataWriter.java']
Docs: Add missing ; in Flink examples (#7908),1,2,2023-06-25 10:01:34+02:00,['flink-queries.md']
Core: Migrate jdbc package to JUnit5 (#7874),3,213,2023-06-26 08:53:34+02:00,"['TestJdbcCatalog.java', 'TestJdbcTableConcurrency.java', 'TestJdbcUtil.java']"
Core: Add create(..) method to UpdateTableRequest (#7867),6,40,2023-06-26 09:19:09+02:00,"['TableCommit.java', 'RESTSessionCatalog.java', 'UpdateTableRequest.java', 'UpdateTableRequestParser.java', 'TestCommitTransactionRequestParser.java', 'TestUpdateTableRequestParser.java']"
Flink: Backport to 1.15 and 1.16: Add possibilit of ordering the splits based on the file sequence number (#7661) (#7889),28,942,2023-06-26 09:48:59+02:00,"['IcebergSource.java', 'DefaultSplitAssigner.java', 'OrderedSplitAssignerFactory.java', 'SimpleSplitAssignerFactory.java', 'IcebergSourceReader.java', 'IcebergSourceSplitReader.java', 'SerializableComparator.java', 'SplitComparators.java', 'SplitHelpers.java', 'SplitAssignerTestBase.java', 'TestDefaultSplitAssigner.java', 'TestFileSequenceNumberBasedSplitAssigner.java', 'TestContinuousIcebergEnumerator.java', 'TestIcebergSourceReader.java', 'IcebergSource.java', 'DefaultSplitAssigner.java', 'OrderedSplitAssignerFactory.java', 'SimpleSplitAssignerFactory.java', 'IcebergSourceReader.java', 'IcebergSourceSplitReader.java', 'SerializableComparator.java', 'SplitComparators.java', 'SplitHelpers.java', 'SplitAssignerTestBase.java', 'TestDefaultSplitAssigner.java', 'TestFileSequenceNumberBasedSplitAssigner.java', 'TestContinuousIcebergEnumerator.java', 'TestIcebergSourceReader.java']"
Spark: Remove usage of AssertHelpers (#7899),13,901,2023-06-26 09:51:00+02:00,"['TestAddFilesProcedure.java', 'TestAlterTableSchema.java', 'TestAncestorsOfProcedure.java', 'TestBranchDDL.java', 'TestCallStatementParser.java', 'TestCherrypickSnapshotProcedure.java', 'TestConflictValidation.java', 'TestDelete.java', 'TestMergeOnReadDelete.java', 'TestRemoveOrphanFilesProcedure.java', 'TestReplaceBranch.java', 'TestRewriteManifestsProcedure.java', 'TestWriteAborts.java']"
Flink: Fix serialization in TableSink with anonymous object (#7866),9,225,2023-06-26 10:27:29+02:00,"['build.gradle', 'FlinkDynamicTableFactory.java', 'TestFlinkAnonymousTable.java', 'build.gradle', 'FlinkDynamicTableFactory.java', 'TestFlinkAnonymousTable.java', 'build.gradle', 'FlinkDynamicTableFactory.java', 'TestFlinkAnonymousTable.java']"
"Build: Bump pytest from 7.3.2 to 7.4.0 in /python (#7902)

Bumps [pytest](https://github.com/pytest-dev/pytest) from 7.3.2 to 7.4.0.
- [Release notes](https://github.com/pytest-dev/pytest/releases)
- [Changelog](https://github.com/pytest-dev/pytest/blob/main/CHANGELOG.rst)
- [Commits](https://github.com/pytest-dev/pytest/compare/7.3.2...7.4.0)

---
updated-dependencies:
- dependency-name: pytest
  dependency-type: direct:development
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,18,2023-06-26 10:27:44+02:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump mkdocs-material from 9.1.16 to 9.1.17 in /python (#7903)

Bumps [mkdocs-material](https://github.com/squidfunk/mkdocs-material) from 9.1.16 to 9.1.17.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/CHANGELOG)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/9.1.16...9.1.17)

---
updated-dependencies:
- dependency-name: mkdocs-material
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-06-26 10:27:59+02:00,['requirements.txt']
"Build: Bump griffe from 0.29.0 to 0.29.1 in /python (#7904)

Bumps [griffe](https://github.com/mkdocstrings/griffe) from 0.29.0 to 0.29.1.
- [Changelog](https://github.com/mkdocstrings/griffe/blob/main/CHANGELOG.md)
- [Commits](https://github.com/mkdocstrings/griffe/compare/0.29.0...0.29.1)

---
updated-dependencies:
- dependency-name: griffe
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-06-26 10:28:12+02:00,['requirements.txt']
"Build: Bump moto from 4.1.11 to 4.1.12 in /python (#7905)

Bumps [moto](https://github.com/getmoto/moto) from 4.1.11 to 4.1.12.
- [Changelog](https://github.com/getmoto/moto/blob/master/CHANGELOG.md)
- [Commits](https://github.com/getmoto/moto/compare/4.1.11...4.1.12)

---
updated-dependencies:
- dependency-name: moto
  dependency-type: direct:development
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,10,2023-06-26 10:38:05+02:00,"['poetry.lock', 'pyproject.toml']"
Python: Bump version to 0.4.0 (#7912),2,4,2023-06-26 10:38:41+02:00,"['__init__.py', 'pyproject.toml']"
Core: Fixes OOM caused by Avro decoder caching (#7791),3,341,2023-06-26 11:25:29+02:00,"['ManifestReadBenchmark.java', 'DecoderResolver.java', 'TestDecoderResolver.java']"
Core: add JSON parser for ContentFile and FileScanTask (#6934),16,1042,2023-06-26 09:02:19-07:00,"['FileScanTask.java', 'BaseContentScanTask.java', 'BaseFileScanTask.java', 'ContentFileParser.java', 'DataFiles.java', 'FileScanTaskParser.java', 'GenericDataFile.java', 'JsonUtil.java', 'TableTestBase.java', 'TestContentFileParser.java', 'TestFileScanTaskParser.java', 'TestManifestWriterVersions.java', 'TestTableIdentifierParser.java', 'TestListTablesResponse.java', 'TestJsonUtil.java', 'spec.md']"
"Flink: Key projection should be based on the requested Flink table schema (#7836)

Co-authored-by: xianyangliu <xianyangliu@tencent.com>",3,141,2023-06-26 10:32:57-07:00,"['BaseDeltaTaskWriter.java', 'SimpleDataUtil.java', 'TestDeltaTaskWriter.java']"
Flink: remove the creation of default database in FlinkCatalog open method (#7795),6,156,2023-06-26 10:36:48-07:00,"['FlinkCatalog.java', 'TestFlinkCatalogDatabase.java', 'FlinkCatalog.java', 'TestFlinkCatalogDatabase.java', 'FlinkCatalog.java', 'TestFlinkCatalogDatabase.java']"
Spark 3.4: Multiple shuffle partitions per file in compaction (#7897),7,244,2023-06-26 17:58:42-07:00,"['ExtendedDataSourceV2Strategy.scala', 'TestRewriteDataFilesProcedure.java', 'SparkShufflingDataRewriter.java', 'OrderAwareCoalesce.scala', 'OrderAwareCoalesceExec.scala', 'TestRewriteDataFilesAction.java', 'TestSparkFileRewriter.java']"
Docs: Add `rewritten_bytes_count` to `rewrite_data_files` (#7916),1,3,2023-06-27 08:16:15+02:00,['spark-procedures.md']
"Dell,Arrow : Migrate test cases in dell,arrow packages to JUnit5 (#7872)",13,276,2023-06-27 08:19:37+02:00,"['ArrowSchemaUtilTest.java', 'ArrowReaderTest.java', 'DecimalVectorUtilTest.java', 'build.gradle', 'TestEcsAppendOutputStream.java', 'TestEcsCatalog.java', 'TestEcsInputFile.java', 'TestEcsOutputFile.java', 'TestEcsSeekableInputStream.java', 'TestEcsURI.java', 'TestPropertiesSerDesUtil.java', 'EcsS3MockRule.java', 'MockS3Client.java']"
"Docs: Add Spark `timestamp_ntz` type to docs (#7917)

* add support for spark TimestampNtz type to docs

* Update type casing in spark docs

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* Update type casing in spark docs

Co-authored-by: Fokko Driesprong <fokko@apache.org>

---------

Co-authored-by: Fokko Driesprong <fokko@apache.org>",1,41,2023-06-27 14:58:06+02:00,['spark-writes.md']
Spark: Bump to 3.4.1 (#7881),3,19,2023-06-27 16:40:19+02:00,"['build.gradle', 'TestSparkOrcReader.java', 'TestParquetVectorizedReads.java']"
"Nessie: Minor Refactoring of NessieTableOperations (#7893)

* Nessie: Minor Refactoring of NessieTableOperations

* Handle comments

* Handle IO outisde the NessieUtil",3,120,2023-06-27 17:01:13+02:00,"['NessieIcebergClient.java', 'NessieTableOperations.java', 'NessieUtil.java']"
"Nessie: Test Nessie's new storage model (#7702)

Nessie tests will only run against Java 11 or newer, because Nessie's storage implementation (server side thing) only works on Java 11. Nessie client libraries still work fine with Java 8.",5,95,2023-06-27 18:54:42+02:00,"['build.gradle', 'NessieIcebergClient.java', 'BaseTestIceberg.java', 'TestNessieCatalog.java', 'TestNessieTable.java']"
"Python: Pin pyparsing and update tests (#7927)

* Python: Update pyparsing tests

* Lock pyparsing to <3.1.0",3,174,2023-06-27 22:29:28+02:00,"['poetry.lock', 'pyproject.toml', 'test_parser.py']"
"Flink: port PR #7836 to 1.15/1.16 (#7923)

Co-authored-by: xianyangliu <xianyangliu@tencent.com>",6,282,2023-06-28 06:42:11-07:00,"['BaseDeltaTaskWriter.java', 'SimpleDataUtil.java', 'TestDeltaTaskWriter.java', 'BaseDeltaTaskWriter.java', 'SimpleDataUtil.java', 'TestDeltaTaskWriter.java']"
Docs: Update Python Release verification steps (#7940),1,8,2023-06-29 11:21:22+02:00,['verify-release.md']
Bump Nessie to 0.63.0 (#7828),2,6,2023-06-29 15:01:54+02:00,"['build.gradle', 'versions.props']"
Docs: Improve hyperlink text for Glue best practices (#7093),1,4,2023-06-29 15:13:15+02:00,['aws.md']
REST Spec: Return 204 on no content response (#7229),1,8,2023-06-29 15:20:46+02:00,['rest-catalog-open-api.yaml']
"Core: Make `TableMetadataParser.fromJson` taking `JsonNode` public (#7032)

In the WIP for the Nessie Iceberg REST catalog server, there are a few places that currently require us to first serialize a `TableMetadata` to a `String` just to parse it right back into a `TableMetadata`, but this time with the right metadata-location.

First occurence is when we write the table metadata, where we have to first store the table metadata, get the metadata location, and then return the table metadata with the metadata location (and updates cleared).
Second occurence is when we return a table metadata with ""transient properties"", which are used to pass the ""expected Nessie commit"" around.

This change makes the two `TableMetadataParser.fromJson()` taking a `JsonNode` public",1,4,2023-06-29 15:28:31+02:00,['TableMetadataParser.java']
"Build: Bump net.ltgt.gradle:gradle-errorprone-plugin from 3.0.1 to 3.1.0 (#7409)

Bumps net.ltgt.gradle:gradle-errorprone-plugin from 3.0.1 to 3.1.0.

---
updated-dependencies:
- dependency-name: net.ltgt.gradle:gradle-errorprone-plugin
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-06-29 17:06:48+02:00,['build.gradle']
Python: Add `rm -rf dist/` step to how-to-release (#7941),1,7,2023-06-29 17:07:38+02:00,['how-to-release.md']
Docs: Fix `expire_snapshots` broken link (#7943),1,4,2023-06-29 18:51:56+02:00,['branching-and-tagging.md']
Build: Update ORC to 1.9.0 (#7945),1,2,2023-06-29 19:15:20+02:00,['versions.props']
"Spark 3.1: Fixes bucket on binary column (#7719)

* fixes bucket binary

* add testDefaultSortOnBinaryBucketedColumn

* address comments

---------

Co-authored-by: xianyangliu <xianyangliu@tencent.com>",4,60,2023-06-29 21:20:59+02:00,"['TestIcebergExpressions.java', 'TestSetWriteDistributionAndOrdering.java', 'TransformExpressions.scala', 'SparkTestBase.java']"
"Spark 3.2: Fixes bucket on binary column (#7717)

Co-authored-by: xianyangliu <xianyangliu@tencent.com>",3,51,2023-06-29 21:21:51+02:00,"['TestIcebergExpressions.java', 'TestRequiredDistributionAndOrdering.java', 'TransformExpressions.scala']"
Spark 3.3: Output the net changes across snapshots for carryover rows in CDC (#7326),7,603,2023-06-29 15:32:11-07:00,"['TestCreateChangelogViewProcedure.java', 'ChangelogIterator.java', 'ComputeUpdateIterator.java', 'RemoveCarryoverIterator.java', 'RemoveNetCarryoverIterator.java', 'CreateChangelogViewProcedure.java', 'TestChangelogIterator.java']"
"Build: Bump com.palantir.gradle.gitversion:gradle-git-version from 1.0.0 to 3.0.0 (#7264)

* Build: Bump com.palantir.gradle.gitversion:gradle-git-version

Bumps [com.palantir.gradle.gitversion:gradle-git-version](https://github.com/palantir/gradle-git-version) from 1.0.0 to 3.0.0.
- [Release notes](https://github.com/palantir/gradle-git-version/releases)
- [Changelog](https://github.com/palantir/gradle-git-version/blob/develop/.changelog.yml)
- [Commits](https://github.com/palantir/gradle-git-version/compare/1.0.0...3.0.0)

---
updated-dependencies:
- dependency-name: com.palantir.gradle.gitversion:gradle-git-version
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>

* Remove dependency to JGit

---------

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>
Co-authored-by: Eduard Tudenhoefner <etudenhoefner@gmail.com>",1,9,2023-06-30 07:45:15+02:00,['build.gradle']
"Core, Spark: Fix migrate table in case of partitioned table with partition containing a special character (#7744)",6,156,2023-06-30 13:17:01-07:00,"['DataFiles.java', 'TableMigrationUtil.java', 'TestMigrateTableProcedure.java', 'TestMigrateTableProcedure.java', 'TestMigrateTableProcedure.java', 'TestMigrateTableProcedure.java']"
Spark 3.4: Output the net changes across snapshots for carryover rows in CDC (#7950),7,603,2023-06-30 23:36:09-07:00,"['TestCreateChangelogViewProcedure.java', 'ChangelogIterator.java', 'ComputeUpdateIterator.java', 'RemoveCarryoverIterator.java', 'RemoveNetCarryoverIterator.java', 'CreateChangelogViewProcedure.java', 'TestChangelogIterator.java']"
Hive: Set commit state as Unknown before throwing CommitStateUnknownException (#7931),2,44,2023-07-03 07:46:18+02:00,"['HiveTableOperations.java', 'TestHiveCommits.java']"
Bump Gradle to 8.2 (#7955),2,6,2023-07-03 09:37:18+02:00,"['gradle-wrapper.properties', 'gradlew']"
"Build: Bump org.apache.hadoop:hadoop-client from 3.3.5 to 3.3.6 (#7964)

Bumps org.apache.hadoop:hadoop-client from 3.3.5 to 3.3.6.

---
updated-dependencies:
- dependency-name: org.apache.hadoop:hadoop-client
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-07-03 09:43:09+02:00,['build.gradle']
"Build: Fix revapi task dependency issue (#7970)

Gradle 8.2 detects this task dependency issue, which means that the build is non-deterministic:

```
FAILURE: Build failed with an exception.

* What went wrong:
A problem was found with the configuration of task ':iceberg-data:revapiAnalyze' (type 'RevapiAnalyzeTask').
  - Gradle detected a problem with the following location: '/home/nastra/Development/workspace/iceberg/common/build/libs/iceberg-common-1.4.0-SNAPSHOT.jar'.

    Reason: Task ':iceberg-data:revapiAnalyze' uses this output of task ':iceberg-common:jar' without declaring an explicit or implicit dependency. This can lead to incorrect results being produced, depending on what order the tasks are executed.

    Possible solutions:
      1. Declare task ':iceberg-common:jar' as an input of ':iceberg-data:revapiAnalyze'.
      2. Declare an explicit dependency on ':iceberg-common:jar' from ':iceberg-data:revapiAnalyze' using Task#dependsOn.
      3. Declare an explicit dependency on ':iceberg-common:jar' from ':iceberg-data:revapiAnalyze' using Task#mustRunAfter.

    For more information, please refer to https://docs.gradle.org/8.2/userguide/validation_problems.html#implicit_dependency in the Gradle documentation.
```",1,3,2023-07-03 11:28:58+02:00,['build.gradle']
AWS: Switch tests to JUnit5 (#7957),13,433,2023-07-03 12:06:52+02:00,"['TestAwsClientFactories.java', 'TestAwsProperties.java', 'TestHttpClientConfigurations.java', 'TestRESTSigV4Signer.java', 'TestDynamoDbCatalog.java', 'TestGlueCatalog.java', 'TestGlueToIcebergConverter.java', 'TestIcebergToGlueConverter.java', 'TestS3RequestUtil.java', 'TestS3URI.java', 'TestS3SignRequestParser.java', 'TestS3SignResponseParser.java', 'TestRetryDetector.java']"
ORC: Switch tests to JUnit5 (#7954),12,523,2023-07-03 12:26:24+02:00,"['build.gradle', 'TestBloomFilter.java', 'TestBuildOrcProjection.java', 'TestEstimateOrcAvgWidthVisitor.java', 'TestExpressionToSearchArgument.java', 'TestIdToOrcName.java', 'TestORCFileIOProxies.java', 'TestORCSchemaUtil.java', 'TestOrcDataReader.java', 'TestOrcDataWriter.java', 'TestOrcDeleteWriters.java', 'TestTableProperties.java']"
"Build: Bump griffe from 0.29.1 to 0.30.0 in /python (#7961)

Bumps [griffe](https://github.com/mkdocstrings/griffe) from 0.29.1 to 0.30.0.
- [Changelog](https://github.com/mkdocstrings/griffe/blob/main/CHANGELOG.md)
- [Commits](https://github.com/mkdocstrings/griffe/compare/0.29.1...0.30.0)

---
updated-dependencies:
- dependency-name: griffe
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-07-03 13:13:34+02:00,['requirements.txt']
"Build: Bump typing-extensions from 4.6.3 to 4.7.0 in /python (#7962)

Bumps [typing-extensions](https://github.com/python/typing_extensions) from 4.6.3 to 4.7.0.
- [Release notes](https://github.com/python/typing_extensions/releases)
- [Changelog](https://github.com/python/typing_extensions/blob/main/CHANGELOG.md)
- [Commits](https://github.com/python/typing_extensions/compare/4.6.3...4.7.0)

---
updated-dependencies:
- dependency-name: typing-extensions
  dependency-type: direct:development
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,20,2023-07-03 13:13:49+02:00,"['poetry.lock', 'pyproject.toml']"
Core: add missing start and length for FileScanTaskParser. Also added `schema()` override for BaseFileScanTask$SplitScanTask class. (#7936),3,18,2023-07-03 08:06:01-07:00,"['BaseFileScanTask.java', 'FileScanTaskParser.java', 'TestFileScanTaskParser.java']"
"Build: Bump Guava to 32.1.1 (#7973)

fixes #7971",1,2,2023-07-03 17:28:04+02:00,['versions.props']
"Build: Bump pydantic from 1.10.9 to 1.10.10 in /python (#7972)

Bumps [pydantic](https://github.com/pydantic/pydantic) from 1.10.9 to 1.10.10.
- [Release notes](https://github.com/pydantic/pydantic/releases)
- [Changelog](https://github.com/pydantic/pydantic/blob/main/HISTORY.md)
- [Commits](https://github.com/pydantic/pydantic/compare/v1.10.9...v1.10.10)

---
updated-dependencies:
- dependency-name: pydantic
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,74,2023-07-04 13:13:08+02:00,['poetry.lock']
"Build: Bump pandas from 2.0.2 to 2.0.3 in /python (#7960)

Bumps [pandas](https://github.com/pandas-dev/pandas) from 2.0.2 to 2.0.3.
- [Release notes](https://github.com/pandas-dev/pandas/releases)
- [Commits](https://github.com/pandas-dev/pandas/compare/v2.0.2...v2.0.3)

---
updated-dependencies:
- dependency-name: pandas
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,56,2023-07-04 13:13:26+02:00,['poetry.lock']
"Python: Update `test_console` tests (#7683)

* Update test_console tests

* Update poetry.lock file",4,1182,2023-07-04 21:16:45+02:00,"['poetry.lock', 'pyproject.toml', 'test_base.py', 'test_console.py']"
"Spark 3.4: Support NOT_EQ for V2 filters (#7898)

Co-authored-by: xianyangliu <xianyangliu@tencent.com>",2,187,2023-07-04 14:03:21-07:00,"['SparkV2Filters.java', 'TestSparkV2Filters.java']"
Core: Support registerTable with REST session catalog (#6512),13,478,2023-07-04 14:06:09-07:00,"['CatalogHandlers.java', 'RESTSerializers.java', 'RESTSessionCatalog.java', 'ResourcePaths.java', 'RegisterTableRequest.java', 'RegisterTableRequestParser.java', 'CatalogTests.java', 'TestJdbcCatalog.java', 'RESTCatalogAdapter.java', 'TestResourcePaths.java', 'TestRegisterTableRequestParser.java', 'rest-catalog-open-api.py', 'rest-catalog-open-api.yaml']"
"Python: Add gzip metadata support (#7984)

* Python: Add gzip metadata support

Resolves #7977

* Remove `get` verb",3,92,2023-07-05 09:39:30+02:00,"['serializers.py', 'conftest.py', 'test_init.py']"
Spark 3.4: Remove 'snapshot-property' prefix in CommitMetadata properties (#7986),3,50,2023-07-05 14:27:09+02:00,"['spark-configuration.md', 'CommitMetadata.java', 'TestDataSourceOptions.java']"
"Revert ""Bump Gradle to 8.2 (#7955)"" (#7995)

This reverts commit d2e570a57658a9e2dc20193120338183590a1651 and e62e0add11f5deab9cbd81c7fa122c8047e2f497.",3,9,2023-07-05 17:25:49+02:00,"['build.gradle', 'gradle-wrapper.properties', 'gradlew']"
Build: Run RevAPI on all configured projects (#7993),1,2,2023-07-06 07:51:30+02:00,['api-binary-compatibility.yml']
Core: Remove deprecated AssertHelpers usage (#7994),10,1684,2023-07-06 08:32:40+02:00,"['TestMergeAppend.java', 'TestOverwriteWithValidation.java', 'TestRemoveSnapshots.java', 'TestReplacePartitions.java', 'TestReplaceTransaction.java', 'TestRewriteFiles.java', 'TestRewriteManifests.java', 'TestRowDelta.java', 'TestSnapshotRefParser.java', 'TestTableMetadata.java']"
"Python: Add catalog name to identifiers (#7946)

* add catalog name to the identifier of table returned by glue catalog

* add catalog name to the identifier of table returned by hive catalog",5,68,2023-07-06 09:34:23+02:00,"['glue.py', 'hive.py', 'integration_test_glue.py', 'test_glue.py', 'test_hive.py']"
"Python: Add S3 proxies to PyIceberg Catalog FileIO (#7958)

* proxies

* proxies config

* typo

* one proxy-uri cofig

* isort

* lint

* proxy uri for both http and https on s3fs

* lint

* rename property

* s3.proxy-uri

* lint",4,25,2023-07-06 09:35:33+02:00,"['configuration.md', '__init__.py', 'fsspec.py', 'pyarrow.py']"
"Python: Avro write (#7873)

* Python: Avro write support

* Add class to write Avro files and add PoC update_table api call

* Add tests for the avro readers and writers

This commit also fixes some small bugs uncovered by the new tests

* Appease pylint and pydocstyle

* Appease pre-commit hooks

* Address PR review comments

* Appease pre-commit hooks

* Add additional metadata to avro output file

---------

Co-authored-by: Fokko Driesprong <fokko@apache.org>",15,1309,2023-07-06 10:09:01+02:00,"['__init__.py', 'decoder.py', 'encoder.py', 'file.py', 'resolver.py', 'writer.py', 'pyarrow.py', 'schema.py', 'typedef.py', 'datetime.py', 'schema_conversion.py', 'test_encoder.py', 'test_file.py', 'test_writer.py', 'test_schema_conversion.py']"
Core: Migrating util module to JUnit5  (#7895),15,1009,2023-07-06 13:54:15+02:00,"['TestBinPacking.java', 'TestEnvironmentUtil.java', 'TestInMemoryLockManager.java', 'TestJsonUtil.java', 'TestLocationUtil.java', 'TestLockManagers.java', 'TestParallelIterable.java', 'TestReachableFileUtil.java', 'TestSnapshotUtil.java', 'TestSortOrderUtil.java', 'TestStructLikeMap.java', 'TestStructLikeSet.java', 'TestTableScanUtil.java', 'TestTasks.java', 'TestZOrderByteUtil.java']"
Core: Rename last updated timestamp column in PartitionsTable (#8003),5,88,2023-07-06 16:54:18-07:00,"['PartitionsTable.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java']"
Spark 3.4: Remove deprecated AssertHelpers usage (#8009),8,785,2023-07-07 14:41:19+02:00,"['TestExpireSnapshotsProcedure.java', 'TestMigrateTableProcedure.java', 'TestPublishChangesProcedure.java', 'TestRewriteDataFilesProcedure.java', 'TestRollbackToSnapshotProcedure.java', 'TestRollbackToTimestampProcedure.java', 'TestSetCurrentSnapshotProcedure.java', 'TestSnapshotTableProcedure.java']"
Core: Add total data size to Partitions table (#7920),5,224,2023-07-07 10:35:01-07:00,"['PartitionsTable.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSourceTablesBase.java']"
Spark 3.4: WAP branch not propagated when using DELETE without WHERE (#7900),3,81,2023-07-07 17:39:44-05:00,"['TestDelete.java', 'SparkTableUtil.java', 'SparkTable.java']"
Flink: switch to FileScanTaskParser for JSON serialization of IcebergSourceSplit (#7978),6,137,2023-07-07 21:44:54-07:00,"['IcebergSource.java', 'IcebergEnumeratorStateSerializer.java', 'IcebergSourceSplit.java', 'IcebergSourceSplitSerializer.java', 'TestIcebergEnumeratorStateSerializer.java', 'TestIcebergSourceSplitSerializer.java']"
Build: Bump pytest-mock from 3.10.0 to 3.11.1 in /python (#8020),2,12,2023-07-09 06:33:21+02:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump mkdocs-material from 9.1.17 to 9.1.18 in /python (#8018),1,2,2023-07-09 06:33:41+02:00,['requirements.txt']
Build: Bump requests-mock from 1.10.0 to 1.11.0 in /python (#8019),2,12,2023-07-09 06:44:38+02:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump typing-extensions from 4.5.0 to 4.7.1 in /python (#8017),2,10,2023-07-09 12:50:51+02:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump org.eclipse.microprofile.openapi:microprofile-openapi-api (#8016)

Bumps [org.eclipse.microprofile.openapi:microprofile-openapi-api](https://github.com/eclipse/microprofile-open-api) from 3.1 to 3.1.1.
- [Release notes](https://github.com/eclipse/microprofile-open-api/releases)
- [Commits](https://github.com/eclipse/microprofile-open-api/compare/3.1...3.1.1)

---
updated-dependencies:
- dependency-name: org.eclipse.microprofile.openapi:microprofile-openapi-api
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,4,2023-07-10 07:59:22+02:00,['build.gradle']
"Python: Let produce last-updated-ms field in metadata at microsecond level (#8026)

* Let produce last-updated-ms field in metadata at microsecond level

* Remove unused function

* Add test for datetime_to_millis

* Lint files

* Add license header in test_datetime.py",3,84,2023-07-10 15:40:24+02:00,"['metadata.py', 'datetime.py', 'test_datetime.py']"
Python: Return location and comments when parameter key does not exist (#8014),1,4,2023-07-10 15:52:20+02:00,['glue.py']
Spark-3.3: Backport 'WAP branch not propagated when using DELETE without WHERE' (#8033),3,81,2023-07-11 08:05:41+02:00,"['TestDelete.java', 'SparkTableUtil.java', 'SparkTable.java']"
"Spark 3.1, 3.2, 3.3: Backport removal of snapshot-property in CommitMetadata properties (#7991)",6,136,2023-07-11 15:53:36+02:00,"['CommitMetadata.java', 'TestDataSourceOptions.java', 'CommitMetadata.java', 'TestDataSourceOptions.java', 'CommitMetadata.java', 'TestDataSourceOptions.java']"
"Docs: Add warning in tiered storage (#8037)

* Docs: Add warning in tiered storage

* Update docs/spark-procedures.md

Co-authored-by: Prashant Singh <35593236+singhpk234@users.noreply.github.com>

---------

Co-authored-by: Prashant Singh <35593236+singhpk234@users.noreply.github.com>",1,4,2023-07-11 19:01:01+02:00,['spark-procedures.md']
Build: Upgrade scala-collection-compat (#8002),1,4,2023-07-11 12:38:21-07:00,['versions.props']
Spark 3.4: Allow importing empty tables (#7980),2,34,2023-07-12 13:11:02-07:00,"['TestMigrateTableProcedure.java', 'SparkTableUtil.java']"
"Core: Fix unicode handling in HTTPClient (#8046)

fixes #7821

Without the fix, tests would fail with
```
expected: struct<1: id: required int (unique ID ), 2: data: required string>
 but was: struct<1: id: required int (unique ID ?), 2: data: required string>
```",2,13,2023-07-13 10:41:07-07:00,"['HTTPClient.java', 'CatalogTests.java']"
Spark: Consolidate duplicated test methods to TestHelpers (#8024),16,186,2023-07-13 11:00:56-07:00,"['TestHelpers.java', 'TestIcebergSourceTablesBase.java', 'TestDelete.java', 'TestRewriteDataFilesAction.java', 'TestHelpers.java', 'TestIcebergSourceTablesBase.java', 'TestDelete.java', 'TestRewriteDataFilesAction.java', 'TestRewritePositionDeleteFilesAction.java', 'TestHelpers.java', 'TestIcebergSourceTablesBase.java', 'TestDelete.java', 'TestRewriteDataFilesAction.java', 'TestRewritePositionDeleteFilesAction.java', 'TestHelpers.java', 'TestIcebergSourceTablesBase.java']"
Core: Abort file groups should be under same lock as committerService (#7933),2,183,2023-07-13 16:28:45-07:00,"['BaseCommitService.java', 'TestCommitService.java']"
Docs: Update Partitions table in Flink/Spark doc (#8021),2,28,2023-07-13 16:30:11-07:00,"['flink-queries.md', 'spark-queries.md']"
"Build: Bump Arrow from 12.0.0 to 12.0.1 (#8038)

Maintenance release:
https://arrow.apache.org/release/12.0.1.html",1,4,2023-07-14 08:35:32+02:00,['versions.props']
"Core: Handle optional fields (#8050)

* Core: Handle allow optional fields

We expect:

- current-snapshot-id
- properties
- snapshots

to be there, but they are actually optional.

* Use AssertJ",3,119,2023-07-14 09:26:19+02:00,"['TableMetadataParser.java', 'TestTableMetadata.java', 'TableMetadataV2ValidMinimal.json']"
Core: Remove deprecated AssertHelpers usage (#8062),3,1184,2023-07-14 10:17:38+02:00,"['TestSchemaUpdate.java', 'TestSnapshotManager.java', 'TestUpdatePartitionSpec.java']"
Spark 3.4: Fix rewrite_position_deletes for certain partition types (#8059),3,463,2023-07-14 10:26:05-07:00,"['TestRewritePositionDeleteFiles.java', 'SparkValueConverter.java', 'SparkBinPackPositionDeletesRewriter.java']"
"Spark 3.1, 3.2, 3.3: Allow importing empty tables (#7980) (#8063)",6,102,2023-07-14 12:29:42-07:00,"['TestMigrateTableProcedure.java', 'SparkTableUtil.java', 'TestMigrateTableProcedure.java', 'SparkTableUtil.java', 'TestMigrateTableProcedure.java', 'SparkTableUtil.java']"
Spark 3.3: Fix rewrite_position_deletes for certain partition types (#8059) (#8069),3,454,2023-07-14 16:14:54-07:00,"['TestRewritePositionDeleteFiles.java', 'SparkValueConverter.java', 'SparkBinPackPositionDeletesRewriter.java']"
Hive: Switch tests to JUnit5 (#8058),14,1052,2023-07-15 11:27:09+02:00,"['build.gradle', 'HiveCreateReplaceTableTest.java', 'HiveMetastoreTest.java', 'HiveTableBaseTest.java', 'HiveTableTest.java', 'TestCachedClientPool.java', 'TestHiveCatalog.java', 'TestHiveClientPool.java', 'TestHiveCommitLocks.java', 'TestHiveCommits.java', 'TestHiveMetastore.java', 'TestHiveSchemaUtil.java', 'TestHiveTableConcurrency.java', 'TestLoadHiveCatalog.java']"
"GCP: fix single byte read in GCSInputStream (#8071)

* GCP: fix byte read in GCSInputStream

* add test",2,18,2023-07-15 05:52:17-07:00,"['GCSInputStream.java', 'GCSInputStreamTest.java']"
"Python: Remove MemoryInputStream in favor of io.BytesIO (#8074)

* Python: Remove MemoryInputStream in favor of io.BytesIO

* Add pre-commit fixes",4,146,2023-07-15 21:52:24+02:00,"['file.py', 'memory.py', 'test_decoder.py', 'test_reader.py']"
"Build: Bump moto from 4.1.12 to 4.1.13 in /python (#8080)

Bumps [moto](https://github.com/getmoto/moto) from 4.1.12 to 4.1.13.
- [Changelog](https://github.com/getmoto/moto/blob/master/CHANGELOG.md)
- [Commits](https://github.com/getmoto/moto/compare/4.1.12...4.1.13)

---
updated-dependencies:
- dependency-name: moto
  dependency-type: direct:development
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,10,2023-07-16 11:32:34+02:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump griffe from 0.30.0 to 0.32.1 in /python (#8078)

Bumps [griffe](https://github.com/mkdocstrings/griffe) from 0.30.0 to 0.32.1.
- [Release notes](https://github.com/mkdocstrings/griffe/releases)
- [Changelog](https://github.com/mkdocstrings/griffe/blob/main/CHANGELOG.md)
- [Commits](https://github.com/mkdocstrings/griffe/compare/0.30.0...0.32.1)

---
updated-dependencies:
- dependency-name: griffe
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-07-16 11:32:48+02:00,['requirements.txt']
"Python: Improve Avro read performance (#8075)

Utilize __slots__ for various Avro classes.

Memoize the key/value reader functions in MapReader.",7,73,2023-07-16 19:09:24+02:00,"['decoder.py', 'file.py', 'reader.py', 'resolver.py', 'manifest.py', 'typedef.py', 'test_file.py']"
Python: Concurrency using `ThreadPoolExecutor` (#8061),3,104,2023-07-17 16:13:00+02:00,"['pyarrow.py', '__init__.py', 'concurrent.py']"
Build: Bump Nessie to 0.65.0 (#8093),1,2,2023-07-18 13:19:35+02:00,['versions.props']
Docs: Fix conflicting description on primary key support in Flink (#7382),2,35,2023-07-18 13:40:38+02:00,"['flink-ddl.md', 'flink-writes.md']"
Spark 3.1: Relocate all Netty classes (#6732),1,11,2023-07-18 13:44:38+02:00,['build.gradle']
"Spark 3.4: Force Jackson version to 2.14.2 (#8052)

Spark 3.4.1 uses Jackson 2.14.2 according to
https://github.com/apache/spark/blob/v3.4.1/pom.xml#L186-L187, so we
should enforce the same version.",1,6,2023-07-18 16:58:55+02:00,['build.gradle']
Spark 3.1: Add prefix mismatch mode for deleting orphan files (#7653),5,537,2023-07-18 13:54:43-07:00,"['TestRemoveOrphanFilesProcedure.java', 'BaseDeleteOrphanFilesSparkAction.java', 'SetAccumulator.java', 'RemoveOrphanFilesProcedure.java', 'TestRemoveOrphanFilesAction.java']"
Spark 3.2: Skip duplicate check on deleted file path when import files (#8092),2,61,2023-07-18 13:56:34-07:00,"['TestAddFilesProcedure.java', 'SparkTableUtil.java']"
"Spark 3.3, 3.4: Migrate TestRewritePositionDeleteFiles to AssertJ (#8070)",2,208,2023-07-19 08:53:57+02:00,"['TestRewritePositionDeleteFiles.java', 'TestRewritePositionDeleteFiles.java']"
"Core, AWS, Delta, Snowflake: Switch tests to JUnit5 (#7996)",21,832,2023-07-19 11:11:11+02:00,"['TestS3FileIO.java', 'TestS3InputStream.java', 'TestS3OutputStream.java', 'TestS3URI.java', 'TestS3RestSigner.java', 'build.gradle', 'TestCatalogUtil.java', 'TestEnvironmentContext.java', 'TestFixedSizeSplitScanTaskIterator.java', 'TestMetricsTruncation.java', 'TestOffsetsBasedSplitScanTaskIterator.java', 'TestSchemaUnionByFieldName.java', 'AvroTestHelpers.java', 'SparkDeltaLakeSnapshotTestBase.java', 'TestSnapshotDeltaLakeTable.java', 'TestBaseSnapshotDeltaLakeTableAction.java', 'TestDeltaLakeTypeToType.java', 'JdbcSnowflakeClientTest.java', 'NamespaceHelpersTest.java', 'SnowflakeCatalogTest.java', 'versions.props']"
Docs: Update wording around nullability (#8094),1,7,2023-07-19 11:11:50+02:00,['spark-ddl.md']
Parquet: Upgrade to JUnit5 (#8056),14,1133,2023-07-19 15:50:15+02:00,"['build.gradle', 'TestHelpers.java', 'TestParquetReadProjection.java', 'TestReadProjection.java', 'ParquetWritingTestUtils.java', 'TestBloomRowGroupFilter.java', 'TestCDHParquetStatistics.java', 'TestDictionaryRowGroupFilter.java', 'TestParquet.java', 'TestParquetDataWriter.java', 'TestParquetDeleteWriters.java', 'TestParquetEncryption.java', 'TestParquetSchemaUtil.java', 'TestPruneColumns.java']"
"Python: Improve Avro Parse speed (#8082)

* Python: Improve Avro Parse speed

Cache the hash value of the Struct types so that when new
Record objects are created time is not spent recomputing
the hash value.

Change the implementation of the Record class to cache the
mapping from field name to position.  Also utilize an array
rather than a dictionary for these lookups.

* fix: adjust PR comments",2,23,2023-07-20 07:54:49+02:00,"['typedef.py', 'types.py']"
"Spark, Flink: Fix running integration tests with JDK17 (#8114)",7,9,2023-07-20 14:26:36+02:00,"['build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle']"
"Python: SqlCatalog (#7921)

* Initial code for pyiceberg JDBC Catalog

* pyiceberg JDBC Catalog PR modifications

* pyiceberg JDBC Catalog PR modifications

* pyiceberg JDBC Catalog PR modifications

* pyiceberg JDBC Catalog PR modifications

* Fix lint errors

* Migrate to SQLAlchemy, initial code

* Migrate to SQLAlchemy

* Migrate to SQLAlchemy

* Apply suggestions from code review

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* Update python/pyiceberg/catalog/sql.py

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* Finish PR review changes and port JDBCCatalog unit tests over

* Migrate to SQLAlchemy

* Fix lint issues

* Fix lint issues

* Fix lint issues

* Fix lint issues

* Add new namespace unit test

* Apply suggestions from code review

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* PR review fix

* Merge conflict

* In-sync with master

---------

Co-authored-by: cccs-eric <eric.ladouceur@cyber.gc.ca>",7,1203,2023-07-20 15:48:40+02:00,"['Makefile', 'configuration.md', 'poetry.lock', '__init__.py', 'sql.py', 'pyproject.toml', 'test_sql.py']"
"Spark 3.4: Create non-existing Tag/Branch when using CREATE OR REPLACE (#8086)

Currently, executing `ALTER TABLE x CREATE OR REPLACE TAG xyz` will fail
with `Tag does not exist: xyz`.

As a user I'd expect this to create the tag due to the `CREATE OR
REPLACE` usage. The same issue happens with branches.",8,124,2023-07-20 08:29:27-07:00,"['IcebergSqlExtensionsAstBuilder.scala', 'CreateOrReplaceBranch.scala', 'CreateOrReplaceTag.scala', 'CreateOrReplaceBranchExec.scala', 'CreateOrReplaceTagExec.scala', 'ExtendedDataSourceV2Strategy.scala', 'TestBranchDDL.java', 'TestTagDDL.java']"
"Build: Bump aiohttp from 3.8.4 to 3.8.5 in /python (#8119)

Bumps [aiohttp](https://github.com/aio-libs/aiohttp) from 3.8.4 to 3.8.5.
- [Release notes](https://github.com/aio-libs/aiohttp/releases)
- [Changelog](https://github.com/aio-libs/aiohttp/blob/v3.8.5/CHANGES.rst)
- [Commits](https://github.com/aio-libs/aiohttp/compare/v3.8.4...v3.8.5)

---
updated-dependencies:
- dependency-name: aiohttp
  dependency-type: indirect
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,301,2023-07-20 21:48:05+02:00,['poetry.lock']
"Build: Bump fastavro from 1.7.4 to 1.8.2 in /python (#8118)

Bumps [fastavro](https://github.com/fastavro/fastavro) from 1.7.4 to 1.8.2.
- [Release notes](https://github.com/fastavro/fastavro/releases)
- [Changelog](https://github.com/fastavro/fastavro/blob/master/ChangeLog)
- [Commits](https://github.com/fastavro/fastavro/compare/1.7.4...1.8.2)

---
updated-dependencies:
- dependency-name: fastavro
  dependency-type: direct:development
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,78,2023-07-20 22:01:43+02:00,"['poetry.lock', 'pyproject.toml']"
Spark 3.4: Display read metrics on Spark SQL UI (#7447),21,768,2023-07-20 16:04:44-07:00,"['BaseScan.java', 'InMemoryMetricsReporter.java', 'SparkBatchQueryScan.java', 'SparkCopyOnWriteScan.java', 'SparkPartitioningAwareScan.java', 'SparkScan.java', 'SparkScanBuilder.java', 'SparkStagedScan.java', 'ScannedDataFiles.java', 'ScannedDataManifests.java', 'SkippedDataFiles.java', 'SkippedDataManifests.java', 'TaskScannedDataFiles.java', 'TaskScannedDataManifests.java', 'TaskSkippedDataFiles.java', 'TaskSkippedDataManifests.java', 'TaskTotalFileSize.java', 'TaskTotalPlanningDuration.java', 'TotalFileSize.java', 'TotalPlanningDuration.java', 'TestSparkReadMetrics.java']"
"Spark 3.1, 3.2, 3.3: Create non-existing Tag/Branch when using CREATE OR REPLACE (#8125)",21,336,2023-07-21 10:57:53+02:00,"['IcebergSqlExtensionsAstBuilder.scala', 'CreateOrReplaceBranch.scala', 'CreateOrReplaceBranchExec.scala', 'ExtendedDataSourceV2Strategy.scala', 'TestBranchDDL.java', 'IcebergSqlExtensionsAstBuilder.scala', 'CreateOrReplaceBranch.scala', 'CreateOrReplaceTag.scala', 'CreateOrReplaceBranchExec.scala', 'CreateOrReplaceTagExec.scala', 'ExtendedDataSourceV2Strategy.scala', 'TestBranchDDL.java', 'TestTagDDL.java', 'IcebergSqlExtensionsAstBuilder.scala', 'CreateOrReplaceBranch.scala', 'CreateOrReplaceTag.scala', 'CreateOrReplaceBranchExec.scala', 'CreateOrReplaceTagExec.scala', 'ExtendedDataSourceV2Strategy.scala', 'TestBranchDDL.java', 'TestTagDDL.java']"
Hive: Fix assertion (#8127),1,2,2023-07-21 18:03:46+02:00,['TestHiveMetastore.java']
"Python: Fix datetime test locally (#8131)

running datetime test locally errors when system timezone is not UTC",1,64,2023-07-21 20:53:09+02:00,['test_datetime.py']
"GCP: Add properties for OAtuh2 and update library (#8073)

Co-authored-by: Daniel Weeks <dweeks@apache.org>",4,38,2023-07-21 11:55:42-07:00,"['ResolvingFileIO.java', 'GCPProperties.java', 'GCSFileIO.java', 'versions.props']"
"Build: Bump mkdocs-material from 9.1.18 to 9.1.19 in /python (#8135)

Bumps [mkdocs-material](https://github.com/squidfunk/mkdocs-material) from 9.1.18 to 9.1.19.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/CHANGELOG)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/9.1.18...9.1.19)

---
updated-dependencies:
- dependency-name: mkdocs-material
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-07-23 08:03:20+02:00,['requirements.txt']
"Build: Bump griffe from 0.32.1 to 0.32.3 in /python (#8136)

Bumps [griffe](https://github.com/mkdocstrings/griffe) from 0.32.1 to 0.32.3.
- [Release notes](https://github.com/mkdocstrings/griffe/releases)
- [Changelog](https://github.com/mkdocstrings/griffe/blob/main/CHANGELOG.md)
- [Commits](https://github.com/mkdocstrings/griffe/compare/0.32.1...0.32.3)

---
updated-dependencies:
- dependency-name: griffe
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-07-23 08:03:32+02:00,['requirements.txt']
"Build: Bump pytest-checkdocs from 2.9.0 to 2.10.0 in /python (#8137)

Bumps [pytest-checkdocs](https://github.com/jaraco/pytest-checkdocs) from 2.9.0 to 2.10.0.
- [Release notes](https://github.com/jaraco/pytest-checkdocs/releases)
- [Changelog](https://github.com/jaraco/pytest-checkdocs/blob/main/NEWS.rst)
- [Commits](https://github.com/jaraco/pytest-checkdocs/compare/v2.9.0...v2.10.0)

---
updated-dependencies:
- dependency-name: pytest-checkdocs
  dependency-type: direct:development
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,16,2023-07-23 08:03:40+02:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump click from 8.1.3 to 8.1.6 in /python (#8138)

Bumps [click](https://github.com/pallets/click) from 8.1.3 to 8.1.6.
- [Release notes](https://github.com/pallets/click/releases)
- [Changelog](https://github.com/pallets/click/blob/8.1.6/CHANGES.rst)
- [Commits](https://github.com/pallets/click/compare/8.1.3...8.1.6)

---
updated-dependencies:
- dependency-name: click
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,6,2023-07-23 08:03:56+02:00,['poetry.lock']
Python: Fix StructWriter `__repr__` to indicate it is a writer (#8105),1,2,2023-07-23 09:10:10+02:00,['writer.py']
"Python: Bump to PyParsing 3.1.0 (#8116)

* Python: Bump to PyParsing 3.1.0

* Update poetry.lock",4,1061,2023-07-23 18:32:05+02:00,"['poetry.lock', 'parser.py', 'pyproject.toml', 'test_parser.py']"
"Remove direct dependency to Apache Commons

The approach followed is to use native Java 8 code when the alternative was clear or replicate/borrow when not following iceberg-core project practice.

Flink and Spark projects declare Apache Commons as direct dependency and therefore on those subprojects the dependency is not removed.

Remove the direct dependency on Apache Commons.

The approach followed is to use native Java 8 code when the alternative was clear or replicate/borrow when not following iceberg-core project practice.

Flink and Spark projects declare Apache Commons as direct dependency and therefore on those subprojects the dependency is not removed.

Remove the direct dependency on Apache Commons.

The approach followed is to use native Java 8 code when the alternative was clear or replicate/borrow when not following iceberg-core project practice.

Flink and Spark projects declare Apache Commons as direct dependency and therefore on those subprojects the dependency is not removed.

Co-authored-by: Angel Conde Manjon <acmanjon@amazon.com>",16,495,2023-07-24 08:52:01+02:00,"['AliyunOSSMockLocalController.java', 'AliyunOSSMockLocalStore.java', 'AliyunOSSMockRule.java', 'TestHelpers.java', 'TestS3FileIOIntegration.java', 'TestS3FileIO.java', 'TestS3InputStream.java', 'ManifestReadBenchmark.java', 'ObjectData.java', 'BaseSnapshotDeltaLakeTableAction.java', 'GCSFileIOTest.java', 'GCSInputStreamTest.java', 'CompatibilityHiveVectorUtils.java', 'HiveVectorizedReader.java', 'TestNessieTable.java', 'ParquetAvro.java']"
Python: Rename Reader to Writer (#8140),1,13,2023-07-24 14:09:29+02:00,['writer.py']
"Python: Improve AVRO reading speed (#8084)

* Python: Improve Avro read performance

Utilize __slots__ for various Avro classes.

Memoize the key/value reader functions in MapReader.

* Python: improve Avro parsing by caching struct types.

Cache the struct types for ManifestEntry and ManifestFile schemas.

Cache the _position_to_field_name lookup in Records if a struct type is passed.

Improve StructReader to use slots and avoid isinstance() lookups on each time
the structure is read, by performing the check in __init__().

Improve StructReader to determine the arguments to create_struct() once in init
and reuse the result each time the structure is read, avoid a try block.

* Python: Improve Avro Parse speed

Cache the hash value of the Struct types so that when new
Record objects are created time is not spent recomputing
the hash value.

Change the implementation of the Record class to cache the
mapping from field name to position.  Also utilize an array
rather than a dictionary for these lookups.

* fix some lints

* fix some type casing

* fix: adjust PR comments

* fix: address PR feedback.

* Add additional tests for InMemoryBinaryDecoder

* Load entire Avro file into memory rather than streaming it

* fix: disable seeking on input file

* Update python/pyiceberg/avro/file.py

---------

Co-authored-by: Fokko Driesprong <fokko@apache.org>",6,500,2023-07-25 08:33:55+02:00,"['decoder.py', 'file.py', 'reader.py', 'manifest.py', 'test_decoder.py', 'test_reader.py']"
"Python: Small fixes (#7989)

Uncovered these when upgrading to Pydantic 2.0",6,50,2023-07-25 08:55:07+02:00,"['__init__.py', 'metadata.py', 'snapshots.py', 'test_hive.py', 'test_init.py', 'test_metadata.py']"
Core: Make InMemoryCatalog#renameTable thread-safe and simplify code (#8146),1,31,2023-07-25 11:49:18+02:00,['InMemoryCatalog.java']
"Update slack invite link (#8145)

follow up for https://github.com/apache/iceberg-docs/pull/257",1,2,2023-07-25 13:48:29+02:00,['iceberg_question.yml']
Spark 3.4: Evaluate ExpressionUtil.selectsPartitions for partitioned table only (#8142),1,9,2023-07-25 11:18:53-07:00,['SparkScanBuilder.java']
Core: Simplify and improve View APIs (#7992),23,630,2023-07-25 16:20:13-07:00,"['revapi.yml', 'ReplaceViewVersion.java', 'VersionBuilder.java', 'View.java', 'ViewBuilder.java', 'ViewHistoryEntry.java', 'ViewVersion.java', 'BaseViewHistoryEntry.java', 'BaseViewVersion.java', 'SQLViewRepresentation.java', 'SQLViewRepresentationParser.java', 'ViewVersionParser.java', 'TestSQLViewRepresentationParser.java', 'TestViewMetadataParser.java', 'TestViewVersionParser.java', 'ValidViewMetadata.json', 'ViewMetadataInvalidCurrentSchema.json', 'ViewMetadataInvalidCurrentVersion.json', 'ViewMetadataLimitedVersions.json', 'ViewMetadataMissingCurrentSchema.json', 'ViewMetadataMissingCurrentVersion.json', 'ViewMetadataMissingLocation.json', 'view-spec.md']"
"Python: Add pyarrow hdfs support (#7997)

* Add pyarrow hdfs support

* Update PR review",4,41,2023-07-26 09:27:45+02:00,"['configuration.md', '__init__.py', 'pyarrow.py', 'test_pyarrow.py']"
Build: Add 1.3.1 to github template version (#8150),1,3,2023-07-26 11:15:25-07:00,['iceberg_bug_report.yml']
"Spark 3.3, 3.4: Fix rewrite_position_delete_files when the partition column contains ""."" (#8111)",4,86,2023-07-26 11:51:13-07:00,"['TestRewritePositionDeleteFiles.java', 'SparkBinPackPositionDeletesRewriter.java', 'TestRewritePositionDeleteFiles.java', 'SparkBinPackPositionDeletesRewriter.java']"
Spark 3.3: Evaluate ExpressionUtil.selectsPartitions for partitioned table only (#8152),1,9,2023-07-26 11:53:32-07:00,['SparkScanBuilder.java']
Core: Optimize DeleteFileIndex (#8157),2,736,2023-07-26 23:10:03-07:00,"['DeleteFileIndex.java', 'PlanningBenchmark.java']"
Docs: Use backticks for quoting Branch/Tag names (#8148),1,8,2023-07-27 09:27:38+02:00,['branching-and-tagging.md']
Spark: Fix the ChangelogScan casting issue (#8167),3,6,2023-07-27 17:26:28-07:00,"['SparkScanBuilder.java', 'SparkScanBuilder.java', 'SparkScanBuilder.java']"
API: Implement bound expression sanitization (#8149),3,326,2023-07-28 10:26:14-07:00,"['ExpressionUtil.java', 'TestExpressionUtil.java', 'SnapshotScan.java']"
"Core: Avoid generating huge manifests during commits (#6335)

Co-authored-by: xianyangliu <xianyangliu@tencent.com>",5,457,2023-07-28 11:06:31-07:00,"['FastAppend.java', 'MergingSnapshotProducer.java', 'RollingManifestWriter.java', 'SnapshotProducer.java', 'TestManifestWriter.java']"
"Core, Spark 3.4: Adjust split size to benefit from parallelism (#7714)",6,54,2023-07-28 14:58:16-07:00,"['TableProperties.java', 'TableScanUtil.java', 'TestTableScanUtil.java', 'SparkReadConf.java', 'SparkPartitioningAwareScan.java', 'SparkScan.java']"
Core: Ability to build DeleteFileIndex from files (#8172),2,156,2023-07-28 19:40:43-07:00,"['DeleteFileIndex.java', 'TestDeleteFileIndex.java']"
API: Fix ContentFile doc on value counts (#8180),1,3,2023-07-30 09:00:27-07:00,['ContentFile.java']
"Build: Bump mkdocs from 1.4.3 to 1.5.1 in /python (#8184)

Bumps [mkdocs](https://github.com/mkdocs/mkdocs) from 1.4.3 to 1.5.1.
- [Release notes](https://github.com/mkdocs/mkdocs/releases)
- [Commits](https://github.com/mkdocs/mkdocs/compare/1.4.3...1.5.1)

---
updated-dependencies:
- dependency-name: mkdocs
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-07-31 14:57:27+02:00,['requirements.txt']
"Build: Bump mkdocstrings-python from 1.1.2 to 1.2.1 in /python (#8185)

Bumps [mkdocstrings-python](https://github.com/mkdocstrings/python) from 1.1.2 to 1.2.1.
- [Release notes](https://github.com/mkdocstrings/python/releases)
- [Changelog](https://github.com/mkdocstrings/python/blob/main/CHANGELOG.md)
- [Commits](https://github.com/mkdocstrings/python/compare/1.1.2...1.2.1)

---
updated-dependencies:
- dependency-name: mkdocstrings-python
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-07-31 14:57:37+02:00,['requirements.txt']
"Build: Bump rich from 13.4.2 to 13.5.0 in /python (#8186)

Bumps [rich](https://github.com/Textualize/rich) from 13.4.2 to 13.5.0.
- [Release notes](https://github.com/Textualize/rich/releases)
- [Changelog](https://github.com/Textualize/rich/blob/master/CHANGELOG.md)
- [Commits](https://github.com/Textualize/rich/compare/v13.4.2...v13.5.0)

---
updated-dependencies:
- dependency-name: rich
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,6,2023-07-31 14:57:48+02:00,['poetry.lock']
"Build: Bump ray from 2.6.0 to 2.6.1 in /python (#8187)

Bumps [ray](https://github.com/ray-project/ray) from 2.6.0 to 2.6.1.
- [Release notes](https://github.com/ray-project/ray/releases)
- [Commits](https://github.com/ray-project/ray/compare/ray-2.6.0...ray-2.6.1)

---
updated-dependencies:
- dependency-name: ray
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,53,2023-07-31 14:58:00+02:00,['poetry.lock']
"Build: Bump mkdocs-material from 9.1.19 to 9.1.21 in /python (#8188)

Bumps [mkdocs-material](https://github.com/squidfunk/mkdocs-material) from 9.1.19 to 9.1.21.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/CHANGELOG)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/9.1.19...9.1.21)

---
updated-dependencies:
- dependency-name: mkdocs-material
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-07-31 14:58:10+02:00,['requirements.txt']
Docs: Fix identifiers and links of branching (#8165),5,22,2023-07-31 16:43:04+02:00,"['branching-and-tagging.md', 'flink-getting-started.md', 'flink-writes.md', 'spark-ddl.md', 'spark-writes.md']"
"API, Core: Move @Value.Immutable usage from iceberg-api to iceberg-core (#8099)",19,444,2023-07-31 16:09:58-07:00,"['revapi.yml', 'DeleteOrphanFiles.java', 'DeleteReachableFiles.java', 'ExpireSnapshots.java', 'MigrateTable.java', 'RewriteDataFiles.java', 'RewriteManifests.java', 'RewritePositionDeleteFiles.java', 'SnapshotTable.java', 'BaseDeleteOrphanFiles.java', 'BaseDeleteReachableFiles.java', 'BaseExpireSnapshots.java', 'BaseMigrateTable.java', 'BaseRewriteDataFiles.java', 'BaseRewriteManifests.java', 'BaseRewritePositionalDeleteFiles.java', 'BaseSnapshotTable.java', 'BaseViewHistoryEntry.java', 'BaseViewVersion.java']"
"API, Spark: Supports create branch on empty table (#8072)

Co-authored-by: xianyangliu <xianyangliu@tencent.com>",5,122,2023-07-31 19:06:08-07:00,"['ManageSnapshots.java', 'SnapshotManager.java', 'TestSnapshotManager.java', 'CreateOrReplaceBranchExec.scala', 'TestBranchDDL.java']"
Parquet: Cache codecs by name and level (#8182),2,114,2023-08-01 09:22:33+02:00,"['ParquetCodecFactory.java', 'ParquetWriter.java']"
Open-API: Add last-sequence-number to TableMetadata (#8193),2,4,2023-08-01 09:30:51+02:00,"['rest-catalog-open-api.py', 'rest-catalog-open-api.yaml']"
Core: Fail branch creation on empty table when branch exists (#8197),2,18,2023-08-01 11:03:09+02:00,"['SnapshotManager.java', 'TestSnapshotManager.java']"
Open-API: Use literals instead (#7780),2,185,2023-08-01 13:32:59+02:00,"['Makefile', 'rest-catalog-open-api.py']"
Core: Make ViewVersion.defaultNamespace required (#8156),7,59,2023-08-01 08:20:14-07:00,"['revapi.yml', 'ViewVersion.java', 'BaseViewVersion.java', 'ViewVersionParser.java', 'TestViewMetadata.java', 'TestViewMetadataParser.java', 'TestViewVersionParser.java']"
Spark 3.4: Support pushing down system functions by V2 filters (#7886),8,1483,2023-08-01 09:09:04-07:00,"['SparkV2Filters.java', 'SparkBatchQueryScan.java', 'SparkScanBuilder.java', 'SparkTable.java', 'SystemFunctionPushDownHelper.java', 'TestSparkV2Filters.java', 'TestFilteredScan.java', 'TestSparkScan.java']"
Python: Update Iceberg and Spark versions,1,11,2023-08-02 11:00:41+02:00,['Dockerfile']
Build: Replace usage of Nebula dependency recommender plugin with Gradle's versionCatalog (#7694),13,1059,2023-08-02 11:02:09+02:00,"['labeler.yml', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'libs.versions.toml', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'versions.props']"
"Python: Fix passing in Glue credentials (#8209)

Co-authored-by: bmaisonneuve <bmaisonneuve@factset.com>",2,4,2023-08-02 17:44:11+02:00,"['glue.py', 'test_glue.py']"
Docs: Update creating branch and tag clause (#8216),1,50,2023-08-03 08:56:37+02:00,['spark-ddl.md']
"Spark 3.1: Backport Tag DDL (#8217)

This is based on https://github.com/apache/iceberg/pull/7097, and back-ports bug fixes https://github.com/apache/iceberg/pull/7652 and https://github.com/apache/iceberg/pull/8086",10,686,2023-08-03 10:09:18+02:00,"['IcebergSqlExtensions.g4', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'CreateOrReplaceTag.scala', 'DropTag.scala', 'TagOptions.scala', 'CreateOrReplaceTagExec.scala', 'DropTagExec.scala', 'ExtendedDataSourceV2Strategy.scala', 'TestTagDDL.java']"
Python: Promotion from `fixed[16]` to `uuid` (#8215),1,9,2023-08-03 14:36:13+02:00,['schema.py']
"Python: Add retry for downloading spark package (#8219)

* curl retry

* fixes

---------

Co-authored-by: xianyangliu <xianyangliu@tencent.com>",1,2,2023-08-03 14:36:36+02:00,['Dockerfile']
AWS: Remove unused GlueCatalog.fileIO field (#8068),5,50,2023-08-03 14:58:33+02:00,"['GlueTestBase.java', 'TestGlueCatalogLock.java', 'TestGlueCatalogTable.java', 'GlueCatalog.java', 'TestGlueCatalog.java']"
Python: Add version command (#8225),2,19,2023-08-04 12:13:51+02:00,"['console.py', 'output.py']"
Python: Prepare for 0.5.0 (#8226),2,4,2023-08-04 12:58:55+02:00,"['__init__.py', 'pyproject.toml']"
"Python: Add support `date`, `time` and `datetime` in to_bytes (#8214)

* added datetime support for to_bytes

* fmt

* resuing datetime_to_micros

* removed unused imports

* added new test cases

* fixed format

* removed type checking

* added new test function

* removed old test cases

* datetypes added in function argument

---------

Co-authored-by: Rishabh Srivastava <rishabh.srivastava@cmd.com.au>",2,53,2023-08-04 13:42:19+02:00,"['conversions.py', 'test_conversions.py']"
Doc: update Flink get started instruction for 1.16+ due to regression of loading external jar (#8170),1,7,2023-08-04 11:45:19-07:00,['flink-getting-started.md']
GCP: Add prefix and bulk operations to GCSFileIO (#8168),5,309,2023-08-05 08:41:53+02:00,"['GCPProperties.java', 'GCSFileIO.java', 'GCSLocation.java', 'GCSFileIOTest.java', 'GCSLocationTest.java']"
"Build: Bump ray from 2.6.1 to 2.6.2 in /python (#8236)

Bumps [ray](https://github.com/ray-project/ray) from 2.6.1 to 2.6.2.
- [Release notes](https://github.com/ray-project/ray/releases)
- [Commits](https://github.com/ray-project/ray/compare/ray-2.6.1...ray-2.6.2)

---
updated-dependencies:
- dependency-name: ray
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,48,2023-08-06 14:40:03+02:00,['poetry.lock']
"Build: Bump mkdocs from 1.5.1 to 1.5.2 in /python (#8235)

Bumps [mkdocs](https://github.com/mkdocs/mkdocs) from 1.5.1 to 1.5.2.
- [Release notes](https://github.com/mkdocs/mkdocs/releases)
- [Commits](https://github.com/mkdocs/mkdocs/compare/1.5.1...1.5.2)

---
updated-dependencies:
- dependency-name: mkdocs
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-08-06 14:40:12+02:00,['requirements.txt']
"Build: Bump mkdocs-autorefs from 0.4.1 to 0.5.0 in /python (#8234)

Bumps [mkdocs-autorefs](https://github.com/mkdocstrings/autorefs) from 0.4.1 to 0.5.0.
- [Release notes](https://github.com/mkdocstrings/autorefs/releases)
- [Changelog](https://github.com/mkdocstrings/autorefs/blob/main/CHANGELOG.md)
- [Commits](https://github.com/mkdocstrings/autorefs/compare/0.4.1...0.5.0)

---
updated-dependencies:
- dependency-name: mkdocs-autorefs
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-08-06 14:40:22+02:00,['requirements.txt']
Python: Support optionally returning empty files in scans (#8204),2,11,2023-08-06 12:58:41-07:00,"['visitors.py', '__init__.py']"
Spark 3.4: Add fast_forward procedure (#8081),3,286,2023-08-06 14:53:52-07:00,"['TestFastForwardBranchProcedure.java', 'FastForwardBranchProcedure.java', 'SparkProcedures.java']"
"Build: Bump nessie from 0.65.0 to 0.67.0 (#8240)

Bumps `nessie` from 0.65.0 to 0.67.0.

Updates `org.projectnessie.nessie:nessie-client` from 0.65.0 to 0.67.0

Updates `org.projectnessie.nessie:nessie-jaxrs-testextension` from 0.65.0 to 0.67.0

Updates `org.projectnessie.nessie:nessie-versioned-storage-inmemory` from 0.65.0 to 0.67.0

Updates `org.projectnessie.nessie:nessie-versioned-storage-testextension` from 0.65.0 to 0.67.0

---
updated-dependencies:
- dependency-name: org.projectnessie.nessie:nessie-client
  dependency-type: direct:production
  update-type: version-update:semver-minor
- dependency-name: org.projectnessie.nessie:nessie-jaxrs-testextension
  dependency-type: direct:production
  update-type: version-update:semver-minor
- dependency-name: org.projectnessie.nessie:nessie-versioned-storage-inmemory
  dependency-type: direct:production
  update-type: version-update:semver-minor
- dependency-name: org.projectnessie.nessie:nessie-versioned-storage-testextension
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-08-07 09:34:16+02:00,['libs.versions.toml']
"Build: Bump pytest-checkdocs from 2.10.0 to 2.10.1 in /python (#8233)

Bumps [pytest-checkdocs](https://github.com/jaraco/pytest-checkdocs) from 2.10.0 to 2.10.1.
- [Release notes](https://github.com/jaraco/pytest-checkdocs/releases)
- [Changelog](https://github.com/jaraco/pytest-checkdocs/blob/main/NEWS.rst)
- [Commits](https://github.com/jaraco/pytest-checkdocs/compare/v2.10.0...v2.10.1)

---
updated-dependencies:
- dependency-name: pytest-checkdocs
  dependency-type: direct:development
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,10,2023-08-07 14:40:26+02:00,"['poetry.lock', 'pyproject.toml']"
Parquet: Fix decimal data reading from ParquetAvroValueReaders (#8246),2,7,2023-08-07 14:56:58+02:00,"['ParquetAvroValueReaders.java', 'TestParquetAvroReader.java']"
"Build: Bump rich from 13.5.0 to 13.5.2 in /python (#8232)

Bumps [rich](https://github.com/Textualize/rich) from 13.5.0 to 13.5.2.
- [Release notes](https://github.com/Textualize/rich/releases)
- [Changelog](https://github.com/Textualize/rich/blob/master/CHANGELOG.md)
- [Commits](https://github.com/Textualize/rich/compare/v13.5.0...v13.5.2)

---
updated-dependencies:
- dependency-name: rich
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,6,2023-08-07 15:35:37+02:00,['poetry.lock']
Core: Fix leak of DeleteFile streams (#8132),2,169,2023-08-07 10:46:35-07:00,"['Deletes.java', 'TestPositionFilter.java']"
"Python: Add more tests for the Avro writer (#8067)

* Python: Add more tests for the Avro writer

* Fix the tests

* WIP

* Update

* Update python/pyiceberg/utils/datetime.py

* Update python/pyiceberg/utils/datetime.py

* Update python/tests/avro/test_encoder.py

* WIP

* Cleanup

* Cleanup

* Cleanup

* Cleanup

* Fix the tests",19,774,2023-08-07 21:27:19+02:00,"['provision.py', 'decoder.py', 'encoder.py', 'file.py', 'reader.py', 'writer.py', 'conversions.py', 'literals.py', 'datetime.py', 'decimal.py', 'schema_conversion.py', 'test_decoder.py', 'test_encoder.py', 'test_file.py', 'test_writer.py', 'test_integration.py', 'test_schema.py', 'test_transforms.py', 'test_decimal.py']"
"Core, Spark 3.4: Add filter to Rewrite position deletes (#7582)",4,452,2023-08-07 13:13:08-07:00,"['PositionDeletesTable.java', 'TestMetadataTableScans.java', 'RewritePositionDeleteFilesSparkAction.java', 'TestRewritePositionDeleteFilesAction.java']"
"Spark 3.4: Fix logging pushed filters (#8249)

Co-authored-by: xianyangliu <xianyangliu@tencent.com>",1,15,2023-08-07 15:41:10-07:00,['RowLevelCommandScanRelationPushDown.scala']
GCP: Add bundle jar for GCP-related dependencies (#8231),13,638,2023-08-08 17:40:15+02:00,"['build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'LICENSE', 'NOTICE', 'build.gradle', 'build.gradle', 'settings.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle']"
API: Update deprecated calls to Transforms APIs (#8206),1,39,2023-08-08 17:55:51+02:00,['PartitionSpec.java']
Docs: Add `fast_forward` procedure (#8271),2,34,2023-08-09 15:20:46+02:00,"['branching-and-tagging.md', 'spark-procedures.md']"
Spark 3.4: Revise PlanningBenchmark (#8262),1,110,2023-08-09 16:47:08-07:00,['PlanningBenchmark.java']
Flink: Custom partitioner for bucket partitions (#7161),9,949,2023-08-09 21:52:51-07:00,"['BucketPartitionKeySelector.java', 'BucketPartitioner.java', 'BucketPartitionerUtil.java', 'FlinkSink.java', 'HadoopCatalogExtension.java', 'TestBucketPartitionKeySelector.java', 'TestBucketPartitioner.java', 'TestBucketPartitionerFlinkIcebergSink.java', 'TestBucketPartitionerUtil.java']"
"Python: Change UUID representation to bytes (#8267)

* Change UUID Inner Representation to bytes, add integration tests for uuid and fixed

* address review comments

* optimize transform code

* supports conversion from bytes or fixed to uuid",11,278,2023-08-10 10:17:24+02:00,"['Dockerfile', 'provision.py', 'conversions.py', 'literals.py', 'pyarrow.py', 'transforms.py', 'test_literals.py', 'test_conversions.py', 'test_integration.py', 'test_schema.py', 'test_transforms.py']"
"ORC: Handle filters with transforms by assuming the filter matches (#8244)

Co-authored-by: xianyangliu <xianyangliu@tencent.com>",2,20,2023-08-10 08:47:07-07:00,"['ExpressionToSearchArgument.java', 'TestExpressionToSearchArgument.java']"
AWS: Add bundle jar for AWS-related dependencies (#8261),4,528,2023-08-10 08:48:07-07:00,"['LICENSE', 'NOTICE', 'build.gradle', 'settings.gradle']"
"Parquet: Handle filters with transforms by assuming data must be scanned (#8243)

Co-authored-by: xianyangliu <xianyangliu@tencent.com>",6,53,2023-08-10 08:48:35-07:00,"['TestMetricsRowGroupFilter.java', 'ParquetBloomRowGroupFilter.java', 'ParquetDictionaryRowGroupFilter.java', 'ParquetMetricsRowGroupFilter.java', 'TestBloomRowGroupFilter.java', 'TestDictionaryRowGroupFilter.java']"
Docs: Update AWS integration docs to use iceberg-aws-bundle (#8283),1,43,2023-08-10 18:00:56+02:00,['aws.md']
Core: Re-apply Hadoop conf if it's null after Kryo ser/de in ResolvingFileIO (#8270),2,53,2023-08-10 18:01:21+02:00,"['ResolvingFileIO.java', 'TestResolvingIO.java']"
Spark 3.3: Add filter to Rewrite position deletes (#8280),2,171,2023-08-10 10:49:34-07:00,"['RewritePositionDeleteFilesSparkAction.java', 'TestRewritePositionDeleteFilesAction.java']"
Flink: backport PR #7978. switch to FileScanTaskParser for JSON serialization of IcebergSourceSplit (#8228),12,274,2023-08-10 13:05:51-07:00,"['IcebergSource.java', 'IcebergEnumeratorStateSerializer.java', 'IcebergSourceSplit.java', 'IcebergSourceSplitSerializer.java', 'TestIcebergEnumeratorStateSerializer.java', 'TestIcebergSourceSplitSerializer.java', 'IcebergSource.java', 'IcebergEnumeratorStateSerializer.java', 'IcebergSourceSplit.java', 'IcebergSourceSplitSerializer.java', 'TestIcebergEnumeratorStateSerializer.java', 'TestIcebergSourceSplitSerializer.java']"
"Python: Simplify `Readers` using inheritance (#8291)

Numerous reader classes are simply reading integers, they can all
inherit from IntegerReader rather than having their own implementations
of read() and skip().  Make this change.",1,32,2023-08-11 08:42:15+02:00,['reader.py']
Use ConcurrentHashMap in ResolvingFileIO (#8292),1,84,2023-08-11 10:38:52+02:00,['ResolvingFileIO.java']
Core: Use lazy iterable in DeleteFileIndex (#8263),2,61,2023-08-11 16:20:31-07:00,"['DeleteFileIndex.java', 'ScanMetricsUtil.java']"
Core: Use regular map for partition wrappers in DeleteFileIndex (#8264),1,17,2023-08-11 17:11:41-07:00,['DeleteFileIndex.java']
"AWS, GCS: Allow access to underlying storage client (#8208)",2,4,2023-08-13 12:05:48-07:00,"['S3FileIO.java', 'GCSFileIO.java']"
Core: Extend ResolvingFileIO to support BulkOperations (#7976),2,104,2023-08-14 09:09:41+02:00,"['ResolvingFileIO.java', 'TestResolvingIO.java']"
Spark 3.3 : Backport `fast_forward` procedure (#8288),3,286,2023-08-14 09:12:15+02:00,"['TestFastForwardBranchProcedure.java', 'FastForwardBranchProcedure.java', 'SparkProcedures.java']"
Docs: Mention how to add new functionality without breaking APIs (#8293),1,79,2023-08-14 09:26:33+02:00,['CONTRIBUTING.md']
"Python: Implement Cython based decoding for Avro (#8134)

* Python: Improve Avro read performance

Utilize __slots__ for various Avro classes.

Memoize the key/value reader functions in MapReader.

* Python: improve Avro parsing by caching struct types.

Cache the struct types for ManifestEntry and ManifestFile schemas.

Cache the _position_to_field_name lookup in Records if a struct type is passed.

Improve StructReader to use slots and avoid isinstance() lookups on each time
the structure is read, by performing the check in __init__().

Improve StructReader to determine the arguments to create_struct() once in init
and reuse the result each time the structure is read, avoid a try block.

* Python: Improve Avro Parse speed

Cache the hash value of the Struct types so that when new
Record objects are created time is not spent recomputing
the hash value.

Change the implementation of the Record class to cache the
mapping from field name to position.  Also utilize an array
rather than a dictionary for these lookups.

* fix some lints

* fix some type casing

* fix: adjust PR comments

* WIP: changes for cython parsing

* fix: address PR feedback.

* Add additional tests for InMemoryBinaryDecoder

* More work on fast Avro decoder

* Work in progress

* Load entire Avro file into memory rather than streaming it

* fix mypy and lint warnings

* fix some more pylint warnings

* Fix lints and build failures

* fix: move lazydict out to its own file.

* fix: disable seeking on input file

* Cleanup expression

* fix: improve integer test case

* fix: rename decoding functions

* fix: remove reader functions that returned native types

* fix: simplify some ReaderClasses via inheritance

Numerous reader classes are simply reading integers, they can all
inherit from IntegerReader rather than having their own implementations
of read() and skip().  Make this change.

* fix: make sqlalchemy optional

* fix: make lazydict generic and move out of avro, add tests

* fix: some lint fixes

* fix: some cleanups and comments

* fix: commit linter changes

---------

Co-authored-by: Fokko Driesprong <fokko@apache.org>",14,1442,2023-08-14 09:50:54+02:00,"['build-module.py', 'poetry.lock', 'decoder.py', 'decoder_basic.c', 'decoder_fast.pyi', 'decoder_fast.pyx', 'file.py', 'reader.py', 'resolver.py', 'lazydict.py', 'pyproject.toml', 'test_decoder.py', 'test_reader.py', 'test_lazydict.py']"
"Build: Bump psycopg2-binary from 2.9.6 to 2.9.7 in /python (#8307)

Bumps [psycopg2-binary](https://github.com/psycopg/psycopg2) from 2.9.6 to 2.9.7.
- [Changelog](https://github.com/psycopg/psycopg2/blob/master/NEWS)
- [Commits](https://github.com/psycopg/psycopg2/compare/2.9.6...2.9.7)

---
updated-dependencies:
- dependency-name: psycopg2-binary
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",0,0,2023-08-14 09:51:35+02:00,[]
"Build: Bump boto3 from 1.26.161 to 1.28.17 in /python (#8309)

Bumps [boto3](https://github.com/boto/boto3) from 1.26.161 to 1.28.17.
- [Release notes](https://github.com/boto/boto3/releases)
- [Changelog](https://github.com/boto/boto3/blob/develop/CHANGELOG.rst)
- [Commits](https://github.com/boto/boto3/compare/1.26.161...1.28.17)

---
updated-dependencies:
- dependency-name: boto3
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",0,0,2023-08-14 09:52:37+02:00,[]
"Build: Bump mkdocstrings-python from 1.2.1 to 1.3.0 in /python (#8310)

Bumps [mkdocstrings-python](https://github.com/mkdocstrings/python) from 1.2.1 to 1.3.0.
- [Release notes](https://github.com/mkdocstrings/python/releases)
- [Changelog](https://github.com/mkdocstrings/python/blob/main/CHANGELOG.md)
- [Commits](https://github.com/mkdocstrings/python/compare/1.2.1...1.3.0)

---
updated-dependencies:
- dependency-name: mkdocstrings-python
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-08-14 09:53:04+02:00,['requirements.txt']
"Build: Bump coverage from 7.2.7 to 7.3.0 in /python (#8308)

Bumps [coverage](https://github.com/nedbat/coveragepy) from 7.2.7 to 7.3.0.
- [Release notes](https://github.com/nedbat/coveragepy/releases)
- [Changelog](https://github.com/nedbat/coveragepy/blob/master/CHANGES.rst)
- [Commits](https://github.com/nedbat/coveragepy/compare/7.2.7...7.3.0)

---
updated-dependencies:
- dependency-name: coverage
  dependency-type: direct:development
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,124,2023-08-14 12:02:36+02:00,"['poetry.lock', 'pyproject.toml']"
"Python: Publish Wheels (#8287)

* Python: Publish Wheels

* Add working-directory

* Clean up the script",2,139,2023-08-14 14:17:37+02:00,"['python-release.yml', 'how-to-release.md']"
"Python: GCS Support (#8207)

* pyiceberg: Add Google Cloud Storage support

* updated project dependecies

* Update python/pyiceberg/io/fsspec.py

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* Fix some configuration

* MOAR tests

* Start GCS server

* Fix makefile

* Move to http

---------

Co-authored-by: Victoria Bukta <me@buktoria.io>
Co-authored-by: Victoria Bukta <3473392+Buktoria@users.noreply.github.com>",15,940,2023-08-14 14:43:46+02:00,"['Makefile', 'docker-compose-gcs-server.yml', 'run-gcs-server.sh', 'configuration.md', 'index.md', 'poetry.lock', '__init__.py', 'fsspec.py', 'pyarrow.py', 'datetime.py', 'pyproject.toml', 'conftest.py', 'test_fsspec.py', 'test_pyarrow.py', 'test_datetime.py']"
Docs: Add supported options for rewrite_data_files and rewrite_position_delete_files (#8251),1,58,2023-08-14 10:40:53-07:00,['spark-procedures.md']
API: Remove overflow checks in DefaultCounter causing performance issues (#8297),5,120,2023-08-14 11:37:44-07:00,"['Counter.java', 'DefaultCounter.java', 'TestDefaultCounter.java', 'TestDefaultMetricsContext.java', 'CountersBenchmark.java']"
"Spark 3.4: Fix expression to SQL with transforms (#8257)

Co-authored-by: xianyangliu <xianyangliu@tencent.com>",2,86,2023-08-14 16:04:42-07:00,"['Spark3Util.java', 'TestSpark3Util.java']"
"AWS, GCP: Include dependency NOTICE content in bundle NOTICE (#8323)",2,180,2023-08-14 16:57:48-07:00,"['NOTICE', 'NOTICE']"
"Python: Update .gitignore and remove unused imports (#8319)

Noticed a few unused imports, and I have some Cython
generated files that we shouldn't commit outside of the
`.gitignore`.",2,11,2023-08-15 09:57:35+02:00,"['.gitignore', 'decoder_fast.pyx']"
"Python: Delegate JSON serialization to Pydantic (#8286)

* refactor TableMetadataUtil parse_object with annotated type

* refactor TableMetadataUtil parse_obj as parse_raw (from dict to string)

* move parse raw and deserialization logic in a separate TableMetadata factory",7,125,2023-08-15 10:35:37+02:00,"['rest.py', 'serializers.py', '__init__.py', 'metadata.py', 'test_hive.py', 'test_metadata.py', 'test_sorting.py']"
API: Remove Immutables dependency (#8326),1,2,2023-08-15 11:37:33+02:00,['build.gradle']
Core: Don't allow setting schema id / derive current schema id from ViewVersion (#8210),7,125,2023-08-15 11:39:03+02:00,"['ViewMetadata.java', 'ViewMetadataParser.java', 'TestViewMetadata.java', 'TestViewMetadataParser.java', 'ViewMetadataInvalidCurrentSchema.json', 'ViewMetadataMissingCurrentSchema.json', 'view-spec.md']"
GCP: Add range reads to GCSInputStream (#8301),5,131,2023-08-15 12:12:54+02:00,"['GCPProperties.java', 'GCSInputFile.java', 'GCSInputStream.java', 'GCSInputStreamTest.java', 'GCSLocationTest.java']"
Spark 3.4: Disallow setting identifier fields table property (#8320),2,43,2023-08-15 08:22:36-07:00,"['SparkCatalog.java', 'TestAlterTable.java']"
"Spark 3.1, 3.2, 3.3: Supports create branch on empty table (#8317)

This change backports PR #8072 to Spark 3.1, 3.2, 3.3.

Co-authored-by: xianyangliu <xianyangliu@tencent.com>",6,195,2023-08-15 08:33:03-07:00,"['CreateOrReplaceBranchExec.scala', 'TestBranchDDL.java', 'CreateOrReplaceBranchExec.scala', 'TestBranchDDL.java', 'CreateOrReplaceBranchExec.scala', 'TestBranchDDL.java']"
"Arrow, Core, Spark: Remove functionality marked for removal in 1.4.0 (#7987)",38,1612,2023-08-15 09:45:44-07:00,"['revapi.yml', 'VectorizedColumnIterator.java', 'VectorizedPageIterator.java', 'MergingSnapshotProducer.java', 'BaseDeleteOrphanFilesActionResult.java', 'BaseDeleteReachableFilesActionResult.java', 'BaseFileGroupRewriteResult.java', 'BaseMigrateTableActionResult.java', 'BaseRewriteDataFilesFileGroupInfo.java', 'BaseRewriteDataFilesResult.java', 'BaseRewriteManifestsActionResult.java', 'BaseSnapshotTableActionResult.java', 'BinPackStrategy.java', 'RewritePositionDeleteStrategy.java', 'RewriteStrategy.java', 'SortStrategy.java', 'BaseDeleteOrphanFilesSparkAction.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseMigrateTableSparkAction.java', 'BaseRewriteDataFilesSparkAction.java', 'BaseRewriteManifestsSparkAction.java', 'BaseSnapshotTableSparkAction.java', 'SparkUtil.java', 'DeleteOrphanFilesSparkAction.java', 'DeleteReachableFilesSparkAction.java', 'MigrateTableSparkAction.java', 'RewriteDataFilesSparkAction.java', 'RewriteManifestsSparkAction.java', 'SnapshotTableSparkAction.java', 'FileRewriteCoordinator.java', 'SparkUtil.java', 'SparkBinPackStrategy.java', 'SparkSizeBasedDataRewriter.java', 'SparkSortStrategy.java', 'SparkZOrderStrategy.java', 'TestFileRewriteCoordinator.java', 'IcebergSortCompactionBenchmark.java', 'TestRewriteDataFilesAction.java']"
Spark: Improve rewrite_data_files exception handling for where clause (#8290),4,8,2023-08-15 09:53:23-07:00,"['RewriteDataFilesProcedure.java', 'RewriteDataFilesProcedure.java', 'RewriteDataFilesProcedure.java', 'RewriteDataFilesProcedure.java']"
"Spark 3.4: Fix logging pushed filters (#8256)

This change backports PR #8249 to Spark 3.3.

Co-authored-by: xianyangliu <xianyangliu@tencent.com>",1,15,2023-08-15 10:01:57-07:00,['RowLevelCommandScanRelationPushDown.scala']
Spark 3.4: Take shuffle partitions into account for parallelism (#8327),2,8,2023-08-15 10:12:47-07:00,"['SparkReadConf.java', 'SparkScan.java']"
Spark 3.4: Support setting current snapshot with ref (#8163),3,99,2023-08-15 16:44:05-07:00,"['spark-procedures.md', 'TestSetCurrentSnapshotProcedure.java', 'SetCurrentSnapshotProcedure.java']"
Spark 3.4: Return empty changed rows when there are no snapshots between start time and end time (#8133),4,70,2023-08-15 22:51:09-07:00,"['SnapshotUtil.java', 'TestChangelogTable.java', 'SparkChangelogScan.java', 'SparkScanBuilder.java']"
Python: Close the file handler (#8329),1,3,2023-08-16 08:45:03+02:00,['file.py']
Build: Update ORC to 1.9.1 and aircompressor to 0.25 (#8332),1,4,2023-08-16 15:02:04+02:00,['libs.versions.toml']
"Python: Optimize concurrency for limited queries (#8104)

* feat(python): remove explicit row count lock

* feat(python): stop waiting for task when limit reached

* fix(python): remove unnecessary arg splat

* fix(python): cancel all futures once result set acquired

* fix(python): consistent scan ordering when limit applied

* feat(python): reuse executor (wip)

* fix(python): consolidate row count tracking

* feat(python): use sortedcontainers in future ordering

* feat(python): global executor

* fix(python): formatting

* fix(python): support limit = 0

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* fix(python): support limit = 0

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* fix(python): support limit = 0

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* feat(python): lazy re-usable executory

* fix(python): appease rat

* fix(python): use row counts container for mutability

* fix(python): scan future cancelling

* fix(python): data scan row count updates in worker

* feat(python): simplify result agg

* fix(python): reusable executor factory method name

* fix(python): remove custom config error

* fix(python): only slice result when limit provided

---------

Co-authored-by: Fokko Driesprong <fokko@apache.org>",5,275,2023-08-16 15:17:00+02:00,"['configuration.md', 'pyarrow.py', '__init__.py', 'concurrent.py', 'test_concurrent.py']"
Docs: Add note that referenced snapshots won't be removed by expire_snapshots procedure (#8224),1,1,2023-08-16 18:01:44+02:00,['spark-procedures.md']
Python: Bump to Pydantic v2 (#7782),32,1393,2023-08-16 10:55:07-07:00,"['poetry.lock', '__init__.py', 'rest.py', 'output.py', 'pyarrow.py', 'partitioning.py', 'serializers.py', '__init__.py', 'metadata.py', 'snapshots.py', 'sorting.py', 'transforms.py', 'typedef.py', 'types.py', 'parsing.py', 'pyproject.toml', 'test_reader.py', 'test_writer.py', 'test_hive.py', 'test_rest.py', 'test_console.py', 'conftest.py', 'test_pyarrow.py', 'test_init.py', 'test_metadata.py', 'test_partitioning.py', 'test_snapshots.py', 'test_sorting.py', 'test_integration.py', 'test_schema.py', 'test_transforms.py', 'test_types.py']"
"Spark 3.3, 3.4: Add where filter to rewrite_position_delete_files procedure (#8289)",6,202,2023-08-16 17:26:09-07:00,"['TestRewritePositionDeleteFilesProcedure.java', 'BaseProcedure.java', 'RewritePositionDeleteFilesProcedure.java', 'TestRewritePositionDeleteFilesProcedure.java', 'BaseProcedure.java', 'RewritePositionDeleteFilesProcedure.java']"
Python: Add default for `load_catalog` API (#8330),1,2,2023-08-17 18:06:44+02:00,['__init__.py']
"Docs: Add failed_data_files_count output to docs (#8341)

Co-authored-by: Eduard Tudenhoefner <etudenhoefner@gmail.com>",1,1,2023-08-17 16:12:38-07:00,['spark-procedures.md']
"Backporting PR 7161 from 1.16 -> 1.15/1.17 (#8328)

Co-authored-by: schongloo <schongloo@apple.com>",18,1898,2023-08-17 20:41:23-07:00,"['BucketPartitionKeySelector.java', 'BucketPartitioner.java', 'BucketPartitionerUtil.java', 'FlinkSink.java', 'HadoopCatalogExtension.java', 'TestBucketPartitionKeySelector.java', 'TestBucketPartitioner.java', 'TestBucketPartitionerFlinkIcebergSink.java', 'TestBucketPartitionerUtil.java', 'BucketPartitionKeySelector.java', 'BucketPartitioner.java', 'BucketPartitionerUtil.java', 'FlinkSink.java', 'HadoopCatalogExtension.java', 'TestBucketPartitionKeySelector.java', 'TestBucketPartitioner.java', 'TestBucketPartitionerFlinkIcebergSink.java', 'TestBucketPartitionerUtil.java']"
AWS: support config storage class for S3FileIO (#8154),3,29,2023-08-18 12:13:59+02:00,"['S3FileIOProperties.java', 'S3OutputStream.java', 'TestS3FileIOProperties.java']"
Build: Bump mkdocstrings-python from 1.3.0 to 1.4.0 in /python (#8358),1,2,2023-08-20 07:37:04+02:00,['requirements.txt']
Build: Bump sqlalchemy from 2.0.19 to 2.0.20 in /python (#8357),1,86,2023-08-20 07:37:12+02:00,['poetry.lock']
Build: Bump click from 8.1.6 to 8.1.7 in /python (#8355),1,6,2023-08-20 07:37:20+02:00,['poetry.lock']
Build: Bump pydantic from 2.1.1 to 2.2.1 in /python (#8354),1,217,2023-08-20 07:37:34+02:00,['poetry.lock']
Build: Bump griffe from 0.32.3 to 0.33.0 in /python (#8356),1,2,2023-08-20 11:51:31+02:00,['requirements.txt']
Docs: Add docs for Metrics Reporting (#8345),2,175,2023-08-21 09:57:01+02:00,"['configuration.md', 'metrics-reporting.md']"
"Build: Bump mockserver from 5.13.2 to 5.15.0 (#8351)

Bumps `mockserver` from 5.13.2 to 5.15.0.

Updates `org.mock-server:mockserver-client-java` from 5.13.2 to 5.15.0
- [Changelog](https://github.com/mock-server/mockserver/blob/master/changelog.md)
- [Commits](https://github.com/jamesdbloom/mockservice/compare/mockserver-5.13.2...mockserver-5.15.0)

Updates `org.mock-server:mockserver-netty` from 5.13.2 to 5.15.0
- [Changelog](https://github.com/mock-server/mockserver/blob/master/changelog.md)
- [Commits](https://github.com/jamesdbloom/mockservice/compare/mockserver-5.13.2...mockserver-5.15.0)

---
updated-dependencies:
- dependency-name: org.mock-server:mockserver-client-java
  dependency-type: direct:production
  update-type: version-update:semver-minor
- dependency-name: org.mock-server:mockserver-netty
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-08-21 10:00:39+02:00,['libs.versions.toml']
"Build: Bump org.xerial:sqlite-jdbc from 3.41.0.0 to 3.42.0.0 (#8350)

Bumps [org.xerial:sqlite-jdbc](https://github.com/xerial/sqlite-jdbc) from 3.41.0.0 to 3.42.0.0.
- [Release notes](https://github.com/xerial/sqlite-jdbc/releases)
- [Changelog](https://github.com/xerial/sqlite-jdbc/blob/master/CHANGELOG)
- [Commits](https://github.com/xerial/sqlite-jdbc/compare/3.41.0.0...3.42.0.0)

---
updated-dependencies:
- dependency-name: org.xerial:sqlite-jdbc
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-08-21 10:00:59+02:00,['libs.versions.toml']
Build: Fix shading of Apache HTTP and Google libraries in runtimes (#8349),8,45,2023-08-21 10:29:29+02:00,"['build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle']"
"AWS, Dell, GCP: Skip stack trace log for missing Hadoop dependency (#8359)",3,55,2023-08-21 10:37:53+02:00,"['S3FileIO.java', 'EcsFileIO.java', 'GCSFileIO.java']"
Python: Pin poetry to 1.5.1 (#8363),2,12,2023-08-21 15:21:18+02:00,"['python-ci.yml', 'Makefile']"
AWS: Add FileIO tracker/closer to Glue catalog (#8315),1,61,2023-08-21 20:36:51+02:00,['GlueCatalog.java']
Core: Optimize split offsets handling (#8336),7,465,2023-08-21 13:06:15-07:00,"['BaseContentScanTask.java', 'BaseFile.java', 'BaseFileScanTask.java', 'OffsetsAwareSplitScanTaskIterator.java', 'ArrayUtil.java', 'TestArrayUtil.java', 'TaskGroupPlanningBenchmark.java']"
"AWS: Update S3 signer spec to allow an optional string body in S3SignRequest. (#8361)

Update S3 signer parser implementation to enable
serialization/deserialization of the body.

Note: This will only be populated for requests which do not transmit
relevant data to sign as part of the URI itself (e.g.
DeleteObjectsRequest)",4,62,2023-08-21 15:14:58-07:00,"['S3SignRequest.java', 'S3SignRequestParser.java', 's3-signer-open-api.yaml', 'TestS3SignRequestParser.java']"
Spark 3.4: Make backup table name configurable during migration (#8227),5,53,2023-08-21 16:34:13-07:00,"['MigrateTable.java', 'spark-procedures.md', 'TestMigrateTableProcedure.java', 'MigrateTableSparkAction.java', 'MigrateTableProcedure.java']"
Core: Don't persist useless file and position bounds for deletes (#8360),4,148,2023-08-21 17:51:25-07:00,"['MetricsUtil.java', 'PositionDeleteWriter.java', 'TestFileWriterFactory.java', 'TestWriterMetrics.java']"
Docs: Add notes on Spark writes support (#8362),1,20,2023-08-22 07:53:52+02:00,['spark-writes.md']
Data: Propagate case sensitivity in GenericReader (#8177),2,10,2023-08-22 08:40:54+02:00,"['GenericReader.java', 'TestLocalScan.java']"
"Python: Support for adding columns (#8174)

* Python: Support add column

* Add integration tests (#264)

* Python: Support add column

* Add the requirement (#265)

* Python: Support add column

---------

Co-authored-by: Fokko Driesprong <fokko@apache.org>",10,1059,2023-08-22 14:05:44+02:00,"['api.md', 'schema.py', '__init__.py', 'metadata.py', 'test_base.py', 'test_console.py', 'conftest.py', 'test_init.py', 'test_integration.py', 'test_schema.py']"
"Python: Fix Windows wheel build (#8371)

The version was not correctly changed. Adding some quotes fixed it.",2,14,2023-08-22 08:20:17-07:00,"['python-release.yml', 'how-to-release.md']"
Build: Remove .java-version file (#8300),1,1,2023-08-22 10:47:22-07:00,['.java-version']
"Core, API: Support incremental scanning with branch (#5984)",4,382,2023-08-23 09:20:41+02:00,"['IncrementalScan.java', 'BaseIncrementalScan.java', 'TableScanContext.java', 'TestBaseIncrementalAppendScan.java']"
"Nessie: avoid creating branches without explicit hashes (#8372)

This commit modifies a few Nessie tests that were
creating branches without explicitly specifying a
target hash.

Nessie will soon forbid such situations, so we are
proactively fixing all their occurrences.",3,18,2023-08-23 13:00:57+02:00,"['BaseTestIceberg.java', 'TestBranchVisibility.java', 'TestNessieIcebergClient.java']"
Core: Optimize lookup in DeleteFileIndex without useful bounds (#8278),2,372,2023-08-23 23:27:56-07:00,"['DeleteFileIndex.java', 'DeleteFileIndexBenchmark.java']"
Core: Optimize computing user-facing state in data tasks (#8346),3,139,2023-08-23 23:45:03-07:00,"['BaseScanTaskGroup.java', 'BaseCombinedScanTask.java', 'BaseFileScanTask.java']"
AWS: Upgrade AWS Java SDK version to 2.20.131 (#8379),4,112,2023-08-24 14:58:39+02:00,"['LICENSE', 'NOTICE', 'aws.md', 'libs.versions.toml']"
Core: Plan concurrently if there are multiple delete manifests (#8388),1,2,2023-08-24 14:17:29-07:00,['DataTableScan.java']
"Azure: Add FileIO that supports ADLSv2 storage (#8303)

* Azure: add support for ADLSv2 for storage

* typo fix

* update labeler

* Simpler URI parsing

* PR feedback

* allow any domain name in URI

* allow optional container in URI

* include notice from dependencies

* notice dedupe

* simpler naming and oauth creds

* naming

* simpler auth

* support sas token

* per-account sas token

* fix runtime shading

* prefix and bulk operations

* checkstyle

* simpler batch delete

* add connection string property

* per account connection string

* more tests

* use Azurite where possible

* move shade fix to separate PR

* add azure dependency to hive runtime

* skip stack trace log for missing Hadoop

* PR feedback

* catch specific exception

* null check

* handle missing path in prefix ops

* PR feedback

* Improved URI regex

---------

Co-authored-by: Fokko Driesprong <fokko@apache.org>",31,2406,2023-08-25 16:02:24+02:00,"['labeler.yml', 'LICENSE', 'NOTICE', 'build.gradle', 'AzureProperties.java', 'ADLSFileIO.java', 'ADLSInputFile.java', 'ADLSInputStream.java', 'ADLSLocation.java', 'ADLSOutputFile.java', 'ADLSOutputStream.java', 'BaseADLSFile.java', 'AzurePropertiesTest.java', 'ADLSFileIOTest.java', 'ADLSInputStreamTest.java', 'ADLSLocationTest.java', 'ADLSOutputStreamTest.java', 'AzuriteContainer.java', 'BaseAzuriteTest.java', 'build.gradle', 'ResolvingFileIO.java', 'build.gradle', 'build.gradle', 'build.gradle', 'libs.versions.toml', 'build.gradle', 'settings.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle']"
"Spark3.2, Spark3.3: Return empty changed rows when there are no snapshots between start time and end time (#8391)

Back-port of https://github.com/apache/iceberg/pull/8133 to `spark/v3.3` and `spark/v3.2`",6,110,2023-08-25 16:47:07+02:00,"['TestChangelogTable.java', 'SparkChangelogScan.java', 'SparkScanBuilder.java', 'TestChangelogTable.java', 'SparkChangelogScan.java', 'SparkScanBuilder.java']"
AWS: Update S3V4RestSignerClient to send body for DeleteObjects requests (#8365),3,93,2023-08-25 10:55:52-07:00,"['S3V4RestSignerClient.java', 'S3SignerServlet.java', 'TestS3RestSigner.java']"
"Build: Bump mkdocs-material from 9.1.21 to 9.2.4 in /python (#8405)

Bumps [mkdocs-material](https://github.com/squidfunk/mkdocs-material) from 9.1.21 to 9.2.4.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/CHANGELOG)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/9.1.21...9.2.4)

---
updated-dependencies:
- dependency-name: mkdocs-material
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-08-27 15:16:17+02:00,['requirements.txt']
"Build: Bump cython from 3.0.0 to 3.0.1 in /python (#8403)

Bumps [cython](https://github.com/cython/cython) from 3.0.0 to 3.0.1.
- [Release notes](https://github.com/cython/cython/releases)
- [Changelog](https://github.com/cython/cython/blob/master/CHANGES.rst)
- [Commits](https://github.com/cython/cython/compare/3.0.0...3.0.1)

---
updated-dependencies:
- dependency-name: cython
  dependency-type: direct:development
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,128,2023-08-27 15:16:44+02:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump griffe from 0.33.0 to 0.35.1 in /python (#8404)

Bumps [griffe](https://github.com/mkdocstrings/griffe) from 0.33.0 to 0.35.1.
- [Release notes](https://github.com/mkdocstrings/griffe/releases)
- [Changelog](https://github.com/mkdocstrings/griffe/blob/main/CHANGELOG.md)
- [Commits](https://github.com/mkdocstrings/griffe/compare/0.33.0...0.35.1)

---
updated-dependencies:
- dependency-name: griffe
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-08-27 15:17:03+02:00,['requirements.txt']
"Build: Bump moto from 4.1.14 to 4.2.0 in /python (#8402)

Bumps [moto](https://github.com/getmoto/moto) from 4.1.14 to 4.2.0.
- [Changelog](https://github.com/getmoto/moto/blob/master/CHANGELOG.md)
- [Commits](https://github.com/getmoto/moto/compare/4.1.14...4.2.0)

---
updated-dependencies:
- dependency-name: moto
  dependency-type: direct:development
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,11,2023-08-27 20:21:29+02:00,"['poetry.lock', 'pyproject.toml']"
"Python: Fix D401 pydocstyle issues (#8401)

* Fix D401 pydocstyle issues

* Update python/tests/conftest.py

---------

Co-authored-by: Fokko Driesprong <fokko@apache.org>",45,718,2023-08-28 09:24:17+02:00,"['.pre-commit-config.yaml', 'decoder.py', 'encoder.py', 'file.py', 'reader.py', 'resolver.py', 'writer.py', '__init__.py', 'dynamodb.py', 'glue.py', 'hive.py', 'rest.py', 'sql.py', 'console.py', 'conversions.py', '__init__.py', 'literals.py', 'parser.py', 'visitors.py', '__init__.py', 'fsspec.py', 'pyarrow.py', 'manifest.py', 'partitioning.py', 'schema.py', 'serializers.py', '__init__.py', 'metadata.py', 'refs.py', 'snapshots.py', 'sorting.py', 'transforms.py', 'typedef.py', 'types.py', 'bin_packing.py', 'concurrent.py', 'config.py', 'datetime.py', 'decimal.py', 'deprecated.py', 'lazydict.py', 'schema_conversion.py', 'integration_test_dynamodb.py', 'integration_test_glue.py', 'conftest.py']"
"Python: Check if identifier fields are valid (#8393)

* Python: Check if identifier fields are valid

* Python: Check if identifier fields are valid

* Python: Check if identifier fields are valid

* model_validator

* change to private

---------

Co-authored-by: Liwei Li <hililiwei@gmaiil.com>",4,205,2023-08-28 12:20:08+02:00,"['schema.py', 'conftest.py', 'test_pyarrow.py', 'test_schema.py']"
Spark 3.4: Add the net_changes option in the changelog procedure doc (#8364),1,39,2023-08-28 11:36:29-07:00,['spark-procedures.md']
"Python: Remove files file (#8411)

This is already in `manifest.py`:

```python
class ManifestContent(int, Enum):
    DATA = 0
    DELETES = 1

    def __repr__(self) -> str:
        """"""Returns the string representation of the ManifestContent class.""""""
        return f""ManifestContent.{self.name}""

class ManifestEntryStatus(int, Enum):
    EXISTING = 0
    ADDED = 1
    DELETED = 2

    def __repr__(self) -> str:
        """"""Returns the string representation of the ManifestEntryStatus class.""""""
        return f""ManifestEntryStatus.{self.name}""

class FileFormat(str, Enum):
    AVRO = ""AVRO""
    PARQUET = ""PARQUET""
    ORC = ""ORC""

    def __repr__(self) -> str:
        """"""Returns the string representation of the FileFormat class.""""""
        return f""FileFormat.{self.name}""
```",1,34,2023-08-28 14:27:00-07:00,['files.py']
"Build: Bump pyarrow from 12.0.1 to 13.0.0 in /python (#8406)

Bumps [pyarrow](https://github.com/apache/arrow) from 12.0.1 to 13.0.0.
- [Commits](https://github.com/apache/arrow/compare/go/v12.0.1...go/v13.0.0)

---
updated-dependencies:
- dependency-name: pyarrow
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,62,2023-08-29 10:17:48+02:00,"['poetry.lock', 'pyproject.toml']"
"Nessie: Fix possible table-metadata loss (#8413)

`NessieTableOperations.doCommit()` wrongly assumes that _every_ exception thrown during a Nessie commit operation is a failure that requires the deletion of the newly written table-metadata. However, for exceptions like `j.l.InterruptedException` or HTTP timeout/error it is unclear whether the Nessie commit went through (or will go through), so deleting the table-metadata is wrong here.

This change updates the logic to only delete the table-metadata file if a `NessieReferenceConflictException` happened, when it is clear that the commit really failed.",1,8,2023-08-29 18:58:20+02:00,['NessieTableOperations.java']
"Build: Bump org.roaringbitmap:RoaringBitmap from 0.9.44 to 0.9.47 (#8407)

Bumps [org.roaringbitmap:RoaringBitmap](https://github.com/RoaringBitmap/RoaringBitmap) from 0.9.44 to 0.9.47.
- [Release notes](https://github.com/RoaringBitmap/RoaringBitmap/releases)
- [Commits](https://github.com/RoaringBitmap/RoaringBitmap/compare/0.9.44...0.9.47)

---
updated-dependencies:
- dependency-name: org.roaringbitmap:RoaringBitmap
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-08-29 18:58:44+02:00,['libs.versions.toml']
Spark 3.4: Refactor JobGroupUtils (#8418),3,40,2023-08-29 11:17:51-07:00,"['JobGroupInfo.java', 'JobGroupUtils.java', 'BaseSparkAction.java']"
Spark 3.4: Add write and SQL options to override compression config (#8313),9,394,2023-08-29 11:30:59-07:00,"['spark-configuration.md', 'SparkSQLProperties.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'SparkFileWriterFactory.java', 'SparkPositionDeletesRewrite.java', 'SparkPositionDeltaWrite.java', 'SparkWrite.java', 'TestCompressionSettings.java']"
"Doc: Reflect Apache HttpClient as Default in AWS Integration Page (#8396)

* partial fix

* fix other places mention url connection http client as the default one.

* fix typo",1,10,2023-08-29 17:38:05-07:00,['aws.md']
Spark3.4: Fix minor code style issue (#8421),1,2,2023-08-30 07:28:55+02:00,['SparkPositionDeltaWrite.java']
Core: Use v2 format in new tables by default (#8381),60,1872,2023-08-30 13:58:54-07:00,"['TableMetadata.java', 'TestTableMetadata.java', 'CatalogTests.java', 'TestHadoopCatalog.java', 'TestJdbcCatalog.java', 'HiveCreateReplaceTableTest.java', 'TestHiveCatalog.java', 'TestAlterTablePartitionFields.java', 'SmokeTest.java', 'TestCreateActions.java', 'TestRewriteDataFilesAction.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestSparkMetadataColumns.java', 'TestTables.java', 'TestCreateTableAsSelect.java', 'TestAlterTablePartitionFields.java', 'TestCreateChangelogViewProcedure.java', 'TestDelete.java', 'SmokeTest.java', 'TestCreateActions.java', 'TestDeleteReachableFilesAction.java', 'TestRewriteDataFilesAction.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestSparkMetadataColumns.java', 'TestTables.java', 'TestCreateTableAsSelect.java', 'TestAlterTablePartitionFields.java', 'TestCreateChangelogViewProcedure.java', 'TestDelete.java', 'SmokeTest.java', 'TestCreateActions.java', 'TestDeleteReachableFilesAction.java', 'TestRewriteDataFilesAction.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestSparkMetadataColumns.java', 'TestTables.java', 'TestCreateTableAsSelect.java', 'TestAlterTablePartitionFields.java', 'TestCreateChangelogViewProcedure.java', 'TestDelete.java', 'SmokeTest.java', 'TestCreateActions.java', 'TestDeleteReachableFilesAction.java', 'TestRewriteDataFilesAction.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestSparkMetadataColumns.java', 'TestTables.java', 'TestCreateTableAsSelect.java']"
Spark 3.4: Clarify concurrent table modification error in copy-on-write operations (#8383),5,28,2023-08-30 18:02:59-07:00,"['TestDelete.java', 'TestMerge.java', 'TestUpdate.java', 'SparkCopyOnWriteScan.java', 'SparkTestBaseWithCatalog.java']"
"Core: FixupTypes copied doc info (#8416)

* Fix: FixupTypes lost doc info

* Run spotlessApply",1,6,2023-08-31 08:48:57+02:00,['FixupTypes.java']
"Add `ajantha-bhat` as project collaborator (#8439)

I need permissions to add partition stats related issues to project dashboard.
https://github.com/apache/iceberg/projects/

Adding myself as collbarator since there is one empty slot and I would like to help other devs too.",1,3,2023-08-31 10:10:58+02:00,['.asf.yaml']
Docs: Add all types of files metadata tables in Spark queries (#8316),1,22,2023-08-31 09:51:37-07:00,['spark-queries.md']
"Python: Add `py.typed` in the package (#8443)

I noticed that the type annotations weren't working when
integrating with Pola.rs",1,0,2023-09-01 09:44:26+02:00,['py.typed']
Python: Bump Poetry to 1.6.1 (#8435),1,2,2023-09-01 09:44:56+02:00,['Makefile']
"Python: Bump boto3 to 1.26.79 (#8436)

This is in line with the minimal version of s3fs",2,10,2023-09-01 09:45:14+02:00,"['poetry.lock', 'pyproject.toml']"
"Docs: Small touchups on the Hive docs (#8464)

Co-authored-by: Ajantha Bhat <ajanthabhat@gmail.com>",1,19,2023-09-01 08:47:45-07:00,['hive.md']
Core: Fix skipped file counts in ManifestReader with deleted entries (#8432),2,72,2023-09-01 16:31:59-07:00,"['ManifestReader.java', 'TestScanPlanningAndReporting.java']"
Build: Bump mkdocstrings from 0.22.0 to 0.23.0 in /python (#8475),1,2,2023-09-03 09:48:43+02:00,['requirements.txt']
Build: Bump cython from 3.0.1 to 3.0.2 in /python (#8477),2,142,2023-09-03 09:48:57+02:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump mkdocs-material from 9.2.4 to 9.2.7 in /python (#8480),1,2,2023-09-03 09:49:15+02:00,['requirements.txt']
"Build: Bump pre-commit from 3.3.3 to 3.4.0 in /python (#8476)

Bumps [pre-commit](https://github.com/pre-commit/pre-commit) from 3.3.3 to 3.4.0.
- [Release notes](https://github.com/pre-commit/pre-commit/releases)
- [Changelog](https://github.com/pre-commit/pre-commit/blob/main/CHANGELOG.md)
- [Commits](https://github.com/pre-commit/pre-commit/compare/v3.3.3...v3.4.0)

---
updated-dependencies:
- dependency-name: pre-commit
  dependency-type: direct:development
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,10,2023-09-03 13:34:04+02:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump mkdocstrings-python from 1.4.0 to 1.6.0 in /python (#8481)

Bumps [mkdocstrings-python](https://github.com/mkdocstrings/python) from 1.4.0 to 1.6.0.
- [Release notes](https://github.com/mkdocstrings/python/releases)
- [Changelog](https://github.com/mkdocstrings/python/blob/main/CHANGELOG.md)
- [Commits](https://github.com/mkdocstrings/python/compare/1.4.0...1.6.0)

---
updated-dependencies:
- dependency-name: mkdocstrings-python
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-09-03 13:34:20+02:00,['requirements.txt']
"Build: Bump griffe from 0.35.1 to 0.36.0 in /python (#8479)

Bumps [griffe](https://github.com/mkdocstrings/griffe) from 0.35.1 to 0.36.0.
- [Release notes](https://github.com/mkdocstrings/griffe/releases)
- [Changelog](https://github.com/mkdocstrings/griffe/blob/main/CHANGELOG.md)
- [Commits](https://github.com/mkdocstrings/griffe/compare/0.35.1...0.36.0)

---
updated-dependencies:
- dependency-name: griffe
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-09-03 13:34:32+02:00,['requirements.txt']
"Build: Bump pytest from 7.4.0 to 7.4.1 in /python (#8478)

Bumps [pytest](https://github.com/pytest-dev/pytest) from 7.4.0 to 7.4.1.
- [Release notes](https://github.com/pytest-dev/pytest/releases)
- [Changelog](https://github.com/pytest-dev/pytest/blob/main/CHANGELOG.rst)
- [Commits](https://github.com/pytest-dev/pytest/compare/7.4.0...7.4.1)

---
updated-dependencies:
- dependency-name: pytest
  dependency-type: direct:development
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,10,2023-09-03 14:09:29+02:00,"['poetry.lock', 'pyproject.toml']"
Core: Fix REST catalog tests with default v2 tables (#8469),2,26,2023-09-03 14:37:00+02:00,"['TableMetadata.java', 'CatalogTests.java']"
"Build: Bump com.azure:azure-sdk-bom from 1.2.15 to 1.2.16 (#8473)

Bumps [com.azure:azure-sdk-bom](https://github.com/azure/azure-sdk-for-java) from 1.2.15 to 1.2.16.
- [Release notes](https://github.com/azure/azure-sdk-for-java/releases)
- [Commits](https://github.com/azure/azure-sdk-for-java/compare/azure-sdk-bom_1.2.15...azure-sdk-bom_1.2.16)

---
updated-dependencies:
- dependency-name: com.azure:azure-sdk-bom
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-09-03 14:37:23+02:00,['libs.versions.toml']
"Build: Bump junit from 5.9.2 to 5.10.0 (#8472)

Bumps `junit` from 5.9.2 to 5.10.0.

Updates `org.junit.jupiter:junit-jupiter` from 5.9.2 to 5.10.0
- [Release notes](https://github.com/junit-team/junit5/releases)
- [Commits](https://github.com/junit-team/junit5/compare/r5.9.2...r5.10.0)

Updates `org.junit.jupiter:junit-jupiter-engine` from 5.9.2 to 5.10.0
- [Release notes](https://github.com/junit-team/junit5/releases)
- [Commits](https://github.com/junit-team/junit5/compare/r5.9.2...r5.10.0)

Updates `org.junit.vintage:junit-vintage-engine` from 5.9.2 to 5.10.0
- [Release notes](https://github.com/junit-team/junit5/releases)
- [Commits](https://github.com/junit-team/junit5/compare/r5.9.2...r5.10.0)

---
updated-dependencies:
- dependency-name: org.junit.jupiter:junit-jupiter
  dependency-type: direct:production
  update-type: version-update:semver-minor
- dependency-name: org.junit.jupiter:junit-jupiter-engine
  dependency-type: direct:production
  update-type: version-update:semver-minor
- dependency-name: org.junit.vintage:junit-vintage-engine
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-09-03 14:37:39+02:00,['libs.versions.toml']
"Python: Add note on pip (#8484)

Fixes #8374",1,8,2023-09-03 14:25:31-07:00,['index.md']
"Docs: Improve the Spark Structured Streaming jobs (#8203)

* Docs: Improve the Spark Structured Streaming jobs

Promote usage of using `toTable(...)` instead of `.option(""path"", ...)`
because I've found that the `.start()` might not inject the catalog
functions when doing the query planning. If the catalog is missing,
this causes issues when using partitioned tables, since the
transforms are not available.

* Update docs/spark-structured-streaming.md

* Update spark-structured-streaming.md

* Update docs/spark-structured-streaming.md

Co-authored-by: Brian ""bits"" Olsen <bits@bitsondata.dev>

* Update docs/spark-structured-streaming.md

Co-authored-by: Brian ""bits"" Olsen <bits@bitsondata.dev>

* Update docs/spark-structured-streaming.md

Co-authored-by: Brian ""bits"" Olsen <bits@bitsondata.dev>

* Update docs/spark-structured-streaming.md

Co-authored-by: Brian ""bits"" Olsen <bits@bitsondata.dev>

* Update docs/spark-structured-streaming.md

Co-authored-by: Brian ""bits"" Olsen <bits@bitsondata.dev>

* Update docs/spark-structured-streaming.md

Co-authored-by: Brian ""bits"" Olsen <bits@bitsondata.dev>

---------

Co-authored-by: Brian ""bits"" Olsen <bits@bitsondata.dev>",1,53,2023-09-03 23:52:30+02:00,['spark-structured-streaming.md']
Core: Fix typo in startingSequenceNumber argument name (#8483),1,6,2023-09-03 15:13:13-07:00,['MergingSnapshotProducer.java']
"Core: Add metadata updates for Views / Use own Builder for ViewMetadata (#8147)

* Core: Add metadata updates for Views / use own Builder for ViewMetadata
* Move validations into Builder to be more lenient when ViewMetadata is read through Parser

There are currently only two ways to create an instance of
`ViewMetadata`:
* through the Builder
* through the Parser

Almost all validations should be happening in the Builder, while we
would like to be more lenient when view metadata is being read (e.g.
from disk) via the parser.

Reading view metadata through the parser, it is acceptable that things
like schemas/versions/history might be empty or that the current version
id points to a version that doesn't exist. In such a case we'd rather
want to lazily fail when accessing the view's current version rather
than when the view metadata is being read by the parser.

Co-authored-by: Ryan Blue <blue@apache.org>",9,1207,2023-09-04 08:33:27-07:00,"['MetadataUpdate.java', 'MetadataUpdateParser.java', 'ViewMetadata.java', 'ViewMetadataParser.java', 'ViewVersionParser.java', 'TestMetadataUpdateParser.java', 'TestViewMetadata.java', 'TestViewMetadataParser.java', 'ViewMetadataLimitedVersions.json']"
"Python: Add updates, moves and deletes (#8374)",9,3686,2023-09-04 08:50:33-07:00,"['Makefile', 'api.md', 'contributing.md', 'schema.py', '__init__.py', 'test_base.py', 'test_init.py', 'test_integration.py', 'test_integration_schema.py']"
Python: Add register table (#8465),9,266,2023-09-04 09:00:44-07:00,"['__init__.py', 'dynamodb.py', 'glue.py', 'hive.py', 'noop.py', 'rest.py', 'sql.py', 'test_base.py', 'test_rest.py']"
Core: Fix lazy snapshot loading history (#8470),1,64,2023-09-04 10:35:22-07:00,['TableMetadata.java']
"Python: Bump fsspec dependencies `>=2023.1.0` (#8433)

* Python: Bump fsspec dependencies `>=2023.1.0`

I think it is good to bump and make the lower bound of the
fsspec dependencies uniform. Also, we don't test for the
older versions.

s3fs `2023.1.0` uses aiobotocore `2.4.2`:
https://github.com/fsspec/s3fs/blob/2023.1.0/requirements.txt

And that depends on `botocore>=1.27.59,<1.27.60`:
https://github.com/aio-libs/aiobotocore/blob/2.4.2/setup.py#L10`

Which is also close to our `boto3` pin of `>=1.24.59`:
https://github.com/apache/iceberg/pull/8436/

* Fix poetry.lock",2,614,2023-09-04 20:46:26+02:00,"['poetry.lock', 'pyproject.toml']"
Python: Set version prior `sdist` release (#8490),1,10,2023-09-04 13:07:33-07:00,['python-release.yml']
"Core: Remove unused field from BaseSnapshot (#8496)

I think this field got superseded by the one from TableMetadata. Hence, this has no callers.",1,2,2023-09-05 19:30:24-07:00,['BaseSnapshot.java']
"Nessie: Update NessieCatalog JavaDoc about namespaces (#8495)

Namespaces are not implicit anymore after Nessie 0.52.3
https://projectnessie.org/blog/namespace-enforcement/",1,9,2023-09-06 08:57:57-07:00,['NessieCatalog.java']
Spark 3.4: Fix write and SQL options to override delete file compression config (#8438),6,486,2023-09-07 09:16:50+08:00,"['SparkWriteConf.java', 'SparkPositionDeletesRewrite.java', 'SparkPositionDeltaWrite.java', 'SparkWrite.java', 'TestSparkWriteConf.java', 'TestCompressionSettings.java']"
Spark3.4: Fix the minor code style issue (#8513),1,3,2023-09-06 21:02:00-07:00,['TestSparkWriteConf.java']
"Add strict metadata cleanup to TableOperation. (#8397)

Co-authored-by: Ryan Blue <blue@apache.org>

Strict metadata cleanup will only trigger cleanups during commits when the commit fails with an
exception which implements the marker interface CleanableFailure
This will get used in SnapshotProducer and BaseTransaction and is
useful for catalogs like the REST catalog where arbitrary HTTP
client exceptions can be thrown (instead of the usual CommitStateUnknown
exceptions).",16,328,2023-09-07 11:06:09-07:00,"['BadRequestException.java', 'CleanableFailure.java', 'CommitFailedException.java', 'ForbiddenException.java', 'NoSuchIcebergTableException.java', 'NoSuchNamespaceException.java', 'NoSuchTableException.java', 'NotAuthorizedException.java', 'ServiceUnavailableException.java', 'ValidationException.java', 'BaseTransaction.java', 'SnapshotProducer.java', 'TableOperations.java', 'RESTTableOperations.java', 'CatalogTests.java', 'TestRESTCatalog.java']"
Python: Improved Readability and Alignment of Timestamp Regex Patterns (#8491),1,4,2023-09-08 08:51:37-07:00,['datetime.py']
"Python: Standardized integer types over relying on C types (#8535)

Utilize libc.stdint for the definition of unsigned 64 bit integers.

Change the array.array type to use integers that are at least 64 bits in width.

Changes motiviated by differences in Windows builds",2,51,2023-09-09 22:59:48+02:00,"['decoder_basic.c', 'decoder_fast.pyx']"
Python: Fix PyArrow HDFS support (#8524),2,41,2023-09-09 23:43:09+02:00,"['pyarrow.py', 'test_pyarrow.py']"
Python: Add integration tests for use_ref (#8534),2,31,2023-09-09 23:49:23+02:00,"['provision.py', 'test_integration.py']"
Build: Bump coverage from 7.3.0 to 7.3.1 in /python (#8537),2,136,2023-09-10 07:46:35+02:00,"['poetry.lock', 'pyproject.toml']"
Build: Bump mkdocstrings-python from 1.6.0 to 1.6.2 in /python (#8538),1,2,2023-09-10 07:46:45+02:00,['requirements.txt']
Build: Bump mkdocs-material from 9.2.7 to 9.2.8 in /python (#8539),1,2,2023-09-10 07:46:52+02:00,['requirements.txt']
Build: Bump griffe from 0.36.0 to 0.36.1 in /python (#8541),1,2,2023-09-10 07:47:08+02:00,['requirements.txt']
Python: Point to the Python docs (#8536),1,2,2023-09-10 08:22:01+02:00,['pyproject.toml']
Build: Bump fastavro from 1.8.2 to 1.8.3 in /python (#8540),2,56,2023-09-10 08:22:40+02:00,"['poetry.lock', 'pyproject.toml']"
"Python: Add checks after building the wheels (#8532)

* Python: Add checks after building the wheels

* Improvements",4,76,2023-09-10 08:06:59-07:00,"['python-release.yml', 'build-module.py', 'pyproject.toml', 'conftest.py']"
Python: Non-Cython fallback Avro parser (#8521),5,145,2023-09-10 12:25:21-07:00,"['build-module.py', 'decoder.py', 'file.py', 'test_decoder.py', 'test_reader.py']"
Core: Add AES GCM encryption stream (#3231),8,1165,2023-09-10 13:52:48-07:00,"['revapi.yml', 'AesGcmInputFile.java', 'AesGcmInputStream.java', 'AesGcmOutputFile.java', 'AesGcmOutputStream.java', 'Ciphers.java', 'TestCiphers.java', 'TestGcmStreams.java']"
"Python: Non-Cython fallback Avro parser (#8545)

* Python: Non-Cython fallback Avro parser

* Python: Non-Cython fallback Avro parser",7,176,2023-09-10 23:08:36+02:00,"['decoder.py', 'decoder_fast.pyi', 'file.py', 'reader.py', 'resolver.py', 'test_decoder.py', 'test_reader.py']"
Python: Add unmarked unit test marker (#8546),2,3,2023-09-10 15:33:22-07:00,"['python-release.yml', 'pyproject.toml']"
Nessie: Provide better commit message on table registation (#8385),1,2,2023-09-11 13:14:15+02:00,['NessieIcebergClient.java']
"Build: Bump actions/checkout from 3 to 4 (#8542)

Bumps [actions/checkout](https://github.com/actions/checkout) from 3 to 4.
- [Release notes](https://github.com/actions/checkout/releases)
- [Changelog](https://github.com/actions/checkout/blob/main/CHANGELOG.md)
- [Commits](https://github.com/actions/checkout/compare/v3...v4)

---
updated-dependencies:
- dependency-name: actions/checkout
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",15,44,2023-09-11 13:14:54+02:00,"['api-binary-compatibility.yml', 'delta-conversion-ci.yml', 'flink-ci.yml', 'hive-ci.yml', 'java-ci.yml', 'jmh-benchmarks.yml', 'license_check.yml', 'open-api.yml', 'publish-snapshot.yml', 'python-ci-docs.yml', 'python-ci.yml', 'python-integration.yml', 'python-release.yml', 'recurring-jmh-benchmarks.yml', 'spark-ci.yml']"
"Python: Inline the Filesystem imports (#8548)

* Python: Inline the Filesystem imports

It can be that certain build flags are turned off:

```
-DARROW_GCS=ON: Build Arrow with GCS support (requires the GCloud SDK for C++)
-DARROW_HDFS=ON: Arrow integration with libhdfs for accessing the Hadoop Filesystem
```
From: https://arrow.apache.org/docs/dev/developers/cpp/building.html#optional-components

This will cause an ImportError when importing `pyarrow.py`,
while it can be that you don't want to use a missing FS.
Therefore it is better to inline the imports

* Move imports to the top",1,17,2023-09-12 10:30:01+02:00,['pyarrow.py']
Core: Add tests for lazy snapshot history loading (#8489),1,94,2023-09-12 09:05:58-07:00,['TestRESTCatalog.java']
Spark 3.4: Support distributed planning (#8123),47,1918,2023-09-12 14:06:15-07:00,"['checkstyle.xml', 'BaseDistributedDataScan.java', 'BaseScan.java', 'DataScan.java', 'DataTableScan.java', 'DeleteFileIndex.java', 'ManifestGroup.java', 'PlanningMode.java', 'SnapshotScan.java', 'TableProperties.java', 'ScanMetricsUtil.java', 'DataTableScanTestBase.java', 'DeleteFileIndexTestBase.java', 'FilterFilesTestBase.java', 'TestLocalDataTableScan.java', 'TestLocalDeleteFileIndex.java', 'TestLocalFilterFiles.java', 'SparkRowLevelOperationsTestBase.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestDelete.java', 'TestMerge.java', 'TestMergeOnReadDelete.java', 'TestMergeOnReadMerge.java', 'TestMergeOnReadUpdate.java', 'TestUpdate.java', 'SparkDistributedDataScan.java', 'SparkReadConf.java', 'SparkSQLProperties.java', 'BaseSparkAction.java', 'ManifestFileBean.java', 'SparkScanBuilder.java', 'SparkDistributedDataScanTestBase.java', 'TestSparkDistributedDataScanDeletes.java', 'TestSparkDistributedDataScanFilterFiles.java', 'TestSparkDistributedDataScanJavaSerialization.java', 'TestSparkDistributedDataScanKryoSerialization.java', 'SparkTestBaseWithCatalog.java', 'TestFilteredScan.java', 'TestIdentityPartitionData.java', 'TestPartitionPruning.java', 'TestRuntimeFiltering.java', 'TestSnapshotSelection.java', 'TestSparkReadProjection.java', 'TestFilterPushDown.java', 'TestStoragePartitionedJoins.java']"
"Python: Fix caching of FileSystem (#8549)

Before:
```
python3 /tmp/benchmark.py

import: 0.175605 seconds
catalog: 0.060079 seconds
table: 0.245859 seconds
scan: 5.218688 seconds
Rows: 119890
```

After:
```
python3 /tmp/benchmark.py

import: 0.169811 seconds
catalog: 0.054512 seconds
table: 0.233786 seconds
scan: 2.165105 seconds
Rows: 119890
```",2,32,2023-09-12 14:15:41-07:00,"['pyarrow.py', 'test_pyarrow.py']"
Spark: Rule for converting StaticInvoke to ApplyFunctionExpression for V2 filter push down (#8088),8,758,2023-09-12 16:21:36-07:00,"['IcebergSparkSessionExtensions.scala', 'ReplaceStaticInvoke.scala', 'TestSystemFunctionPushDownDQL.java', 'PlanUtils.java', 'SparkFunctions.java', 'SystemFunctionPushDownHelper.java', 'TestSparkFunctions.java', 'TestSparkScan.java']"
"Python: Change logic to use `startsWith` (#8556)

We've moved from 20.04 to 22.04 but forgot to update
the if-conditions below. This should fix it",1,4,2023-09-12 16:27:48-07:00,['python-release.yml']
Core: Extend ResolvingFileIO to support prefix-based operations (#8334),9,222,2023-09-13 10:06:06-05:00,"['DelegateFileIO.java', 'S3FileIO.java', 'TestS3FileIO.java', 'HadoopFileIO.java', 'ResolvingFileIO.java', 'HadoopFileIOTest.java', 'TestResolvingIO.java', 'GCSFileIO.java', 'GCSFileIOTest.java']"
"Arrow, Spark 3.4: Support vectorized reads with struct constants (#8466)",13,367,2023-09-13 22:17:08-07:00,"['VectorHolder.java', 'VectorizedArrowReader.java', 'VectorizedReaderBuilder.java', 'MetadataColumns.java', 'SparkPlanUtil.java', 'SparkRowLevelOperationsTestBase.java', 'TestDelete.java', 'TestMerge.java', 'TestUpdate.java', 'ColumnVectorBuilder.java', 'ConstantColumnVector.java', 'SparkBatch.java', 'TestParquetScan.java']"
Azure: Make ADLSFileIO implement DelegateFileIO (#8563),1,6,2023-09-14 17:05:49+02:00,['ADLSFileIO.java']
"Spark 3.4: Set metricsReporter for more scan types (#8445)

Fixes #8444.",1,12,2023-09-14 08:32:42-07:00,['SparkScanBuilder.java']
Docs: Spark Schema Merge docs (#8528),1,27,2023-09-14 11:31:49-05:00,['spark-writes.md']
Core: Default to exponential retry strategy in REST client (#8366),12,450,2023-09-14 15:31:40-07:00,"['LICENSE', 'ExponentialHttpRequestRetryStrategy.java', 'HTTPClient.java', 'TestExponentialHttpRequestRetryStrategy.java', 'LICENSE', 'LICENSE', 'LICENSE', 'LICENSE', 'LICENSE', 'LICENSE', 'LICENSE', 'LICENSE']"
"HIVE: Fix the Hive version checking in MetastoreLock logical error (#8547)

Thanks @Paddy0523 for finding the bug and for the fix",2,33,2023-09-15 07:59:02+02:00,"['MetastoreLock.java', 'TestHiveCommitLocks.java']"
Docs: Fix CREATE BRANCH syntax and broken link in Writing to Branches section (#8562),2,6,2023-09-15 09:05:12+02:00,"['branching-and-tagging.md', 'spark-ddl.md']"
Docs: Fix Flink configuration example doc. (#8564),1,2,2023-09-15 09:07:11+02:00,['flink-configuration.md']
Docs: Fix links from Flink DDL to upsert mode (#8561),1,2,2023-09-15 09:12:00+02:00,['flink-ddl.md']
"Build: Bump mkdocs-section-index from 0.3.5 to 0.3.7 in /python (#8572)

Bumps [mkdocs-section-index](https://github.com/oprypin/mkdocs-section-index) from 0.3.5 to 0.3.7.
- [Release notes](https://github.com/oprypin/mkdocs-section-index/releases)
- [Commits](https://github.com/oprypin/mkdocs-section-index/compare/v0.3.5...v0.3.7)

---
updated-dependencies:
- dependency-name: mkdocs-section-index
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-09-17 08:55:45+02:00,['requirements.txt']
"Build: Bump mkdocstrings-python from 1.6.2 to 1.7.0 in /python (#8573)

Bumps [mkdocstrings-python](https://github.com/mkdocstrings/python) from 1.6.2 to 1.7.0.
- [Release notes](https://github.com/mkdocstrings/python/releases)
- [Changelog](https://github.com/mkdocstrings/python/blob/main/CHANGELOG.md)
- [Commits](https://github.com/mkdocstrings/python/compare/1.6.2...1.7.0)

---
updated-dependencies:
- dependency-name: mkdocstrings-python
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-09-17 08:55:54+02:00,['requirements.txt']
"Build: Bump moto from 4.2.2 to 4.2.3 in /python (#8574)

Bumps [moto](https://github.com/getmoto/moto) from 4.2.2 to 4.2.3.
- [Release notes](https://github.com/getmoto/moto/releases)
- [Changelog](https://github.com/getmoto/moto/blob/master/CHANGELOG.md)
- [Commits](https://github.com/getmoto/moto/compare/4.2.2...4.2.3)

---
updated-dependencies:
- dependency-name: moto
  dependency-type: direct:development
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,27,2023-09-17 08:56:03+02:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump mkdocs-material from 9.2.8 to 9.3.1 in /python (#8576)

Bumps [mkdocs-material](https://github.com/squidfunk/mkdocs-material) from 9.2.8 to 9.3.1.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/CHANGELOG)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/9.2.8...9.3.1)

---
updated-dependencies:
- dependency-name: mkdocs-material
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-09-17 08:56:15+02:00,['requirements.txt']
"Build: Bump griffe from 0.36.1 to 0.36.2 in /python (#8575)

Bumps [griffe](https://github.com/mkdocstrings/griffe) from 0.36.1 to 0.36.2.
- [Release notes](https://github.com/mkdocstrings/griffe/releases)
- [Changelog](https://github.com/mkdocstrings/griffe/blob/main/CHANGELOG.md)
- [Commits](https://github.com/mkdocstrings/griffe/compare/0.36.1...0.36.2)

---
updated-dependencies:
- dependency-name: griffe
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-09-17 09:15:17+02:00,['requirements.txt']
Spark: Fix spacing in warn log in ExpireSnapshotsProcedure (#8578),3,6,2023-09-18 08:11:30+02:00,"['ExpireSnapshotsProcedure.java', 'ExpireSnapshotsProcedure.java', 'ExpireSnapshotsProcedure.java']"
Spark 3.4: Push down system functions by V2 filters for rewriting DataFiles and PositionDeleteFiles (#8560),4,135,2023-09-18 15:14:53-05:00,"['TestRewriteDataFilesProcedure.java', 'RewriteDataFilesProcedure.java', 'SparkExpressionConverter.scala', 'TestRewriteDataFilesAction.java']"
Arrow: Propagate correct field info while reading metadata columns (#8568),2,7,2023-09-18 13:31:42-07:00,"['VectorHolder.java', 'VectorizedArrowReader.java']"
Spark 3.5: Move 3.4 as 3.5,506,0,2023-09-18 15:12:09-07:00,"['build.gradle', 'DeleteFileIndexBenchmark.java', 'MergeCardinalityCheckBenchmark.java', 'PlanningBenchmark.java', 'TaskGroupPlanningBenchmark.java', 'UpdateProjectionBenchmark.java', 'IcebergSqlExtensions.g4', 'IcebergSparkSessionExtensions.scala', 'AlignRowLevelCommandAssignments.scala', 'AlignedRowLevelIcebergCommandCheck.scala', 'AssignmentAlignmentSupport.scala', 'CheckMergeIntoTableConditions.scala', 'MergeIntoIcebergTableResolutionCheck.scala', 'ProcedureArgumentCoercion.scala', 'ResolveMergeIntoTableReferences.scala', 'ResolveProcedures.scala', 'RewriteMergeIntoTable.scala', 'RewriteRowLevelIcebergCommand.scala', 'RewriteUpdateTable.scala', 'AssignmentUtils.scala', 'ExtendedReplaceNullWithFalseInPredicate.scala', 'ExtendedSimplifyConditionalsInPredicate.scala', 'ReplaceStaticInvoke.scala', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'RewrittenRowLevelCommand.scala', 'AddPartitionField.scala', 'BranchOptions.scala', 'Call.scala', 'CreateOrReplaceBranch.scala', 'CreateOrReplaceTag.scala', 'DropBranch.scala', 'DropIdentifierFields.scala', 'DropPartitionField.scala', 'DropTag.scala', 'MergeIntoIcebergTable.scala', 'MergeRows.scala', 'NoStatsUnaryNode.scala', 'ReplaceIcebergData.scala', 'ReplacePartitionField.scala', 'RowLevelCommand.scala', 'SetIdentifierFields.scala', 'TagOptions.scala', 'UnresolvedMergeIntoIcebergTable.scala', 'UpdateIcebergTable.scala', 'UpdateRows.scala', 'V2WriteCommandLike.scala', 'WriteIcebergDelta.scala', 'statements.scala', 'AddPartitionFieldExec.scala', 'CallExec.scala', 'CreateOrReplaceBranchExec.scala', 'CreateOrReplaceTagExec.scala', 'DropBranchExec.scala', 'DropIdentifierFieldsExec.scala', 'DropPartitionFieldExec.scala', 'DropTagExec.scala', 'ExtendedDataSourceV2Implicits.scala', 'ExtendedDataSourceV2Strategy.scala', 'ExtendedV2Writes.scala', 'MergeRowsExec.scala', 'ReplaceDataExec.scala', 'ReplacePartitionFieldExec.scala', 'ReplaceRewrittenRowLevelCommand.scala', 'RowLevelCommandScanRelationPushDown.scala', 'SetIdentifierFieldsExec.scala', 'SetWriteDistributionAndOrderingExec.scala', 'UpdateRowsExec.scala', 'RowLevelCommandDynamicPruning.scala', 'Employee.java', 'SparkExtensionsTestBase.java', 'SparkPlanUtil.java', 'SparkRowLevelOperationsTestBase.java', 'TestAddFilesProcedure.java', 'TestAlterTablePartitionFields.java', 'TestAlterTableSchema.java', 'TestAncestorsOfProcedure.java', 'TestBranchDDL.java', 'TestCallStatementParser.java', 'TestChangelogTable.java', 'TestCherrypickSnapshotProcedure.java', 'TestConflictValidation.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestCreateChangelogViewProcedure.java', 'TestDelete.java', 'TestExpireSnapshotsProcedure.java', 'TestFastForwardBranchProcedure.java', 'TestMerge.java', 'TestMergeOnReadDelete.java', 'TestMergeOnReadMerge.java', 'TestMergeOnReadUpdate.java', 'TestMetadataTables.java', 'TestMigrateTableProcedure.java', 'TestPublishChangesProcedure.java', 'TestRegisterTableProcedure.java', 'TestRemoveOrphanFilesProcedure.java', 'TestReplaceBranch.java', 'TestRequiredDistributionAndOrdering.java', 'TestRewriteDataFilesProcedure.java', 'TestRewriteManifestsProcedure.java', 'TestRewritePositionDeleteFiles.java', 'TestRewritePositionDeleteFilesProcedure.java', 'TestRollbackToSnapshotProcedure.java', 'TestRollbackToTimestampProcedure.java', 'TestSetCurrentSnapshotProcedure.java', 'TestSetWriteDistributionAndOrdering.java', 'TestSnapshotTableProcedure.java', 'TestStoragePartitionedJoinsInRowLevelOperations.java', 'TestSystemFunctionPushDownDQL.java', 'TestTagDDL.java', 'TestUpdate.java', 'TestWriteAborts.java', 'PlanUtils.java', 'LICENSE', 'NOTICE', 'SmokeTest.java', 'SparkBenchmarkUtil.java', 'DeleteOrphanFilesBenchmark.java', 'IcebergSortCompactionBenchmark.java', 'RandomGeneratingUDF.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'Action.java', 'IcebergSourceBenchmark.java', 'IcebergSourceDeleteBenchmark.java', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'IcebergSourceNestedListDataBenchmark.java', 'WritersBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'IcebergSourceParquetEqDeleteBenchmark.java', 'IcebergSourceParquetMultiDeleteFileBenchmark.java', 'IcebergSourceParquetPosDeleteBenchmark.java', 'IcebergSourceParquetWithUnrelatedDeleteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'VectorizedReadParquetDecimalBenchmark.java', 'SparkDistributedDataScan.java', 'BaseCatalog.java', 'BaseFileRewriteCoordinator.java', 'ChangelogIterator.java', 'CommitMetadata.java', 'ComputeUpdateIterator.java', 'ExtendedParser.java', 'FileRewriteCoordinator.java', 'IcebergSpark.java', 'JobGroupInfo.java', 'JobGroupUtils.java', 'PathIdentifier.java', 'PositionDeletesRewriteCoordinator.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'RemoveCarryoverIterator.java', 'RemoveNetCarryoverIterator.java', 'RollbackStagedTable.java', 'ScanTaskSetManager.java', 'SortOrderToSpark.java', 'Spark3Util.java', 'SparkAggregates.java', 'SparkCachedTableCatalog.java', 'SparkCatalog.java', 'SparkConfParser.java', 'SparkDataFile.java', 'SparkExceptionUtil.java', 'SparkFilters.java', 'SparkFixupTypes.java', 'SparkFunctionCatalog.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkSQLProperties.java', 'SparkSchemaUtil.java', 'SparkSessionCatalog.java', 'SparkStructLike.java', 'SparkTableCache.java', 'SparkTableUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'SparkUtil.java', 'SparkV2Filters.java', 'SparkValueConverter.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'SparkWriteRequirements.java', 'SparkWriteUtil.java', 'SupportsFunctions.java', 'TypeToSparkType.java', 'BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java', 'BaseTableCreationSparkAction.java', 'DeleteOrphanFilesSparkAction.java', 'DeleteReachableFilesSparkAction.java', 'ExpireSnapshotsSparkAction.java', 'FileInfo.java', 'ManifestFileBean.java', 'MigrateTableSparkAction.java', 'RewriteDataFilesSparkAction.java', 'RewriteManifestsSparkAction.java', 'RewritePositionDeleteFilesSparkAction.java', 'SetAccumulator.java', 'SnapshotTableSparkAction.java', 'SparkActions.java', 'SparkBinPackDataRewriter.java', 'SparkBinPackPositionDeletesRewriter.java', 'SparkShufflingDataRewriter.java', 'SparkSizeBasedDataRewriter.java', 'SparkSortDataRewriter.java', 'SparkZOrderDataRewriter.java', 'SparkZOrderUDF.java', 'AvroWithSparkSchemaVisitor.java', 'ParquetWithSparkSchemaVisitor.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'ArrowVectorAccessorFactory.java', 'ArrowVectorAccessors.java', 'ColumnVectorBuilder.java', 'ColumnVectorWithFilter.java', 'ColumnarBatchReader.java', 'ConstantColumnVector.java', 'DeletedColumnVector.java', 'IcebergArrowColumnVector.java', 'RowPositionColumnVector.java', 'VectorizedSparkOrcReaders.java', 'VectorizedSparkParquetReaders.java', 'BucketFunction.java', 'DaysFunction.java', 'HoursFunction.java', 'IcebergVersionFunction.java', 'MonthsFunction.java', 'SparkFunctions.java', 'TruncateFunction.java', 'UnaryUnboundFunction.java', 'YearsFunction.java', 'AddFilesProcedure.java', 'AncestorsOfProcedure.java', 'BaseProcedure.java', 'CherrypickSnapshotProcedure.java', 'CreateChangelogViewProcedure.java', 'ExpireSnapshotsProcedure.java', 'FastForwardBranchProcedure.java', 'MigrateTableProcedure.java', 'ProcedureInput.java', 'PublishChangesProcedure.java', 'RegisterTableProcedure.java', 'RemoveOrphanFilesProcedure.java', 'RewriteDataFilesProcedure.java', 'RewriteManifestsProcedure.java', 'RewritePositionDeleteFilesProcedure.java', 'RollbackToSnapshotProcedure.java', 'RollbackToTimestampProcedure.java', 'SetCurrentSnapshotProcedure.java', 'SnapshotTableProcedure.java', 'SparkProcedures.java', 'BaseBatchReader.java', 'BaseReader.java', 'BaseRowReader.java', 'BatchDataReader.java', 'ChangelogRowReader.java', 'EqualityDeleteRowReader.java', 'HasIcebergCatalog.java', 'IcebergSource.java', 'InternalRowWrapper.java', 'PositionDeletesRowReader.java', 'RowDataReader.java', 'SerializableTableWithSize.java', 'SparkAppenderFactory.java', 'SparkBatch.java', 'SparkBatchQueryScan.java', 'SparkChangelogScan.java', 'SparkChangelogTable.java', 'SparkCleanupUtil.java', 'SparkColumnarReaderFactory.java', 'SparkCopyOnWriteOperation.java', 'SparkCopyOnWriteScan.java', 'SparkFileWriterFactory.java', 'SparkInputPartition.java', 'SparkLocalScan.java', 'SparkMetadataColumn.java', 'SparkMicroBatchStream.java', 'SparkPartitionedFanoutWriter.java', 'SparkPartitionedWriter.java', 'SparkPartitioningAwareScan.java', 'SparkPositionDeletesRewrite.java', 'SparkPositionDeletesRewriteBuilder.java', 'SparkPositionDeltaOperation.java', 'SparkPositionDeltaWrite.java', 'SparkPositionDeltaWriteBuilder.java', 'SparkRowLevelOperationBuilder.java', 'SparkRowReaderFactory.java', 'SparkScan.java', 'SparkScanBuilder.java', 'SparkStagedScan.java', 'SparkStagedScanBuilder.java', 'SparkTable.java', 'SparkWrite.java', 'SparkWriteBuilder.java', 'StagedSparkTable.java', 'Stats.java', 'StreamingOffset.java', 'StructInternalRow.java', 'NumDeletes.java', 'NumSplits.java', 'ScannedDataFiles.java', 'ScannedDataManifests.java', 'SkippedDataFiles.java', 'SkippedDataManifests.java', 'TaskNumDeletes.java', 'TaskNumSplits.java', 'TaskScannedDataFiles.java', 'TaskScannedDataManifests.java', 'TaskSkippedDataFiles.java', 'TaskSkippedDataManifests.java', 'TaskTotalFileSize.java', 'TaskTotalPlanningDuration.java', 'TotalFileSize.java', 'TotalPlanningDuration.java', 'NoSuchProcedureException.java', 'Procedure.java', 'ProcedureCatalog.java', 'ProcedureParameter.java', 'ProcedureParameterImpl.java', 'org.apache.spark.sql.sources.DataSourceRegister', 'OrderAwareCoalesce.scala', 'SetWriteDistributionAndOrdering.scala', 'SortOrderParserUtil.scala', 'PlanUtils.scala', 'OrderAwareCoalesceExec.scala', 'SparkExpressionConverter.scala', 'KryoHelpers.java', 'SparkDistributedDataScanTestBase.java', 'TaskCheckHelper.java', 'TestDataFileSerialization.java', 'TestFileIOSerialization.java', 'TestHadoopMetricsContextSerialization.java', 'TestManifestFileSerialization.java', 'TestScanTaskSerialization.java', 'TestSparkDistributedDataScanDeletes.java', 'TestSparkDistributedDataScanFilterFiles.java', 'TestSparkDistributedDataScanJavaSerialization.java', 'TestSparkDistributedDataScanKryoSerialization.java', 'TestTableSerialization.java', 'ValidationHelpers.java', 'SparkCatalogConfig.java', 'SparkCatalogTestBase.java', 'SparkTestBase.java', 'SparkTestBaseWithCatalog.java', 'SparkTestHelperBase.java', 'SystemFunctionPushDownHelper.java', 'TestChangelogIterator.java', 'TestFileRewriteCoordinator.java', 'TestFunctionCatalog.java', 'TestSpark3Util.java', 'TestSparkCachedTableCatalog.java', 'TestSparkCatalogOperations.java', 'TestSparkDistributionAndOrderingUtil.java', 'TestSparkFilters.java', 'TestSparkSchemaUtil.java', 'TestSparkSessionCatalog.java', 'TestSparkTableUtil.java', 'TestSparkV2Filters.java', 'TestSparkValueConverter.java', 'TestSparkWriteConf.java', 'TestCreateActions.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction3.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'TestRewritePositionDeleteFilesAction.java', 'TestSparkFileRewriter.java', 'AvroDataTest.java', 'GenericsHelpers.java', 'RandomData.java', 'TestHelpers.java', 'TestOrcWrite.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkAvroEnums.java', 'TestSparkAvroReader.java', 'TestSparkDateTimes.java', 'TestSparkOrcReadMetadataColumns.java', 'TestSparkOrcReader.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkParquetReader.java', 'TestSparkParquetWriter.java', 'TestSparkRecordOrcReaderWriter.java', 'TestVectorizedOrcDataReader.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryFallbackToPlainEncodingVectorizedReads.java', 'TestParquetVectorizedReads.java', 'TestSparkFunctions.java', 'ComplexRecord.java', 'FilePathLastModifiedRecord.java', 'FourColumnRecord.java', 'LogMessage.java', 'ManualSource.java', 'NestedRecord.java', 'SimpleRecord.java', 'SparkSQLExecutionHelper.java', 'TestAvroScan.java', 'TestBaseReader.java', 'TestChangelogReader.java', 'TestCompressionSettings.java', 'TestDataFrameWriterV2.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestFilteredScan.java', 'TestForwardCompatibility.java', 'TestIcebergSource.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSpark.java', 'TestIdentityPartitionData.java', 'TestInternalRowWrapper.java', 'TestMetadataTableReadableMetrics.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestParquetScan.java', 'TestPartitionPruning.java', 'TestPartitionValues.java', 'TestPathIdentifier.java', 'TestPositionDeletesTable.java', 'TestReadProjection.java', 'TestRequiredDistributionAndOrdering.java', 'TestRuntimeFiltering.java', 'TestSnapshotSelection.java', 'TestSparkAggregates.java', 'TestSparkAppenderFactory.java', 'TestSparkCatalog.java', 'TestSparkCatalogCacheExpiration.java', 'TestSparkCatalogHadoopOverrides.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestSparkFileWriterFactory.java', 'TestSparkMergingMetrics.java', 'TestSparkMetadataColumns.java', 'TestSparkPartitioningWriters.java', 'TestSparkPositionDeltaWriters.java', 'TestSparkReadMetrics.java', 'TestSparkReadProjection.java', 'TestSparkReaderDeletes.java', 'TestSparkReaderWithBloomFilter.java', 'TestSparkRollingFileWriters.java', 'TestSparkScan.java', 'TestSparkStagedScan.java', 'TestSparkTable.java', 'TestSparkWriterMetrics.java', 'TestStreamingOffset.java', 'TestStructuredStreaming.java', 'TestStructuredStreamingRead3.java', 'TestTables.java', 'TestTimestampWithoutZone.java', 'TestWriteMetricsConfig.java', 'ThreeColumnRecord.java', 'PartitionedWritesTestBase.java', 'TestAggregatePushDown.java', 'TestAlterTable.java', 'TestCreateTable.java', 'TestCreateTableAsSelect.java', 'TestDeleteFrom.java', 'TestDropTable.java', 'TestFilterPushDown.java', 'TestNamespaceSQL.java', 'TestPartitionedWrites.java', 'TestPartitionedWritesAsSelect.java', 'TestPartitionedWritesToBranch.java', 'TestPartitionedWritesToWapBranch.java', 'TestRefreshTable.java', 'TestSelect.java', 'TestSparkBucketFunction.java', 'TestSparkDaysFunction.java', 'TestSparkHoursFunction.java', 'TestSparkMonthsFunction.java', 'TestSparkTruncateFunction.java', 'TestSparkYearsFunction.java', 'TestStoragePartitionedJoins.java', 'TestTimestampWithoutZone.java', 'TestUnpartitionedWrites.java', 'TestUnpartitionedWritesToBranch.java', 'UnpartitionedWritesTestBase.java']"
Spark 3.4: Copy back 3.5 as 3.4,506,114837,2023-09-18 15:12:09-07:00,"['build.gradle', 'DeleteFileIndexBenchmark.java', 'MergeCardinalityCheckBenchmark.java', 'PlanningBenchmark.java', 'TaskGroupPlanningBenchmark.java', 'UpdateProjectionBenchmark.java', 'IcebergSqlExtensions.g4', 'IcebergSparkSessionExtensions.scala', 'AlignRowLevelCommandAssignments.scala', 'AlignedRowLevelIcebergCommandCheck.scala', 'AssignmentAlignmentSupport.scala', 'CheckMergeIntoTableConditions.scala', 'MergeIntoIcebergTableResolutionCheck.scala', 'ProcedureArgumentCoercion.scala', 'ResolveMergeIntoTableReferences.scala', 'ResolveProcedures.scala', 'RewriteMergeIntoTable.scala', 'RewriteRowLevelIcebergCommand.scala', 'RewriteUpdateTable.scala', 'AssignmentUtils.scala', 'ExtendedReplaceNullWithFalseInPredicate.scala', 'ExtendedSimplifyConditionalsInPredicate.scala', 'ReplaceStaticInvoke.scala', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'RewrittenRowLevelCommand.scala', 'AddPartitionField.scala', 'BranchOptions.scala', 'Call.scala', 'CreateOrReplaceBranch.scala', 'CreateOrReplaceTag.scala', 'DropBranch.scala', 'DropIdentifierFields.scala', 'DropPartitionField.scala', 'DropTag.scala', 'MergeIntoIcebergTable.scala', 'MergeRows.scala', 'NoStatsUnaryNode.scala', 'ReplaceIcebergData.scala', 'ReplacePartitionField.scala', 'RowLevelCommand.scala', 'SetIdentifierFields.scala', 'TagOptions.scala', 'UnresolvedMergeIntoIcebergTable.scala', 'UpdateIcebergTable.scala', 'UpdateRows.scala', 'V2WriteCommandLike.scala', 'WriteIcebergDelta.scala', 'statements.scala', 'AddPartitionFieldExec.scala', 'CallExec.scala', 'CreateOrReplaceBranchExec.scala', 'CreateOrReplaceTagExec.scala', 'DropBranchExec.scala', 'DropIdentifierFieldsExec.scala', 'DropPartitionFieldExec.scala', 'DropTagExec.scala', 'ExtendedDataSourceV2Implicits.scala', 'ExtendedDataSourceV2Strategy.scala', 'ExtendedV2Writes.scala', 'MergeRowsExec.scala', 'ReplaceDataExec.scala', 'ReplacePartitionFieldExec.scala', 'ReplaceRewrittenRowLevelCommand.scala', 'RowLevelCommandScanRelationPushDown.scala', 'SetIdentifierFieldsExec.scala', 'SetWriteDistributionAndOrderingExec.scala', 'UpdateRowsExec.scala', 'RowLevelCommandDynamicPruning.scala', 'Employee.java', 'SparkExtensionsTestBase.java', 'SparkPlanUtil.java', 'SparkRowLevelOperationsTestBase.java', 'TestAddFilesProcedure.java', 'TestAlterTablePartitionFields.java', 'TestAlterTableSchema.java', 'TestAncestorsOfProcedure.java', 'TestBranchDDL.java', 'TestCallStatementParser.java', 'TestChangelogTable.java', 'TestCherrypickSnapshotProcedure.java', 'TestConflictValidation.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestCreateChangelogViewProcedure.java', 'TestDelete.java', 'TestExpireSnapshotsProcedure.java', 'TestFastForwardBranchProcedure.java', 'TestMerge.java', 'TestMergeOnReadDelete.java', 'TestMergeOnReadMerge.java', 'TestMergeOnReadUpdate.java', 'TestMetadataTables.java', 'TestMigrateTableProcedure.java', 'TestPublishChangesProcedure.java', 'TestRegisterTableProcedure.java', 'TestRemoveOrphanFilesProcedure.java', 'TestReplaceBranch.java', 'TestRequiredDistributionAndOrdering.java', 'TestRewriteDataFilesProcedure.java', 'TestRewriteManifestsProcedure.java', 'TestRewritePositionDeleteFiles.java', 'TestRewritePositionDeleteFilesProcedure.java', 'TestRollbackToSnapshotProcedure.java', 'TestRollbackToTimestampProcedure.java', 'TestSetCurrentSnapshotProcedure.java', 'TestSetWriteDistributionAndOrdering.java', 'TestSnapshotTableProcedure.java', 'TestStoragePartitionedJoinsInRowLevelOperations.java', 'TestSystemFunctionPushDownDQL.java', 'TestTagDDL.java', 'TestUpdate.java', 'TestWriteAborts.java', 'PlanUtils.java', 'LICENSE', 'NOTICE', 'SmokeTest.java', 'SparkBenchmarkUtil.java', 'DeleteOrphanFilesBenchmark.java', 'IcebergSortCompactionBenchmark.java', 'RandomGeneratingUDF.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'Action.java', 'IcebergSourceBenchmark.java', 'IcebergSourceDeleteBenchmark.java', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'IcebergSourceNestedListDataBenchmark.java', 'WritersBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'IcebergSourceParquetEqDeleteBenchmark.java', 'IcebergSourceParquetMultiDeleteFileBenchmark.java', 'IcebergSourceParquetPosDeleteBenchmark.java', 'IcebergSourceParquetWithUnrelatedDeleteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'VectorizedReadParquetDecimalBenchmark.java', 'SparkDistributedDataScan.java', 'BaseCatalog.java', 'BaseFileRewriteCoordinator.java', 'ChangelogIterator.java', 'CommitMetadata.java', 'ComputeUpdateIterator.java', 'ExtendedParser.java', 'FileRewriteCoordinator.java', 'IcebergSpark.java', 'JobGroupInfo.java', 'JobGroupUtils.java', 'PathIdentifier.java', 'PositionDeletesRewriteCoordinator.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'RemoveCarryoverIterator.java', 'RemoveNetCarryoverIterator.java', 'RollbackStagedTable.java', 'ScanTaskSetManager.java', 'SortOrderToSpark.java', 'Spark3Util.java', 'SparkAggregates.java', 'SparkCachedTableCatalog.java', 'SparkCatalog.java', 'SparkConfParser.java', 'SparkDataFile.java', 'SparkExceptionUtil.java', 'SparkFilters.java', 'SparkFixupTypes.java', 'SparkFunctionCatalog.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkSQLProperties.java', 'SparkSchemaUtil.java', 'SparkSessionCatalog.java', 'SparkStructLike.java', 'SparkTableCache.java', 'SparkTableUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'SparkUtil.java', 'SparkV2Filters.java', 'SparkValueConverter.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'SparkWriteRequirements.java', 'SparkWriteUtil.java', 'SupportsFunctions.java', 'TypeToSparkType.java', 'BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java', 'BaseTableCreationSparkAction.java', 'DeleteOrphanFilesSparkAction.java', 'DeleteReachableFilesSparkAction.java', 'ExpireSnapshotsSparkAction.java', 'FileInfo.java', 'ManifestFileBean.java', 'MigrateTableSparkAction.java', 'RewriteDataFilesSparkAction.java', 'RewriteManifestsSparkAction.java', 'RewritePositionDeleteFilesSparkAction.java', 'SetAccumulator.java', 'SnapshotTableSparkAction.java', 'SparkActions.java', 'SparkBinPackDataRewriter.java', 'SparkBinPackPositionDeletesRewriter.java', 'SparkShufflingDataRewriter.java', 'SparkSizeBasedDataRewriter.java', 'SparkSortDataRewriter.java', 'SparkZOrderDataRewriter.java', 'SparkZOrderUDF.java', 'AvroWithSparkSchemaVisitor.java', 'ParquetWithSparkSchemaVisitor.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'ArrowVectorAccessorFactory.java', 'ArrowVectorAccessors.java', 'ColumnVectorBuilder.java', 'ColumnVectorWithFilter.java', 'ColumnarBatchReader.java', 'ConstantColumnVector.java', 'DeletedColumnVector.java', 'IcebergArrowColumnVector.java', 'RowPositionColumnVector.java', 'VectorizedSparkOrcReaders.java', 'VectorizedSparkParquetReaders.java', 'BucketFunction.java', 'DaysFunction.java', 'HoursFunction.java', 'IcebergVersionFunction.java', 'MonthsFunction.java', 'SparkFunctions.java', 'TruncateFunction.java', 'UnaryUnboundFunction.java', 'YearsFunction.java', 'AddFilesProcedure.java', 'AncestorsOfProcedure.java', 'BaseProcedure.java', 'CherrypickSnapshotProcedure.java', 'CreateChangelogViewProcedure.java', 'ExpireSnapshotsProcedure.java', 'FastForwardBranchProcedure.java', 'MigrateTableProcedure.java', 'ProcedureInput.java', 'PublishChangesProcedure.java', 'RegisterTableProcedure.java', 'RemoveOrphanFilesProcedure.java', 'RewriteDataFilesProcedure.java', 'RewriteManifestsProcedure.java', 'RewritePositionDeleteFilesProcedure.java', 'RollbackToSnapshotProcedure.java', 'RollbackToTimestampProcedure.java', 'SetCurrentSnapshotProcedure.java', 'SnapshotTableProcedure.java', 'SparkProcedures.java', 'BaseBatchReader.java', 'BaseReader.java', 'BaseRowReader.java', 'BatchDataReader.java', 'ChangelogRowReader.java', 'EqualityDeleteRowReader.java', 'HasIcebergCatalog.java', 'IcebergSource.java', 'InternalRowWrapper.java', 'PositionDeletesRowReader.java', 'RowDataReader.java', 'SerializableTableWithSize.java', 'SparkAppenderFactory.java', 'SparkBatch.java', 'SparkBatchQueryScan.java', 'SparkChangelogScan.java', 'SparkChangelogTable.java', 'SparkCleanupUtil.java', 'SparkColumnarReaderFactory.java', 'SparkCopyOnWriteOperation.java', 'SparkCopyOnWriteScan.java', 'SparkFileWriterFactory.java', 'SparkInputPartition.java', 'SparkLocalScan.java', 'SparkMetadataColumn.java', 'SparkMicroBatchStream.java', 'SparkPartitionedFanoutWriter.java', 'SparkPartitionedWriter.java', 'SparkPartitioningAwareScan.java', 'SparkPositionDeletesRewrite.java', 'SparkPositionDeletesRewriteBuilder.java', 'SparkPositionDeltaOperation.java', 'SparkPositionDeltaWrite.java', 'SparkPositionDeltaWriteBuilder.java', 'SparkRowLevelOperationBuilder.java', 'SparkRowReaderFactory.java', 'SparkScan.java', 'SparkScanBuilder.java', 'SparkStagedScan.java', 'SparkStagedScanBuilder.java', 'SparkTable.java', 'SparkWrite.java', 'SparkWriteBuilder.java', 'StagedSparkTable.java', 'Stats.java', 'StreamingOffset.java', 'StructInternalRow.java', 'NumDeletes.java', 'NumSplits.java', 'ScannedDataFiles.java', 'ScannedDataManifests.java', 'SkippedDataFiles.java', 'SkippedDataManifests.java', 'TaskNumDeletes.java', 'TaskNumSplits.java', 'TaskScannedDataFiles.java', 'TaskScannedDataManifests.java', 'TaskSkippedDataFiles.java', 'TaskSkippedDataManifests.java', 'TaskTotalFileSize.java', 'TaskTotalPlanningDuration.java', 'TotalFileSize.java', 'TotalPlanningDuration.java', 'NoSuchProcedureException.java', 'Procedure.java', 'ProcedureCatalog.java', 'ProcedureParameter.java', 'ProcedureParameterImpl.java', 'org.apache.spark.sql.sources.DataSourceRegister', 'OrderAwareCoalesce.scala', 'SetWriteDistributionAndOrdering.scala', 'SortOrderParserUtil.scala', 'PlanUtils.scala', 'OrderAwareCoalesceExec.scala', 'SparkExpressionConverter.scala', 'KryoHelpers.java', 'SparkDistributedDataScanTestBase.java', 'TaskCheckHelper.java', 'TestDataFileSerialization.java', 'TestFileIOSerialization.java', 'TestHadoopMetricsContextSerialization.java', 'TestManifestFileSerialization.java', 'TestScanTaskSerialization.java', 'TestSparkDistributedDataScanDeletes.java', 'TestSparkDistributedDataScanFilterFiles.java', 'TestSparkDistributedDataScanJavaSerialization.java', 'TestSparkDistributedDataScanKryoSerialization.java', 'TestTableSerialization.java', 'ValidationHelpers.java', 'SparkCatalogConfig.java', 'SparkCatalogTestBase.java', 'SparkTestBase.java', 'SparkTestBaseWithCatalog.java', 'SparkTestHelperBase.java', 'SystemFunctionPushDownHelper.java', 'TestChangelogIterator.java', 'TestFileRewriteCoordinator.java', 'TestFunctionCatalog.java', 'TestSpark3Util.java', 'TestSparkCachedTableCatalog.java', 'TestSparkCatalogOperations.java', 'TestSparkDistributionAndOrderingUtil.java', 'TestSparkFilters.java', 'TestSparkSchemaUtil.java', 'TestSparkSessionCatalog.java', 'TestSparkTableUtil.java', 'TestSparkV2Filters.java', 'TestSparkValueConverter.java', 'TestSparkWriteConf.java', 'TestCreateActions.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction3.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'TestRewritePositionDeleteFilesAction.java', 'TestSparkFileRewriter.java', 'AvroDataTest.java', 'GenericsHelpers.java', 'RandomData.java', 'TestHelpers.java', 'TestOrcWrite.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkAvroEnums.java', 'TestSparkAvroReader.java', 'TestSparkDateTimes.java', 'TestSparkOrcReadMetadataColumns.java', 'TestSparkOrcReader.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkParquetReader.java', 'TestSparkParquetWriter.java', 'TestSparkRecordOrcReaderWriter.java', 'TestVectorizedOrcDataReader.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryFallbackToPlainEncodingVectorizedReads.java', 'TestParquetVectorizedReads.java', 'TestSparkFunctions.java', 'ComplexRecord.java', 'FilePathLastModifiedRecord.java', 'FourColumnRecord.java', 'LogMessage.java', 'ManualSource.java', 'NestedRecord.java', 'SimpleRecord.java', 'SparkSQLExecutionHelper.java', 'TestAvroScan.java', 'TestBaseReader.java', 'TestChangelogReader.java', 'TestCompressionSettings.java', 'TestDataFrameWriterV2.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestFilteredScan.java', 'TestForwardCompatibility.java', 'TestIcebergSource.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSpark.java', 'TestIdentityPartitionData.java', 'TestInternalRowWrapper.java', 'TestMetadataTableReadableMetrics.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestParquetScan.java', 'TestPartitionPruning.java', 'TestPartitionValues.java', 'TestPathIdentifier.java', 'TestPositionDeletesTable.java', 'TestReadProjection.java', 'TestRequiredDistributionAndOrdering.java', 'TestRuntimeFiltering.java', 'TestSnapshotSelection.java', 'TestSparkAggregates.java', 'TestSparkAppenderFactory.java', 'TestSparkCatalog.java', 'TestSparkCatalogCacheExpiration.java', 'TestSparkCatalogHadoopOverrides.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestSparkFileWriterFactory.java', 'TestSparkMergingMetrics.java', 'TestSparkMetadataColumns.java', 'TestSparkPartitioningWriters.java', 'TestSparkPositionDeltaWriters.java', 'TestSparkReadMetrics.java', 'TestSparkReadProjection.java', 'TestSparkReaderDeletes.java', 'TestSparkReaderWithBloomFilter.java', 'TestSparkRollingFileWriters.java', 'TestSparkScan.java', 'TestSparkStagedScan.java', 'TestSparkTable.java', 'TestSparkWriterMetrics.java', 'TestStreamingOffset.java', 'TestStructuredStreaming.java', 'TestStructuredStreamingRead3.java', 'TestTables.java', 'TestTimestampWithoutZone.java', 'TestWriteMetricsConfig.java', 'ThreeColumnRecord.java', 'PartitionedWritesTestBase.java', 'TestAggregatePushDown.java', 'TestAlterTable.java', 'TestCreateTable.java', 'TestCreateTableAsSelect.java', 'TestDeleteFrom.java', 'TestDropTable.java', 'TestFilterPushDown.java', 'TestNamespaceSQL.java', 'TestPartitionedWrites.java', 'TestPartitionedWritesAsSelect.java', 'TestPartitionedWritesToBranch.java', 'TestPartitionedWritesToWapBranch.java', 'TestRefreshTable.java', 'TestSelect.java', 'TestSparkBucketFunction.java', 'TestSparkDaysFunction.java', 'TestSparkHoursFunction.java', 'TestSparkMonthsFunction.java', 'TestSparkTruncateFunction.java', 'TestSparkYearsFunction.java', 'TestStoragePartitionedJoins.java', 'TestTimestampWithoutZone.java', 'TestUnpartitionedWrites.java', 'TestUnpartitionedWritesToBranch.java', 'UnpartitionedWritesTestBase.java']"
Spark 3.5: Initial support,95,4217,2023-09-18 15:12:09-07:00,"['jmh-benchmarks.yml', 'publish-snapshot.yml', 'recurring-jmh-benchmarks.yml', 'spark-ci.yml', '.gitignore', 'gradle.properties', 'libs.versions.toml', 'jmh.gradle', 'settings.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'DeleteFileIndexBenchmark.java', 'MergeCardinalityCheckBenchmark.java', 'PlanningBenchmark.java', 'TaskGroupPlanningBenchmark.java', 'IcebergSparkSessionExtensions.scala', 'AlignRowLevelCommandAssignments.scala', 'AlignedRowLevelIcebergCommandCheck.scala', 'AssignmentAlignmentSupport.scala', 'CheckMergeIntoTableConditions.scala', 'MergeIntoIcebergTableResolutionCheck.scala', 'ResolveMergeIntoTableReferences.scala', 'RewriteMergeIntoTable.scala', 'RewriteRowLevelIcebergCommand.scala', 'RewriteUpdateTable.scala', 'AssignmentUtils.scala', 'ExtendedReplaceNullWithFalseInPredicate.scala', 'ExtendedSimplifyConditionalsInPredicate.scala', 'IcebergSparkSqlExtensionsParser.scala', 'RewrittenRowLevelCommand.scala', 'Call.scala', 'MergeIntoIcebergTable.scala', 'MergeRows.scala', 'NoStatsUnaryNode.scala', 'ReplaceIcebergData.scala', 'RowLevelCommand.scala', 'UnresolvedMergeIntoIcebergTable.scala', 'UpdateIcebergTable.scala', 'UpdateRows.scala', 'V2WriteCommandLike.scala', 'WriteIcebergDelta.scala', 'ExtendedDataSourceV2Implicits.scala', 'ExtendedDataSourceV2Strategy.scala', 'ExtendedV2Writes.scala', 'MergeRowsExec.scala', 'ReplaceDataExec.scala', 'ReplaceRewrittenRowLevelCommand.scala', 'RowLevelCommandScanRelationPushDown.scala', 'UpdateRowsExec.scala', 'RowLevelCommandDynamicPruning.scala', 'TestAddFilesProcedure.java', 'TestDelete.java', 'TestMerge.java', 'TestSnapshotTableProcedure.java', 'TestStoragePartitionedJoinsInRowLevelOperations.java', 'TestUpdate.java', 'SmokeTest.java', 'SparkBenchmarkUtil.java', 'DeleteOrphanFilesBenchmark.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'IcebergSourceParquetEqDeleteBenchmark.java', 'IcebergSourceParquetMultiDeleteFileBenchmark.java', 'IcebergSourceParquetPosDeleteBenchmark.java', 'IcebergSourceParquetWithUnrelatedDeleteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'VectorizedReadParquetDecimalBenchmark.java', 'Spark3Util.java', 'CreateChangelogViewProcedure.java', 'SparkPositionDeltaOperation.java', 'NoSuchProcedureException.java', 'TestSparkSchemaUtil.java', 'TestCreateActions.java', 'TestDataFrameWriterV2.java', 'TestDataFrameWrites.java', 'TestStoragePartitionedJoins.java']"
"Core, Spark 3.4:  Write properties of PositionDeletesTable should respect ones of BaseTable (#8428)",2,38,2023-09-19 10:55:25+08:00,"['PositionDeletesTable.java', 'TestCompressionSettings.java']"
Spark 3.5: Remove conditional testing in TestCompressionSettings (#8584),1,26,2023-09-19 08:14:43+02:00,['TestCompressionSettings.java']
"Fix incorrect metrics in ParquetUtil (#8559)

Statistics might be missing when hasNonNullValue is false.",2,68,2023-09-19 14:21:49+02:00,"['ParquetUtil.java', 'TestParquet.java']"
Nessie: Permit Iceberg GC via explicit property overrides (#8382),5,135,2023-09-19 16:08:20+02:00,"['NessieCatalog.java', 'NessieTableOperations.java', 'NessieUtil.java', 'BaseTestIceberg.java', 'TestNessieTable.java']"
Spark 3.5: Remove date logic with `anyToMicros` (#8585),1,13,2023-09-19 13:24:50-07:00,['SparkValueConverter.java']
"Spark 3.5: Add tests for WHEN NOT MATCHED BY SOURCE clauses (#8592)

This resolves #8276.",1,101,2023-09-19 13:26:43-07:00,['TestMerge.java']
"Build: Fix Gradle issue for consuming projects with Maven classifier (#8588)

For some reason, Gradle has issues to detect the maven classifier
properly in a consuming project from Gradle metadata.

The issue has been reported in
https://youtrack.jetbrains.com/issue/IDEA-327421/IJ-fails-to-import-Gradle-project-with-dependency-with-classifier
and in https://github.com/gradle/gradle/issues/15756.

I'm able to verify that this workaround fixes the issue for consuming
projects.",11,118,2023-09-20 08:23:44+02:00,"['build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle', 'build.gradle']"
Spark 3.4: Throw better exception when filter expression cannot be translated in Rewrite procedure (#8394),3,53,2023-09-20 08:35:03+02:00,"['TestRewriteDataFilesProcedure.java', 'TestRewritePositionDeleteFilesProcedure.java', 'SparkExpressionConverter.scala']"
"Core: Switch tests to JUnit5 in avro, data.avro packages (#8380)",5,493,2023-09-20 08:41:03+02:00,"['TestAvroNameMapping.java', 'TestAvroReadProjection.java', 'TestBuildAvroProjection.java', 'TestReadProjection.java', 'TestDecoderResolver.java']"
"Python: Compute parquet stats (#7831)

* Add function to compute parquet file metadata

* Addition of docstring and extra parameter to avoid reading the file
unnecessarily

* Refactor the statistics computation entirely to use pyarrow metadata

This commit makes sure to test the metadata computation both using
`pyarrow.parquet.ParqueWriter` and `pyarrow.parquet.write_to_dataset`.

* Appease pre-commit hooks

* Fix temporary path

* Make the metrics mode configurable as documented here: https://iceberg.apache.org/docs/latest/configuration/

* Initialize binary serializers only once

* Log arrow not implemented exception

* Fix None comparison expression

* Add map column to test data

* Moving pyarrow specific code to io.pyarrow

* type annotation

* Refactor the stats collection using the pyarrow visitor

* Clean redundant code and add warning message to the log

* Address some of the review comments

* Add tests to check of the number of columns found by the statistics
collector is correct

* We don't want to truncate numeric data types

* Verify match of Iceberg types with Parquet physical types

* Fix truncation of upper bounds

* Transform asserts to ValueErrors

* Add review suggestions

* Address simple code style review comments

* Fix potential null write

* Apply function name refactoring

* Move pyarrow statistics tests to a new file

* Disable stats computation for nested types

* Modularize the fill_parquet_file_metadata function

* Allow metrics modes to have extra whitespace but not other trailing
characters

* Move upper bound truncation logic to another file

* Be defensive with regards to missing row group statistics

* Add tests for structs

* Remove special treatment of UUIDType

* Rely on parquet column path rather than column order

This commit adds a visitor to compute a mapping from
parquet column path to iceberg field ID.

* Change mood to imperative to appease linter

* Factor out the logic to obtain the current table schema",5,1318,2023-09-20 12:59:17+02:00,"['__init__.py', 'pyarrow.py', 'truncate.py', 'test_pyarrow_stats.py', 'test_truncate.py']"
Core: Enable strict metadata cleanup by default (#8599),2,10,2023-09-20 12:04:48-07:00,"['TableOperations.java', 'RESTTableOperations.java']"
"Python: Register table functionality for SQL Catalog (#8589)

* Add register table implementation for sql catalog

* Fix lint",2,51,2023-09-20 22:37:33+02:00,"['sql.py', 'test_sql.py']"
Core: Add UUID to ViewMetadata (#8591),11,110,2023-09-20 14:19:32-07:00,"['MetadataUpdate.java', 'ViewMetadata.java', 'ViewMetadataParser.java', 'TestViewMetadata.java', 'TestViewMetadataParser.java', 'ValidViewMetadata.json', 'ViewMetadataInvalidCurrentSchema.json', 'ViewMetadataInvalidCurrentVersion.json', 'ViewMetadataMissingCurrentVersion.json', 'ViewMetadataMissingLocation.json', 'view-spec.md']"
Core: Default to local planning if column stats must be serialized (#8595),1,29,2023-09-20 14:24:31-07:00,['BaseDistributedDataScan.java']
Core: Don't persist counts for paths and positions in position delete files (#8590),3,80,2023-09-20 14:30:31-07:00,"['MetricsUtil.java', 'PositionDeleteWriter.java', 'TestFileWriterFactory.java']"
Spark 3.5: Add distibuted planning benchmarks (#8594),1,100,2023-09-20 15:37:15-07:00,['PlanningBenchmark.java']
"Spark 3.1, 3.2, 3.3, 3.5: Throw better exception when filter expression cannot be translated in Rewrite procedure (#8605)",10,173,2023-09-21 07:29:44+02:00,"['TestRewriteDataFilesProcedure.java', 'SparkExpressionConverter.scala', 'TestRewriteDataFilesProcedure.java', 'SparkExpressionConverter.scala', 'TestRewriteDataFilesProcedure.java', 'TestRewritePositionDeleteFilesProcedure.java', 'SparkExpressionConverter.scala', 'TestRewriteDataFilesProcedure.java', 'TestRewritePositionDeleteFilesProcedure.java', 'SparkExpressionConverter.scala']"
Spec: Mark added_snapshot_id as optional (#8600),1,2,2023-09-21 10:41:19+02:00,['spec.md']
Spark 3.5: Fix metrics reporting in distributed planning (#8602),6,185,2023-09-21 08:57:29-07:00,"['BaseTable.java', 'ScanPlanningAndReportingTestBase.java', 'TestCommitReporting.java', 'TestLocalScanPlanningAndReporting.java', 'SparkDistributedDataScan.java', 'TestSparkDistributedDataScanReporting.java']"
Spark 3.5: Add tests for distributed planning with deletes (#8604),1,22,2023-09-21 08:58:03-07:00,['TestSparkReaderDeletes.java']
"Nessie: Bump Nessie to 0.71.0, adjust to Nessie client-builder updates (#8607)",4,93,2023-09-21 18:24:16+02:00,"['libs.versions.toml', 'NessieCatalog.java', 'TestCustomNessieClient.java', 'org.projectnessie.client.NessieClientBuilder']"
"Core: Default to zstd compression for Parquet in new tables (#8593)

Co-authored-by: Szehon Ho <szehon.apache@gmail.com>
Co-authored-by: Szehon Ho <szehon_ho@apple.com>
Co-authored-by: Kyle Bendickson <kjbendickson@gmail.com>",15,243,2023-09-21 09:46:15-07:00,"['TableMetadata.java', 'TableProperties.java', 'TestTableMetadata.java', 'TestFlinkCatalogTable.java', 'TestCompressionSettings.java', 'TestFlinkCatalogTable.java', 'TestCompressionSettings.java', 'TestFlinkCatalogTable.java', 'TestCompressionSettings.java', 'TestHiveCatalog.java', 'TestCatalogs.java', 'TestHiveIcebergStorageHandlerNoScan.java', 'TestMetadataTableReadableMetrics.java', 'TestMetadataTableReadableMetrics.java', 'TestMetadataTableReadableMetrics.java']"
"Flink: table supplier in writer operator for optional table refresh (#8555)

* Flink: provide table supplier for optional table reload

* add log for reload

* open table loader if needed

* reload table at commit in committer

* store initial table props in manifest util

* PR feedback

* comment grammar

* use junit5 for new test

* spacing

* explicit refresh of table

* reload test fix

* PR cleanup feedback

* remove jitter, rename vars

* update log statement

* javadoc fix

* test assertion fix

* log warning on reload failure

* refresh table in writer at startup also

* specify table supplier in sink builder

* add comments

* comment typo

* update method name

* use table loader interface instead of table supplier

* check if table loader is already open

* PR feedback

* checkstyle

* package private method

* grammar/typo

* revert back to table supplier

* test fix

* update test name

* change param to SerializableTable

* update test assertion

* move refresh interval config to Flink config

* javadoc

* duration config

* test fix

* store last load time instead of next

* add duration type support for config

* refresh table on get in supplier

* fix comment

* ensure initial table is used for schema for now

* refresh before creating task writer",19,539,2023-09-21 11:47:14-07:00,"['OutputFileFactory.java', 'build.gradle', 'FlinkConfParser.java', 'FlinkWriteConf.java', 'FlinkWriteOptions.java', 'TableLoader.java', 'CachingTableSupplier.java', 'FlinkManifestUtil.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'ManifestOutputFileFactory.java', 'RowDataTaskWriterFactory.java', 'TestFlinkConfParser.java', 'TestTableLoader.java', 'TestCachingTableSupplier.java', 'TestCompressionSettings.java', 'TestFlinkIcebergSink.java', 'TestFlinkManifest.java', 'TestIcebergStreamWriter.java']"
Core: Track metadata file location in ViewMetadata (#8608),4,137,2023-09-21 12:44:10-07:00,"['ViewMetadata.java', 'ViewMetadataParser.java', 'TestViewMetadata.java', 'TestViewMetadataParser.java']"
"Core: Add a validation API to DeleteFiles which validates files exist (#8525)

prior to attempting to deletion.

Simplify/improve the validation check

Use failMissingDeletePaths, more simplification",3,57,2023-09-21 14:03:06-07:00,"['DeleteFiles.java', 'StreamingDelete.java', 'TestDeleteFiles.java']"
Spark 3.4: Fix metrics reporting in distributed planning (#8613),2,112,2023-09-21 14:29:04-07:00,"['SparkDistributedDataScan.java', 'TestSparkDistributedDataScanReporting.java']"
Spark 3.4: Add tests for distributed planning with deletes (#8615),1,22,2023-09-21 17:12:32-07:00,['TestSparkReaderDeletes.java']
Python: Remove D106 Docstring Issue (#8618),1,2,2023-09-22 09:36:10+02:00,['.pre-commit-config.yaml']
"Flink 1.15, 1.16: Table supplier in writer operator for optional table refresh",39,1014,2023-09-22 09:42:12+02:00,"['build.gradle', 'FlinkConfParser.java', 'FlinkWriteConf.java', 'FlinkWriteOptions.java', 'TableLoader.java', 'CachingTableSupplier.java', 'FlinkManifestUtil.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'ManifestOutputFileFactory.java', 'RowDataTaskWriterFactory.java', 'TestFlinkConfParser.java', 'TestTableLoader.java', 'TestCachingTableSupplier.java', 'TestCompressionSettings.java', 'TestFlinkIcebergSink.java', 'TestFlinkManifest.java', 'TestIcebergStreamWriter.java', 'build.gradle', 'FlinkConfParser.java', 'FlinkWriteConf.java', 'FlinkWriteOptions.java', 'TableLoader.java', 'CachingTableSupplier.java', 'FlinkManifestUtil.java', 'FlinkSink.java', 'IcebergFilesCommitter.java', 'ManifestOutputFileFactory.java', 'RowDataTaskWriterFactory.java', 'TestFlinkConfParser.java', 'TestTableLoader.java', 'TestCachingTableSupplier.java', 'TestCompressionSettings.java', 'TestFlinkIcebergSink.java', 'TestFlinkManifest.java', 'TestIcebergStreamWriter.java', 'FlinkWriteConf.java', 'FlinkWriteOptions.java', 'TestFlinkIcebergSink.java']"
"Python: Add `__repr__` method to Table class (#8447)

* Python: Add __repr__ method to Table class

* update test for __repr__ of Table class

* add sort_order to table repr

---------

Co-authored-by: Thi Cam Tu Phan <u7779236@anu.edu.au>",2,22,2023-09-22 13:09:55+02:00,"['__init__.py', 'test_init.py']"
Python: Create HadoopFileSystem from netloc (merge request !1060) (#8596),2,63,2023-09-22 13:25:38+02:00,"['pyarrow.py', 'test_pyarrow.py']"
"Python: Improve Glue catalog using Boto3 types (#8304)

* Python: improve Glue catalog using Boto3 types

* fix: address PR feedback

---------

Co-authored-by: Fokko Driesprong <fokko@apache.org>",4,1035,2023-09-22 14:10:25+02:00,"['poetry.lock', 'glue.py', 'pyproject.toml', 'test_glue.py']"
AWS: Remove deprecated APIs for 1.4.0 (#8612),23,2279,2023-09-22 16:45:03+02:00,"['TestAssumeRoleAwsClientFactory.java', 'TestDefaultAwsClientFactory.java', 'GlueTestBase.java', 'TestGlueCatalogLock.java', 'TestGlueCatalogTable.java', 'LakeFormationTestBase.java', 'TestLakeFormationAwsClientFactory.java', 'TestS3FileIOIntegration.java', 'ApacheHttpClientConfigurations.java', 'AssumeRoleAwsClientFactory.java', 'AwsClientFactories.java', 'AwsClientProperties.java', 'AwsProperties.java', 'UrlConnectionHttpClientConfigurations.java', 'GlueCatalog.java', 'LakeFormationAwsClientFactory.java', 'S3FileIOProperties.java', 'TestAwsClientFactories.java', 'TestAwsProperties.java', 'TestHttpClientConfigurations.java', 'TestHttpClientProperties.java', 'TestS3FileIOProperties.java', 'TestGlueCatalog.java']"
"Core: Move a column with the same name as a deleted column (#8325)

* allow move a column naming the same as a deleted column

* refactor

* stylistic fixes

* fix code style

* fix toString of Move

* comments

* fix the compilation

* fix merge errors",2,196,2023-09-22 17:32:38+02:00,"['SchemaUpdate.java', 'TestSchemaUpdate.java']"
"Python: Add `__repr__` for `Catalog` (#8558)

* Python: Add `__repr__` for `Table` and `Catalog`

* remove properties in `__repr__` output

* remove table `__repr__`

* clean up catalog __repr__ and add test

* actually use repr instead of str

* Update python/tests/catalog/test_base.py

Co-authored-by: Fokko Driesprong <fokko@apache.org>

* Update python/pyiceberg/catalog/__init__.py

* Update python/tests/catalog/test_base.py

---------

Co-authored-by: Fokko Driesprong <fokko@apache.org>",2,9,2023-09-22 17:34:27+02:00,"['__init__.py', 'test_base.py']"
"Python: Replace `isort`, `pylint`, `prettier`, `pyupgrade` & `flake8` with `ruff` (#8408)",9,126,2023-09-22 22:17:47+02:00,"['.pre-commit-config.yaml', 'decoder_fast.pyi', 'decoder_fast.pyx', 'hive.py', 'pyarrow.py', 'metadata.py', 'transforms.py', 'pyproject.toml', 'test_hive.py']"
"Build: Bump mkdocs from 1.5.2 to 1.5.3 in /python (#8633)

Bumps [mkdocs](https://github.com/mkdocs/mkdocs) from 1.5.2 to 1.5.3.
- [Release notes](https://github.com/mkdocs/mkdocs/releases)
- [Commits](https://github.com/mkdocs/mkdocs/compare/1.5.2...1.5.3)

---
updated-dependencies:
- dependency-name: mkdocs
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-09-24 19:51:15+02:00,['requirements.txt']
"Build: Bump mkdocs-material-extensions from 1.1.1 to 1.2 in /python (#8632)

Bumps [mkdocs-material-extensions](https://github.com/facelessuser/mkdocs-material-extensions) from 1.1.1 to 1.2.
- [Release notes](https://github.com/facelessuser/mkdocs-material-extensions/releases)
- [Changelog](https://github.com/facelessuser/mkdocs-material-extensions/blob/master/changelog.md)
- [Commits](https://github.com/facelessuser/mkdocs-material-extensions/compare/1.1.1...1.2)

---
updated-dependencies:
- dependency-name: mkdocs-material-extensions
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-09-24 19:51:23+02:00,['requirements.txt']
"Build: Bump moto from 4.2.3 to 4.2.4 in /python (#8631)

Bumps [moto](https://github.com/getmoto/moto) from 4.2.3 to 4.2.4.
- [Release notes](https://github.com/getmoto/moto/releases)
- [Changelog](https://github.com/getmoto/moto/blob/master/CHANGELOG.md)
- [Commits](https://github.com/getmoto/moto/compare/4.2.3...4.2.4)

---
updated-dependencies:
- dependency-name: moto
  dependency-type: direct:development
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,53,2023-09-24 19:51:29+02:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump pypa/cibuildwheel from 2.15.0 to 2.16.0 (#8629)

Bumps [pypa/cibuildwheel](https://github.com/pypa/cibuildwheel) from 2.15.0 to 2.16.0.
- [Release notes](https://github.com/pypa/cibuildwheel/releases)
- [Changelog](https://github.com/pypa/cibuildwheel/blob/main/docs/changelog.md)
- [Commits](https://github.com/pypa/cibuildwheel/compare/v2.15.0...v2.16.0)

---
updated-dependencies:
- dependency-name: pypa/cibuildwheel
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-09-24 19:52:08+02:00,['python-release.yml']
Core: Move ViewVersion#check() to Immutable class (#8634),4,33,2023-09-24 14:14:21-07:00,"['revapi.yml', 'ViewVersion.java', 'BaseViewVersion.java', 'TestViewVersionParser.java']"
Flink: Implement data statistics coordinator to aggregate data statistics from operator subtasks (#7360),13,1480,2023-09-24 20:57:16-07:00,"['AggregatedStatistics.java', 'AggregatedStatisticsTracker.java', 'DataStatisticsCoordinator.java', 'DataStatisticsCoordinatorProvider.java', 'DataStatisticsEvent.java', 'DataStatisticsOperator.java', 'DataStatisticsOrRecord.java', 'DataStatisticsUtil.java', 'TestAggregatedStatistics.java', 'TestAggregatedStatisticsTracker.java', 'TestDataStatisticsCoordinator.java', 'TestDataStatisticsCoordinatorProvider.java', 'TestDataStatisticsOperator.java']"
"Build: Bump pytest from 7.4.1 to 7.4.2 in /python (#8630)

Bumps [pytest](https://github.com/pytest-dev/pytest) from 7.4.1 to 7.4.2.
- [Release notes](https://github.com/pytest-dev/pytest/releases)
- [Changelog](https://github.com/pytest-dev/pytest/blob/main/CHANGELOG.rst)
- [Commits](https://github.com/pytest-dev/pytest/compare/7.4.1...7.4.2)

---
updated-dependencies:
- dependency-name: pytest
  dependency-type: direct:development
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",2,10,2023-09-25 08:22:19+02:00,"['poetry.lock', 'pyproject.toml']"
"Build: Bump mkdocs-material from 9.3.1 to 9.4.1 in /python (#8628)

Bumps [mkdocs-material](https://github.com/squidfunk/mkdocs-material) from 9.3.1 to 9.4.1.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/CHANGELOG)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/9.3.1...9.4.1)

---
updated-dependencies:
- dependency-name: mkdocs-material
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-09-25 08:22:35+02:00,['requirements.txt']
"Build: Bump mkdocs-literate-nav from 0.6.0 to 0.6.1 in /python (#8627)

Bumps [mkdocs-literate-nav](https://github.com/oprypin/mkdocs-literate-nav) from 0.6.0 to 0.6.1.
- [Release notes](https://github.com/oprypin/mkdocs-literate-nav/releases)
- [Commits](https://github.com/oprypin/mkdocs-literate-nav/compare/v0.6.0...v0.6.1)

---
updated-dependencies:
- dependency-name: mkdocs-literate-nav
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-09-25 08:22:50+02:00,['requirements.txt']
Spark: Correct partition transform functions to match Spec (#8192),15,525,2023-09-25 14:57:12+02:00,"['TestAlterTablePartitionFields.java', 'Spark3Util.java', 'TestCreateTable.java', 'TestAlterTablePartitionFields.java', 'Spark3Util.java', 'TestCreateTable.java', 'TestAlterTablePartitionFields.java', 'Spark3Util.java', 'TestCreateTable.java', 'TestAlterTablePartitionFields.java', 'Spark3Util.java', 'TestCreateTable.java', 'TestAlterTablePartitionFields.java', 'Spark3Util.java', 'TestCreateTable.java']"
Docs: Update spark partition transform as per Spec (#8640),1,18,2023-09-25 17:32:09+02:00,['spark-ddl.md']
AWS: Replace FileOutputStream/InputStream constructor with NIO Files APIs (#8626),1,16,2023-09-25 11:34:27-07:00,['S3OutputStream.java']
AWS: Fix DefaultAwsClientFactory#S3FileIOEndpointOverride test (#8643),1,2,2023-09-25 13:33:17-07:00,['TestDefaultAwsClientFactory.java']
"Open-API: Make the CI happy (#8647)

The new 2.4.0 release of Pydantic breaks the
Python code generator",1,4,2023-09-26 09:38:00+02:00,['requirements.txt']
Spark 3.5: Remove legacy configs for timestamps without zone (#8654),8,157,2023-09-26 09:59:10-07:00,"['SparkCatalog.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkSQLProperties.java', 'SparkUtil.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'TestTimestampWithoutZone.java']"
Spark 3.5: Drop the remove_carryovers flag for CDC view creation (#8656),2,91,2023-09-26 13:04:09-07:00,"['TestCreateChangelogViewProcedure.java', 'CreateChangelogViewProcedure.java']"
Spark 3.5: Use fanout writers for unsorted tables by default (#8621),9,515,2023-09-26 16:04:30-07:00,"['TestRequiredDistributionAndOrdering.java', 'TestWriteAborts.java', 'SparkWriteConf.java', 'SparkPositionDeltaWrite.java', 'SparkWrite.java', 'TestSparkDistributionAndOrderingUtil.java', 'TestFilteredScan.java', 'TestPartitionValues.java', 'TestRequiredDistributionAndOrdering.java']"
Flink: Support alter table column (#7628),6,717,2023-09-26 21:47:15-07:00,"['FlinkCatalog.java', 'FlinkSchemaUtil.java', 'FlinkTypeToType.java', 'FlinkAlterTableUtil.java', 'FlinkCompatibilityUtil.java', 'TestFlinkCatalogTable.java']"
Spark 3.1: Remove module (#8661),374,72189,2023-09-27 13:03:45-07:00,"['spark-ci.yml', '.gitignore', 'stage-binaries.sh', 'gradle.properties', 'libs.versions.toml', 'jmh.gradle', 'settings.gradle', 'build.gradle', 'build.gradle', 'IcebergSqlExtensions.g4', 'IcebergSparkSessionExtensions.scala', 'AlignRowLevelOperations.scala', 'AssignmentAlignmentSupport.scala', 'ProcedureArgumentCoercion.scala', 'ResolveProcedures.scala', 'RowLevelOperationsPredicateCheck.scala', 'AccumulateFiles.scala', 'OptimizeConditionsInRowLevelOperations.scala', 'PullupCorrelatedPredicatesInRowLevelOperations.scala', 'RewriteDelete.scala', 'RewriteMergeInto.scala', 'RewriteUpdate.scala', 'IcebergSparkSqlExtensionsParser.scala', 'IcebergSqlExtensionsAstBuilder.scala', 'AddPartitionField.scala', 'BranchOptions.scala', 'Call.scala', 'CreateOrReplaceBranch.scala', 'CreateOrReplaceTag.scala', 'DropBranch.scala', 'DropIdentifierFields.scala', 'DropPartitionField.scala', 'DropTag.scala', 'DynamicFileFilter.scala', 'MergeInto.scala', 'ReplaceData.scala', 'ReplacePartitionField.scala', 'SetIdentifierFields.scala', 'TagOptions.scala', 'statements.scala', 'RewriteRowLevelOperationHelper.scala', 'SetAccumulator.scala', 'AddPartitionFieldExec.scala', 'CallExec.scala', 'CreateOrReplaceBranchExec.scala', 'CreateOrReplaceTagExec.scala', 'DropBranchExec.scala', 'DropIdentifierFieldsExec.scala', 'DropPartitionFieldExec.scala', 'DropTagExec.scala', 'DynamicFileFilterExec.scala', 'ExtendedBatchScanExec.scala', 'ExtendedDataSourceV2Implicits.scala', 'ExtendedDataSourceV2Strategy.scala', 'MergeIntoExec.scala', 'ReplaceDataExec.scala', 'ReplacePartitionFieldExec.scala', 'SetIdentifierFieldsExec.scala', 'SetWriteDistributionAndOrderingExec.scala', 'Employee.java', 'SparkExtensionsTestBase.java', 'SparkRowLevelOperationsTestBase.java', 'TestAddFilesProcedure.java', 'TestAlterTablePartitionFields.java', 'TestAlterTableSchema.java', 'TestAncestorsOfProcedure.java', 'TestBranchDDL.java', 'TestCallStatementParser.java', 'TestCherrypickSnapshotProcedure.java', 'TestCopyOnWriteDelete.java', 'TestCopyOnWriteMerge.java', 'TestCopyOnWriteUpdate.java', 'TestDelete.java', 'TestExpireSnapshotsProcedure.java', 'TestIcebergExpressions.java', 'TestMerge.java', 'TestMetadataTables.java', 'TestMigrateTableProcedure.java', 'TestPublishChangesProcedure.java', 'TestRemoveOrphanFilesProcedure.java', 'TestRewriteDataFilesProcedure.java', 'TestRewriteManifestsProcedure.java', 'TestRollbackToSnapshotProcedure.java', 'TestRollbackToTimestampProcedure.java', 'TestSetCurrentSnapshotProcedure.java', 'TestSetWriteDistributionAndOrdering.java', 'TestSnapshotTableProcedure.java', 'TestTagDDL.java', 'TestUpdate.java', 'LICENSE', 'NOTICE', 'SmokeTest.java', 'SparkBenchmarkUtil.java', 'SparkParquetReadersFlatDataBenchmark.java', 'SparkParquetReadersNestedDataBenchmark.java', 'SparkParquetWritersFlatDataBenchmark.java', 'SparkParquetWritersNestedDataBenchmark.java', 'Action.java', 'IcebergSourceBenchmark.java', 'IcebergSourceDeleteBenchmark.java', 'IcebergSourceFlatDataBenchmark.java', 'IcebergSourceNestedDataBenchmark.java', 'IcebergSourceNestedListDataBenchmark.java', 'WritersBenchmark.java', 'AvroWritersBenchmark.java', 'IcebergSourceFlatAvroDataReadBenchmark.java', 'IcebergSourceNestedAvroDataReadBenchmark.java', 'IcebergSourceFlatORCDataBenchmark.java', 'IcebergSourceFlatORCDataReadBenchmark.java', 'IcebergSourceNestedListORCDataWriteBenchmark.java', 'IcebergSourceNestedORCDataReadBenchmark.java', 'IcebergSourceFlatParquetDataFilterBenchmark.java', 'IcebergSourceFlatParquetDataReadBenchmark.java', 'IcebergSourceFlatParquetDataWriteBenchmark.java', 'IcebergSourceNestedListParquetDataWriteBenchmark.java', 'IcebergSourceNestedParquetDataFilterBenchmark.java', 'IcebergSourceNestedParquetDataReadBenchmark.java', 'IcebergSourceNestedParquetDataWriteBenchmark.java', 'IcebergSourceParquetDeleteBenchmark.java', 'IcebergSourceParquetMultiDeleteFileBenchmark.java', 'IcebergSourceParquetWithUnrelatedDeleteBenchmark.java', 'ParquetWritersBenchmark.java', 'VectorizedReadDictionaryEncodedFlatParquetDataBenchmark.java', 'VectorizedReadFlatParquetDataBenchmark.java', 'BaseCatalog.java', 'CommitMetadata.java', 'FileRewriteCoordinator.java', 'FileScanTaskSetManager.java', 'IcebergSpark.java', 'JobGroupInfo.java', 'JobGroupUtils.java', 'OrderField.java', 'PathIdentifier.java', 'PruneColumnsWithReordering.java', 'PruneColumnsWithoutReordering.java', 'RollbackStagedTable.java', 'SortOrderToSpark.java', 'Spark3Util.java', 'SparkCatalog.java', 'SparkConfParser.java', 'SparkDataFile.java', 'SparkExceptionUtil.java', 'SparkFilters.java', 'SparkFixupTimestampType.java', 'SparkFixupTypes.java', 'SparkReadConf.java', 'SparkReadOptions.java', 'SparkSQLProperties.java', 'SparkSchemaUtil.java', 'SparkSessionCatalog.java', 'SparkStructLike.java', 'SparkTableUtil.java', 'SparkTypeToType.java', 'SparkTypeVisitor.java', 'SparkUtil.java', 'SparkValueConverter.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'TypeToSparkType.java', 'BaseDeleteOrphanFilesSparkAction.java', 'BaseDeleteReachableFilesSparkAction.java', 'BaseExpireSnapshotsSparkAction.java', 'BaseMigrateTableSparkAction.java', 'BaseRewriteDataFilesSpark3Action.java', 'BaseRewriteDataFilesSparkAction.java', 'BaseRewriteManifestsSparkAction.java', 'BaseSnapshotTableSparkAction.java', 'BaseSnapshotUpdateSparkAction.java', 'BaseSparkAction.java', 'BaseSparkActions.java', 'BaseTableCreationSparkAction.java', 'ManifestFileBean.java', 'SetAccumulator.java', 'Spark3BinPackStrategy.java', 'Spark3SortStrategy.java', 'SparkActions.java', 'AvroWithSparkSchemaVisitor.java', 'ParquetWithSparkSchemaVisitor.java', 'SparkAvroReader.java', 'SparkAvroWriter.java', 'SparkOrcReader.java', 'SparkOrcValueReaders.java', 'SparkOrcValueWriters.java', 'SparkOrcWriter.java', 'SparkParquetReaders.java', 'SparkParquetWriters.java', 'SparkValueReaders.java', 'SparkValueWriters.java', 'ArrowVectorAccessorFactory.java', 'ArrowVectorAccessors.java', 'ColumnVectorWithFilter.java', 'ColumnarBatchReader.java', 'ConstantColumnVector.java', 'IcebergArrowColumnVector.java', 'RowPositionColumnVector.java', 'VectorizedSparkOrcReaders.java', 'VectorizedSparkParquetReaders.java', 'AddFilesProcedure.java', 'AncestorsOfProcedure.java', 'BaseProcedure.java', 'CherrypickSnapshotProcedure.java', 'ExpireSnapshotsProcedure.java', 'MigrateTableProcedure.java', 'PublishChangesProcedure.java', 'RemoveOrphanFilesProcedure.java', 'RewriteDataFilesProcedure.java', 'RewriteManifestsProcedure.java', 'RollbackToSnapshotProcedure.java', 'RollbackToTimestampProcedure.java', 'SetCurrentSnapshotProcedure.java', 'SnapshotTableProcedure.java', 'SparkProcedures.java', 'BaseDataReader.java', 'BatchDataReader.java', 'EqualityDeleteRowReader.java', 'IcebergSource.java', 'InternalRowWrapper.java', 'RowDataReader.java', 'RowDataRewriter.java', 'SerializableTableWithSize.java', 'SparkAppenderFactory.java', 'SparkBatchQueryScan.java', 'SparkBatchScan.java', 'SparkFileWriterFactory.java', 'SparkFilesScan.java', 'SparkFilesScanBuilder.java', 'SparkMergeBuilder.java', 'SparkMergeScan.java', 'SparkMetadataColumn.java', 'SparkMicroBatchStream.java', 'SparkPartitionedFanoutWriter.java', 'SparkPartitionedWriter.java', 'SparkRewriteBuilder.java', 'SparkScanBuilder.java', 'SparkTable.java', 'SparkWrite.java', 'SparkWriteBuilder.java', 'StagedSparkTable.java', 'Stats.java', 'StreamingOffset.java', 'StructInternalRow.java', 'NoSuchProcedureException.java', 'ExtendedSupportsDelete.java', 'Procedure.java', 'ProcedureCatalog.java', 'ProcedureParameter.java', 'ProcedureParameterImpl.java', 'SupportsMerge.java', 'ClusteredDistribution.java', 'Distribution.java', 'Distributions.java', 'OrderedDistribution.java', 'UnspecifiedDistribution.java', 'ClusterDistributionImpl.java', 'OrderedDistributionImpl.java', 'UnspecifiedDistributionImpl.java', 'NullOrdering.java', 'SortDirection.java', 'SortOrder.java', 'SupportsFileFilter.java', 'MergeBuilder.java', 'org.apache.spark.sql.sources.DataSourceRegister', 'TransformExpressions.scala', 'SetWriteDistributionAndOrdering.scala', 'SortOrderParserUtil.scala', 'DistributionAndOrderingUtils.scala', 'PlanUtils.scala', 'SparkExpressionConverter.scala', 'KryoHelpers.java', 'TaskCheckHelper.java', 'TestDataFileSerialization.java', 'TestFileIOSerialization.java', 'TestManifestFileSerialization.java', 'TestScanTaskSerialization.java', 'TestTableSerialization.java', 'ValidationHelpers.java', 'SparkCatalogConfig.java', 'SparkCatalogTestBase.java', 'SparkTestBase.java', 'SparkTestBaseWithCatalog.java', 'TestFileRewriteCoordinator.java', 'TestSpark3Util.java', 'TestSparkCatalogOperations.java', 'TestSparkFilters.java', 'TestSparkSchemaUtil.java', 'TestSparkTableUtil.java', 'TestSparkValueConverter.java', 'TestCreateActions.java', 'TestDeleteReachableFilesAction.java', 'TestExpireSnapshotsAction.java', 'TestRemoveOrphanFilesAction.java', 'TestRemoveOrphanFilesAction3.java', 'TestRewriteDataFilesAction.java', 'TestRewriteManifestsAction.java', 'AvroDataTest.java', 'GenericsHelpers.java', 'RandomData.java', 'TestHelpers.java', 'TestOrcWrite.java', 'TestParquetAvroReader.java', 'TestParquetAvroWriter.java', 'TestSparkAvroEnums.java', 'TestSparkAvroReader.java', 'TestSparkDateTimes.java', 'TestSparkOrcReadMetadataColumns.java', 'TestSparkOrcReader.java', 'TestSparkParquetReadMetadataColumns.java', 'TestSparkParquetReader.java', 'TestSparkParquetWriter.java', 'TestSparkRecordOrcReaderWriter.java', 'TestParquetDictionaryEncodedVectorizedReads.java', 'TestParquetDictionaryFallbackToPlainEncodingVectorizedReads.java', 'TestParquetVectorizedReads.java', 'ComplexRecord.java', 'LogMessage.java', 'ManualSource.java', 'NestedRecord.java', 'SimpleRecord.java', 'SparkTestTable.java', 'TestAvroScan.java', 'TestDataFrameWrites.java', 'TestDataSourceOptions.java', 'TestFilteredScan.java', 'TestForwardCompatibility.java', 'TestIcebergSource.java', 'TestIcebergSourceHadoopTables.java', 'TestIcebergSourceHiveTables.java', 'TestIcebergSourceTablesBase.java', 'TestIcebergSpark.java', 'TestIdentityPartitionData.java', 'TestInternalRowWrapper.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestParquetScan.java', 'TestPartitionPruning.java', 'TestPartitionValues.java', 'TestPathIdentifier.java', 'TestReadProjection.java', 'TestSnapshotSelection.java', 'TestSparkAppenderFactory.java', 'TestSparkBaseDataReader.java', 'TestSparkCatalog.java', 'TestSparkCatalogCacheExpiration.java', 'TestSparkCatalogHadoopOverrides.java', 'TestSparkDataFile.java', 'TestSparkDataWrite.java', 'TestSparkFileWriterFactory.java', 'TestSparkFilesScan.java', 'TestSparkMergingMetrics.java', 'TestSparkMetadataColumns.java', 'TestSparkPartitioningWriters.java', 'TestSparkPositionDeltaWriters.java', 'TestSparkReadProjection.java', 'TestSparkReaderDeletes.java', 'TestSparkRollingFileWriters.java', 'TestSparkTable.java', 'TestSparkWriterMetrics.java', 'TestStreamingOffset.java', 'TestStructuredStreaming.java', 'TestStructuredStreamingRead3.java', 'TestTables.java', 'TestTimestampWithoutZone.java', 'TestWriteMetricsConfig.java', 'ThreeColumnRecord.java', 'TestAlterTable.java', 'TestCreateTable.java', 'TestCreateTableAsSelect.java', 'TestDeleteFrom.java', 'TestDropTable.java', 'TestNamespaceSQL.java', 'TestPartitionedWrites.java', 'TestRefreshTable.java', 'TestSelect.java', 'TestTimestampWithoutZone.java', 'TestUnpartitionedWrites.java']"
Spark 3.5: Increase default advisory partition size for writes (#8660),14,632,2023-09-27 13:08:41-07:00,"['TableProperties.java', 'TestDelete.java', 'TestMerge.java', 'TestUpdate.java', 'SparkCompressionUtil.java', 'SparkConfParser.java', 'SparkSQLProperties.java', 'SparkWriteConf.java', 'SparkWriteOptions.java', 'SparkWriteRequirements.java', 'SparkWriteUtil.java', 'SparkPositionDeltaWrite.java', 'SparkWrite.java', 'TestSparkCompressionUtil.java']"
Core: Drop unused MERGE cardinality check table properties (#8668),2,19,2023-09-27 14:09:41-07:00,"['revapi.yml', 'TableProperties.java']"
Spark 3.5: Never lower advisory partition size (#8667),2,27,2023-09-27 14:47:20-07:00,"['SparkWriteConf.java', 'TestSparkWriteConf.java']"
Build: Fix staging script to include Spark 3.5 (#8669),1,3,2023-09-27 15:36:08-07:00,['stage-binaries.sh']
Docs: Remove spark-3.1 mention (#8671),5,10,2023-09-28 11:16:26+02:00,"['BinPackStrategy.java', 'RewriteStrategy.java', 'SortStrategy.java', 'nessie.md', 'spark-writes.md']"
"Core: Fix view version ID reassigment and deduplication, start schema ID at 0 (#8664)",4,385,2023-09-28 09:49:10-07:00,"['ViewMetadata.java', 'TestViewMetadata.java', 'TestViewMetadataParser.java', 'ValidViewMetadata.json']"
Core: Add remaining View APIs and support for InMemoryCatalog (#7880),14,2721,2023-09-28 15:24:07-07:00,"['InMemoryCatalog.java', 'BaseMetastoreViewCatalog.java', 'BaseView.java', 'BaseViewOperations.java', 'PropertiesUpdate.java', 'ViewMetadata.java', 'ViewOperations.java', 'ViewUtil.java', 'ViewVersionReplace.java', 'TestInMemoryViewCatalog.java', 'TestViewMetadata.java', 'TestViewMetadataParser.java', 'ViewCatalogTests.java', 'ViewMetadataMultipleSQLsForDialect.json']"
Python: Update pre-commit (#8651),1,10,2023-09-28 15:47:38-07:00,['.pre-commit-config.yaml']
Python: Add more Ruff rules (#8652),1,13,2023-09-28 15:48:28-07:00,['pyproject.toml']
"Python: ManifestWriter and ManifestListWriter (#8622)

* add ManifestWriter and ManifestListWriter

* fix lint issue

* remove assert, fix format issue

* add prepare to ManifestWriter, remove TODO, fix format issue

* fix some nit issue, add prepare... to ensure the correctness of data written

* fix format issue

* fix lint issue

* avoid creating too much objects, handling v1, v2 data_file_type and DataFile class properly.

* modify tests

* refactor the way of handling two version of DataFile record

* add integration tests, fix bugs, change PartitionSummary to a function

* fix format issue

* make data_type_v2 constants",6,864,2023-09-29 11:00:29+02:00,"['writer.py', 'manifest.py', 'typedef.py', 'test_file.py', 'test_integration_manifest.py', 'test_manifest.py']"
Spark: Fix Decimal value conversion in V2 filters (#8682),6,68,2023-09-29 12:38:36-07:00,"['SparkV2Filters.java', 'TestFilterPushDown.java', 'SparkV2Filters.java', 'TestFilterPushDown.java', 'SparkV2Filters.java', 'TestFilterPushDown.java']"
AWS: avoid static global credentials provider which doesn't play well with lifecycle management (#8677),4,22,2023-10-01 18:55:31-07:00,"['AwsClientFactories.java', 'AwsClientProperties.java', 'AwsProperties.java', 'AwsClientPropertiesTest.java']"
"Docs: Add links to Go, Python and Rust (#8681)

* Add links to Go, Python and Rust

In alphabetic order :)

* Update README.md",1,8,2023-10-02 15:37:41+02:00,['README.md']
"Open-API: Add namespaceExist API (#8569)

* open-api: Add namespaceExist API

* Address feedback

* Reword exists API description

---------

Co-authored-by: Steve Zhang <hongyue_zhang@apple.com>",1,50,2023-10-02 21:12:10+02:00,['rest-catalog-open-api.yaml']
Labeler: Add Specification label (#8700),1,2,2023-10-02 13:56:58-07:00,['labeler.yml']
"API, Core: Allow setting a View's location (#8648)",7,252,2023-10-04 11:17:34+02:00,"['UpdateLocation.java', 'View.java', 'ViewBuilder.java', 'BaseMetastoreViewCatalog.java', 'BaseView.java', 'SetViewLocation.java', 'ViewCatalogTests.java']"
Docs: Document publish_changes procedure (#8706),1,38,2023-10-05 08:36:34+02:00,['spark-procedures.md']
OpenAPI: Add AssignUUID update to metadata updates (#8716),2,18,2023-10-05 11:23:10+02:00,"['rest-catalog-open-api.py', 'rest-catalog-open-api.yaml']"
Spec: Inconsistency around files_count (#5338),2,32,2023-10-05 21:51:37+02:00,"['ManifestFile.java', 'TestManifestListVersions.java']"
"Revert ""Spec: Mark added_snapshot_id as optional (#8600)"" (#8726)

This reverts commit f7a7eb2c10cb4a9b6b3ea5bfdfc5d085be8b9c31.",1,2,2023-10-05 13:05:51-07:00,['spec.md']
Build: Let revapi compare against 1.4.0 (#8727),1,2,2023-10-06 08:11:22+02:00,['build.gradle']
Build: Add 1.4.0 to issue template (#8728),1,3,2023-10-06 08:11:41+02:00,['iceberg_bug_report.yml']
Spark: Clean up FileIO instances on executors (#8685),8,264,2023-10-06 14:23:46-07:00,"['SerializableTableWithSize.java', 'TestTableSerialization.java', 'SerializableTableWithSize.java', 'TestTableSerialization.java', 'SerializableTableWithSize.java', 'TestTableSerialization.java', 'SerializableTableWithSize.java', 'TestTableSerialization.java']"
"Build: Bump com.google.cloud:libraries-bom from 26.18.0 to 26.24.0 (#8735)

Bumps [com.google.cloud:libraries-bom](https://github.com/googleapis/java-cloud-bom) from 26.18.0 to 26.24.0.
- [Release notes](https://github.com/googleapis/java-cloud-bom/releases)
- [Changelog](https://github.com/googleapis/java-cloud-bom/blob/main/release-please-config.json)
- [Commits](https://github.com/googleapis/java-cloud-bom/compare/v26.18.0...v26.24.0)

---
updated-dependencies:
- dependency-name: com.google.cloud:libraries-bom
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-09 08:11:46+02:00,['libs.versions.toml']
Python: Remove python directory and references (#8695),175,172520,2023-10-09 08:13:15+02:00,"['.gitattributes', 'dependabot.yml', 'labeler.yml', 'delta-conversion-ci.yml', 'flink-ci.yml', 'hive-ci.yml', 'java-ci.yml', 'python-ci-docs.yml', 'python-ci.yml', 'python-integration.yml', 'python-release.yml', 'spark-ci.yml', '.gitignore', 'README.md', '.pre-commit-config.yaml', 'LICENSE', 'MANIFEST.in', 'Makefile', 'NOTICE', 'README.md', 'build-module.py', '.rat-excludes', 'Dockerfile', 'check-license', 'docker-compose-azurite.yml', 'docker-compose-gcs-server.yml', 'docker-compose-integration.yml', 'docker-compose.yml', 'entrypoint.sh', 'provision.py', 'run-azurite.sh', 'run-gcs-server.sh', 'run-minio.sh', 'spark-defaults.conf', 'README.md', 'SUMMARY.md', 'api.md', 'iceberg-logo-icon.png', 'cli.md', 'configuration.md', 'contributing.md', 'feature-support.md', 'how-to-release.md', 'index.md', 'verify-release.md', 'gen_doc_stubs.py', 'mkdocs.yml', 'requirements.txt', 'poetry.lock', '__init__.py', '__init__.py', '__init__.py', 'bzip2.py', 'codec.py', 'deflate.py', 'snappy_codec.py', 'zstandard_codec.py', 'decoder.py', 'decoder_basic.c', 'decoder_fast.pyi', 'decoder_fast.pyx', 'encoder.py', 'file.py', 'reader.py', 'resolver.py', 'writer.py', '__init__.py', 'dynamodb.py', 'glue.py', 'hive.py', 'noop.py', 'rest.py', 'sql.py', '__init__.py', 'console.py', 'output.py', 'conversions.py', 'exceptions.py', '__init__.py', 'literals.py', 'parser.py', 'visitors.py', '__init__.py', 'fsspec.py', 'pyarrow.py', 'manifest.py', 'partitioning.py', 'py.typed', 'schema.py', 'serializers.py', '__init__.py', 'metadata.py', 'refs.py', 'snapshots.py', 'sorting.py', 'transforms.py', 'typedef.py', 'types.py', '__init__.py', 'bin_packing.py', 'concurrent.py', 'config.py', 'datetime.py', 'decimal.py', 'deprecated.py', 'lazydict.py', 'parsing.py', 'schema_conversion.py', 'singleton.py', 'truncate.py', 'pylintrc', 'pyproject.toml', 'test_decoder.py', 'test_encoder.py', 'test_file.py', 'test_reader.py', 'test_resolver.py', 'test_writer.py', 'integration_test_dynamodb.py', 'integration_test_glue.py', 'test_base.py', 'test_dynamodb.py', 'test_glue.py', 'test_hive.py', 'test_rest.py', 'test_sql.py', 'test_console.py', 'test_output.py', 'conftest.py', 'test_evaluator.py', 'test_expressions.py', 'test_literals.py', 'test_parser.py', 'test_projection.py', 'test_visitors.py', 'test_fsspec.py', 'test_io.py', 'test_pyarrow.py', 'test_pyarrow_stats.py', 'test_pyarrow_visitor.py', 'test_init.py', 'test_metadata.py', 'test_partitioning.py', 'test_refs.py', 'test_snapshots.py', 'test_sorting.py', 'test_conversions.py', 'test_integration.py', 'test_integration_manifest.py', 'test_integration_schema.py', 'test_schema.py', 'test_transforms.py', 'test_typedef.py', 'test_types.py', 'test_version.py', 'test_bin_packing.py', 'test_concurrent.py', 'test_config.py', 'test_datetime.py', 'test_decimal.py', 'test_deprecated.py', 'test_lazydict.py', 'test_manifest.py', 'test_schema_conversion.py', 'test_singleton.py', 'test_truncate.py', 'README.md', 'FacebookService.py', '__init__.py', 'constants.py', 'ttypes.py', 'ThriftHiveMetastore.py', '__init__.py', 'constants.py', 'ttypes.py']"
Nessie: Remove dead code in NessieCatalog (#8750),1,18,2023-10-09 09:38:15+02:00,['NessieCatalog.java']
"Build: Bump org.immutables:value from 2.9.2 to 2.10.0 (#8736)

Bumps [org.immutables:value](https://github.com/immutables/immutables) from 2.9.2 to 2.10.0.
- [Release notes](https://github.com/immutables/immutables/releases)
- [Commits](https://github.com/immutables/immutables/compare/2.9.2...2.10.0)

---
updated-dependencies:
- dependency-name: org.immutables:value
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-09 12:32:39+02:00,['libs.versions.toml']
OpenAPI: uniqueItems is not valid on type object (#8751),1,1,2023-10-09 16:09:58+02:00,['rest-catalog-open-api.yaml']
"Core: Use visibility string instead of enum for Immutable visibility (#8752)

Now that https://github.com/immutables/immutables/pull/1474 has been fixed and
was shipped as part of Immutables 2.10.0, we can switch to using the
visibility string to fix the below compiler warnings for consuming
projects:

```
warning: unknown enum constant ImplementationVisibility.PACKAGE
  reason: class file for org.immutables.value.Value$Style$ImplementationVisibility not found
warning: unknown enum constant ImplementationVisibility.PACKAGE
  reason: class file for org.immutables.value.Value$Style$ImplementationVisibility not found
warning: unknown enum constant ImplementationVisibility.PACKAGE
  reason: class file for org.immutables.value.Value$Style$ImplementationVisibility not found
warning: unknown enum constant ImplementationVisibility.PACKAGE
  reason: class file for org.immutables.value.Value$Style$ImplementationVisibility not found
warning: unknown enum constant ImplementationVisibility.PACKAGE
  reason: class file for org.immutables.value.Value$Style$ImplementationVisibility not found

```",11,63,2023-10-09 08:59:40-07:00,"['BaseDeleteOrphanFiles.java', 'BaseDeleteReachableFiles.java', 'BaseExpireSnapshots.java', 'BaseMigrateTable.java', 'BaseRewriteDataFiles.java', 'BaseRewriteManifests.java', 'BaseRewritePositionalDeleteFiles.java', 'BaseSnapshotTable.java', 'BaseViewHistoryEntry.java', 'BaseViewVersion.java', 'ViewMetadata.java']"
Dell: Migrate Files using TestRule to Junit5 (#8707),8,85,2023-10-10 10:03:16+02:00,"['TestEcsAppendOutputStream.java', 'TestEcsCatalog.java', 'TestEcsInputFile.java', 'TestEcsOutputFile.java', 'TestEcsSeekableInputStream.java', 'TestEcsTableOperations.java', 'EcsS3MockRule.java', 'TestExceptionCode.java']"
Fix minor compilation warnings (#8758),2,3,2023-10-10 14:17:49+02:00,"['CountersBenchmark.java', 'DataStatisticsCoordinator.java']"
"Docs: Fix missing semicolons in SQL snippets. (#8748)

* Update spark-getting-started.md

Add a missing semicolon to the ""CREATE TABLE ..."" statement.

* Fix all missing semicolons in spark-getting-started.md

- And a couple of minor typo/brevity fixes.

* Fix missing semicolons in all of docs/.",10,202,2023-10-10 17:00:52+02:00,"['branching-and-tagging.md', 'dell.md', 'flink-ddl.md', 'flink-queries.md', 'partitioning.md', 'spark-configuration.md', 'spark-ddl.md', 'spark-getting-started.md', 'spark-procedures.md', 'spark-queries.md']"
Core: Use more permissive check when registering existing table (#8759),1,2,2023-10-10 17:03:40+02:00,['CatalogTests.java']
Docs: Document all metadata tables (#8709),1,49,2023-10-10 18:07:32+02:00,['spark-queries.md']
Build: increase open-pull-requests-limit to 50 (#8768),1,2,2023-10-11 07:29:02+02:00,['dependabot.yml']
OpenAPI: Add description for AssignUUID (#8753),2,5,2023-10-11 08:26:13+02:00,"['rest-catalog-open-api.py', 'rest-catalog-open-api.yaml']"
Build: Bump to Avro 1.11.3 (#8587),2,8,2023-10-11 09:01:27+02:00,"['revapi.yml', 'libs.versions.toml']"
"Build: Bump software.amazon.awssdk:bom from 2.20.131 to 2.20.162 (#8773)

Bumps software.amazon.awssdk:bom from 2.20.131 to 2.20.162.

---
updated-dependencies:
- dependency-name: software.amazon.awssdk:bom
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-11 09:02:20+02:00,['libs.versions.toml']
"Build: Bump org.xerial:sqlite-jdbc from 3.42.0.0 to 3.43.0.0 (#8775)

Bumps [org.xerial:sqlite-jdbc](https://github.com/xerial/sqlite-jdbc) from 3.42.0.0 to 3.43.0.0.
- [Release notes](https://github.com/xerial/sqlite-jdbc/releases)
- [Changelog](https://github.com/xerial/sqlite-jdbc/blob/master/CHANGELOG)
- [Commits](https://github.com/xerial/sqlite-jdbc/compare/3.42.0.0...3.43.0.0)

---
updated-dependencies:
- dependency-name: org.xerial:sqlite-jdbc
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-11 09:02:40+02:00,['libs.versions.toml']
"Build: Bump nessie from 0.71.0 to 0.71.1 (#8771)

Bumps `nessie` from 0.71.0 to 0.71.1.

Updates `org.projectnessie.nessie:nessie-client` from 0.71.0 to 0.71.1

Updates `org.projectnessie.nessie:nessie-jaxrs-testextension` from 0.71.0 to 0.71.1

Updates `org.projectnessie.nessie:nessie-versioned-storage-inmemory` from 0.71.0 to 0.71.1

Updates `org.projectnessie.nessie:nessie-versioned-storage-testextension` from 0.71.0 to 0.71.1

---
updated-dependencies:
- dependency-name: org.projectnessie.nessie:nessie-client
  dependency-type: direct:production
  update-type: version-update:semver-patch
- dependency-name: org.projectnessie.nessie:nessie-jaxrs-testextension
  dependency-type: direct:production
  update-type: version-update:semver-patch
- dependency-name: org.projectnessie.nessie:nessie-versioned-storage-inmemory
  dependency-type: direct:production
  update-type: version-update:semver-patch
- dependency-name: org.projectnessie.nessie:nessie-versioned-storage-testextension
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-11 09:08:04+02:00,['libs.versions.toml']
"Build: Bump org.roaringbitmap:RoaringBitmap from 0.9.47 to 1.0.0 (#8792)

Bumps [org.roaringbitmap:RoaringBitmap](https://github.com/RoaringBitmap/RoaringBitmap) from 0.9.47 to 1.0.0.
- [Release notes](https://github.com/RoaringBitmap/RoaringBitmap/releases)
- [Commits](https://github.com/RoaringBitmap/RoaringBitmap/compare/0.9.47...1.0.0)

---
updated-dependencies:
- dependency-name: org.roaringbitmap:RoaringBitmap
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-11 09:34:06+02:00,['libs.versions.toml']
"Build: Bump guava from 32.1.1-jre to 32.1.3-jre (#8777)

Bumps `guava` from 32.1.1-jre to 32.1.3-jre.

Updates `com.google.guava:guava` from 32.1.1-jre to 32.1.3-jre
- [Release notes](https://github.com/google/guava/releases)
- [Commits](https://github.com/google/guava/commits)

Updates `com.google.guava:guava-testlib` from 32.1.1-jre to 32.1.3-jre
- [Release notes](https://github.com/google/guava/releases)
- [Commits](https://github.com/google/guava/commits)

---
updated-dependencies:
- dependency-name: com.google.guava:guava
  dependency-type: direct:production
  update-type: version-update:semver-patch
- dependency-name: com.google.guava:guava-testlib
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-11 10:09:42+02:00,['libs.versions.toml']
"Build: Bump com.google.errorprone:error_prone_annotations (#8776)

Bumps [com.google.errorprone:error_prone_annotations](https://github.com/google/error-prone) from 2.3.3 to 2.22.0.
- [Release notes](https://github.com/google/error-prone/releases)
- [Commits](https://github.com/google/error-prone/compare/v2.3.3...v2.22.0)

---
updated-dependencies:
- dependency-name: com.google.errorprone:error_prone_annotations
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-11 10:11:35+02:00,['libs.versions.toml']
"Build: Bump org.testcontainers:testcontainers from 1.17.6 to 1.19.1 (#8780)

Bumps [org.testcontainers:testcontainers](https://github.com/testcontainers/testcontainers-java) from 1.17.6 to 1.19.1.
- [Release notes](https://github.com/testcontainers/testcontainers-java/releases)
- [Changelog](https://github.com/testcontainers/testcontainers-java/blob/main/CHANGELOG.md)
- [Commits](https://github.com/testcontainers/testcontainers-java/compare/1.17.6...1.19.1)

---
updated-dependencies:
- dependency-name: org.testcontainers:testcontainers
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-11 10:48:41+02:00,['libs.versions.toml']
"Build: Bump com.azure:azure-sdk-bom from 1.2.16 to 1.2.17 (#8794)

Bumps [com.azure:azure-sdk-bom](https://github.com/azure/azure-sdk-for-java) from 1.2.16 to 1.2.17.
- [Release notes](https://github.com/azure/azure-sdk-for-java/releases)
- [Commits](https://github.com/azure/azure-sdk-for-java/compare/azure-sdk-bom_1.2.16...azure-sdk-bom_1.2.17)

---
updated-dependencies:
- dependency-name: com.azure:azure-sdk-bom
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-11 10:50:24+02:00,['libs.versions.toml']
Core: Support view metadata compression (#8552),4,91,2023-10-11 10:28:28-07:00,"['BaseViewOperations.java', 'ViewMetadataParser.java', 'ViewProperties.java', 'TestViewMetadataParser.java']"
Nessie: Remove deprecated usage of Operation.Put.of() (#8796),2,24,2023-10-12 08:06:33+02:00,"['NessieIcebergClient.java', 'NessieTableOperations.java']"
Add ASF DOAP rdf file (#8586),1,57,2023-10-12 11:22:06+02:00,['doap.rdf']
Rename master branch to main (#8722),11,24,2023-10-12 15:39:53+02:00,"['api-binary-compatibility.yml', 'delta-conversion-ci.yml', 'flink-ci.yml', 'hive-ci.yml', 'java-ci.yml', 'open-api.yml', 'spark-ci.yml', 'README.md', 'build.gradle', 'flink-writes.md', 'metrics-reporting.md']"
Build: Fix compiler warnings (#8763),6,41,2023-10-13 12:54:50+02:00,"['TestGlueCatalogCommitFailure.java', 'ADLSFileIOTest.java', 'GCSFileIOTest.java', 'HiveTableOperations.java', 'JdbcSnowflakeClientTest.java', 'IcebergSortCompactionBenchmark.java']"
"Replace `.size() > 0` with `.isNotEmpty()` (#8819)

* [ISSUE #8810] aliyun/*: replaced .size() > 0 with isEmpty()

* [ISSUE #8810] mr/*: replaced .size() > 0 with isEmpty()

* [ISSUE #8810] flink/*: replaced .size() > 0 with isEmpty()

* [ISSUE #8810] delta-lake/*: replaced .size() > 0 with isEmpty()

* [ISSUE #8810] hive3/*: replaced .size() > 0 with isEmpty()

* [ISSUE #8810] api/*: replaced .size() > 0 with isEmpty()

* [ISSUE #8810] aws/*: replaced .size() > 0 with isEmpty()

* Simplified assertion

* [ISSUE #8810] parquet/*: replaced .size() > 0 with isEmpty()

* [ISSUE #8810] data/*: replaced .size() > 0 with isEmpty()

* Updated indentation

Co-authored-by: Fokko Driesprong <fokko@apache.org>

---------

Co-authored-by: Fokko Driesprong <fokko@apache.org>",13,32,2023-10-13 12:59:05+02:00,"['AliyunOSSMockLocalStore.java', 'ResidualEvaluator.java', 'TestGlueCatalogNamespace.java', 'TestMetricsRowGroupFilter.java', 'TestMetricsRowGroupFilterTypes.java', 'BaseSnapshotDeltaLakeTableAction.java', 'FlinkSink.java', 'FlinkSink.java', 'FlinkSink.java', 'DataStatisticsCoordinator.java', 'OrcSplit.java', 'HiveIcebergOutputCommitter.java', 'ParquetBloomRowGroupFilter.java']"
Spark: Replace .size() > 0 with isEmpty() (#8814),27,144,2023-10-13 05:52:39-07:00,"['FileScanTaskSetManager.java', 'RewriteDataFilesSparkAction.java', 'SparkBatch.java', 'TestScanTaskSerialization.java', 'TestCreateActions.java', 'ScanTaskSetManager.java', 'SparkBinPackPositionDeletesRewriter.java', 'SparkZOrderDataRewriter.java', 'SparkBatch.java', 'SparkPositionDeletesRewriteBuilder.java', 'TestScanTaskSerialization.java', 'TestCreateActions.java', 'TestRewritePositionDeleteFilesAction.java', 'ScanTaskSetManager.java', 'SparkBinPackPositionDeletesRewriter.java', 'SparkZOrderDataRewriter.java', 'SparkPositionDeletesRewriteBuilder.java', 'TestScanTaskSerialization.java', 'TestCreateActions.java', 'TestRewritePositionDeleteFilesAction.java', 'ScanTaskSetManager.java', 'SparkBinPackPositionDeletesRewriter.java', 'SparkZOrderDataRewriter.java', 'SparkPositionDeletesRewriteBuilder.java', 'TestScanTaskSerialization.java', 'TestCreateActions.java', 'TestRewritePositionDeleteFilesAction.java']"
Build: Upgrade to spring-web 5.3.30 (#8828),1,2,2023-10-13 19:22:32+02:00,['libs.versions.toml']
Build: Upgrade to Jetty 9.4.53.v20231009 (#8830),1,2,2023-10-13 19:22:59+02:00,['libs.versions.toml']
"Core: Replace `.size() > 0` with `!.isEmpty()` (#8813)

Core: Replace .size() > 0` with `!.isEmpty() (#8813)",16,50,2023-10-13 10:45:50-07:00,"['BaseDistributedDataScan.java', 'BaseIncrementalChangelogScan.java', 'BaseOverwriteFiles.java', 'BaseRewriteFiles.java', 'FastAppend.java', 'ManifestFilterManager.java', 'MergingSnapshotProducer.java', 'PositionDeletesTable.java', 'ReachableFileUtil.java', 'SnapshotSummary.java', 'TableMetadata.java', 'BaseCommitService.java', 'RewritePositionDeletesGroup.java', 'DeleteWriteResult.java', 'PartitionUtil.java', 'ViewMetadata.java']"
"Flink:backport PR to 1.16 #7360: Implement data statistics coordinator to aggregate data statistics from operator subtasks (#8747)

Co-authored-by: gang_ye <gang_ye@apple.com>",13,1480,2023-10-15 15:57:07-07:00,"['AggregatedStatistics.java', 'AggregatedStatisticsTracker.java', 'DataStatisticsCoordinator.java', 'DataStatisticsCoordinatorProvider.java', 'DataStatisticsEvent.java', 'DataStatisticsOperator.java', 'DataStatisticsOrRecord.java', 'DataStatisticsUtil.java', 'TestAggregatedStatistics.java', 'TestAggregatedStatisticsTracker.java', 'TestDataStatisticsCoordinator.java', 'TestDataStatisticsCoordinatorProvider.java', 'TestDataStatisticsOperator.java']"
"Flink:backport PR to 1.15 #7360: Implement data statistics coordinator to aggregate data statistics from operator subtasks (#8749)

Co-authored-by: gang_ye <gang_ye@apple.com>",13,1405,2023-10-15 15:59:54-07:00,"['AggregatedStatistics.java', 'AggregatedStatisticsTracker.java', 'DataStatisticsCoordinator.java', 'DataStatisticsCoordinatorProvider.java', 'DataStatisticsEvent.java', 'DataStatisticsOperator.java', 'DataStatisticsOrRecord.java', 'DataStatisticsUtil.java', 'TestAggregatedStatistics.java', 'TestAggregatedStatisticsTracker.java', 'TestDataStatisticsCoordinator.java', 'TestDataStatisticsCoordinatorProvider.java', 'TestDataStatisticsOperator.java']"
Docs: Remove AWS Version (#8842),1,2,2023-10-16 07:49:24+02:00,['aws.md']
"Build: Bump software.amazon.awssdk:bom from 2.20.162 to 2.21.0 (#8838)

Bumps software.amazon.awssdk:bom from 2.20.162 to 2.21.0.

---
updated-dependencies:
- dependency-name: software.amazon.awssdk:bom
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-16 07:50:04+02:00,['libs.versions.toml']
"Build: Bump com.google.cloud:libraries-bom from 26.24.0 to 26.25.0 (#8841)

Bumps [com.google.cloud:libraries-bom](https://github.com/googleapis/java-cloud-bom) from 26.24.0 to 26.25.0.
- [Release notes](https://github.com/googleapis/java-cloud-bom/releases)
- [Changelog](https://github.com/googleapis/java-cloud-bom/blob/main/release-please-config.json)
- [Commits](https://github.com/googleapis/java-cloud-bom/compare/v26.24.0...v26.25.0)

---
updated-dependencies:
- dependency-name: com.google.cloud:libraries-bom
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-16 07:50:18+02:00,['libs.versions.toml']
"Build: Bump nessie from 0.71.1 to 0.72.0 (#8835)

Bumps `nessie` from 0.71.1 to 0.72.0.

Updates `org.projectnessie.nessie:nessie-client` from 0.71.1 to 0.72.0

Updates `org.projectnessie.nessie:nessie-jaxrs-testextension` from 0.71.1 to 0.72.0

Updates `org.projectnessie.nessie:nessie-versioned-storage-inmemory` from 0.71.1 to 0.72.0

Updates `org.projectnessie.nessie:nessie-versioned-storage-testextension` from 0.71.1 to 0.72.0

---
updated-dependencies:
- dependency-name: org.projectnessie.nessie:nessie-client
  dependency-type: direct:production
  update-type: version-update:semver-minor
- dependency-name: org.projectnessie.nessie:nessie-jaxrs-testextension
  dependency-type: direct:production
  update-type: version-update:semver-minor
- dependency-name: org.projectnessie.nessie:nessie-versioned-storage-inmemory
  dependency-type: direct:production
  update-type: version-update:semver-minor
- dependency-name: org.projectnessie.nessie:nessie-versioned-storage-testextension
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-16 07:51:03+02:00,['libs.versions.toml']
"Build: Bump arrow from 12.0.1 to 13.0.0 (#8785)

Bumps `arrow` from 12.0.1 to 13.0.0.

Updates `org.apache.arrow:arrow-memory-netty` from 12.0.1 to 13.0.0

Updates `org.apache.arrow:arrow-vector` from 12.0.1 to 13.0.0
- [Commits](https://github.com/apache/arrow/compare/go/v12.0.1...go/v13.0.0)

---
updated-dependencies:
- dependency-name: org.apache.arrow:arrow-memory-netty
  dependency-type: direct:production
  update-type: version-update:semver-major
- dependency-name: org.apache.arrow:arrow-vector
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-16 07:56:44+02:00,['libs.versions.toml']
"Build: Bump com.fasterxml.jackson.core:jackson-annotations (#8836)

Bumps [com.fasterxml.jackson.core:jackson-annotations](https://github.com/FasterXML/jackson) from 2.15.2 to 2.15.3.
- [Commits](https://github.com/FasterXML/jackson/commits)

---
updated-dependencies:
- dependency-name: com.fasterxml.jackson.core:jackson-annotations
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-16 08:33:33+02:00,['libs.versions.toml']
Infra: Cleanup labeler.yml (#8795),1,6,2023-10-16 09:40:35+02:00,['labeler.yml']
"Build: Bump org.xerial:sqlite-jdbc from 3.43.0.0 to 3.43.2.0 (#8837)

Bumps [org.xerial:sqlite-jdbc](https://github.com/xerial/sqlite-jdbc) from 3.43.0.0 to 3.43.2.0.
- [Release notes](https://github.com/xerial/sqlite-jdbc/releases)
- [Changelog](https://github.com/xerial/sqlite-jdbc/blob/master/CHANGELOG)
- [Commits](https://github.com/xerial/sqlite-jdbc/compare/3.43.0.0...3.43.2.0)

---
updated-dependencies:
- dependency-name: org.xerial:sqlite-jdbc
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-16 09:55:35+02:00,['libs.versions.toml']
Build: add gradle configuration to enforce reproducible build (#8826),1,5,2023-10-16 09:59:56+02:00,['build.gradle']
"Core: Do not use a lazy split offset list in manifests (#8834)

The list was not correctly invalidated when reusing the file.",3,31,2023-10-16 08:47:02-07:00,"['BaseFile.java', 'TableTestBase.java', 'TestManifestReader.java']"
Build: Document missing `docker.sock` on OSX (#8766),1,10,2023-10-17 11:58:58+02:00,['README.md']
Spark 3.5: Use Awaitility instead of Thread.sleep() (#8853),2,36,2023-10-17 17:14:46+02:00,"['build.gradle', 'SparkSQLExecutionHelper.java']"
"Flink: Reverting the default custom partitioner for bucket column (#8848)

Co-authored-by: schongloo <schongloo@apple.com>",6,114,2023-10-17 09:00:42-07:00,"['FlinkSink.java', 'TestBucketPartitionerFlinkIcebergSink.java', 'FlinkSink.java', 'TestBucketPartitionerFlinkIcebergSink.java', 'FlinkSink.java', 'TestBucketPartitionerFlinkIcebergSink.java']"
Core: Ignore split offsets when the last split offset is past the file length (#8860),3,31,2023-10-17 12:13:57-07:00,"['BaseFile.java', 'TableTestBase.java', 'TestManifestReader.java']"
Flink 1.17: Use awaitility instead of Thread.sleep() (#8852),4,103,2023-10-18 08:07:08+02:00,"['SimpleDataUtil.java', 'TestIcebergSourceContinuous.java', 'TestIcebergSourceFailover.java', 'TestStreamingMonitorFunction.java']"
Open-API: Make error required (#8765),2,4,2023-10-18 17:23:10+02:00,"['rest-catalog-open-api.py', 'rest-catalog-open-api.yaml']"
Add missing license headers (#8875),4,64,2023-10-19 10:04:28+02:00,"['checkstyle-suppressions.xml', 'checkstyle.xml', 'intellij-java-palantir-style.xml', 'libs.versions.toml']"
Nessie: Use custom client builder name (#8798),1,30,2023-10-19 13:47:44+02:00,['TestCustomNessieClient.java']
"Build: Bump org.apache.pig:pig from 0.14.0 to 0.17.0 (#8774)

Bumps org.apache.pig:pig from 0.14.0 to 0.17.0.

---
updated-dependencies:
- dependency-name: org.apache.pig:pig
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-19 14:50:12+02:00,['libs.versions.toml']
AWS: Glue catalog strip trailing slash on DB URI (#8870),2,26,2023-10-19 07:11:34-07:00,"['GlueCatalog.java', 'TestGlueCatalog.java']"
Flink 1.15: Use Awaitility instead of Thread.sleep() (#8877),4,90,2023-10-19 16:52:53+02:00,"['SimpleDataUtil.java', 'TestIcebergSourceContinuous.java', 'TestIcebergSourceFailover.java', 'TestStreamingMonitorFunction.java']"
Flink 1.16: Use Awaitility instead of Thread.sleep() (#8880),4,89,2023-10-19 16:53:41+02:00,"['SimpleDataUtil.java', 'TestIcebergSourceContinuous.java', 'TestIcebergSourceFailover.java', 'TestStreamingMonitorFunction.java']"
Build: Replace deprecated command with environment file (#8666),1,4,2023-10-19 17:04:45+02:00,['jmh-benchmarks.yml']
"Doc: Fix Iceberg Javadoc link (#8885)

Co-authored-by: Steve Zhang <hongyue_zhang@apple.com>",1,4,2023-10-19 23:01:15+02:00,['README.md']
Spark 3.4: Use Awaitility instead of Thread.sleep() (#8884),2,36,2023-10-20 08:48:54+02:00,"['build.gradle', 'SparkSQLExecutionHelper.java']"
Spark 3.3: Use Awaitility instead of Thread.sleep() (#8883),2,36,2023-10-20 08:49:10+02:00,"['build.gradle', 'SparkSQLExecutionHelper.java']"
Spark 3.2: Use Awaitility instead of Thread.sleep() (#8882),2,36,2023-10-20 08:49:34+02:00,"['build.gradle', 'SparkSQLExecutionHelper.java']"
"Build: Bump net.snowflake:snowflake-jdbc from 3.13.30 to 3.14.2 (#8790)

Bumps [net.snowflake:snowflake-jdbc](https://github.com/snowflakedb/snowflake-jdbc) from 3.13.30 to 3.14.2.
- [Release notes](https://github.com/snowflakedb/snowflake-jdbc/releases)
- [Changelog](https://github.com/snowflakedb/snowflake-jdbc/blob/master/CHANGELOG.rst)
- [Commits](https://github.com/snowflakedb/snowflake-jdbc/compare/v3.13.30...v3.14.2)

---
updated-dependencies:
- dependency-name: net.snowflake:snowflake-jdbc
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-20 09:06:16+02:00,['libs.versions.toml']
Core: Add sort_order_id to SCAN_COLUMNS to address null sort order ID after planned data files (#8873),2,33,2023-10-20 10:31:16+02:00,"['BaseScan.java', 'ScanTestBase.java']"
Infra: Update slack invite link (#8889),1,2,2023-10-20 20:45:09+02:00,['iceberg_question.yml']
Core: Derive View operation from version (#8678),17,177,2023-10-20 16:10:05-07:00,"['ViewVersion.java', 'BaseMetastoreViewCatalog.java', 'BaseViewVersion.java', 'ViewMetadata.java', 'ViewVersionReplace.java', 'TestMetadataUpdateParser.java', 'TestViewMetadata.java', 'TestViewMetadataParser.java', 'TestViewVersionParser.java', 'ViewCatalogTests.java', 'ValidViewMetadata.json', 'ViewMetadataInvalidCurrentSchema.json', 'ViewMetadataInvalidCurrentVersion.json', 'ViewMetadataMissingCurrentVersion.json', 'ViewMetadataMissingLocation.json', 'ViewMetadataMultipleSQLsForDialect.json', 'view-spec.md']"
Core: Make view metadata properties optional in JSON parser (#8723),2,69,2023-10-20 16:13:44-07:00,"['ViewMetadataParser.java', 'TestViewMetadataParser.java']"
Core: Improvements around View catalog tests (#8865),2,128,2023-10-20 16:40:08-07:00,"['InMemoryCatalog.java', 'ViewCatalogTests.java']"
Build: Avoid Running engine and core CI on template update (#8890),5,10,2023-10-21 09:27:01+02:00,"['delta-conversion-ci.yml', 'flink-ci.yml', 'hive-ci.yml', 'java-ci.yml', 'spark-ci.yml']"
Docs: Add new site deployment (#8659),83,14007,2023-10-22 13:34:00-07:00,"['.gitignore', '.gitignore', 'README.md', 'about.md', 'Iceberg-logo-wordmark.png', 'Iceberg-logo.png', 'favicon-16x16.png', 'favicon-32x32.png', 'favicon-96x96.png', 'favicon.ico', 'favicon.png', 'iceberg-logo-icon.png', 'iceberg-metadata.png', 'intro-bg.webp', 'benchmarks.md', 'blogs.md', 'catalog.md', 'community.md', 'contribute.md', 'api.md', 'audit-branch.png', 'historical-snapshot-tag.png', 'iceberg-in-place-metadata-migration.png', 'iceberg-migrateaction-step1.png', 'iceberg-migrateaction-step2.png', 'iceberg-migrateaction-step3.png', 'iceberg-snapshotaction-step1.png', 'iceberg-snapshotaction-step2.png', 'partition-spec-evolution.png', 'aws.md', 'branching.md', 'configuration.md', 'custom-catalog.md', 'dell.md', 'delta-lake-migration.md', 'evolution.md', 'flink-actions.md', 'flink-configuration.md', 'flink-connector.md', 'flink-ddl.md', 'flink-queries.md', 'flink-writes.md', 'flink.md', 'hive-migration.md', 'hive.md', 'index.md', 'java-api-quickstart.md', 'jdbc.md', 'maintenance.md', 'metrics-reporting.md', 'nessie.md', 'partitioning.md', 'performance.md', 'reliability.md', 'schemas.md', 'spark-configuration.md', 'spark-ddl.md', 'spark-getting-started.md', 'spark-procedures.md', 'spark-queries.md', 'spark-structured-streaming.md', 'spark-writes.md', 'table-migration.md', 'mkdocs.yml', 'fileio.md', 'gcm-stream-spec.md', 'hive-quickstart.md', 'how-to-release.md', 'index.md', 'multi-engine-support.md', 'puffin-spec.md', 'releases.md', 'roadmap.md', 'security.md', 'spark-quickstart.md', 'spec.md', 'talks.md', 'terms.md', 'vendors.md', 'view-spec.md', 'mkdocs.yml', 'requirements.txt', 'variables.yml']"
Infra: Add 1.4.1 to Bug template (#8886),1,3,2023-10-23 17:16:56+02:00,['iceberg_bug_report.yml']
"Build: Bump nessie from 0.72.0 to 0.72.1 (#8900)

Bumps `nessie` from 0.72.0 to 0.72.1.

Updates `org.projectnessie.nessie:nessie-client` from 0.72.0 to 0.72.1

Updates `org.projectnessie.nessie:nessie-jaxrs-testextension` from 0.72.0 to 0.72.1

Updates `org.projectnessie.nessie:nessie-versioned-storage-inmemory` from 0.72.0 to 0.72.1

Updates `org.projectnessie.nessie:nessie-versioned-storage-testextension` from 0.72.0 to 0.72.1

---
updated-dependencies:
- dependency-name: org.projectnessie.nessie:nessie-client
  dependency-type: direct:production
  update-type: version-update:semver-patch
- dependency-name: org.projectnessie.nessie:nessie-jaxrs-testextension
  dependency-type: direct:production
  update-type: version-update:semver-patch
- dependency-name: org.projectnessie.nessie:nessie-versioned-storage-inmemory
  dependency-type: direct:production
  update-type: version-update:semver-patch
- dependency-name: org.projectnessie.nessie:nessie-versioned-storage-testextension
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-25 13:59:16+02:00,['libs.versions.toml']
"Update release template (#8879)

I think we should remove the excluding weekends part
of the wait period. With a patch release like we're doing now, I don't think we want to be constrained by this. In practice, I don't think many releases are being published over the weekend.

Apache states that a vote **should** be open for 72 hours.
https://www.apache.org/foundation/voting.html#expressing-votes-1-0-1-and-fractions.",1,2,2023-10-25 14:00:36+02:00,['source-release.sh']
"Build: Bump com.google.errorprone:error_prone_annotations (#8897)

Bumps [com.google.errorprone:error_prone_annotations](https://github.com/google/error-prone) from 2.22.0 to 2.23.0.
- [Release notes](https://github.com/google/error-prone/releases)
- [Commits](https://github.com/google/error-prone/compare/v2.22.0...v2.23.0)

---
updated-dependencies:
- dependency-name: com.google.errorprone:error_prone_annotations
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-25 14:00:57+02:00,['libs.versions.toml']
"Build: Bump software.amazon.awssdk:bom from 2.21.0 to 2.21.5 (#8896)

Bumps software.amazon.awssdk:bom from 2.21.0 to 2.21.5.

---
updated-dependencies:
- dependency-name: software.amazon.awssdk:bom
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-25 14:01:17+02:00,['libs.versions.toml']
"Build: Bump org.xerial:sqlite-jdbc from 3.43.2.0 to 3.43.2.1 (#8893)

Bumps [org.xerial:sqlite-jdbc](https://github.com/xerial/sqlite-jdbc) from 3.43.2.0 to 3.43.2.1.
- [Release notes](https://github.com/xerial/sqlite-jdbc/releases)
- [Changelog](https://github.com/xerial/sqlite-jdbc/blob/master/CHANGELOG)
- [Commits](https://github.com/xerial/sqlite-jdbc/compare/3.43.2.0...3.43.2.1)

---
updated-dependencies:
- dependency-name: org.xerial:sqlite-jdbc
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-25 14:01:35+02:00,['libs.versions.toml']
"Infra: Disable merging explicitly in `.asf.yaml` (#8878)

This was done earlier before there was a `.asf.yaml` through an INFRA ticket, but I think it is good to also add it to the `yaml`.",1,10,2023-10-25 08:57:36-04:00,['.asf.yaml']
Spec: Fix error response model definition in OpenAPI spec (#8914),2,85,2023-10-25 09:45:49-07:00,"['rest-catalog-open-api.py', 'rest-catalog-open-api.yaml']"
Core: Reduce unnecessary add operations in deletedPaths set (#8868),1,2,2023-10-25 10:30:21-07:00,['ManifestFilterManager.java']
Spark: Clean up FileIO instances on executors for metadata tables (#8924),8,316,2023-10-26 17:44:29-07:00,"['SerializableTableWithSize.java', 'TestTableSerialization.java', 'SerializableTableWithSize.java', 'TestTableSerialization.java', 'SerializableTableWithSize.java', 'TestTableSerialization.java', 'SerializableTableWithSize.java', 'TestTableSerialization.java']"
Core: Ignore split offsets array when split offset is past file length (#8925),2,70,2023-10-28 09:43:02-07:00,"['BaseFile.java', 'TestTableScanUtil.java']"
"Build: Bump me.champeau.jmh:jmh-gradle-plugin from 0.7.1 to 0.7.2 (#8942)

Bumps me.champeau.jmh:jmh-gradle-plugin from 0.7.1 to 0.7.2.

---
updated-dependencies:
- dependency-name: me.champeau.jmh:jmh-gradle-plugin
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-30 08:21:45+01:00,['build.gradle']
"Build: Bump software.amazon.awssdk:bom from 2.21.5 to 2.21.10 (#8943)

Bumps software.amazon.awssdk:bom from 2.21.5 to 2.21.10.

---
updated-dependencies:
- dependency-name: software.amazon.awssdk:bom
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-30 08:22:00+01:00,['libs.versions.toml']
"Build: Bump com.google.cloud:libraries-bom from 26.25.0 to 26.26.0 (#8940)

Bumps [com.google.cloud:libraries-bom](https://github.com/googleapis/java-cloud-bom) from 26.25.0 to 26.26.0.
- [Release notes](https://github.com/googleapis/java-cloud-bom/releases)
- [Changelog](https://github.com/googleapis/java-cloud-bom/blob/main/release-please-config.json)
- [Commits](https://github.com/googleapis/java-cloud-bom/compare/v26.25.0...v26.26.0)

---
updated-dependencies:
- dependency-name: com.google.cloud:libraries-bom
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-30 08:22:15+01:00,['libs.versions.toml']
"Build: Bump nessie from 0.72.1 to 0.73.0 (#8941)

Bumps `nessie` from 0.72.1 to 0.73.0.

Updates `org.projectnessie.nessie:nessie-client` from 0.72.1 to 0.73.0

Updates `org.projectnessie.nessie:nessie-jaxrs-testextension` from 0.72.1 to 0.73.0

Updates `org.projectnessie.nessie:nessie-versioned-storage-inmemory` from 0.72.1 to 0.73.0

Updates `org.projectnessie.nessie:nessie-versioned-storage-testextension` from 0.72.1 to 0.73.0

---
updated-dependencies:
- dependency-name: org.projectnessie.nessie:nessie-client
  dependency-type: direct:production
  update-type: version-update:semver-minor
- dependency-name: org.projectnessie.nessie:nessie-jaxrs-testextension
  dependency-type: direct:production
  update-type: version-update:semver-minor
- dependency-name: org.projectnessie.nessie:nessie-versioned-storage-inmemory
  dependency-type: direct:production
  update-type: version-update:semver-minor
- dependency-name: org.projectnessie.nessie:nessie-versioned-storage-testextension
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-30 08:22:45+01:00,['libs.versions.toml']
"Build: Bump com.azure:azure-sdk-bom from 1.2.17 to 1.2.18 (#8939)

Bumps [com.azure:azure-sdk-bom](https://github.com/azure/azure-sdk-for-java) from 1.2.17 to 1.2.18.
- [Release notes](https://github.com/azure/azure-sdk-for-java/releases)
- [Commits](https://github.com/azure/azure-sdk-for-java/compare/azure-sdk-bom_1.2.17...azure-sdk-bom_1.2.18)

---
updated-dependencies:
- dependency-name: com.azure:azure-sdk-bom
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-10-30 09:54:39+01:00,['libs.versions.toml']
"AWS, Core: Use Awaitility instead of Thread.sleep()",12,161,2023-10-30 12:33:11+01:00,"['TestAssumeRoleAwsClientFactory.java', 'TestGlueCatalogLock.java', 'LakeFormationTestBase.java', 'TestLakeFormationAwsClientFactory.java', 'build.gradle', 'TestHadoopCommits.java', 'TestJdbcTableConcurrency.java', 'TestHiveTableConcurrency.java', 'SparkSQLExecutionHelper.java', 'SparkSQLExecutionHelper.java', 'SparkSQLExecutionHelper.java', 'SparkSQLExecutionHelper.java']"
AWS: Remove AssertHelpers usage (#8937),8,567,2023-10-30 14:10:40+01:00,"['TestDefaultAwsClientFactory.java', 'TestDynamoDbCatalog.java', 'TestDynamoDbLockManager.java', 'TestGlueCatalogCommitFailure.java', 'TestGlueCatalogNamespace.java', 'TestGlueCatalogTable.java', 'TestLakeFormationDataOperations.java', 'TestLakeFormationMetadataOperations.java']"
Core: Fix NPE when calling InMemoryLockManager#release using Hadoop catalog (#8494),1,3,2023-10-30 14:33:48+01:00,['LockManagers.java']
"API, Core: Add uuid API to Table (#8800)",6,39,2023-10-30 15:02:16+01:00,"['Table.java', 'BaseMetadataTable.java', 'BaseTable.java', 'BaseTransaction.java', 'SerializableTable.java', 'CatalogTests.java']"
"Docs: Fix typos (#8892)

* Fix some typos in docs

* fix the table format",2,6,2023-10-30 16:53:24+01:00,"['java-custom-catalog.md', 'spark-procedures.md']"
"Open-API: Refactor TableRequirements (#7710)

* Open-API: Refactor TableRequirements

I believe the constraints are not defined in the right way.
After generating code I got:

```python
class TableRequirement(BaseModel):
    type: Literal[
        'assert-create',
        'assert-table-uuid',
        'assert-ref-snapshot-id',
        'assert-last-assigned-field-id',
        'assert-current-schema-id',
        'assert-last-assigned-partition-id',
        'assert-default-spec-id',
        'assert-default-sort-order-id',
    ]
    ref: Optional[str] = None
    uuid: Optional[str] = None
    snapshot_id: Optional[int] = Field(None, alias='snapshot-id')
    last_assigned_field_id: Optional[int] = Field(None, alias='last-assigned-field-id')
    current_schema_id: Optional[int] = Field(None, alias='current-schema-id')
    last_assigned_partition_id: Optional[int] = Field(
        None, alias='last-assigned-partition-id'
    )
    default_spec_id: Optional[int] = Field(None, alias='default-spec-id')
    default_sort_order_id: Optional[int] = Field(None, alias='default-sort-order-id')
```

Which encapulates all the requirements. After the refactor in this
PR, we'll end up with:

```python
class AssertCreate(BaseModel):
    type: Literal['assert-create']

class AssertTableUUID(BaseModel):
    type: Literal['assert-table-uuid']
    uuid: str

class AssertRefSnapshotId(BaseModel):
    type: Literal['assert-ref-snapshot-id']
    ref: str
    snapshot_id: int = Field(..., alias='snapshot-id')

class AssertLastAssignedFieldId(BaseModel):
    type: Literal['assert-last-assigned-field-id']
    last_assigned_partition_id: int = Field(..., alias='last-assigned-partition-id')

class AssertCurrentSchemaId(BaseModel):
    type: Literal['assert-current-schema-id']
    current_schema_id: int = Field(..., alias='current-schema-id')

class AssertLastAssignedPartitionId(BaseModel):
    type: Literal['assert-last-assigned-partition-id']
    last_assigned_partition_id: int = Field(..., alias='last-assigned-partition-id')

class AssertDefaultSpecId(BaseModel):
    type: Literal['assert-default-spec-id']
    default_spec_id: int = Field(..., alias='default-spec-id')

class AssertDefaultSortOrderId(BaseModel):
    type: Literal['assert-default-sort-order-id']
    default_sort_order_id: int = Field(..., alias='default-sort-order-id')

class TableRequirement(BaseModel):
    __root__: Union[
        AssertCreate,
        AssertTableUUID,
        AssertRefSnapshotId,
        AssertLastAssignedFieldId,
        AssertCurrentSchemaId,
        AssertLastAssignedPartitionId,
        AssertDefaultSpecId,
        AssertDefaultSortOrderId,
    ] = Field(..., discriminator='type')
```

Which makes sense to me.

* Apply suggestions from code review

Co-authored-by: Eduard Tudenhoefner <etudenhoefner@gmail.com>

* WIP

* Fixed the inheritance

* Generate the code

* Fix order

---------

Co-authored-by: Eduard Tudenhoefner <etudenhoefner@gmail.com>",2,245,2023-10-30 16:58:59+01:00,"['rest-catalog-open-api.py', 'rest-catalog-open-api.yaml']"
"Spark 3.5: Don't cache or reuse manifest entries while rewriting metadata by default (#8935)

The action for rewriting manifests caches the manifest entry DF or does an extra shuffle in order to skip reading the actual manifest files twice. We did this assuming it would increase the performance. However, the caching seems to perform poorly for larger tables as it requires substantial cluster resources. In addition, doing a round-robin repartition is expensive as the entries must be written to disk. The extra write is actually more expensive than the extra read required for the range-based shuffle of manifest entries.

Therefore, this change disables caching by default and removes the optional round-robin repartition step. Instead, we will read the manifests twice (this step is distributed and scales really well even for tables with huge metadata). The new approach should be both faster and more robust.",2,51,2023-10-30 10:53:23-07:00,"['RewriteManifestsSparkAction.java', 'TestRewriteManifestsAction.java']"
"Spark 3.2: Don't cache or reuse manifest entries while rewriting metadata by default (#8956)

This change cherry-picks PR #8935 to Spark 3.2.",2,51,2023-10-30 17:34:48-07:00,"['RewriteManifestsSparkAction.java', 'TestRewriteManifestsAction.java']"
"Spark 3.3: Don't cache or reuse manifest entries while rewriting metadata by default (#8955)

This change cherry-picks PR #8935 to Spark 3.3.",2,51,2023-10-30 17:35:04-07:00,"['RewriteManifestsSparkAction.java', 'TestRewriteManifestsAction.java']"
"Spark 3.4: Don't cache or reuse manifest entries while rewriting metadata by default (#8954)

This change cherry-picks PR #8935 to Spark 3.4.",2,51,2023-10-30 17:35:59-07:00,"['RewriteManifestsSparkAction.java', 'TestRewriteManifestsAction.java']"
"API, Core: Add uuid() to View (#8851)",3,19,2023-10-31 07:57:49+01:00,"['View.java', 'BaseView.java', 'ViewCatalogTests.java']"
Spark 3.5:  Remove AssertHelpers usage (#8948),5,1376,2023-10-31 11:03:31+01:00,"['TestChangelogTable.java', 'TestMerge.java', 'TestRequiredDistributionAndOrdering.java', 'TestTagDDL.java', 'TestUpdate.java']"
Flink 1.15: Remove usage of AssertHelpers (#8945),15,477,2023-10-31 14:58:59+01:00,"['TestFlinkCatalogFactory.java', 'TestFlinkCatalogTable.java', 'TestFlinkCatalogTablePartitions.java', 'TestFlinkSchemaUtil.java', 'TestIcebergConnector.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkV2.java', 'TestFlinkIcebergSinkV2Base.java', 'TestFlinkScan.java', 'TestFlinkSourceConfig.java', 'TestFlinkTableSource.java', 'TestStreamScanSql.java', 'TestStreamingMonitorFunction.java', 'TestContinuousSplitPlannerImpl.java', 'TestContinuousSplitPlannerImplStartStrategy.java']"
Flink 1.16: Remove usage of AssertHelpers (#8946),15,431,2023-10-31 16:02:13+01:00,"['TestFlinkCatalogFactory.java', 'TestFlinkCatalogTable.java', 'TestFlinkCatalogTablePartitions.java', 'TestFlinkSchemaUtil.java', 'TestIcebergConnector.java', 'TestFlinkIcebergSink.java', 'TestFlinkIcebergSinkV2.java', 'TestFlinkIcebergSinkV2Base.java', 'TestFlinkScan.java', 'TestFlinkSourceConfig.java', 'TestFlinkTableSource.java', 'TestStreamScanSql.java', 'TestStreamingMonitorFunction.java', 'TestContinuousSplitPlannerImpl.java', 'TestContinuousSplitPlannerImplStartStrategy.java']"
"Spec: add nanosecond timestamp types (#8683)

This change embodies this design doc:
https://docs.google.com/document/d/1bE1DcEGNzZAMiVJSZ0X1wElKLNkT9kRkk0hDlfkXzvU/edit

Co-authored-by: Ryan Blue <blue@apache.org>",1,98,2023-10-31 09:15:24-07:00,['spec.md']
Docs: Document UNORDERED for spark write (#8958),1,6,2023-10-31 17:20:38+01:00,['spark-ddl.md']
"Core, Spark: Avoid extra copies of manifests while optimizing V2 tables (#8928)",13,149,2023-10-31 09:42:02-07:00,"['BaseRewriteManifests.java', 'SnapshotProducer.java', 'TestRewriteManifests.java', 'configuration.md', 'spark-procedures.md', 'RewriteManifestsSparkAction.java', 'TestRewriteManifestsAction.java', 'RewriteManifestsSparkAction.java', 'TestRewriteManifestsAction.java', 'RewriteManifestsSparkAction.java', 'TestRewriteManifestsAction.java', 'RewriteManifestsSparkAction.java', 'TestRewriteManifestsAction.java']"
Spark: Use SerializableTableWithSize when optimizing metadata (#8957),4,36,2023-10-31 10:59:49-07:00,"['RewriteManifestsSparkAction.java', 'RewriteManifestsSparkAction.java', 'RewriteManifestsSparkAction.java', 'RewriteManifestsSparkAction.java']"
Spark 3.4: Remove usage of AssertHelpers (#8963),5,1207,2023-11-01 14:30:35+01:00,"['TestChangelogTable.java', 'TestMerge.java', 'TestRequiredDistributionAndOrdering.java', 'TestTagDDL.java', 'TestUpdate.java']"
Spec: Add partition stats spec (#7105),1,54,2023-11-01 08:15:29-07:00,['spec.md']
"Core: Scan only live entries in partitions table (#8969)


Co-authored-by: Steve Zhang <hongyue_zhang@apple.com>",5,130,2023-11-01 18:48:22-07:00,"['PartitionsTable.java', 'TestDelete.java', 'TestDelete.java', 'TestDelete.java', 'TestDelete.java']"
"Core: Use ParallelIterable in Deletes::toPositionIndex (6387) (#8805)

Co-authored-by: Rajesh Balamohan <rbalamohan@apache.org>",5,74,2023-11-02 08:50:42+01:00,"['SystemConfigs.java', 'BitmapPositionDeleteIndex.java', 'Deletes.java', 'ThreadPools.java', 'TestPositionFilter.java']"
Remove outdated `tox` command from doc (#8961),1,2,2023-11-02 12:51:32+01:00,['contribute.md']
Parquet: Remove duplicate test code (#8098),2,576,2023-11-02 14:22:17+01:00,"['TestParquetReadProjection.java', 'TestReadProjection.java']"
Spark 3.5: Use DataFile constants in SparkDataFile (#8936),1,41,2023-11-02 09:42:11-07:00,['SparkDataFile.java']
Spark 3.5: Display more read metrics on Spark SQL UI (#8717),26,1052,2023-11-02 18:19:55-07:00,"['SparkScan.java', 'EqualityDeleteFiles.java', 'IndexedDeleteFiles.java', 'PositionalDeleteFiles.java', 'ResultDataFiles.java', 'ResultDeleteFiles.java', 'ScannedDeleteManifests.java', 'SkippedDeleteFiles.java', 'SkippedDeleteManifests.java', 'TaskEqualityDeleteFiles.java', 'TaskIndexedDeleteFiles.java', 'TaskPositionalDeleteFiles.java', 'TaskResultDataFiles.java', 'TaskResultDeleteFiles.java', 'TaskScannedDeleteManifests.java', 'TaskSkippedDeleteFiles.java', 'TaskSkippedDeleteManifests.java', 'TaskTotalDataFileSize.java', 'TaskTotalDataManifests.java', 'TaskTotalDeleteFileSize.java', 'TaskTotalDeleteManifests.java', 'TotalDataFileSize.java', 'TotalDataManifests.java', 'TotalDeleteFileSize.java', 'TotalDeleteManifests.java', 'TestSparkReadMetrics.java']"
Spark: Fix usage of staging location when optimizing metadata (#8959),8,300,2023-11-02 20:39:45-07:00,"['RewriteManifestsSparkAction.java', 'TestRewriteManifestsAction.java', 'RewriteManifestsSparkAction.java', 'TestRewriteManifestsAction.java', 'RewriteManifestsSparkAction.java', 'TestRewriteManifestsAction.java', 'RewriteManifestsSparkAction.java', 'TestRewriteManifestsAction.java']"
Spark 3.5: Use rolling manifest writers when optimizing metadata (#8972),2,292,2023-11-03 19:19:33-07:00,"['RewriteManifestsSparkAction.java', 'TestRewriteManifestsAction.java']"
"Build: Bump arrow from 13.0.0 to 14.0.0 (#8984)

Bumps `arrow` from 13.0.0 to 14.0.0.

Updates `org.apache.arrow:arrow-memory-netty` from 13.0.0 to 14.0.0

Updates `org.apache.arrow:arrow-vector` from 13.0.0 to 14.0.0
- [Commits](https://github.com/apache/arrow/compare/go/v13.0.0...go/v14.0.0)

---
updated-dependencies:
- dependency-name: org.apache.arrow:arrow-memory-netty
  dependency-type: direct:production
  update-type: version-update:semver-major
- dependency-name: org.apache.arrow:arrow-vector
  dependency-type: direct:production
  update-type: version-update:semver-major
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-11-06 12:28:57+01:00,['libs.versions.toml']
"Build: Bump software.amazon.awssdk:bom from 2.21.10 to 2.21.15 (#8983)

Bumps software.amazon.awssdk:bom from 2.21.10 to 2.21.15.

---
updated-dependencies:
- dependency-name: software.amazon.awssdk:bom
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-11-06 12:29:30+01:00,['libs.versions.toml']
Core: De-dup props in JdbcUtil (#8992),2,25,2023-11-07 07:27:45+01:00,"['JdbcTableOperations.java', 'JdbcUtil.java']"
Test: Add a test utility method to programmatically create expected partition specs (#8467),17,454,2023-11-07 14:55:41-06:00,"['TestHelpers.java', 'TestAlterTablePartitionFields.java', 'TestForwardCompatibility.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestSparkMetadataColumns.java', 'TestAlterTablePartitionFields.java', 'TestForwardCompatibility.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestSparkMetadataColumns.java', 'TestAlterTablePartitionFields.java', 'TestForwardCompatibility.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestSparkMetadataColumns.java', 'TestAlterTablePartitionFields.java', 'TestForwardCompatibility.java', 'TestMetadataTablesWithPartitionEvolution.java', 'TestSparkMetadataColumns.java']"
Infra: Add 1.4.2 as latest release to issue template (#9001),1,3,2023-11-08 08:00:44+01:00,['iceberg_bug_report.yml']
Core: Add a constructor to StaticTableOperations (#8996),3,19,2023-11-08 10:41:44+01:00,"['StaticTableOperations.java', 'TestReachableFileUtil.java', 'BaseSparkAction.java']"
Docs: Add note that snapshot expiration and cleanup orphan files could corrupt Flink job state (#9002),1,11,2023-11-08 12:40:02+01:00,['flink-writes.md']
"Spec: Clarify ns timestamps for ORC deserialization (#9007)

Helps #8657

In order for ORC types `timestamp` and `timestamp_instant` to be correctly converted to Iceberg `timestamp`, `timestamp_ns`, `timestamptz`, and `timestamptz_ns`, we need an ORC type attribute.",1,10,2023-11-08 12:51:38-08:00,['spec.md']
"Spark 3.4: Display more read metrics on Spark SQL UI (#9009)

This change cherry-picks PR #8717 to Spark 3.4.",26,1052,2023-11-08 16:31:28-08:00,"['SparkScan.java', 'EqualityDeleteFiles.java', 'IndexedDeleteFiles.java', 'PositionalDeleteFiles.java', 'ResultDataFiles.java', 'ResultDeleteFiles.java', 'ScannedDeleteManifests.java', 'SkippedDeleteFiles.java', 'SkippedDeleteManifests.java', 'TaskEqualityDeleteFiles.java', 'TaskIndexedDeleteFiles.java', 'TaskPositionalDeleteFiles.java', 'TaskResultDataFiles.java', 'TaskResultDeleteFiles.java', 'TaskScannedDeleteManifests.java', 'TaskSkippedDeleteFiles.java', 'TaskSkippedDeleteManifests.java', 'TaskTotalDataFileSize.java', 'TaskTotalDataManifests.java', 'TaskTotalDeleteFileSize.java', 'TaskTotalDeleteManifests.java', 'TotalDataFileSize.java', 'TotalDataManifests.java', 'TotalDeleteFileSize.java', 'TotalDeleteManifests.java', 'TestSparkReadMetrics.java']"
Core: Use InMemoryCatalog as backend catalog (#9014),1,103,2023-11-09 15:44:20+01:00,['TestRESTCatalog.java']
Spark 3.5: Fix rewriting manifests for evolved unpartitioned V1 tables (#9015),2,65,2023-11-09 13:43:24-08:00,"['RewriteManifestsSparkAction.java', 'TestRewriteManifestsAction.java']"
Core: Support replacing delete manifests (#9000),3,632,2023-11-09 14:54:32-08:00,"['BaseRewriteManifests.java', 'TableTestBase.java', 'TestRewriteManifests.java']"
Spark 3.4: Use rolling manifest writers when optimizing metadata (#9019),2,292,2023-11-09 15:30:28-08:00,"['RewriteManifestsSparkAction.java', 'TestRewriteManifestsAction.java']"
Docs: Fix Javadoc for ManifestFile (#9016),1,24,2023-11-09 16:26:11-08:00,['ManifestFile.java']
Spec: Fix view example (#8966),1,4,2023-11-10 12:31:58+01:00,['view-spec.md']
Docs: `DataFrameReader` does not take parameters (#9021),1,2,2023-11-10 19:51:28+01:00,['spark-queries.md']
"Spark 3.5: Set useCommitCoordinator to false in batch writes (#9017)

Co-authored-by: Huaxin Gao <huaxin.gao@apple.com>",3,15,2023-11-10 11:36:01-08:00,"['SparkPositionDeletesRewrite.java', 'SparkPositionDeltaWrite.java', 'SparkWrite.java']"
"Spark 3.5: Set useCommitCoordinator to false in streaming writes (#9027)

Co-authored-by: Huaxin Gao <huaxin.gao@apple.com>",1,5,2023-11-11 10:15:38-08:00,['SparkWrite.java']
"Spark 3.4: Set useCommitCoordinator to false in batch writes (#9028)

This change cherrypicks PR #9017 to Spark 3.4.

Co-authored-by: Huaxin Gao <huaxin.gao@apple.com>",3,15,2023-11-11 10:17:24-08:00,"['SparkPositionDeletesRewrite.java', 'SparkPositionDeltaWrite.java', 'SparkWrite.java']"
API: Optimize equals in CharSequenceWrapper (#9035),1,9,2023-11-12 19:09:55-08:00,['CharSequenceWrapper.java']
"Build: Bump software.amazon.awssdk:bom from 2.21.15 to 2.21.21 (#9044)

Bumps software.amazon.awssdk:bom from 2.21.15 to 2.21.21.

---
updated-dependencies:
- dependency-name: software.amazon.awssdk:bom
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-11-13 09:59:56+01:00,['libs.versions.toml']
"Build: Bump orc from 1.9.1 to 1.9.2 (#9045)

Bumps `orc` from 1.9.1 to 1.9.2.

Updates `org.apache.orc:orc-core` from 1.9.1 to 1.9.2

Updates `org.apache.orc:orc-tools` from 1.9.1 to 1.9.2

---
updated-dependencies:
- dependency-name: org.apache.orc:orc-core
  dependency-type: direct:production
  update-type: version-update:semver-patch
- dependency-name: org.apache.orc:orc-tools
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-11-13 10:00:17+01:00,['libs.versions.toml']
"Build: Bump arrow from 14.0.0 to 14.0.1 (#9043)

Bumps `arrow` from 14.0.0 to 14.0.1.

Updates `org.apache.arrow:arrow-memory-netty` from 14.0.0 to 14.0.1

Updates `org.apache.arrow:arrow-vector` from 14.0.0 to 14.0.1
- [Commits](https://github.com/apache/arrow/compare/go/v14.0.0...go/v14.0.1)

---
updated-dependencies:
- dependency-name: org.apache.arrow:arrow-memory-netty
  dependency-type: direct:production
  update-type: version-update:semver-patch
- dependency-name: org.apache.arrow:arrow-vector
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-11-13 10:00:35+01:00,['libs.versions.toml']
"Build: Bump net.snowflake:snowflake-jdbc from 3.14.2 to 3.14.3 (#9039)

Bumps [net.snowflake:snowflake-jdbc](https://github.com/snowflakedb/snowflake-jdbc) from 3.14.2 to 3.14.3.
- [Release notes](https://github.com/snowflakedb/snowflake-jdbc/releases)
- [Changelog](https://github.com/snowflakedb/snowflake-jdbc/blob/master/CHANGELOG.rst)
- [Commits](https://github.com/snowflakedb/snowflake-jdbc/compare/v3.14.2...v3.14.3)

---
updated-dependencies:
- dependency-name: net.snowflake:snowflake-jdbc
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-11-13 10:00:52+01:00,['libs.versions.toml']
"Build: Bump junit from 5.10.0 to 5.10.1 (#9037)

Bumps `junit` from 5.10.0 to 5.10.1.

Updates `org.junit.jupiter:junit-jupiter` from 5.10.0 to 5.10.1
- [Release notes](https://github.com/junit-team/junit5/releases)
- [Commits](https://github.com/junit-team/junit5/compare/r5.10.0...r5.10.1)

Updates `org.junit.jupiter:junit-jupiter-engine` from 5.10.0 to 5.10.1
- [Release notes](https://github.com/junit-team/junit5/releases)
- [Commits](https://github.com/junit-team/junit5/compare/r5.10.0...r5.10.1)

Updates `org.junit.vintage:junit-vintage-engine` from 5.10.0 to 5.10.1
- [Release notes](https://github.com/junit-team/junit5/releases)
- [Commits](https://github.com/junit-team/junit5/compare/r5.10.0...r5.10.1)

---
updated-dependencies:
- dependency-name: org.junit.jupiter:junit-jupiter
  dependency-type: direct:production
  update-type: version-update:semver-patch
- dependency-name: org.junit.jupiter:junit-jupiter-engine
  dependency-type: direct:production
  update-type: version-update:semver-patch
- dependency-name: org.junit.vintage:junit-vintage-engine
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-11-13 10:09:10+01:00,['libs.versions.toml']
"Build: Bump com.google.cloud:libraries-bom from 26.26.0 to 26.27.0 (#9036)

Bumps [com.google.cloud:libraries-bom](https://github.com/googleapis/java-cloud-bom) from 26.26.0 to 26.27.0.
- [Release notes](https://github.com/googleapis/java-cloud-bom/releases)
- [Changelog](https://github.com/googleapis/java-cloud-bom/blob/main/release-please-config.json)
- [Commits](https://github.com/googleapis/java-cloud-bom/compare/v26.26.0...v26.27.0)

---
updated-dependencies:
- dependency-name: com.google.cloud:libraries-bom
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-11-13 10:09:36+01:00,['libs.versions.toml']
"Build: Bump org.xerial:sqlite-jdbc from 3.43.2.1 to 3.44.0.0 (#9051)

Bumps [org.xerial:sqlite-jdbc](https://github.com/xerial/sqlite-jdbc) from 3.43.2.1 to 3.44.0.0.
- [Release notes](https://github.com/xerial/sqlite-jdbc/releases)
- [Changelog](https://github.com/xerial/sqlite-jdbc/blob/master/CHANGELOG)
- [Commits](https://github.com/xerial/sqlite-jdbc/compare/3.43.2.1...3.44.0.0)

---
updated-dependencies:
- dependency-name: org.xerial:sqlite-jdbc
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-11-13 14:26:25+01:00,['libs.versions.toml']
"Add dependabot to automatically update the site (#9004)

Since we're moving the site back into the main repository, it would be great to have Dependabot update `site/requirements.txt`",1,6,2023-11-13 23:58:05+01:00,['dependabot.yml']
"Build: Bump mkdocs-macros-plugin from 1.0.4 to 1.0.5 (#9058)

Bumps [mkdocs-macros-plugin](https://github.com/fralau/mkdocs_macros_plugin) from 1.0.4 to 1.0.5.
- [Release notes](https://github.com/fralau/mkdocs_macros_plugin/releases)
- [Changelog](https://github.com/fralau/mkdocs_macros_plugin/blob/master/CHANGELOG.md)
- [Commits](https://github.com/fralau/mkdocs_macros_plugin/compare/v1.0.4...v1.0.5)

---
updated-dependencies:
- dependency-name: mkdocs-macros-plugin
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-11-14 07:58:28+01:00,['requirements.txt']
"Build: Bump datamodel-code-generator from 0.22.0 to 0.23.0 (#9054)

Bumps [datamodel-code-generator](https://github.com/koxudaxi/datamodel-code-generator) from 0.22.0 to 0.23.0.
- [Release notes](https://github.com/koxudaxi/datamodel-code-generator/releases)
- [Commits](https://github.com/koxudaxi/datamodel-code-generator/compare/0.22.0...0.23.0)

---
updated-dependencies:
- dependency-name: datamodel-code-generator
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-11-14 07:59:04+01:00,['requirements.txt']
"Build: Bump mkdocs-material-extensions from 1.1.1 to 1.3 (#9052)

Bumps [mkdocs-material-extensions](https://github.com/facelessuser/mkdocs-material-extensions) from 1.1.1 to 1.3.
- [Release notes](https://github.com/facelessuser/mkdocs-material-extensions/releases)
- [Changelog](https://github.com/facelessuser/mkdocs-material-extensions/blob/master/changelog.md)
- [Commits](https://github.com/facelessuser/mkdocs-material-extensions/compare/1.1.1...1.3)

---
updated-dependencies:
- dependency-name: mkdocs-material-extensions
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-11-14 08:09:51+01:00,['requirements.txt']
"Build: Bump mkdocs-material from 9.1.21 to 9.4.8 (#9055)

Bumps [mkdocs-material](https://github.com/squidfunk/mkdocs-material) from 9.1.21 to 9.4.8.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/CHANGELOG)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/9.1.21...9.4.8)

---
updated-dependencies:
- dependency-name: mkdocs-material
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-11-14 09:47:44+01:00,['requirements.txt']
"Build: Bump software.amazon.awssdk:bom from 2.21.21 to 2.21.22 (#9053)

Bumps software.amazon.awssdk:bom from 2.21.21 to 2.21.22.

---
updated-dependencies:
- dependency-name: software.amazon.awssdk:bom
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-11-14 10:36:30+01:00,['libs.versions.toml']
GCP: Use correct Guava imports (#9067),2,4,2023-11-14 18:58:25+01:00,"['GCSInputStream.java', 'GCSOutputStream.java']"
Core: Enable column statistics filtering after planning (#8803),25,481,2023-11-14 13:09:08-08:00,"['revapi.yml', 'BatchScanAdapter.java', 'ContentFile.java', 'Scan.java', 'TestHelpers.java', 'BaseDistributedDataScan.java', 'BaseFile.java', 'BaseIncrementalAppendScan.java', 'BaseIncrementalChangelogScan.java', 'BaseScan.java', 'DataScan.java', 'DataTableScan.java', 'GenericDataFile.java', 'GenericDeleteFile.java', 'IncrementalDataTableScan.java', 'ManifestGroup.java', 'TableScanContext.java', 'V1Metadata.java', 'V2Metadata.java', 'ContentFileUtil.java', 'SerializableMap.java', 'TestScanDataFileColumns.java', 'FlinkSplitPlanner.java', 'ScanContext.java', 'TestContinuousSplitPlannerImpl.java']"
Spark 3.5: Support metadata columns in staged scan (#8872),3,189,2023-11-15 20:52:47-08:00,"['TestMetaColumnProjectionWithStageScan.java', 'SparkStagedScan.java', 'SparkStagedScanBuilder.java']"
Docs: Fix parquet default compression codec (#9096),1,2,2023-11-16 16:38:24+01:00,['configuration.md']
"Azure: Allow shared-key auth for testing purposes (#9068)

The Azure Blob Storage client library, including the hadoop-azure stuff, allow using shared-key authentication, which is handy for testing purposes with Azurite. Unfortunately, `AzureProperties` does not play nicely here, because it does not support shared-keys. This change adds two new properties to allow shared-key authentication.",2,60,2023-11-16 16:39:54+01:00,"['AzureProperties.java', 'AzurePropertiesTest.java']"
Core: Disallow setting equality field IDs for data (#8970),5,23,2023-11-16 08:33:02-08:00,"['ContentFileParser.java', 'DataFiles.java', 'GenericDataFile.java', 'TestContentFileParser.java', 'TestManifestWriterVersions.java']"
Core: Fix split size calculations in file rewriters (#9069),2,116,2023-11-16 11:31:17-06:00,"['SizeBasedFileRewriter.java', 'TestSizeBasedRewriter.java']"
API: Add CharSequenceMap (#9047),2,422,2023-11-16 15:41:29-08:00,"['CharSequenceMap.java', 'TestCharSequenceMap.java']"
"Parquet: Add log entry when Bloom filters are used (#9010)

Co-authored-by: Huaxin Gao <huaxin.gao@apple.com>",1,16,2023-11-16 16:16:15-08:00,['ParquetBloomRowGroupFilter.java']
"GCS: Allow no-auth for testing purposes (#9061)

Although there is no ""official"" Google Cloud Storage emulator available yet, there is [one available](https://github.com/oittaa/gcp-storage-emulator) that allows at least some basic testing. To use an emulator, the client needs to be configured to use no authentication, otherwise it will fallback to ""automatic credential detection"".",3,73,2023-11-17 14:52:17+01:00,"['GCPProperties.java', 'GCSFileIO.java', 'GCPPropertiesTest.java']"
"Spark 3.4, 3.3: Support metadata columns in staged scans (#9098)

This change cherry-picks PR #8872 to Spark 3.4 and 3.3.",6,378,2023-11-17 17:26:32-08:00,"['TestMetaColumnProjectionWithStageScan.java', 'SparkStagedScan.java', 'SparkStagedScanBuilder.java', 'TestMetaColumnProjectionWithStageScan.java', 'SparkStagedScan.java', 'SparkStagedScanBuilder.java']"
Spark 3.5: Extend action for rewriting manifests to support deletes (#9020),6,1224,2023-11-17 18:34:25-08:00,"['SparkContentFile.java', 'SparkDataFile.java', 'SparkDeleteFile.java', 'RewriteManifestsSparkAction.java', 'TestRewriteManifestsAction.java', 'TestSparkDataFile.java']"
"Build: Bump datamodel-code-generator from 0.23.0 to 0.24.2 (#9109)

Bumps [datamodel-code-generator](https://github.com/koxudaxi/datamodel-code-generator) from 0.23.0 to 0.24.2.
- [Release notes](https://github.com/koxudaxi/datamodel-code-generator/releases)
- [Commits](https://github.com/koxudaxi/datamodel-code-generator/compare/0.23.0...0.24.2)

---
updated-dependencies:
- dependency-name: datamodel-code-generator
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-11-19 07:12:36+01:00,['requirements.txt']
Build: Bump openapi-spec-validator from 0.5.2 to 0.7.1 (#9057),1,2,2023-11-19 07:57:53+01:00,['requirements.txt']
Open-API: Remove pydantic pin (#9110),1,2,2023-11-19 10:39:06+01:00,['requirements.txt']
"Build: Bump com.fasterxml.jackson.core:jackson-annotations (#9106)

Bumps [com.fasterxml.jackson.core:jackson-annotations](https://github.com/FasterXML/jackson) from 2.15.3 to 2.16.0.
- [Commits](https://github.com/FasterXML/jackson/commits)

---
updated-dependencies:
- dependency-name: com.fasterxml.jackson.core:jackson-annotations
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-11-19 10:39:44+01:00,['libs.versions.toml']
"Build: Bump org.testcontainers:testcontainers from 1.19.1 to 1.19.2 (#9103)

Bumps [org.testcontainers:testcontainers](https://github.com/testcontainers/testcontainers-java) from 1.19.1 to 1.19.2.
- [Release notes](https://github.com/testcontainers/testcontainers-java/releases)
- [Changelog](https://github.com/testcontainers/testcontainers-java/blob/main/CHANGELOG.md)
- [Commits](https://github.com/testcontainers/testcontainers-java/compare/1.19.1...1.19.2)

---
updated-dependencies:
- dependency-name: org.testcontainers:testcontainers
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-11-19 10:40:02+01:00,['libs.versions.toml']
"Build: Bump com.fasterxml.jackson.dataformat:jackson-dataformat-xml (#9107)

Bumps [com.fasterxml.jackson.dataformat:jackson-dataformat-xml](https://github.com/FasterXML/jackson-dataformat-xml) from 2.9.9 to 2.16.0.
- [Commits](https://github.com/FasterXML/jackson-dataformat-xml/compare/jackson-dataformat-xml-2.9.9...jackson-dataformat-xml-2.16.0)

---
updated-dependencies:
- dependency-name: com.fasterxml.jackson.dataformat:jackson-dataformat-xml
  dependency-type: direct:production
  update-type: version-update:semver-minor
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-11-19 10:40:46+01:00,['libs.versions.toml']
Spark: Fix metadata delete check with branches (#9102),4,9,2023-11-19 15:56:55-08:00,"['SparkRowLevelOperationsTestBase.java', 'TestDelete.java', 'SparkTable.java', 'TestHelpers.java']"
"Build: Bump software.amazon.awssdk:bom from 2.21.22 to 2.21.26 (#9105)

Bumps software.amazon.awssdk:bom from 2.21.22 to 2.21.26.

---
updated-dependencies:
- dependency-name: software.amazon.awssdk:bom
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-11-20 08:38:33+01:00,['libs.versions.toml']
"Build: Bump mkdocs-material from 9.4.8 to 9.4.10 (#9114)

Bumps [mkdocs-material](https://github.com/squidfunk/mkdocs-material) from 9.4.8 to 9.4.10.
- [Release notes](https://github.com/squidfunk/mkdocs-material/releases)
- [Changelog](https://github.com/squidfunk/mkdocs-material/blob/master/CHANGELOG)
- [Commits](https://github.com/squidfunk/mkdocs-material/compare/9.4.8...9.4.10)

---
updated-dependencies:
- dependency-name: mkdocs-material
  dependency-type: direct:production
  update-type: version-update:semver-patch
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",1,2,2023-11-20 21:42:08+01:00,['requirements.txt']
"Spark 3.3, 3.4: Backport fix for metadata delete condition check for branches (#9115)",8,18,2023-11-20 14:06:54-08:00,"['SparkRowLevelOperationsTestBase.java', 'TestDelete.java', 'SparkTable.java', 'TestHelpers.java', 'SparkRowLevelOperationsTestBase.java', 'TestDelete.java', 'SparkTable.java', 'TestHelpers.java']"
Spark: Add SQL config to control locality (#9101),6,30,2023-11-20 15:08:59-08:00,"['SparkReadConf.java', 'SparkSQLProperties.java', 'SparkReadConf.java', 'SparkSQLProperties.java', 'SparkReadConf.java', 'SparkSQLProperties.java']"
Core: Remove synchronization from BitmapPositionDeleteIndex (#9119),1,2,2023-11-21 08:25:56+01:00,['BitmapPositionDeleteIndex.java']
Data: Always use delete index for position deletes (#9117),1,18,2023-11-21 12:20:41-08:00,['DeleteFilter.java']
Core: Lazily create LocationProvider in SerializableTable (#9029),1,22,2023-11-21 20:53:23-08:00,['SerializableTable.java']
Flink: Emit watermarks from the IcebergSource (#8553),17,1263,2023-11-23 10:40:33+01:00,"['GenericAppenderHelper.java', 'IcebergSource.java', 'ColumnStatsWatermarkExtractor.java', 'IcebergSourceReader.java', 'SerializableRecordEmitter.java', 'SplitWatermarkExtractor.java', 'WatermarkExtractorRecordEmitter.java', 'SplitComparators.java', 'TestIcebergSourceFailover.java', 'TestIcebergSourceFailoverWithWatermarkExtractor.java', 'TestIcebergSourceWithWatermarkExtractor.java', 'SplitAssignerTestBase.java', 'TestFileSequenceNumberBasedSplitAssigner.java', 'TestWatermarkBasedSplitAssigner.java', 'ReaderUtil.java', 'TestColumnStatsWatermarkExtractor.java', 'TestIcebergSourceReader.java']"
Docs: Remove UNIQUE keyword as it is not supported in Flink (#9046),1,2,2023-11-23 12:05:44+01:00,['flink-writes.md']
Spark: Fix Fast forward before/after snapshot output for non-main branches (#8854),2,70,2023-11-23 10:12:26-08:00,"['TestFastForwardBranchProcedure.java', 'FastForwardBranchProcedure.java']"
Hive: Refactor HiveTableOperations with common code for View. (#9011),3,335,2023-11-24 06:46:39+01:00,"['HiveCatalog.java', 'HiveOperationsBase.java', 'HiveTableOperations.java']"
Flink: Create JUnit5 version of FlinkTestBase (#9120),3,204,2023-11-24 07:55:52+01:00,"['MiniFlinkClusterExtension.java', 'TestBase.java', 'TestCatalogTableLoader.java']"
Spark: Create base classes for migration to JUnit5 (#9129),5,597,2023-11-24 12:30:04+01:00,"['CatalogTestBase.java', 'SparkTestHelperBase.java', 'TestBase.java', 'TestBaseWithCatalog.java', 'TestSparkFileRewriter.java']"
Flink: Proper backport for #8852 (#9146),4,49,2023-11-24 17:57:04+01:00,"['TestIcebergSourceFailover.java', 'TestStreamingMonitorFunction.java', 'TestIcebergSourceFailover.java', 'TestStreamingMonitorFunction.java']"
"Flink: Backport #8803 to v1.16 and v1.15 (#9144)

Co-authored-by: Peter Vary <peter_vary4@apple.com>",6,328,2023-11-24 11:00:29-08:00,"['FlinkSplitPlanner.java', 'ScanContext.java', 'TestContinuousSplitPlannerImpl.java', 'FlinkSplitPlanner.java', 'ScanContext.java', 'TestContinuousSplitPlannerImpl.java']"
Flink: Backport #9078 to v1.16 and v1.15 (#9151),6,408,2023-11-27 11:16:19+01:00,"['MiniFlinkClusterExtension.java', 'TestBase.java', 'TestCatalogTableLoader.java', 'MiniFlinkClusterExtension.java', 'TestBase.java', 'TestCatalogTableLoader.java']"
